Using TensorFlow backend.
WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

2019-10-30 16:11:42.222658: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-30 16:11:42.233900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 16:11:42.355934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x61f1a70 executing computations on platform CUDA. Devices:
2019-10-30 16:11:42.355987: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2019-10-30 16:11:42.359003: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599260000 Hz
2019-10-30 16:11:42.359532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6263a70 executing computations on platform Host. Devices:
2019-10-30 16:11:42.359570: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 16:11:42.361034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
2019-10-30 16:11:42.361509: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 16:11:42.363689: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 16:11:42.365522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 16:11:42.366079: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 16:11:42.368616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 16:11:42.370492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 16:11:42.376389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 16:11:42.381120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 16:11:42.381208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 16:11:42.383349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 16:11:42.383379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 16:11:42.383391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 16:11:42.385430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7191 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-10-30 16:11:43.511131: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
Training size : 60000 	 Test size : 10000
Shapes :  (60000, 28, 28, 1) 	 (10000, 28, 28, 1)
Label shaped :  (60000,) 	 (10000,)
Train set : 
Mean: 0.132, Standard Deviation: 0.339
Min: 0.000, Max: 1.000
Test set : 
Mean: 0.134, Standard Deviation: 0.341
Min: 0.000, Max: 1.000
Train SHAPE :  (60000, 28, 28, 1)
MEAN :  {0: 0.17545253, 1: 0.076792635, 2: 0.15080415, 3: 0.14343987, 4: 0.12237671, 5: 0.1303105, 6: 0.13914657, 7: 0.115682974, 8: 0.152574, 9: 0.12411578}
STD :  {0: 0.3803538, 1: 0.2662621, 2: 0.35785785, 3: 0.35052088, 4: 0.32772046, 5: 0.33664477, 6: 0.3460994, 7: 0.31984428, 8: 0.3595763, 9: 0.3297136}
Test SHAPE :  (10000, 28, 28, 1)
MEAN :  {0: 0.13342878, 1: 0.13489054, 2: 0.13343419, 3: 0.13348657, 4: 0.13438058, 5: 0.1343075, 6: 0.13384469, 7: 0.13388762, 8: 0.13512419, 9: 0.13545439}
STD :  {0: 0.34003752, 1: 0.34160662, 2: 0.3400434, 3: 0.34009984, 4: 0.34106073, 5: 0.3409824, 6: 0.34048536, 7: 0.34053153, 8: 0.34185618, 9: 0.34220827}
Training size : 60000 	 Test size : 10000
Shapes :  (60000, 28, 28, 1) 	 (10000, 28, 28, 1)
Label shaped :  (60000,) 	 (10000,)
Train set : 
Mean: 0.132, Standard Deviation: 0.339
Min: 0.000, Max: 1.000
Test set : 
Mean: 0.134, Standard Deviation: 0.341
Min: 0.000, Max: 1.000
Train set : 
Mean: 0.132, Standard Deviation: 0.339
Min: 0.000, Max: 1.000
Train SHAPE :  (60000, 28, 28, 1)
Test SHAPE :  (10000, 28, 28, 1)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (100, 784)           0                                            
__________________________________________________________________________________________________
dense_encoder (Model)           multiple             1788416     input_1[0][0]                    
__________________________________________________________________________________________________
mean (Dense)                    (100, 2)             514         dense_encoder[1][0]              
__________________________________________________________________________________________________
log_sigma (Dense)               (100, 2)             514         dense_encoder[1][0]              
__________________________________________________________________________________________________
sampling_z (Lambda)             (100, 2)             0           mean[0][0]                       
                                                                 log_sigma[0][0]                  
__________________________________________________________________________________________________
dense_decoder (Model)           multiple             5544720     sampling_z[0][0]                 
==================================================================================================
Total params: 7,334,164
Trainable params: 7,334,164
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

  1/200 [..............................] - ETA: 4:57 - loss: 54332.2969 - KL_divergence: 0.0072
  7/200 [>.............................] - ETA: 42s - loss: 49106.8331 - KL_divergence: 231.5866
 13/200 [>.............................] - ETA: 23s - loss: 40936.8421 - KL_divergence: 183.0274
 19/200 [=>............................] - ETA: 15s - loss: 36180.5004 - KL_divergence: 160.6327
 25/200 [==>...........................] - ETA: 12s - loss: 33325.3847 - KL_divergence: 142.2463
 31/200 [===>..........................] - ETA: 9s - loss: 31399.9747 - KL_divergence: 126.8788 
 37/200 [====>.........................] - ETA: 8s - loss: 30105.2882 - KL_divergence: 113.4873
 43/200 [=====>........................] - ETA: 6s - loss: 29093.9392 - KL_divergence: 103.0904
 49/200 [======>.......................] - ETA: 6s - loss: 28268.7881 - KL_divergence: 95.0049 
 55/200 [=======>......................] - ETA: 5s - loss: 27649.1861 - KL_divergence: 86.8904
 61/200 [========>.....................] - ETA: 4s - loss: 27127.5326 - KL_divergence: 80.2968
 67/200 [=========>....................] - ETA: 4s - loss: 26669.7853 - KL_divergence: 74.5836
 73/200 [=========>....................] - ETA: 3s - loss: 26267.2954 - KL_divergence: 69.7484
 79/200 [==========>...................] - ETA: 3s - loss: 25893.0193 - KL_divergence: 65.4901
 86/200 [===========>..................] - ETA: 3s - loss: 25489.5203 - KL_divergence: 60.8500
 92/200 [============>.................] - ETA: 2s - loss: 25207.8814 - KL_divergence: 57.3655
 99/200 [=============>................] - ETA: 2s - loss: 24881.9600 - KL_divergence: 53.8290
105/200 [==============>...............] - ETA: 2s - loss: 24636.5614 - KL_divergence: 51.0677
111/200 [===============>..............] - ETA: 2s - loss: 24405.7965 - KL_divergence: 48.5108
117/200 [================>.............] - ETA: 1s - loss: 24221.7143 - KL_divergence: 46.1859
123/200 [=================>............] - ETA: 1s - loss: 24055.4774 - KL_divergence: 44.0321
129/200 [==================>...........] - ETA: 1s - loss: 23875.0197 - KL_divergence: 42.1043
135/200 [===================>..........] - ETA: 1s - loss: 23722.9322 - KL_divergence: 40.3033
141/200 [====================>.........] - ETA: 1s - loss: 23576.0952 - KL_divergence: 38.6800
147/200 [=====================>........] - ETA: 1s - loss: 23428.7262 - KL_divergence: 37.1661
153/200 [=====================>........] - ETA: 0s - loss: 23301.9589 - KL_divergence: 35.7685
159/200 [======================>.......] - ETA: 0s - loss: 23183.0510 - KL_divergence: 34.4815
165/200 [=======================>......] - ETA: 0s - loss: 23056.8875 - KL_divergence: 33.2874
171/200 [========================>.....] - ETA: 0s - loss: 22952.1563 - KL_divergence: 32.1841
177/200 [=========================>....] - ETA: 0s - loss: 22841.3168 - KL_divergence: 31.1734
183/200 [==========================>...] - ETA: 0s - loss: 22749.3212 - KL_divergence: 30.2309
189/200 [===========================>..] - ETA: 0s - loss: 22661.2741 - KL_divergence: 29.3425
195/200 [============================>.] - ETA: 0s - loss: 22567.0055 - KL_divergence: 28.5212
200/200 [==============================] - 4s 18ms/step - loss: 22502.6302 - KL_divergence: 27.8757 - val_loss: 19671.8026 - val_KL_divergence: 2.7047
Epoch 2/100

  1/200 [..............................] - ETA: 1s - loss: 19633.8945 - KL_divergence: 2.3747
  7/200 [>.............................] - ETA: 1s - loss: 20018.5181 - KL_divergence: 2.4906
 13/200 [>.............................] - ETA: 1s - loss: 19832.0491 - KL_divergence: 2.5465
 19/200 [=>............................] - ETA: 1s - loss: 19773.1166 - KL_divergence: 2.6307
 25/200 [==>...........................] - ETA: 1s - loss: 19769.7480 - KL_divergence: 2.6741
 31/200 [===>..........................] - ETA: 1s - loss: 19736.0102 - KL_divergence: 2.7058
 37/200 [====>.........................] - ETA: 1s - loss: 19683.4511 - KL_divergence: 2.7915
 43/200 [=====>........................] - ETA: 1s - loss: 19654.5886 - KL_divergence: 2.9505
 49/200 [======>.......................] - ETA: 1s - loss: 19633.1283 - KL_divergence: 3.1353
 55/200 [=======>......................] - ETA: 1s - loss: 19605.7257 - KL_divergence: 3.3213
 61/200 [========>.....................] - ETA: 1s - loss: 19595.6165 - KL_divergence: 3.4648
 68/200 [=========>....................] - ETA: 1s - loss: 19570.5410 - KL_divergence: 3.7210
 74/200 [==========>...................] - ETA: 1s - loss: 19550.9515 - KL_divergence: 3.9536
 80/200 [===========>..................] - ETA: 1s - loss: 19520.2794 - KL_divergence: 4.3001
 86/200 [===========>..................] - ETA: 0s - loss: 19497.1731 - KL_divergence: 4.5310
 92/200 [============>.................] - ETA: 0s - loss: 19497.7837 - KL_divergence: 4.7896
 98/200 [=============>................] - ETA: 0s - loss: 19505.0586 - KL_divergence: 4.9398
104/200 [==============>...............] - ETA: 0s - loss: 19495.1246 - KL_divergence: 5.2153
110/200 [===============>..............] - ETA: 0s - loss: 19467.2327 - KL_divergence: 5.4452
116/200 [================>.............] - ETA: 0s - loss: 19481.5585 - KL_divergence: 5.5973
122/200 [=================>............] - ETA: 0s - loss: 19459.4334 - KL_divergence: 5.9478
128/200 [==================>...........] - ETA: 0s - loss: 19433.7777 - KL_divergence: 6.1233
134/200 [===================>..........] - ETA: 0s - loss: 19413.9404 - KL_divergence: 6.2841
140/200 [====================>.........] - ETA: 0s - loss: 19367.8120 - KL_divergence: 6.4132
146/200 [====================>.........] - ETA: 0s - loss: 19350.2228 - KL_divergence: 6.4588
152/200 [=====================>........] - ETA: 0s - loss: 19323.4052 - KL_divergence: 6.5712
158/200 [======================>.......] - ETA: 0s - loss: 19317.1512 - KL_divergence: 6.5606
164/200 [=======================>......] - ETA: 0s - loss: 19301.2152 - KL_divergence: 6.5708
170/200 [========================>.....] - ETA: 0s - loss: 19277.4592 - KL_divergence: 6.7817
176/200 [=========================>....] - ETA: 0s - loss: 19256.3509 - KL_divergence: 6.9552
182/200 [==========================>...] - ETA: 0s - loss: 19249.5828 - KL_divergence: 7.0598
188/200 [===========================>..] - ETA: 0s - loss: 19212.2125 - KL_divergence: 7.1181
194/200 [============================>.] - ETA: 0s - loss: 19191.2635 - KL_divergence: 7.1229
200/200 [==============================] - 2s 10ms/step - loss: 19182.7606 - KL_divergence: 7.1845 - val_loss: 18583.1585 - val_KL_divergence: 10.1004
Epoch 3/100

  1/200 [..............................] - ETA: 1s - loss: 18324.2031 - KL_divergence: 6.0349
  7/200 [>.............................] - ETA: 1s - loss: 18384.0033 - KL_divergence: 9.1817
 13/200 [>.............................] - ETA: 1s - loss: 18549.4868 - KL_divergence: 8.2961
 19/200 [=>............................] - ETA: 1s - loss: 18496.8368 - KL_divergence: 8.1860
 25/200 [==>...........................] - ETA: 1s - loss: 18393.4588 - KL_divergence: 7.5087
 31/200 [===>..........................] - ETA: 1s - loss: 18300.2942 - KL_divergence: 7.0026
 37/200 [====>.........................] - ETA: 1s - loss: 18183.2014 - KL_divergence: 6.7269
 43/200 [=====>........................] - ETA: 1s - loss: 18124.4457 - KL_divergence: 6.5433
 49/200 [======>.......................] - ETA: 1s - loss: 18086.9852 - KL_divergence: 6.4222
 55/200 [=======>......................] - ETA: 1s - loss: 18033.9272 - KL_divergence: 6.3674
 61/200 [========>.....................] - ETA: 1s - loss: 18011.2587 - KL_divergence: 6.3010
 67/200 [=========>....................] - ETA: 1s - loss: 18004.8428 - KL_divergence: 6.2550
 73/200 [=========>....................] - ETA: 1s - loss: 17985.5033 - KL_divergence: 6.2205
 80/200 [===========>..................] - ETA: 1s - loss: 17943.0739 - KL_divergence: 6.2243
 87/200 [============>.................] - ETA: 1s - loss: 17904.1797 - KL_divergence: 6.2558
 93/200 [============>.................] - ETA: 0s - loss: 17871.0883 - KL_divergence: 6.2767
100/200 [==============>...............] - ETA: 0s - loss: 17855.8201 - KL_divergence: 6.3078
106/200 [==============>...............] - ETA: 0s - loss: 17825.0752 - KL_divergence: 6.3336
112/200 [===============>..............] - ETA: 0s - loss: 17777.6559 - KL_divergence: 6.3968
118/200 [================>.............] - ETA: 0s - loss: 17763.4624 - KL_divergence: 6.4427
124/200 [=================>............] - ETA: 0s - loss: 17740.5229 - KL_divergence: 6.4873
130/200 [==================>...........] - ETA: 0s - loss: 17708.2671 - KL_divergence: 6.5431
136/200 [===================>..........] - ETA: 0s - loss: 17682.9965 - KL_divergence: 6.5928
142/200 [====================>.........] - ETA: 0s - loss: 17661.6541 - KL_divergence: 6.6406
148/200 [=====================>........] - ETA: 0s - loss: 17642.4526 - KL_divergence: 6.6737
154/200 [======================>.......] - ETA: 0s - loss: 17628.1569 - KL_divergence: 6.7112
160/200 [=======================>......] - ETA: 0s - loss: 17614.6479 - KL_divergence: 6.7270
166/200 [=======================>......] - ETA: 0s - loss: 17595.2314 - KL_divergence: 6.7713
172/200 [========================>.....] - ETA: 0s - loss: 17572.3189 - KL_divergence: 6.8020
178/200 [=========================>....] - ETA: 0s - loss: 17552.6245 - KL_divergence: 6.8489
184/200 [==========================>...] - ETA: 0s - loss: 17536.3987 - KL_divergence: 6.8927
190/200 [===========================>..] - ETA: 0s - loss: 17517.0189 - KL_divergence: 6.9292
196/200 [============================>.] - ETA: 0s - loss: 17489.1340 - KL_divergence: 6.9819
200/200 [==============================] - 2s 10ms/step - loss: 17480.6223 - KL_divergence: 7.0116 - val_loss: 16837.9574 - val_KL_divergence: 9.0063
Epoch 4/100

  1/200 [..............................] - ETA: 1s - loss: 15578.9277 - KL_divergence: 12.9254
  7/200 [>.............................] - ETA: 1s - loss: 16592.1568 - KL_divergence: 8.8352 
 13/200 [>.............................] - ETA: 1s - loss: 16531.2569 - KL_divergence: 8.8765
 19/200 [=>............................] - ETA: 1s - loss: 16628.9668 - KL_divergence: 8.7456
 25/200 [==>...........................] - ETA: 1s - loss: 16596.6519 - KL_divergence: 8.7640
 31/200 [===>..........................] - ETA: 1s - loss: 16644.4256 - KL_divergence: 8.6899
 37/200 [====>.........................] - ETA: 1s - loss: 16635.6932 - KL_divergence: 8.6577
 43/200 [=====>........................] - ETA: 1s - loss: 16612.8373 - KL_divergence: 8.7634
 49/200 [======>.......................] - ETA: 1s - loss: 16641.4498 - KL_divergence: 8.7016
 55/200 [=======>......................] - ETA: 1s - loss: 16649.9067 - KL_divergence: 8.7275
 61/200 [========>.....................] - ETA: 1s - loss: 16672.6420 - KL_divergence: 8.7110
 67/200 [=========>....................] - ETA: 1s - loss: 16725.6750 - KL_divergence: 8.6185
 73/200 [=========>....................] - ETA: 1s - loss: 16733.1457 - KL_divergence: 8.6181
 79/200 [==========>...................] - ETA: 1s - loss: 16747.4344 - KL_divergence: 8.6241
 85/200 [===========>..................] - ETA: 1s - loss: 16743.3201 - KL_divergence: 8.6583
 91/200 [============>.................] - ETA: 0s - loss: 16767.3262 - KL_divergence: 8.6645
 97/200 [=============>................] - ETA: 0s - loss: 16758.6078 - KL_divergence: 8.7131
103/200 [==============>...............] - ETA: 0s - loss: 16758.5176 - KL_divergence: 8.7279
109/200 [===============>..............] - ETA: 0s - loss: 16741.3634 - KL_divergence: 8.7778
115/200 [================>.............] - ETA: 0s - loss: 16719.3383 - KL_divergence: 8.8310
121/200 [=================>............] - ETA: 0s - loss: 16705.7863 - KL_divergence: 8.8424
127/200 [==================>...........] - ETA: 0s - loss: 16684.6190 - KL_divergence: 8.9123
133/200 [==================>...........] - ETA: 0s - loss: 16672.3833 - KL_divergence: 8.9526
140/200 [====================>.........] - ETA: 0s - loss: 16675.4477 - KL_divergence: 8.9379
146/200 [====================>.........] - ETA: 0s - loss: 16670.2067 - KL_divergence: 8.9310
152/200 [=====================>........] - ETA: 0s - loss: 16653.6972 - KL_divergence: 8.9700
158/200 [======================>.......] - ETA: 0s - loss: 16646.6432 - KL_divergence: 8.9571
164/200 [=======================>......] - ETA: 0s - loss: 16646.8592 - KL_divergence: 8.9359
170/200 [========================>.....] - ETA: 0s - loss: 16626.6312 - KL_divergence: 8.9456
176/200 [=========================>....] - ETA: 0s - loss: 16623.8196 - KL_divergence: 8.9613
182/200 [==========================>...] - ETA: 0s - loss: 16634.4106 - KL_divergence: 8.9369
188/200 [===========================>..] - ETA: 0s - loss: 16632.1908 - KL_divergence: 8.9500
194/200 [============================>.] - ETA: 0s - loss: 16628.2465 - KL_divergence: 8.9445
200/200 [==============================] - 2s 10ms/step - loss: 16619.5332 - KL_divergence: 8.9488 - val_loss: 16205.8074 - val_KL_divergence: 9.7225
Epoch 5/100

  1/200 [..............................] - ETA: 1s - loss: 16398.0430 - KL_divergence: 8.9914
  8/200 [>.............................] - ETA: 1s - loss: 16357.1570 - KL_divergence: 9.0989
 15/200 [=>............................] - ETA: 1s - loss: 16525.2228 - KL_divergence: 9.0979
 21/200 [==>...........................] - ETA: 1s - loss: 16531.8215 - KL_divergence: 8.8438
 27/200 [===>..........................] - ETA: 1s - loss: 16541.6535 - KL_divergence: 8.8906
 33/200 [===>..........................] - ETA: 1s - loss: 16521.7027 - KL_divergence: 8.9992
 39/200 [====>.........................] - ETA: 1s - loss: 16468.5979 - KL_divergence: 9.0171
 45/200 [=====>........................] - ETA: 1s - loss: 16448.5842 - KL_divergence: 9.0331
 51/200 [======>.......................] - ETA: 1s - loss: 16413.8654 - KL_divergence: 9.0413
 57/200 [=======>......................] - ETA: 1s - loss: 16423.2071 - KL_divergence: 8.9700
 63/200 [========>.....................] - ETA: 1s - loss: 16421.4767 - KL_divergence: 8.9811
 69/200 [=========>....................] - ETA: 1s - loss: 16404.6398 - KL_divergence: 8.9913
 75/200 [==========>...................] - ETA: 1s - loss: 16401.5403 - KL_divergence: 9.0037
 81/200 [===========>..................] - ETA: 1s - loss: 16394.8397 - KL_divergence: 9.0919
 87/200 [============>.................] - ETA: 0s - loss: 16375.8664 - KL_divergence: 9.1655
 93/200 [============>.................] - ETA: 0s - loss: 16355.4413 - KL_divergence: 9.2420
 99/200 [=============>................] - ETA: 0s - loss: 16333.0089 - KL_divergence: 9.3016
105/200 [==============>...............] - ETA: 0s - loss: 16315.1992 - KL_divergence: 9.3174
111/200 [===============>..............] - ETA: 0s - loss: 16287.3587 - KL_divergence: 9.3742
117/200 [================>.............] - ETA: 0s - loss: 16284.1987 - KL_divergence: 9.3475
123/200 [=================>............] - ETA: 0s - loss: 16273.3058 - KL_divergence: 9.3874
129/200 [==================>...........] - ETA: 0s - loss: 16261.6535 - KL_divergence: 9.3980
135/200 [===================>..........] - ETA: 0s - loss: 16259.0189 - KL_divergence: 9.4307
141/200 [====================>.........] - ETA: 0s - loss: 16240.8090 - KL_divergence: 9.4495
147/200 [=====================>........] - ETA: 0s - loss: 16227.0230 - KL_divergence: 9.4277
153/200 [=====================>........] - ETA: 0s - loss: 16214.4794 - KL_divergence: 9.4485
159/200 [======================>.......] - ETA: 0s - loss: 16202.8483 - KL_divergence: 9.4805
165/200 [=======================>......] - ETA: 0s - loss: 16205.4465 - KL_divergence: 9.4669
171/200 [========================>.....] - ETA: 0s - loss: 16199.1797 - KL_divergence: 9.5075
177/200 [=========================>....] - ETA: 0s - loss: 16177.7603 - KL_divergence: 9.5301
183/200 [==========================>...] - ETA: 0s - loss: 16169.2573 - KL_divergence: 9.5499
189/200 [===========================>..] - ETA: 0s - loss: 16154.8117 - KL_divergence: 9.5657
195/200 [============================>.] - ETA: 0s - loss: 16146.0240 - KL_divergence: 9.5921
200/200 [==============================] - 2s 10ms/step - loss: 16139.7753 - KL_divergence: 9.6134 - val_loss: 15941.9959 - val_KL_divergence: 10.3367
Epoch 6/100

  1/200 [..............................] - ETA: 1s - loss: 16186.3564 - KL_divergence: 10.8100
  7/200 [>.............................] - ETA: 1s - loss: 15787.9699 - KL_divergence: 9.5860 
 13/200 [>.............................] - ETA: 1s - loss: 15726.5802 - KL_divergence: 9.9575
 19/200 [=>............................] - ETA: 1s - loss: 15829.1437 - KL_divergence: 9.9261
 25/200 [==>...........................] - ETA: 1s - loss: 15839.9692 - KL_divergence: 9.7720
 32/200 [===>..........................] - ETA: 1s - loss: 15824.0381 - KL_divergence: 9.7647
 38/200 [====>.........................] - ETA: 1s - loss: 15854.4042 - KL_divergence: 9.7279
 44/200 [=====>........................] - ETA: 1s - loss: 15823.0093 - KL_divergence: 9.6977
 50/200 [======>.......................] - ETA: 1s - loss: 15855.9717 - KL_divergence: 9.6815
 56/200 [=======>......................] - ETA: 1s - loss: 15833.2215 - KL_divergence: 9.7436
 62/200 [========>.....................] - ETA: 1s - loss: 15841.2987 - KL_divergence: 9.7489
 69/200 [=========>....................] - ETA: 1s - loss: 15869.0167 - KL_divergence: 9.8246
 75/200 [==========>...................] - ETA: 1s - loss: 15865.8359 - KL_divergence: 9.8621
 81/200 [===========>..................] - ETA: 1s - loss: 15889.1885 - KL_divergence: 9.8383
 87/200 [============>.................] - ETA: 0s - loss: 15900.4155 - KL_divergence: 9.8790
 93/200 [============>.................] - ETA: 0s - loss: 15916.4744 - KL_divergence: 9.8489
 99/200 [=============>................] - ETA: 0s - loss: 15904.9628 - KL_divergence: 9.9218
105/200 [==============>...............] - ETA: 0s - loss: 15902.4310 - KL_divergence: 9.9743
111/200 [===============>..............] - ETA: 0s - loss: 15907.2615 - KL_divergence: 9.9455
117/200 [================>.............] - ETA: 0s - loss: 15898.6071 - KL_divergence: 9.9685
123/200 [=================>............] - ETA: 0s - loss: 15896.6951 - KL_divergence: 10.0196
129/200 [==================>...........] - ETA: 0s - loss: 15874.6731 - KL_divergence: 10.0586
135/200 [===================>..........] - ETA: 0s - loss: 15875.5765 - KL_divergence: 10.0818
141/200 [====================>.........] - ETA: 0s - loss: 15879.5617 - KL_divergence: 10.1231
147/200 [=====================>........] - ETA: 0s - loss: 15865.9668 - KL_divergence: 10.1567
153/200 [=====================>........] - ETA: 0s - loss: 15854.6938 - KL_divergence: 10.1574
159/200 [======================>.......] - ETA: 0s - loss: 15857.2288 - KL_divergence: 10.1668
164/200 [=======================>......] - ETA: 0s - loss: 15863.8192 - KL_divergence: 10.1656
170/200 [========================>.....] - ETA: 0s - loss: 15871.1654 - KL_divergence: 10.1423
176/200 [=========================>....] - ETA: 0s - loss: 15851.3659 - KL_divergence: 10.1688
182/200 [==========================>...] - ETA: 0s - loss: 15848.1572 - KL_divergence: 10.2043
188/200 [===========================>..] - ETA: 0s - loss: 15840.9490 - KL_divergence: 10.2071
194/200 [============================>.] - ETA: 0s - loss: 15833.9728 - KL_divergence: 10.2097
200/200 [==============================] - 2s 10ms/step - loss: 15827.9484 - KL_divergence: 10.2586 - val_loss: 15588.3724 - val_KL_divergence: 10.1243
Epoch 7/100

  1/200 [..............................] - ETA: 1s - loss: 15611.9199 - KL_divergence: 11.6450
  7/200 [>.............................] - ETA: 1s - loss: 16042.9866 - KL_divergence: 10.8147
 13/200 [>.............................] - ETA: 1s - loss: 16002.7268 - KL_divergence: 10.4974
 19/200 [=>............................] - ETA: 1s - loss: 15931.0080 - KL_divergence: 10.5151
 25/200 [==>...........................] - ETA: 1s - loss: 15871.1041 - KL_divergence: 10.5522
 31/200 [===>..........................] - ETA: 1s - loss: 15765.1680 - KL_divergence: 10.8676
 37/200 [====>.........................] - ETA: 1s - loss: 15748.7540 - KL_divergence: 10.7746
 42/200 [=====>........................] - ETA: 1s - loss: 15702.1715 - KL_divergence: 10.7000
 48/200 [======>.......................] - ETA: 1s - loss: 15701.3647 - KL_divergence: 10.6629
 54/200 [=======>......................] - ETA: 1s - loss: 15700.2020 - KL_divergence: 10.5826
 60/200 [========>.....................] - ETA: 1s - loss: 15705.9077 - KL_divergence: 10.6865
 66/200 [========>.....................] - ETA: 1s - loss: 15700.9313 - KL_divergence: 10.6729
 72/200 [=========>....................] - ETA: 1s - loss: 15707.1670 - KL_divergence: 10.7001
 78/200 [==========>...................] - ETA: 1s - loss: 15689.1024 - KL_divergence: 10.6933
 84/200 [===========>..................] - ETA: 1s - loss: 15661.7700 - KL_divergence: 10.7714
 90/200 [============>.................] - ETA: 1s - loss: 15610.2586 - KL_divergence: 10.8837
 96/200 [=============>................] - ETA: 0s - loss: 15617.1561 - KL_divergence: 10.8762
102/200 [==============>...............] - ETA: 0s - loss: 15599.1138 - KL_divergence: 10.9087
108/200 [===============>..............] - ETA: 0s - loss: 15587.3848 - KL_divergence: 11.0029
114/200 [================>.............] - ETA: 0s - loss: 15586.7473 - KL_divergence: 10.9715
120/200 [=================>............] - ETA: 0s - loss: 15582.9228 - KL_divergence: 11.0130
126/200 [=================>............] - ETA: 0s - loss: 15560.1880 - KL_divergence: 11.0273
132/200 [==================>...........] - ETA: 0s - loss: 15564.1793 - KL_divergence: 11.0293
138/200 [===================>..........] - ETA: 0s - loss: 15554.8257 - KL_divergence: 11.0139
144/200 [====================>.........] - ETA: 0s - loss: 15536.0358 - KL_divergence: 11.0293
150/200 [=====================>........] - ETA: 0s - loss: 15529.4951 - KL_divergence: 11.0003
156/200 [======================>.......] - ETA: 0s - loss: 15519.1221 - KL_divergence: 11.0347
162/200 [=======================>......] - ETA: 0s - loss: 15527.4550 - KL_divergence: 11.0249
169/200 [========================>.....] - ETA: 0s - loss: 15519.8175 - KL_divergence: 11.0017
175/200 [=========================>....] - ETA: 0s - loss: 15517.9976 - KL_divergence: 10.9867
181/200 [==========================>...] - ETA: 0s - loss: 15512.4090 - KL_divergence: 10.9816
187/200 [===========================>..] - ETA: 0s - loss: 15502.8586 - KL_divergence: 10.9999
193/200 [===========================>..] - ETA: 0s - loss: 15499.0885 - KL_divergence: 11.0002
199/200 [============================>.] - ETA: 0s - loss: 15496.9692 - KL_divergence: 10.9805
200/200 [==============================] - 2s 10ms/step - loss: 15495.5121 - KL_divergence: 10.9796 - val_loss: 15278.5204 - val_KL_divergence: 10.8452
Epoch 8/100

  1/200 [..............................] - ETA: 1s - loss: 15396.6309 - KL_divergence: 11.0828
  7/200 [>.............................] - ETA: 1s - loss: 15064.9773 - KL_divergence: 11.2147
 13/200 [>.............................] - ETA: 1s - loss: 15098.7374 - KL_divergence: 10.7922
 19/200 [=>............................] - ETA: 1s - loss: 15237.0455 - KL_divergence: 10.6502
 25/200 [==>...........................] - ETA: 1s - loss: 15308.1857 - KL_divergence: 10.5795
 31/200 [===>..........................] - ETA: 1s - loss: 15319.5749 - KL_divergence: 10.6711
 37/200 [====>.........................] - ETA: 1s - loss: 15255.9966 - KL_divergence: 10.9617
 43/200 [=====>........................] - ETA: 1s - loss: 15186.3962 - KL_divergence: 11.1757
 49/200 [======>.......................] - ETA: 1s - loss: 15172.6210 - KL_divergence: 11.2099
 55/200 [=======>......................] - ETA: 1s - loss: 15163.0634 - KL_divergence: 11.2311
 61/200 [========>.....................] - ETA: 1s - loss: 15165.9451 - KL_divergence: 11.2831
 67/200 [=========>....................] - ETA: 1s - loss: 15191.9102 - KL_divergence: 11.2237
 73/200 [=========>....................] - ETA: 1s - loss: 15183.7054 - KL_divergence: 11.2633
 79/200 [==========>...................] - ETA: 1s - loss: 15184.5243 - KL_divergence: 11.2436
 85/200 [===========>..................] - ETA: 1s - loss: 15178.7703 - KL_divergence: 11.2647
 91/200 [============>.................] - ETA: 0s - loss: 15159.1194 - KL_divergence: 11.3043
 97/200 [=============>................] - ETA: 0s - loss: 15177.2059 - KL_divergence: 11.2417
103/200 [==============>...............] - ETA: 0s - loss: 15146.6706 - KL_divergence: 11.3607
110/200 [===============>..............] - ETA: 0s - loss: 15164.5882 - KL_divergence: 11.3924
116/200 [================>.............] - ETA: 0s - loss: 15145.9060 - KL_divergence: 11.3845
122/200 [=================>............] - ETA: 0s - loss: 15137.4321 - KL_divergence: 11.4099
128/200 [==================>...........] - ETA: 0s - loss: 15130.5762 - KL_divergence: 11.4076
134/200 [===================>..........] - ETA: 0s - loss: 15125.6488 - KL_divergence: 11.4604
140/200 [====================>.........] - ETA: 0s - loss: 15130.9582 - KL_divergence: 11.4461
145/200 [====================>.........] - ETA: 0s - loss: 15134.7171 - KL_divergence: 11.4433
150/200 [=====================>........] - ETA: 0s - loss: 15129.0569 - KL_divergence: 11.4503
156/200 [======================>.......] - ETA: 0s - loss: 15125.8297 - KL_divergence: 11.4170
163/200 [=======================>......] - ETA: 0s - loss: 15118.8063 - KL_divergence: 11.4292
169/200 [========================>.....] - ETA: 0s - loss: 15124.8222 - KL_divergence: 11.3802
175/200 [=========================>....] - ETA: 0s - loss: 15117.6296 - KL_divergence: 11.3898
182/200 [==========================>...] - ETA: 0s - loss: 15114.5051 - KL_divergence: 11.3610
188/200 [===========================>..] - ETA: 0s - loss: 15104.4386 - KL_divergence: 11.4146
194/200 [============================>.] - ETA: 0s - loss: 15101.3456 - KL_divergence: 11.4026
200/200 [==============================] - 2s 10ms/step - loss: 15102.7234 - KL_divergence: 11.3918 - val_loss: 15004.1499 - val_KL_divergence: 10.5373
Epoch 9/100

  1/200 [..............................] - ETA: 1s - loss: 14725.8203 - KL_divergence: 10.1814
  8/200 [>.............................] - ETA: 1s - loss: 14506.0792 - KL_divergence: 12.0696
 14/200 [=>............................] - ETA: 1s - loss: 14746.9441 - KL_divergence: 11.6183
 20/200 [==>...........................] - ETA: 1s - loss: 14716.5208 - KL_divergence: 11.7591
 27/200 [===>..........................] - ETA: 1s - loss: 14918.4295 - KL_divergence: 11.3277
 34/200 [====>.........................] - ETA: 1s - loss: 14919.6839 - KL_divergence: 11.3640
 40/200 [=====>........................] - ETA: 1s - loss: 14890.4310 - KL_divergence: 11.4854
 46/200 [=====>........................] - ETA: 1s - loss: 14898.4484 - KL_divergence: 11.4149
 52/200 [======>.......................] - ETA: 1s - loss: 14968.5842 - KL_divergence: 11.2953
 58/200 [=======>......................] - ETA: 1s - loss: 14975.8288 - KL_divergence: 11.2928
 64/200 [========>.....................] - ETA: 1s - loss: 14985.3740 - KL_divergence: 11.2358
 70/200 [=========>....................] - ETA: 1s - loss: 14974.6177 - KL_divergence: 11.1671
 76/200 [==========>...................] - ETA: 1s - loss: 14982.4193 - KL_divergence: 11.1080
 81/200 [===========>..................] - ETA: 1s - loss: 14976.0504 - KL_divergence: 11.1192
 87/200 [============>.................] - ETA: 1s - loss: 14983.1621 - KL_divergence: 11.1081
 93/200 [============>.................] - ETA: 0s - loss: 14959.3896 - KL_divergence: 11.1279
 99/200 [=============>................] - ETA: 0s - loss: 14949.1377 - KL_divergence: 11.1498
105/200 [==============>...............] - ETA: 0s - loss: 14962.1089 - KL_divergence: 11.0950
111/200 [===============>..............] - ETA: 0s - loss: 14955.5298 - KL_divergence: 11.0543
117/200 [================>.............] - ETA: 0s - loss: 14952.0811 - KL_divergence: 11.0583
122/200 [=================>............] - ETA: 0s - loss: 14965.9786 - KL_divergence: 11.0339
128/200 [==================>...........] - ETA: 0s - loss: 14940.9297 - KL_divergence: 11.0949
134/200 [===================>..........] - ETA: 0s - loss: 14935.2315 - KL_divergence: 11.0887
140/200 [====================>.........] - ETA: 0s - loss: 14922.3435 - KL_divergence: 11.0739
146/200 [====================>.........] - ETA: 0s - loss: 14917.8998 - KL_divergence: 11.0551
153/200 [=====================>........] - ETA: 0s - loss: 14901.0199 - KL_divergence: 11.0928
159/200 [======================>.......] - ETA: 0s - loss: 14893.0953 - KL_divergence: 11.1020
165/200 [=======================>......] - ETA: 0s - loss: 14875.2249 - KL_divergence: 11.1592
171/200 [========================>.....] - ETA: 0s - loss: 14869.7383 - KL_divergence: 11.1674
177/200 [=========================>....] - ETA: 0s - loss: 14858.7019 - KL_divergence: 11.2156
183/200 [==========================>...] - ETA: 0s - loss: 14851.6161 - KL_divergence: 11.2330
189/200 [===========================>..] - ETA: 0s - loss: 14839.5359 - KL_divergence: 11.2438
195/200 [============================>.] - ETA: 0s - loss: 14832.1424 - KL_divergence: 11.2425
200/200 [==============================] - 2s 10ms/step - loss: 14831.8772 - KL_divergence: 11.2430 - val_loss: 14657.7794 - val_KL_divergence: 11.2543
Epoch 10/100

  1/200 [..............................] - ETA: 1s - loss: 14255.6533 - KL_divergence: 11.8438
  7/200 [>.............................] - ETA: 1s - loss: 14489.5356 - KL_divergence: 12.5697
 13/200 [>.............................] - ETA: 1s - loss: 14416.8038 - KL_divergence: 12.1572
 19/200 [=>............................] - ETA: 1s - loss: 14558.5126 - KL_divergence: 12.0724
 25/200 [==>...........................] - ETA: 1s - loss: 14590.2126 - KL_divergence: 11.6365
 31/200 [===>..........................] - ETA: 1s - loss: 14573.7609 - KL_divergence: 11.6674
 37/200 [====>.........................] - ETA: 1s - loss: 14614.3215 - KL_divergence: 11.6317
 43/200 [=====>........................] - ETA: 1s - loss: 14600.8934 - KL_divergence: 11.4114
 49/200 [======>.......................] - ETA: 1s - loss: 14612.6883 - KL_divergence: 11.2447
 54/200 [=======>......................] - ETA: 1s - loss: 14615.3519 - KL_divergence: 11.2193
 59/200 [=======>......................] - ETA: 1s - loss: 14617.7576 - KL_divergence: 11.2448
 65/200 [========>.....................] - ETA: 1s - loss: 14613.6541 - KL_divergence: 11.2538
 71/200 [=========>....................] - ETA: 1s - loss: 14629.8109 - KL_divergence: 11.1652
 77/200 [==========>...................] - ETA: 1s - loss: 14603.2117 - KL_divergence: 11.1838
 83/200 [===========>..................] - ETA: 1s - loss: 14564.3886 - KL_divergence: 11.2992
 89/200 [============>.................] - ETA: 1s - loss: 14579.1825 - KL_divergence: 11.3002
 95/200 [=============>................] - ETA: 0s - loss: 14563.1380 - KL_divergence: 11.2981
101/200 [==============>...............] - ETA: 0s - loss: 14547.5053 - KL_divergence: 11.3232
107/200 [===============>..............] - ETA: 0s - loss: 14534.6393 - KL_divergence: 11.3420
113/200 [===============>..............] - ETA: 0s - loss: 14540.4593 - KL_divergence: 11.2687
119/200 [================>.............] - ETA: 0s - loss: 14545.8009 - KL_divergence: 11.2076
125/200 [=================>............] - ETA: 0s - loss: 14548.0747 - KL_divergence: 11.1749
131/200 [==================>...........] - ETA: 0s - loss: 14562.1788 - KL_divergence: 11.1633
137/200 [===================>..........] - ETA: 0s - loss: 14544.3142 - KL_divergence: 11.1750
143/200 [====================>.........] - ETA: 0s - loss: 14534.0941 - KL_divergence: 11.2131
149/200 [=====================>........] - ETA: 0s - loss: 14521.1096 - KL_divergence: 11.2081
155/200 [======================>.......] - ETA: 0s - loss: 14536.0245 - KL_divergence: 11.1629
161/200 [=======================>......] - ETA: 0s - loss: 14523.0749 - KL_divergence: 11.1498
167/200 [========================>.....] - ETA: 0s - loss: 14514.2750 - KL_divergence: 11.1719
173/200 [========================>.....] - ETA: 0s - loss: 14516.9456 - KL_divergence: 11.1338
179/200 [=========================>....] - ETA: 0s - loss: 14511.0761 - KL_divergence: 11.1406
185/200 [==========================>...] - ETA: 0s - loss: 14505.7207 - KL_divergence: 11.1247
191/200 [===========================>..] - ETA: 0s - loss: 14499.2990 - KL_divergence: 11.1215
197/200 [============================>.] - ETA: 0s - loss: 14496.8312 - KL_divergence: 11.1378
200/200 [==============================] - 2s 10ms/step - loss: 14490.3669 - KL_divergence: 11.1606 - val_loss: 14424.0312 - val_KL_divergence: 11.3354
Epoch 11/100

  1/200 [..............................] - ETA: 1s - loss: 14886.2559 - KL_divergence: 9.9688
  7/200 [>.............................] - ETA: 1s - loss: 14464.1417 - KL_divergence: 10.7907
 13/200 [>.............................] - ETA: 1s - loss: 14604.8561 - KL_divergence: 10.3532
 19/200 [=>............................] - ETA: 1s - loss: 14590.9782 - KL_divergence: 10.7393
 25/200 [==>...........................] - ETA: 1s - loss: 14573.5766 - KL_divergence: 10.8291
 31/200 [===>..........................] - ETA: 1s - loss: 14569.9277 - KL_divergence: 10.7947
 37/200 [====>.........................] - ETA: 1s - loss: 14531.0116 - KL_divergence: 10.8465
 43/200 [=====>........................] - ETA: 1s - loss: 14520.0231 - KL_divergence: 10.8255
 49/200 [======>.......................] - ETA: 1s - loss: 14540.5574 - KL_divergence: 10.7980
 55/200 [=======>......................] - ETA: 1s - loss: 14541.9669 - KL_divergence: 10.8225
 60/200 [========>.....................] - ETA: 1s - loss: 14523.8535 - KL_divergence: 10.9117
 66/200 [========>.....................] - ETA: 1s - loss: 14548.4992 - KL_divergence: 10.8624
 72/200 [=========>....................] - ETA: 1s - loss: 14553.6944 - KL_divergence: 10.9093
 78/200 [==========>...................] - ETA: 1s - loss: 14538.9608 - KL_divergence: 10.9066
 84/200 [===========>..................] - ETA: 1s - loss: 14515.3296 - KL_divergence: 10.9483
 90/200 [============>.................] - ETA: 1s - loss: 14498.2776 - KL_divergence: 10.9685
 96/200 [=============>................] - ETA: 0s - loss: 14483.1056 - KL_divergence: 10.9515
102/200 [==============>...............] - ETA: 0s - loss: 14476.8877 - KL_divergence: 10.9743
108/200 [===============>..............] - ETA: 0s - loss: 14466.9179 - KL_divergence: 10.9961
114/200 [================>.............] - ETA: 0s - loss: 14471.5705 - KL_divergence: 10.9683
120/200 [=================>............] - ETA: 0s - loss: 14460.2717 - KL_divergence: 10.9905
126/200 [=================>............] - ETA: 0s - loss: 14446.5230 - KL_divergence: 11.0178
132/200 [==================>...........] - ETA: 0s - loss: 14448.7559 - KL_divergence: 11.0258
138/200 [===================>..........] - ETA: 0s - loss: 14441.2851 - KL_divergence: 11.0674
144/200 [====================>.........] - ETA: 0s - loss: 14420.4523 - KL_divergence: 11.0825
150/200 [=====================>........] - ETA: 0s - loss: 14421.1787 - KL_divergence: 11.0735
156/200 [======================>.......] - ETA: 0s - loss: 14406.2831 - KL_divergence: 11.0977
162/200 [=======================>......] - ETA: 0s - loss: 14408.0987 - KL_divergence: 11.0939
168/200 [========================>.....] - ETA: 0s - loss: 14402.6038 - KL_divergence: 11.0674
174/200 [=========================>....] - ETA: 0s - loss: 14402.3202 - KL_divergence: 11.0574
180/200 [==========================>...] - ETA: 0s - loss: 14390.6400 - KL_divergence: 11.0623
186/200 [==========================>...] - ETA: 0s - loss: 14389.1967 - KL_divergence: 11.0388
192/200 [===========================>..] - ETA: 0s - loss: 14386.8374 - KL_divergence: 11.0344
198/200 [============================>.] - ETA: 0s - loss: 14393.5724 - KL_divergence: 10.9959
200/200 [==============================] - 2s 10ms/step - loss: 14396.6974 - KL_divergence: 10.9919 - val_loss: 14212.1437 - val_KL_divergence: 10.3796
Epoch 12/100

  1/200 [..............................] - ETA: 1s - loss: 14221.7373 - KL_divergence: 9.1116
  7/200 [>.............................] - ETA: 1s - loss: 14462.5117 - KL_divergence: 10.6576
 13/200 [>.............................] - ETA: 1s - loss: 14283.0938 - KL_divergence: 11.2035
 19/200 [=>............................] - ETA: 1s - loss: 14329.8270 - KL_divergence: 10.9521
 25/200 [==>...........................] - ETA: 1s - loss: 14265.6655 - KL_divergence: 10.8228
 31/200 [===>..........................] - ETA: 1s - loss: 14276.9769 - KL_divergence: 10.8926
 36/200 [====>.........................] - ETA: 1s - loss: 14260.9552 - KL_divergence: 10.9065
 42/200 [=====>........................] - ETA: 1s - loss: 14247.4863 - KL_divergence: 10.9832
 48/200 [======>.......................] - ETA: 1s - loss: 14217.1548 - KL_divergence: 11.0630
 54/200 [=======>......................] - ETA: 1s - loss: 14263.2504 - KL_divergence: 10.9582
 60/200 [========>.....................] - ETA: 1s - loss: 14258.6546 - KL_divergence: 10.9397
 65/200 [========>.....................] - ETA: 1s - loss: 14225.8655 - KL_divergence: 11.0444
 71/200 [=========>....................] - ETA: 1s - loss: 14239.4699 - KL_divergence: 11.0520
 77/200 [==========>...................] - ETA: 1s - loss: 14214.9202 - KL_divergence: 11.1056
 83/200 [===========>..................] - ETA: 1s - loss: 14181.0543 - KL_divergence: 11.1307
 89/200 [============>.................] - ETA: 1s - loss: 14156.1775 - KL_divergence: 11.1662
 94/200 [=============>................] - ETA: 1s - loss: 14172.8438 - KL_divergence: 11.1498
100/200 [==============>...............] - ETA: 0s - loss: 14171.2710 - KL_divergence: 11.1818
106/200 [==============>...............] - ETA: 0s - loss: 14177.5392 - KL_divergence: 11.1853
112/200 [===============>..............] - ETA: 0s - loss: 14175.4050 - KL_divergence: 11.2006
118/200 [================>.............] - ETA: 0s - loss: 14162.3623 - KL_divergence: 11.2595
123/200 [=================>............] - ETA: 0s - loss: 14173.4386 - KL_divergence: 11.2322
129/200 [==================>...........] - ETA: 0s - loss: 14180.4019 - KL_divergence: 11.2272
135/200 [===================>..........] - ETA: 0s - loss: 14179.8890 - KL_divergence: 11.2170
140/200 [====================>.........] - ETA: 0s - loss: 14186.2584 - KL_divergence: 11.1878
146/200 [====================>.........] - ETA: 0s - loss: 14185.6863 - KL_divergence: 11.1557
152/200 [=====================>........] - ETA: 0s - loss: 14191.2775 - KL_divergence: 11.1218
158/200 [======================>.......] - ETA: 0s - loss: 14184.6962 - KL_divergence: 11.1256
164/200 [=======================>......] - ETA: 0s - loss: 14187.1444 - KL_divergence: 11.0862
170/200 [========================>.....] - ETA: 0s - loss: 14177.3537 - KL_divergence: 11.0752
176/200 [=========================>....] - ETA: 0s - loss: 14163.9243 - KL_divergence: 11.0830
182/200 [==========================>...] - ETA: 0s - loss: 14164.5067 - KL_divergence: 11.0691
188/200 [===========================>..] - ETA: 0s - loss: 14176.6998 - KL_divergence: 11.0136
194/200 [============================>.] - ETA: 0s - loss: 14172.6547 - KL_divergence: 11.0161
200/200 [==============================] - 2s 10ms/step - loss: 14164.7619 - KL_divergence: 11.0228 - val_loss: 14032.3193 - val_KL_divergence: 10.4702
Epoch 13/100

  1/200 [..............................] - ETA: 1s - loss: 14724.0146 - KL_divergence: 8.7633
  7/200 [>.............................] - ETA: 1s - loss: 14135.7123 - KL_divergence: 10.4669
 13/200 [>.............................] - ETA: 1s - loss: 14062.1504 - KL_divergence: 10.8814
 19/200 [=>............................] - ETA: 1s - loss: 14012.5352 - KL_divergence: 11.2505
 25/200 [==>...........................] - ETA: 1s - loss: 13946.4877 - KL_divergence: 11.3390
 31/200 [===>..........................] - ETA: 1s - loss: 13997.7021 - KL_divergence: 11.3110
 36/200 [====>.........................] - ETA: 1s - loss: 14001.5568 - KL_divergence: 11.2934
 41/200 [=====>........................] - ETA: 1s - loss: 14070.5872 - KL_divergence: 11.1095
 47/200 [======>.......................] - ETA: 1s - loss: 14129.3443 - KL_divergence: 10.9129
 53/200 [======>.......................] - ETA: 1s - loss: 14121.0832 - KL_divergence: 10.8543
 59/200 [=======>......................] - ETA: 1s - loss: 14102.2385 - KL_divergence: 10.8959
 65/200 [========>.....................] - ETA: 1s - loss: 14108.1553 - KL_divergence: 10.9070
 71/200 [=========>....................] - ETA: 1s - loss: 14103.4996 - KL_divergence: 10.8824
 77/200 [==========>...................] - ETA: 1s - loss: 14099.2972 - KL_divergence: 10.8503
 83/200 [===========>..................] - ETA: 1s - loss: 14087.1989 - KL_divergence: 10.8277
 89/200 [============>.................] - ETA: 1s - loss: 14077.6079 - KL_divergence: 10.8806
 95/200 [=============>................] - ETA: 0s - loss: 14067.4377 - KL_divergence: 10.8970
101/200 [==============>...............] - ETA: 0s - loss: 14044.8791 - KL_divergence: 10.9868
107/200 [===============>..............] - ETA: 0s - loss: 14022.5714 - KL_divergence: 10.9631
113/200 [===============>..............] - ETA: 0s - loss: 14021.3220 - KL_divergence: 10.9545
119/200 [================>.............] - ETA: 0s - loss: 14024.8109 - KL_divergence: 10.9252
125/200 [=================>............] - ETA: 0s - loss: 14029.4214 - KL_divergence: 10.9086
131/200 [==================>...........] - ETA: 0s - loss: 14024.4383 - KL_divergence: 10.8832
137/200 [===================>..........] - ETA: 0s - loss: 14028.1960 - KL_divergence: 10.8922
143/200 [====================>.........] - ETA: 0s - loss: 14017.2039 - KL_divergence: 10.9511
149/200 [=====================>........] - ETA: 0s - loss: 14003.5671 - KL_divergence: 10.9424
155/200 [======================>.......] - ETA: 0s - loss: 14006.0470 - KL_divergence: 10.9249
161/200 [=======================>......] - ETA: 0s - loss: 13999.5790 - KL_divergence: 10.9641
167/200 [========================>.....] - ETA: 0s - loss: 13999.3764 - KL_divergence: 10.9747
173/200 [========================>.....] - ETA: 0s - loss: 14000.6251 - KL_divergence: 10.9522
179/200 [=========================>....] - ETA: 0s - loss: 13998.1324 - KL_divergence: 10.9565
185/200 [==========================>...] - ETA: 0s - loss: 14011.2974 - KL_divergence: 10.9170
191/200 [===========================>..] - ETA: 0s - loss: 14008.1202 - KL_divergence: 10.9180
197/200 [============================>.] - ETA: 0s - loss: 14015.7994 - KL_divergence: 10.9053
200/200 [==============================] - 2s 10ms/step - loss: 14013.9084 - KL_divergence: 10.9143 - val_loss: 13942.8727 - val_KL_divergence: 10.6191
Epoch 14/100

  1/200 [..............................] - ETA: 1s - loss: 13746.7979 - KL_divergence: 12.5675
  7/200 [>.............................] - ETA: 1s - loss: 14025.5075 - KL_divergence: 10.6692
 13/200 [>.............................] - ETA: 1s - loss: 14053.9575 - KL_divergence: 10.2422
 19/200 [=>............................] - ETA: 1s - loss: 13920.4618 - KL_divergence: 10.3918
 25/200 [==>...........................] - ETA: 1s - loss: 13834.2487 - KL_divergence: 10.4334
 31/200 [===>..........................] - ETA: 1s - loss: 13870.3112 - KL_divergence: 10.4839
 37/200 [====>.........................] - ETA: 1s - loss: 13953.5711 - KL_divergence: 10.3400
 43/200 [=====>........................] - ETA: 1s - loss: 13892.5379 - KL_divergence: 10.3863
 49/200 [======>.......................] - ETA: 1s - loss: 13909.4543 - KL_divergence: 10.3764
 55/200 [=======>......................] - ETA: 1s - loss: 13927.4455 - KL_divergence: 10.4200
 61/200 [========>.....................] - ETA: 1s - loss: 13934.3729 - KL_divergence: 10.4110
 67/200 [=========>....................] - ETA: 1s - loss: 13924.2748 - KL_divergence: 10.5042
 73/200 [=========>....................] - ETA: 1s - loss: 13934.0378 - KL_divergence: 10.5351
 79/200 [==========>...................] - ETA: 1s - loss: 13897.7676 - KL_divergence: 10.6097
 85/200 [===========>..................] - ETA: 1s - loss: 13903.0933 - KL_divergence: 10.6132
 91/200 [============>.................] - ETA: 0s - loss: 13886.1167 - KL_divergence: 10.5502
 97/200 [=============>................] - ETA: 0s - loss: 13887.0244 - KL_divergence: 10.5372
103/200 [==============>...............] - ETA: 0s - loss: 13882.3739 - KL_divergence: 10.5580
110/200 [===============>..............] - ETA: 0s - loss: 13864.3115 - KL_divergence: 10.5875
117/200 [================>.............] - ETA: 0s - loss: 13864.2370 - KL_divergence: 10.5851
123/200 [=================>............] - ETA: 0s - loss: 13864.1191 - KL_divergence: 10.5698
129/200 [==================>...........] - ETA: 0s - loss: 13879.8083 - KL_divergence: 10.5783
135/200 [===================>..........] - ETA: 0s - loss: 13889.4043 - KL_divergence: 10.5395
141/200 [====================>.........] - ETA: 0s - loss: 13873.6170 - KL_divergence: 10.6116
147/200 [=====================>........] - ETA: 0s - loss: 13885.2009 - KL_divergence: 10.5686
153/200 [=====================>........] - ETA: 0s - loss: 13875.2491 - KL_divergence: 10.5699
159/200 [======================>.......] - ETA: 0s - loss: 13884.4290 - KL_divergence: 10.5482
165/200 [=======================>......] - ETA: 0s - loss: 13873.0306 - KL_divergence: 10.5673
171/200 [========================>.....] - ETA: 0s - loss: 13887.1499 - KL_divergence: 10.5240
177/200 [=========================>....] - ETA: 0s - loss: 13885.0636 - KL_divergence: 10.5255
183/200 [==========================>...] - ETA: 0s - loss: 13875.0961 - KL_divergence: 10.5604
189/200 [===========================>..] - ETA: 0s - loss: 13859.3388 - KL_divergence: 10.5701
195/200 [============================>.] - ETA: 0s - loss: 13862.4043 - KL_divergence: 10.5769
200/200 [==============================] - 2s 10ms/step - loss: 13865.4870 - KL_divergence: 10.5704 - val_loss: 14134.1731 - val_KL_divergence: 10.2646
Epoch 15/100

  1/200 [..............................] - ETA: 2s - loss: 13520.1699 - KL_divergence: 13.5463
  7/200 [>.............................] - ETA: 1s - loss: 13673.9566 - KL_divergence: 11.1565
 13/200 [>.............................] - ETA: 1s - loss: 13780.3552 - KL_divergence: 10.9272
 19/200 [=>............................] - ETA: 1s - loss: 13863.6345 - KL_divergence: 10.7283
 25/200 [==>...........................] - ETA: 1s - loss: 13822.8340 - KL_divergence: 10.5925
 31/200 [===>..........................] - ETA: 1s - loss: 13762.5205 - KL_divergence: 10.5198
 37/200 [====>.........................] - ETA: 1s - loss: 13743.4064 - KL_divergence: 10.5849
 43/200 [=====>........................] - ETA: 1s - loss: 13762.6419 - KL_divergence: 10.4296
 49/200 [======>.......................] - ETA: 1s - loss: 13787.6843 - KL_divergence: 10.4276
 55/200 [=======>......................] - ETA: 1s - loss: 13756.2852 - KL_divergence: 10.4909
 61/200 [========>.....................] - ETA: 1s - loss: 13765.1351 - KL_divergence: 10.4978
 67/200 [=========>....................] - ETA: 1s - loss: 13749.5700 - KL_divergence: 10.5467
 73/200 [=========>....................] - ETA: 1s - loss: 13736.0885 - KL_divergence: 10.5319
 79/200 [==========>...................] - ETA: 1s - loss: 13735.0165 - KL_divergence: 10.5253
 85/200 [===========>..................] - ETA: 1s - loss: 13742.0593 - KL_divergence: 10.5562
 91/200 [============>.................] - ETA: 1s - loss: 13742.5035 - KL_divergence: 10.5245
 97/200 [=============>................] - ETA: 0s - loss: 13756.6224 - KL_divergence: 10.4559
103/200 [==============>...............] - ETA: 0s - loss: 13747.9779 - KL_divergence: 10.4637
109/200 [===============>..............] - ETA: 0s - loss: 13753.3633 - KL_divergence: 10.4363
115/200 [================>.............] - ETA: 0s - loss: 13746.9683 - KL_divergence: 10.4459
121/200 [=================>............] - ETA: 0s - loss: 13754.1013 - KL_divergence: 10.4415
127/200 [==================>...........] - ETA: 0s - loss: 13761.1355 - KL_divergence: 10.4206
134/200 [===================>..........] - ETA: 0s - loss: 13733.0001 - KL_divergence: 10.4507
140/200 [====================>.........] - ETA: 0s - loss: 13712.6632 - KL_divergence: 10.4794
146/200 [====================>.........] - ETA: 0s - loss: 13711.6136 - KL_divergence: 10.4891
152/200 [=====================>........] - ETA: 0s - loss: 13707.6008 - KL_divergence: 10.4687
158/200 [======================>.......] - ETA: 0s - loss: 13718.5488 - KL_divergence: 10.4544
164/200 [=======================>......] - ETA: 0s - loss: 13726.5630 - KL_divergence: 10.4314
170/200 [========================>.....] - ETA: 0s - loss: 13733.3767 - KL_divergence: 10.4293
176/200 [=========================>....] - ETA: 0s - loss: 13727.5484 - KL_divergence: 10.4451
182/200 [==========================>...] - ETA: 0s - loss: 13733.2532 - KL_divergence: 10.4158
188/200 [===========================>..] - ETA: 0s - loss: 13736.6120 - KL_divergence: 10.4043
194/200 [============================>.] - ETA: 0s - loss: 13753.0157 - KL_divergence: 10.3828
200/200 [==============================] - 2s 10ms/step - loss: 13756.5156 - KL_divergence: 10.3866 - val_loss: 13728.0148 - val_KL_divergence: 10.7376
Epoch 16/100

  1/200 [..............................] - ETA: 2s - loss: 14603.2754 - KL_divergence: 8.0907
  7/200 [>.............................] - ETA: 1s - loss: 13981.6200 - KL_divergence: 10.0729
 13/200 [>.............................] - ETA: 1s - loss: 13974.0306 - KL_divergence: 9.9203 
 18/200 [=>............................] - ETA: 1s - loss: 13930.1381 - KL_divergence: 9.9724
 24/200 [==>...........................] - ETA: 1s - loss: 13816.2868 - KL_divergence: 10.1692
 30/200 [===>..........................] - ETA: 1s - loss: 13753.0231 - KL_divergence: 10.3133
 36/200 [====>.........................] - ETA: 1s - loss: 13695.9933 - KL_divergence: 10.3990
 42/200 [=====>........................] - ETA: 1s - loss: 13698.6202 - KL_divergence: 10.3662
 48/200 [======>.......................] - ETA: 1s - loss: 13661.1404 - KL_divergence: 10.4415
 54/200 [=======>......................] - ETA: 1s - loss: 13649.5755 - KL_divergence: 10.4931
 60/200 [========>.....................] - ETA: 1s - loss: 13686.9207 - KL_divergence: 10.4049
 66/200 [========>.....................] - ETA: 1s - loss: 13692.1026 - KL_divergence: 10.3780
 73/200 [=========>....................] - ETA: 1s - loss: 13702.7370 - KL_divergence: 10.3529
 77/200 [==========>...................] - ETA: 1s - loss: 13692.7722 - KL_divergence: 10.3868
 81/200 [===========>..................] - ETA: 1s - loss: 13688.8791 - KL_divergence: 10.3883
 87/200 [============>.................] - ETA: 1s - loss: 13691.1736 - KL_divergence: 10.3688
 93/200 [============>.................] - ETA: 1s - loss: 13697.1408 - KL_divergence: 10.3862
 99/200 [=============>................] - ETA: 0s - loss: 13674.0134 - KL_divergence: 10.4040
105/200 [==============>...............] - ETA: 0s - loss: 13687.3259 - KL_divergence: 10.3511
111/200 [===============>..............] - ETA: 0s - loss: 13690.0072 - KL_divergence: 10.3415
117/200 [================>.............] - ETA: 0s - loss: 13686.3139 - KL_divergence: 10.3427
123/200 [=================>............] - ETA: 0s - loss: 13692.0173 - KL_divergence: 10.3439
129/200 [==================>...........] - ETA: 0s - loss: 13703.0410 - KL_divergence: 10.3430
135/200 [===================>..........] - ETA: 0s - loss: 13688.5150 - KL_divergence: 10.3465
141/200 [====================>.........] - ETA: 0s - loss: 13691.1443 - KL_divergence: 10.3285
146/200 [====================>.........] - ETA: 0s - loss: 13689.1443 - KL_divergence: 10.3499
152/200 [=====================>........] - ETA: 0s - loss: 13687.0565 - KL_divergence: 10.3345
158/200 [======================>.......] - ETA: 0s - loss: 13673.1373 - KL_divergence: 10.3211
164/200 [=======================>......] - ETA: 0s - loss: 13667.6519 - KL_divergence: 10.3075
170/200 [========================>.....] - ETA: 0s - loss: 13687.0299 - KL_divergence: 10.2765
176/200 [=========================>....] - ETA: 0s - loss: 13690.2634 - KL_divergence: 10.2728
182/200 [==========================>...] - ETA: 0s - loss: 13680.5691 - KL_divergence: 10.2779
188/200 [===========================>..] - ETA: 0s - loss: 13667.5886 - KL_divergence: 10.3031
194/200 [============================>.] - ETA: 0s - loss: 13660.6871 - KL_divergence: 10.2938
200/200 [==============================] - 2s 11ms/step - loss: 13660.4735 - KL_divergence: 10.3003 - val_loss: 13687.1963 - val_KL_divergence: 9.5360
Epoch 17/100

  1/200 [..............................] - ETA: 1s - loss: 14531.3135 - KL_divergence: 9.2412
  7/200 [>.............................] - ETA: 1s - loss: 14009.7634 - KL_divergence: 9.1088
 14/200 [=>............................] - ETA: 1s - loss: 13892.1662 - KL_divergence: 9.6188
 20/200 [==>...........................] - ETA: 1s - loss: 13713.5868 - KL_divergence: 10.0127
 26/200 [==>...........................] - ETA: 1s - loss: 13658.2752 - KL_divergence: 10.0462
 32/200 [===>..........................] - ETA: 1s - loss: 13633.2493 - KL_divergence: 10.1432
 38/200 [====>.........................] - ETA: 1s - loss: 13614.9283 - KL_divergence: 10.0104
 44/200 [=====>........................] - ETA: 1s - loss: 13638.0353 - KL_divergence: 9.9597 
 50/200 [======>.......................] - ETA: 1s - loss: 13579.8236 - KL_divergence: 10.1051
 56/200 [=======>......................] - ETA: 1s - loss: 13629.2626 - KL_divergence: 10.0449
 62/200 [========>.....................] - ETA: 1s - loss: 13677.2351 - KL_divergence: 9.9863 
 68/200 [=========>....................] - ETA: 1s - loss: 13634.3755 - KL_divergence: 10.0577
 74/200 [==========>...................] - ETA: 1s - loss: 13625.2184 - KL_divergence: 10.1075
 80/200 [===========>..................] - ETA: 1s - loss: 13606.0833 - KL_divergence: 10.1408
 86/200 [===========>..................] - ETA: 1s - loss: 13599.2833 - KL_divergence: 10.2014
 92/200 [============>.................] - ETA: 0s - loss: 13610.7864 - KL_divergence: 10.2133
 97/200 [=============>................] - ETA: 0s - loss: 13601.2097 - KL_divergence: 10.2453
103/200 [==============>...............] - ETA: 0s - loss: 13597.1693 - KL_divergence: 10.2808
109/200 [===============>..............] - ETA: 0s - loss: 13608.1294 - KL_divergence: 10.2832
115/200 [================>.............] - ETA: 0s - loss: 13605.3987 - KL_divergence: 10.3103
121/200 [=================>............] - ETA: 0s - loss: 13606.8956 - KL_divergence: 10.3193
127/200 [==================>...........] - ETA: 0s - loss: 13597.3241 - KL_divergence: 10.3306
133/200 [==================>...........] - ETA: 0s - loss: 13595.4213 - KL_divergence: 10.3375
139/200 [===================>..........] - ETA: 0s - loss: 13586.1654 - KL_divergence: 10.3428
145/200 [====================>.........] - ETA: 0s - loss: 13582.9976 - KL_divergence: 10.3179
151/200 [=====================>........] - ETA: 0s - loss: 13570.9632 - KL_divergence: 10.2983
157/200 [======================>.......] - ETA: 0s - loss: 13572.3688 - KL_divergence: 10.2811
164/200 [=======================>......] - ETA: 0s - loss: 13576.7689 - KL_divergence: 10.2591
170/200 [========================>.....] - ETA: 0s - loss: 13559.7372 - KL_divergence: 10.2884
176/200 [=========================>....] - ETA: 0s - loss: 13559.5343 - KL_divergence: 10.2810
182/200 [==========================>...] - ETA: 0s - loss: 13560.1618 - KL_divergence: 10.2635
188/200 [===========================>..] - ETA: 0s - loss: 13564.5616 - KL_divergence: 10.2546
194/200 [============================>.] - ETA: 0s - loss: 13562.7117 - KL_divergence: 10.2615
200/200 [==============================] - 2s 10ms/step - loss: 13553.6431 - KL_divergence: 10.2647 - val_loss: 13699.9213 - val_KL_divergence: 10.0225
Epoch 18/100

  1/200 [..............................] - ETA: 1s - loss: 14025.3877 - KL_divergence: 10.1081
  8/200 [>.............................] - ETA: 1s - loss: 13408.7776 - KL_divergence: 10.4637
 15/200 [=>............................] - ETA: 1s - loss: 13530.2842 - KL_divergence: 9.8990 
 22/200 [==>...........................] - ETA: 1s - loss: 13489.3630 - KL_divergence: 9.8524
 28/200 [===>..........................] - ETA: 1s - loss: 13557.0999 - KL_divergence: 9.7649
 34/200 [====>.........................] - ETA: 1s - loss: 13541.7179 - KL_divergence: 9.8170
 40/200 [=====>........................] - ETA: 1s - loss: 13616.6666 - KL_divergence: 9.7442
 46/200 [=====>........................] - ETA: 1s - loss: 13606.3325 - KL_divergence: 9.7015
 53/200 [======>.......................] - ETA: 1s - loss: 13623.4986 - KL_divergence: 9.7240
 59/200 [=======>......................] - ETA: 1s - loss: 13608.2358 - KL_divergence: 9.7937
 65/200 [========>.....................] - ETA: 1s - loss: 13582.1483 - KL_divergence: 9.8183
 71/200 [=========>....................] - ETA: 1s - loss: 13559.2779 - KL_divergence: 9.8227
 77/200 [==========>...................] - ETA: 1s - loss: 13546.9201 - KL_divergence: 9.7781
 83/200 [===========>..................] - ETA: 1s - loss: 13533.7470 - KL_divergence: 9.8304
 89/200 [============>.................] - ETA: 0s - loss: 13540.5333 - KL_divergence: 9.7941
 94/200 [=============>................] - ETA: 0s - loss: 13531.9139 - KL_divergence: 9.8075
100/200 [==============>...............] - ETA: 0s - loss: 13540.4866 - KL_divergence: 9.8307
106/200 [==============>...............] - ETA: 0s - loss: 13534.8929 - KL_divergence: 9.8278
112/200 [===============>..............] - ETA: 0s - loss: 13544.3389 - KL_divergence: 9.8296
118/200 [================>.............] - ETA: 0s - loss: 13520.7946 - KL_divergence: 9.8498
124/200 [=================>............] - ETA: 0s - loss: 13526.9917 - KL_divergence: 9.8365
130/200 [==================>...........] - ETA: 0s - loss: 13510.8825 - KL_divergence: 9.8707
136/200 [===================>..........] - ETA: 0s - loss: 13518.2500 - KL_divergence: 9.8828
142/200 [====================>.........] - ETA: 0s - loss: 13505.3495 - KL_divergence: 9.9305
148/200 [=====================>........] - ETA: 0s - loss: 13502.2559 - KL_divergence: 9.9229
154/200 [======================>.......] - ETA: 0s - loss: 13486.0693 - KL_divergence: 9.9513
160/200 [=======================>......] - ETA: 0s - loss: 13488.3920 - KL_divergence: 9.9584
166/200 [=======================>......] - ETA: 0s - loss: 13482.1976 - KL_divergence: 9.9401
173/200 [========================>.....] - ETA: 0s - loss: 13479.4441 - KL_divergence: 9.9379
179/200 [=========================>....] - ETA: 0s - loss: 13480.8525 - KL_divergence: 9.9257
186/200 [==========================>...] - ETA: 0s - loss: 13481.8507 - KL_divergence: 9.9225
192/200 [===========================>..] - ETA: 0s - loss: 13486.9697 - KL_divergence: 9.9178
198/200 [============================>.] - ETA: 0s - loss: 13488.7573 - KL_divergence: 9.9235
200/200 [==============================] - 2s 10ms/step - loss: 13485.5457 - KL_divergence: 9.9273 - val_loss: 13429.4137 - val_KL_divergence: 10.1009
Epoch 19/100

  1/200 [..............................] - ETA: 1s - loss: 12702.3135 - KL_divergence: 10.7865
  7/200 [>.............................] - ETA: 1s - loss: 13428.6330 - KL_divergence: 9.6156 
 13/200 [>.............................] - ETA: 1s - loss: 13324.3454 - KL_divergence: 9.8888
 19/200 [=>............................] - ETA: 1s - loss: 13201.3009 - KL_divergence: 9.9857
 25/200 [==>...........................] - ETA: 1s - loss: 13267.6101 - KL_divergence: 10.0496
 31/200 [===>..........................] - ETA: 1s - loss: 13289.7774 - KL_divergence: 10.1228
 37/200 [====>.........................] - ETA: 1s - loss: 13276.3450 - KL_divergence: 10.2214
 43/200 [=====>........................] - ETA: 1s - loss: 13305.4742 - KL_divergence: 10.1519
 49/200 [======>.......................] - ETA: 1s - loss: 13284.1509 - KL_divergence: 10.1915
 55/200 [=======>......................] - ETA: 1s - loss: 13292.5235 - KL_divergence: 10.0588
 61/200 [========>.....................] - ETA: 1s - loss: 13290.5270 - KL_divergence: 10.0608
 67/200 [=========>....................] - ETA: 1s - loss: 13293.1272 - KL_divergence: 10.1122
 73/200 [=========>....................] - ETA: 1s - loss: 13276.9677 - KL_divergence: 10.1582
 79/200 [==========>...................] - ETA: 1s - loss: 13298.6026 - KL_divergence: 10.1230
 85/200 [===========>..................] - ETA: 1s - loss: 13276.8849 - KL_divergence: 10.1418
 91/200 [============>.................] - ETA: 1s - loss: 13271.2750 - KL_divergence: 10.1236
 97/200 [=============>................] - ETA: 0s - loss: 13314.7011 - KL_divergence: 10.0569
103/200 [==============>...............] - ETA: 0s - loss: 13328.9352 - KL_divergence: 10.0292
109/200 [===============>..............] - ETA: 0s - loss: 13333.1887 - KL_divergence: 10.0015
114/200 [================>.............] - ETA: 0s - loss: 13338.8060 - KL_divergence: 10.0214
120/200 [=================>............] - ETA: 0s - loss: 13356.6899 - KL_divergence: 9.9789 
126/200 [=================>............] - ETA: 0s - loss: 13349.8822 - KL_divergence: 9.9965
132/200 [==================>...........] - ETA: 0s - loss: 13354.9603 - KL_divergence: 10.0030
138/200 [===================>..........] - ETA: 0s - loss: 13367.8971 - KL_divergence: 9.9956 
144/200 [====================>.........] - ETA: 0s - loss: 13355.2978 - KL_divergence: 10.0025
150/200 [=====================>........] - ETA: 0s - loss: 13349.2007 - KL_divergence: 9.9685 
156/200 [======================>.......] - ETA: 0s - loss: 13353.7167 - KL_divergence: 9.9453
161/200 [=======================>......] - ETA: 0s - loss: 13351.6328 - KL_divergence: 9.9282
167/200 [========================>.....] - ETA: 0s - loss: 13338.1163 - KL_divergence: 9.9411
173/200 [========================>.....] - ETA: 0s - loss: 13346.2888 - KL_divergence: 9.9156
179/200 [=========================>....] - ETA: 0s - loss: 13345.2778 - KL_divergence: 9.9086
185/200 [==========================>...] - ETA: 0s - loss: 13343.5562 - KL_divergence: 9.9225
191/200 [===========================>..] - ETA: 0s - loss: 13353.6341 - KL_divergence: 9.8888
197/200 [============================>.] - ETA: 0s - loss: 13338.3727 - KL_divergence: 9.9038
200/200 [==============================] - 2s 10ms/step - loss: 13334.2647 - KL_divergence: 9.9012 - val_loss: 13380.3459 - val_KL_divergence: 9.8601
Epoch 20/100

  1/200 [..............................] - ETA: 1s - loss: 13372.3926 - KL_divergence: 8.6949
  7/200 [>.............................] - ETA: 1s - loss: 13255.5021 - KL_divergence: 8.9422
 12/200 [>.............................] - ETA: 1s - loss: 13219.9206 - KL_divergence: 9.5236
 18/200 [=>............................] - ETA: 1s - loss: 13250.9485 - KL_divergence: 9.5972
 24/200 [==>...........................] - ETA: 1s - loss: 13342.0581 - KL_divergence: 9.1906
 30/200 [===>..........................] - ETA: 1s - loss: 13404.9231 - KL_divergence: 9.2349
 36/200 [====>.........................] - ETA: 1s - loss: 13426.4597 - KL_divergence: 9.2183
 42/200 [=====>........................] - ETA: 1s - loss: 13406.2932 - KL_divergence: 9.3558
 48/200 [======>.......................] - ETA: 1s - loss: 13373.8049 - KL_divergence: 9.4892
 54/200 [=======>......................] - ETA: 1s - loss: 13377.1118 - KL_divergence: 9.5236
 60/200 [========>.....................] - ETA: 1s - loss: 13360.8124 - KL_divergence: 9.5180
 66/200 [========>.....................] - ETA: 1s - loss: 13350.1533 - KL_divergence: 9.5631
 72/200 [=========>....................] - ETA: 1s - loss: 13373.1339 - KL_divergence: 9.5632
 78/200 [==========>...................] - ETA: 1s - loss: 13357.4566 - KL_divergence: 9.5775
 84/200 [===========>..................] - ETA: 1s - loss: 13359.0755 - KL_divergence: 9.5495
 89/200 [============>.................] - ETA: 1s - loss: 13366.1483 - KL_divergence: 9.5519
 95/200 [=============>................] - ETA: 0s - loss: 13348.1767 - KL_divergence: 9.5607
101/200 [==============>...............] - ETA: 0s - loss: 13393.3798 - KL_divergence: 9.4966
107/200 [===============>..............] - ETA: 0s - loss: 13403.1438 - KL_divergence: 9.4932
113/200 [===============>..............] - ETA: 0s - loss: 13393.1628 - KL_divergence: 9.4943
120/200 [=================>............] - ETA: 0s - loss: 13387.5071 - KL_divergence: 9.4600
126/200 [=================>............] - ETA: 0s - loss: 13385.8557 - KL_divergence: 9.4677
132/200 [==================>...........] - ETA: 0s - loss: 13390.6440 - KL_divergence: 9.4660
138/200 [===================>..........] - ETA: 0s - loss: 13378.2269 - KL_divergence: 9.4954
144/200 [====================>.........] - ETA: 0s - loss: 13382.4576 - KL_divergence: 9.4980
150/200 [=====================>........] - ETA: 0s - loss: 13390.6306 - KL_divergence: 9.4957
156/200 [======================>.......] - ETA: 0s - loss: 13383.6728 - KL_divergence: 9.4973
162/200 [=======================>......] - ETA: 0s - loss: 13386.1276 - KL_divergence: 9.5024
168/200 [========================>.....] - ETA: 0s - loss: 13394.4398 - KL_divergence: 9.4872
174/200 [=========================>....] - ETA: 0s - loss: 13383.1351 - KL_divergence: 9.4813
180/200 [==========================>...] - ETA: 0s - loss: 13375.0288 - KL_divergence: 9.4836
186/200 [==========================>...] - ETA: 0s - loss: 13369.2807 - KL_divergence: 9.4699
192/200 [===========================>..] - ETA: 0s - loss: 13372.6825 - KL_divergence: 9.4998
198/200 [============================>.] - ETA: 0s - loss: 13374.1792 - KL_divergence: 9.4931
200/200 [==============================] - 2s 10ms/step - loss: 13371.7378 - KL_divergence: 9.4963 - val_loss: 13499.1193 - val_KL_divergence: 9.8040
Epoch 21/100

  1/200 [..............................] - ETA: 1s - loss: 13524.2764 - KL_divergence: 10.4050
  7/200 [>.............................] - ETA: 1s - loss: 13453.8179 - KL_divergence: 9.7149 
 13/200 [>.............................] - ETA: 1s - loss: 13402.5899 - KL_divergence: 9.7847
 19/200 [=>............................] - ETA: 1s - loss: 13317.5767 - KL_divergence: 9.8318
 26/200 [==>...........................] - ETA: 1s - loss: 13320.7554 - KL_divergence: 9.7865
 32/200 [===>..........................] - ETA: 1s - loss: 13250.3324 - KL_divergence: 9.8481
 39/200 [====>.........................] - ETA: 1s - loss: 13283.2781 - KL_divergence: 9.7352
 45/200 [=====>........................] - ETA: 1s - loss: 13279.2480 - KL_divergence: 9.7305
 51/200 [======>.......................] - ETA: 1s - loss: 13307.0586 - KL_divergence: 9.6815
 58/200 [=======>......................] - ETA: 1s - loss: 13263.2428 - KL_divergence: 9.7386
 64/200 [========>.....................] - ETA: 1s - loss: 13265.5480 - KL_divergence: 9.7339
 71/200 [=========>....................] - ETA: 1s - loss: 13291.9508 - KL_divergence: 9.6470
 77/200 [==========>...................] - ETA: 1s - loss: 13298.9390 - KL_divergence: 9.6186
 83/200 [===========>..................] - ETA: 1s - loss: 13309.9451 - KL_divergence: 9.5955
 89/200 [============>.................] - ETA: 0s - loss: 13313.4803 - KL_divergence: 9.6198
 95/200 [=============>................] - ETA: 0s - loss: 13305.4485 - KL_divergence: 9.6602
101/200 [==============>...............] - ETA: 0s - loss: 13300.4128 - KL_divergence: 9.6664
107/200 [===============>..............] - ETA: 0s - loss: 13302.0083 - KL_divergence: 9.6792
113/200 [===============>..............] - ETA: 0s - loss: 13293.7843 - KL_divergence: 9.6837
119/200 [================>.............] - ETA: 0s - loss: 13299.2702 - KL_divergence: 9.6852
125/200 [=================>............] - ETA: 0s - loss: 13306.7513 - KL_divergence: 9.6789
131/200 [==================>...........] - ETA: 0s - loss: 13318.1041 - KL_divergence: 9.6461
137/200 [===================>..........] - ETA: 0s - loss: 13311.8099 - KL_divergence: 9.6588
142/200 [====================>.........] - ETA: 0s - loss: 13317.4169 - KL_divergence: 9.6592
148/200 [=====================>........] - ETA: 0s - loss: 13316.2223 - KL_divergence: 9.6544
154/200 [======================>.......] - ETA: 0s - loss: 13328.6495 - KL_divergence: 9.6464
160/200 [=======================>......] - ETA: 0s - loss: 13330.5691 - KL_divergence: 9.6140
166/200 [=======================>......] - ETA: 0s - loss: 13338.9131 - KL_divergence: 9.5971
172/200 [========================>.....] - ETA: 0s - loss: 13353.8686 - KL_divergence: 9.5704
178/200 [=========================>....] - ETA: 0s - loss: 13349.3827 - KL_divergence: 9.5801
184/200 [==========================>...] - ETA: 0s - loss: 13351.0877 - KL_divergence: 9.5780
190/200 [===========================>..] - ETA: 0s - loss: 13339.3236 - KL_divergence: 9.5658
196/200 [============================>.] - ETA: 0s - loss: 13338.8531 - KL_divergence: 9.5547
200/200 [==============================] - 2s 10ms/step - loss: 13331.0939 - KL_divergence: 9.5636 - val_loss: 13441.0883 - val_KL_divergence: 10.0292
Epoch 22/100

  1/200 [..............................] - ETA: 1s - loss: 13536.4092 - KL_divergence: 8.9421
  7/200 [>.............................] - ETA: 1s - loss: 13674.7585 - KL_divergence: 9.4203
 14/200 [=>............................] - ETA: 1s - loss: 13400.7300 - KL_divergence: 9.5349
 21/200 [==>...........................] - ETA: 1s - loss: 13446.0819 - KL_divergence: 9.5999
 27/200 [===>..........................] - ETA: 1s - loss: 13421.4419 - KL_divergence: 9.5554
 33/200 [===>..........................] - ETA: 1s - loss: 13366.4622 - KL_divergence: 9.6274
 39/200 [====>.........................] - ETA: 1s - loss: 13403.6785 - KL_divergence: 9.5509
 45/200 [=====>........................] - ETA: 1s - loss: 13360.2226 - KL_divergence: 9.5399
 51/200 [======>.......................] - ETA: 1s - loss: 13339.4310 - KL_divergence: 9.5812
 57/200 [=======>......................] - ETA: 1s - loss: 13330.3460 - KL_divergence: 9.5901
 63/200 [========>.....................] - ETA: 1s - loss: 13308.2488 - KL_divergence: 9.6173
 69/200 [=========>....................] - ETA: 1s - loss: 13290.1328 - KL_divergence: 9.6443
 75/200 [==========>...................] - ETA: 1s - loss: 13274.0424 - KL_divergence: 9.6146
 81/200 [===========>..................] - ETA: 1s - loss: 13255.9609 - KL_divergence: 9.6284
 87/200 [============>.................] - ETA: 1s - loss: 13267.5952 - KL_divergence: 9.6299
 93/200 [============>.................] - ETA: 0s - loss: 13245.0705 - KL_divergence: 9.7069
 99/200 [=============>................] - ETA: 0s - loss: 13244.5951 - KL_divergence: 9.6853
105/200 [==============>...............] - ETA: 0s - loss: 13256.7388 - KL_divergence: 9.6690
111/200 [===============>..............] - ETA: 0s - loss: 13256.2417 - KL_divergence: 9.6528
117/200 [================>.............] - ETA: 0s - loss: 13254.7868 - KL_divergence: 9.6350
123/200 [=================>............] - ETA: 0s - loss: 13272.8557 - KL_divergence: 9.6410
129/200 [==================>...........] - ETA: 0s - loss: 13272.9876 - KL_divergence: 9.6271
135/200 [===================>..........] - ETA: 0s - loss: 13264.5671 - KL_divergence: 9.6578
141/200 [====================>.........] - ETA: 0s - loss: 13270.1176 - KL_divergence: 9.6302
147/200 [=====================>........] - ETA: 0s - loss: 13270.7095 - KL_divergence: 9.6002
153/200 [=====================>........] - ETA: 0s - loss: 13263.0026 - KL_divergence: 9.6019
159/200 [======================>.......] - ETA: 0s - loss: 13255.3377 - KL_divergence: 9.6194
165/200 [=======================>......] - ETA: 0s - loss: 13247.6856 - KL_divergence: 9.6192
171/200 [========================>.....] - ETA: 0s - loss: 13247.0804 - KL_divergence: 9.6125
177/200 [=========================>....] - ETA: 0s - loss: 13236.5012 - KL_divergence: 9.6050
183/200 [==========================>...] - ETA: 0s - loss: 13226.8176 - KL_divergence: 9.6154
189/200 [===========================>..] - ETA: 0s - loss: 13217.3364 - KL_divergence: 9.6219
195/200 [============================>.] - ETA: 0s - loss: 13218.4870 - KL_divergence: 9.6420
200/200 [==============================] - 2s 10ms/step - loss: 13211.7048 - KL_divergence: 9.6516 - val_loss: 13284.2650 - val_KL_divergence: 9.7232
Epoch 23/100

  1/200 [..............................] - ETA: 1s - loss: 13467.1348 - KL_divergence: 8.8985
  7/200 [>.............................] - ETA: 1s - loss: 12661.4891 - KL_divergence: 10.1457
 13/200 [>.............................] - ETA: 1s - loss: 12889.7188 - KL_divergence: 9.7221 
 19/200 [=>............................] - ETA: 1s - loss: 12960.3755 - KL_divergence: 9.8385
 25/200 [==>...........................] - ETA: 1s - loss: 12928.5801 - KL_divergence: 9.8130
 31/200 [===>..........................] - ETA: 1s - loss: 13046.3017 - KL_divergence: 9.8058
 36/200 [====>.........................] - ETA: 1s - loss: 13066.8255 - KL_divergence: 9.8395
 42/200 [=====>........................] - ETA: 1s - loss: 13068.3371 - KL_divergence: 9.8256
 48/200 [======>.......................] - ETA: 1s - loss: 13075.6960 - KL_divergence: 9.7809
 54/200 [=======>......................] - ETA: 1s - loss: 13091.9701 - KL_divergence: 9.8032
 60/200 [========>.....................] - ETA: 1s - loss: 13087.0702 - KL_divergence: 9.7723
 66/200 [========>.....................] - ETA: 1s - loss: 13099.7475 - KL_divergence: 9.7377
 72/200 [=========>....................] - ETA: 1s - loss: 13111.4479 - KL_divergence: 9.7042
 78/200 [==========>...................] - ETA: 1s - loss: 13122.0228 - KL_divergence: 9.6817
 84/200 [===========>..................] - ETA: 1s - loss: 13136.8241 - KL_divergence: 9.6474
 90/200 [============>.................] - ETA: 1s - loss: 13131.9151 - KL_divergence: 9.6386
 96/200 [=============>................] - ETA: 0s - loss: 13122.6192 - KL_divergence: 9.6186
102/200 [==============>...............] - ETA: 0s - loss: 13143.5239 - KL_divergence: 9.6178
108/200 [===============>..............] - ETA: 0s - loss: 13145.8528 - KL_divergence: 9.6115
114/200 [================>.............] - ETA: 0s - loss: 13156.7908 - KL_divergence: 9.5980
120/200 [=================>............] - ETA: 0s - loss: 13146.9047 - KL_divergence: 9.5878
126/200 [=================>............] - ETA: 0s - loss: 13159.4158 - KL_divergence: 9.5701
132/200 [==================>...........] - ETA: 0s - loss: 13165.1314 - KL_divergence: 9.5484
138/200 [===================>..........] - ETA: 0s - loss: 13165.4509 - KL_divergence: 9.5660
144/200 [====================>.........] - ETA: 0s - loss: 13167.4833 - KL_divergence: 9.5643
150/200 [=====================>........] - ETA: 0s - loss: 13166.7373 - KL_divergence: 9.5479
156/200 [======================>.......] - ETA: 0s - loss: 13157.4135 - KL_divergence: 9.5462
162/200 [=======================>......] - ETA: 0s - loss: 13156.8281 - KL_divergence: 9.5507
168/200 [========================>.....] - ETA: 0s - loss: 13160.8895 - KL_divergence: 9.5501
174/200 [=========================>....] - ETA: 0s - loss: 13150.2920 - KL_divergence: 9.5518
180/200 [==========================>...] - ETA: 0s - loss: 13153.6678 - KL_divergence: 9.5599
186/200 [==========================>...] - ETA: 0s - loss: 13156.1795 - KL_divergence: 9.5479
192/200 [===========================>..] - ETA: 0s - loss: 13160.6303 - KL_divergence: 9.5339
198/200 [============================>.] - ETA: 0s - loss: 13159.5583 - KL_divergence: 9.5140
200/200 [==============================] - 2s 10ms/step - loss: 13157.8848 - KL_divergence: 9.5102 - val_loss: 13253.3081 - val_KL_divergence: 9.7809
Epoch 24/100

  1/200 [..............................] - ETA: 1s - loss: 13514.3887 - KL_divergence: 9.2375
  7/200 [>.............................] - ETA: 1s - loss: 13159.9565 - KL_divergence: 9.2140
 13/200 [>.............................] - ETA: 1s - loss: 13114.0442 - KL_divergence: 9.3537
 19/200 [=>............................] - ETA: 1s - loss: 13020.1706 - KL_divergence: 9.3996
 25/200 [==>...........................] - ETA: 1s - loss: 13016.4825 - KL_divergence: 9.5459
 31/200 [===>..........................] - ETA: 1s - loss: 13018.9789 - KL_divergence: 9.7058
 37/200 [====>.........................] - ETA: 1s - loss: 13045.8360 - KL_divergence: 9.6940
 43/200 [=====>........................] - ETA: 1s - loss: 13074.7465 - KL_divergence: 9.6964
 48/200 [======>.......................] - ETA: 1s - loss: 13107.7530 - KL_divergence: 9.7103
 54/200 [=======>......................] - ETA: 1s - loss: 13108.3511 - KL_divergence: 9.6972
 59/200 [=======>......................] - ETA: 1s - loss: 13110.8580 - KL_divergence: 9.7606
 65/200 [========>.....................] - ETA: 1s - loss: 13155.6338 - KL_divergence: 9.7429
 71/200 [=========>....................] - ETA: 1s - loss: 13164.2536 - KL_divergence: 9.7093
 77/200 [==========>...................] - ETA: 1s - loss: 13163.1078 - KL_divergence: 9.6901
 83/200 [===========>..................] - ETA: 1s - loss: 13165.9522 - KL_divergence: 9.6739
 89/200 [============>.................] - ETA: 1s - loss: 13146.4879 - KL_divergence: 9.7015
 95/200 [=============>................] - ETA: 0s - loss: 13152.9344 - KL_divergence: 9.7134
101/200 [==============>...............] - ETA: 0s - loss: 13160.8765 - KL_divergence: 9.6797
108/200 [===============>..............] - ETA: 0s - loss: 13147.6064 - KL_divergence: 9.6862
114/200 [================>.............] - ETA: 0s - loss: 13163.6645 - KL_divergence: 9.6736
120/200 [=================>............] - ETA: 0s - loss: 13159.5785 - KL_divergence: 9.6709
126/200 [=================>............] - ETA: 0s - loss: 13144.3615 - KL_divergence: 9.6925
132/200 [==================>...........] - ETA: 0s - loss: 13144.3305 - KL_divergence: 9.6844
139/200 [===================>..........] - ETA: 0s - loss: 13151.4842 - KL_divergence: 9.6583
145/200 [====================>.........] - ETA: 0s - loss: 13154.5510 - KL_divergence: 9.6399
151/200 [=====================>........] - ETA: 0s - loss: 13151.9387 - KL_divergence: 9.6329
157/200 [======================>.......] - ETA: 0s - loss: 13162.3328 - KL_divergence: 9.6046
163/200 [=======================>......] - ETA: 0s - loss: 13159.2766 - KL_divergence: 9.6036
169/200 [========================>.....] - ETA: 0s - loss: 13158.1245 - KL_divergence: 9.6012
175/200 [=========================>....] - ETA: 0s - loss: 13153.4959 - KL_divergence: 9.5930
181/200 [==========================>...] - ETA: 0s - loss: 13151.1959 - KL_divergence: 9.5989
187/200 [===========================>..] - ETA: 0s - loss: 13160.7964 - KL_divergence: 9.5823
193/200 [===========================>..] - ETA: 0s - loss: 13165.7825 - KL_divergence: 9.5680
200/200 [==============================] - 2s 10ms/step - loss: 13166.7391 - KL_divergence: 9.5572 - val_loss: 13097.0421 - val_KL_divergence: 9.1373
Epoch 25/100

  1/200 [..............................] - ETA: 1s - loss: 13039.0264 - KL_divergence: 8.6534
  7/200 [>.............................] - ETA: 1s - loss: 12857.8799 - KL_divergence: 9.1743
 14/200 [=>............................] - ETA: 1s - loss: 12834.6996 - KL_divergence: 9.2836
 20/200 [==>...........................] - ETA: 1s - loss: 12865.1526 - KL_divergence: 9.3417
 26/200 [==>...........................] - ETA: 1s - loss: 12905.5573 - KL_divergence: 9.2698
 32/200 [===>..........................] - ETA: 1s - loss: 12909.1399 - KL_divergence: 9.3200
 38/200 [====>.........................] - ETA: 1s - loss: 12891.3185 - KL_divergence: 9.4480
 44/200 [=====>........................] - ETA: 1s - loss: 12937.7947 - KL_divergence: 9.4502
 50/200 [======>.......................] - ETA: 1s - loss: 12959.5378 - KL_divergence: 9.5119
 56/200 [=======>......................] - ETA: 1s - loss: 12986.5186 - KL_divergence: 9.4998
 62/200 [========>.....................] - ETA: 1s - loss: 12972.0397 - KL_divergence: 9.5192
 68/200 [=========>....................] - ETA: 1s - loss: 12977.2267 - KL_divergence: 9.5318
 74/200 [==========>...................] - ETA: 1s - loss: 13021.4284 - KL_divergence: 9.4778
 80/200 [===========>..................] - ETA: 1s - loss: 13025.0905 - KL_divergence: 9.5454
 86/200 [===========>..................] - ETA: 1s - loss: 13018.6090 - KL_divergence: 9.5301
 92/200 [============>.................] - ETA: 0s - loss: 13017.3750 - KL_divergence: 9.5302
 98/200 [=============>................] - ETA: 0s - loss: 13021.5084 - KL_divergence: 9.5010
104/200 [==============>...............] - ETA: 0s - loss: 13004.5248 - KL_divergence: 9.5080
110/200 [===============>..............] - ETA: 0s - loss: 13013.9253 - KL_divergence: 9.4853
116/200 [================>.............] - ETA: 0s - loss: 13005.8186 - KL_divergence: 9.5060
122/200 [=================>............] - ETA: 0s - loss: 13000.6435 - KL_divergence: 9.4924
128/200 [==================>...........] - ETA: 0s - loss: 12993.9284 - KL_divergence: 9.5137
134/200 [===================>..........] - ETA: 0s - loss: 12997.8915 - KL_divergence: 9.5164
140/200 [====================>.........] - ETA: 0s - loss: 13003.9677 - KL_divergence: 9.4973
146/200 [====================>.........] - ETA: 0s - loss: 13012.6171 - KL_divergence: 9.5213
152/200 [=====================>........] - ETA: 0s - loss: 13010.6286 - KL_divergence: 9.5186
158/200 [======================>.......] - ETA: 0s - loss: 13009.6012 - KL_divergence: 9.5261
164/200 [=======================>......] - ETA: 0s - loss: 13007.9703 - KL_divergence: 9.5102
170/200 [========================>.....] - ETA: 0s - loss: 13010.1738 - KL_divergence: 9.5234
176/200 [=========================>....] - ETA: 0s - loss: 13013.6484 - KL_divergence: 9.5238
182/200 [==========================>...] - ETA: 0s - loss: 13016.5552 - KL_divergence: 9.5232
188/200 [===========================>..] - ETA: 0s - loss: 13027.2530 - KL_divergence: 9.5363
194/200 [============================>.] - ETA: 0s - loss: 13013.4568 - KL_divergence: 9.5523
200/200 [==============================] - 2s 10ms/step - loss: 13007.7151 - KL_divergence: 9.5626 - val_loss: 13182.0479 - val_KL_divergence: 9.2865
Epoch 26/100

  1/200 [..............................] - ETA: 1s - loss: 11861.1035 - KL_divergence: 10.2802
  7/200 [>.............................] - ETA: 1s - loss: 12917.0544 - KL_divergence: 9.8255 
 13/200 [>.............................] - ETA: 1s - loss: 12894.4165 - KL_divergence: 9.7204
 19/200 [=>............................] - ETA: 1s - loss: 13015.1321 - KL_divergence: 9.4238
 25/200 [==>...........................] - ETA: 1s - loss: 13071.0316 - KL_divergence: 9.4116
 31/200 [===>..........................] - ETA: 1s - loss: 13074.5476 - KL_divergence: 9.4909
 37/200 [====>.........................] - ETA: 1s - loss: 13058.5996 - KL_divergence: 9.4905
 43/200 [=====>........................] - ETA: 1s - loss: 13067.6356 - KL_divergence: 9.4532
 49/200 [======>.......................] - ETA: 1s - loss: 13052.8896 - KL_divergence: 9.4380
 55/200 [=======>......................] - ETA: 1s - loss: 13000.0295 - KL_divergence: 9.4386
 61/200 [========>.....................] - ETA: 1s - loss: 13016.5513 - KL_divergence: 9.3931
 67/200 [=========>....................] - ETA: 1s - loss: 13033.6192 - KL_divergence: 9.4115
 73/200 [=========>....................] - ETA: 1s - loss: 13014.4779 - KL_divergence: 9.4304
 79/200 [==========>...................] - ETA: 1s - loss: 13020.6980 - KL_divergence: 9.4095
 85/200 [===========>..................] - ETA: 1s - loss: 13034.6496 - KL_divergence: 9.3787
 91/200 [============>.................] - ETA: 0s - loss: 13069.6851 - KL_divergence: 9.3209
 97/200 [=============>................] - ETA: 0s - loss: 13110.1030 - KL_divergence: 9.2796
102/200 [==============>...............] - ETA: 0s - loss: 13083.8742 - KL_divergence: 9.3028
108/200 [===============>..............] - ETA: 0s - loss: 13079.7472 - KL_divergence: 9.3008
114/200 [================>.............] - ETA: 0s - loss: 13089.7318 - KL_divergence: 9.2843
120/200 [=================>............] - ETA: 0s - loss: 13088.3422 - KL_divergence: 9.2914
126/200 [=================>............] - ETA: 0s - loss: 13090.9621 - KL_divergence: 9.3232
132/200 [==================>...........] - ETA: 0s - loss: 13070.4959 - KL_divergence: 9.3995
138/200 [===================>..........] - ETA: 0s - loss: 13069.2069 - KL_divergence: 9.4263
144/200 [====================>.........] - ETA: 0s - loss: 13053.6749 - KL_divergence: 9.4242
150/200 [=====================>........] - ETA: 0s - loss: 13033.3625 - KL_divergence: 9.4399
156/200 [======================>.......] - ETA: 0s - loss: 13036.4316 - KL_divergence: 9.4271
162/200 [=======================>......] - ETA: 0s - loss: 13036.4810 - KL_divergence: 9.4181
167/200 [========================>.....] - ETA: 0s - loss: 13034.7739 - KL_divergence: 9.4217
174/200 [=========================>....] - ETA: 0s - loss: 13040.0330 - KL_divergence: 9.4133
180/200 [==========================>...] - ETA: 0s - loss: 13059.1258 - KL_divergence: 9.4021
186/200 [==========================>...] - ETA: 0s - loss: 13050.5132 - KL_divergence: 9.4049
192/200 [===========================>..] - ETA: 0s - loss: 13049.6914 - KL_divergence: 9.4180
198/200 [============================>.] - ETA: 0s - loss: 13045.7719 - KL_divergence: 9.4146
200/200 [==============================] - 2s 10ms/step - loss: 13046.5347 - KL_divergence: 9.4108 - val_loss: 13072.9394 - val_KL_divergence: 9.5473
Epoch 27/100

  1/200 [..............................] - ETA: 1s - loss: 12757.2627 - KL_divergence: 8.6001
  7/200 [>.............................] - ETA: 1s - loss: 13014.3223 - KL_divergence: 9.2124
 13/200 [>.............................] - ETA: 1s - loss: 12942.7261 - KL_divergence: 9.6048
 19/200 [=>............................] - ETA: 1s - loss: 13009.2301 - KL_divergence: 9.4475
 25/200 [==>...........................] - ETA: 1s - loss: 13027.7807 - KL_divergence: 9.4095
 31/200 [===>..........................] - ETA: 1s - loss: 12951.7871 - KL_divergence: 9.3940
 37/200 [====>.........................] - ETA: 1s - loss: 12990.5482 - KL_divergence: 9.4712
 42/200 [=====>........................] - ETA: 1s - loss: 12987.1729 - KL_divergence: 9.4643
 48/200 [======>.......................] - ETA: 1s - loss: 13028.5025 - KL_divergence: 9.4418
 54/200 [=======>......................] - ETA: 1s - loss: 12951.9272 - KL_divergence: 9.4360
 60/200 [========>.....................] - ETA: 1s - loss: 12959.2658 - KL_divergence: 9.4687
 66/200 [========>.....................] - ETA: 1s - loss: 12963.0455 - KL_divergence: 9.4753
 72/200 [=========>....................] - ETA: 1s - loss: 12983.1847 - KL_divergence: 9.4821
 78/200 [==========>...................] - ETA: 1s - loss: 13007.6426 - KL_divergence: 9.4849
 84/200 [===========>..................] - ETA: 1s - loss: 13040.0616 - KL_divergence: 9.4478
 90/200 [============>.................] - ETA: 1s - loss: 13059.6729 - KL_divergence: 9.3917
 96/200 [=============>................] - ETA: 0s - loss: 13058.8581 - KL_divergence: 9.3845
102/200 [==============>...............] - ETA: 0s - loss: 13083.1548 - KL_divergence: 9.3489
108/200 [===============>..............] - ETA: 0s - loss: 13077.6283 - KL_divergence: 9.3591
114/200 [================>.............] - ETA: 0s - loss: 13073.0771 - KL_divergence: 9.3481
120/200 [=================>............] - ETA: 0s - loss: 13055.1159 - KL_divergence: 9.3372
126/200 [=================>............] - ETA: 0s - loss: 13053.0982 - KL_divergence: 9.3156
132/200 [==================>...........] - ETA: 0s - loss: 13053.6786 - KL_divergence: 9.3212
138/200 [===================>..........] - ETA: 0s - loss: 13065.3718 - KL_divergence: 9.2816
144/200 [====================>.........] - ETA: 0s - loss: 13051.9008 - KL_divergence: 9.3233
150/200 [=====================>........] - ETA: 0s - loss: 13052.4046 - KL_divergence: 9.3199
157/200 [======================>.......] - ETA: 0s - loss: 13054.4017 - KL_divergence: 9.3111
163/200 [=======================>......] - ETA: 0s - loss: 13048.1449 - KL_divergence: 9.3092
169/200 [========================>.....] - ETA: 0s - loss: 13054.2707 - KL_divergence: 9.3009
176/200 [=========================>....] - ETA: 0s - loss: 13056.0378 - KL_divergence: 9.3038
182/200 [==========================>...] - ETA: 0s - loss: 13055.6803 - KL_divergence: 9.3085
188/200 [===========================>..] - ETA: 0s - loss: 13056.7222 - KL_divergence: 9.3235
194/200 [============================>.] - ETA: 0s - loss: 13057.1877 - KL_divergence: 9.3372
200/200 [==============================] - 2s 10ms/step - loss: 13053.6312 - KL_divergence: 9.3329 - val_loss: 13070.5488 - val_KL_divergence: 9.7789
Epoch 28/100

  1/200 [..............................] - ETA: 1s - loss: 13665.5898 - KL_divergence: 9.7029
  8/200 [>.............................] - ETA: 1s - loss: 12929.8912 - KL_divergence: 9.3260
 14/200 [=>............................] - ETA: 1s - loss: 12964.5515 - KL_divergence: 8.9292
 21/200 [==>...........................] - ETA: 1s - loss: 12892.8428 - KL_divergence: 8.9920
 27/200 [===>..........................] - ETA: 1s - loss: 12871.5644 - KL_divergence: 9.0720
 34/200 [====>.........................] - ETA: 1s - loss: 12941.0321 - KL_divergence: 9.0694
 40/200 [=====>........................] - ETA: 1s - loss: 12974.8414 - KL_divergence: 9.0054
 46/200 [=====>........................] - ETA: 1s - loss: 12915.0438 - KL_divergence: 9.1074
 52/200 [======>.......................] - ETA: 1s - loss: 12873.0573 - KL_divergence: 9.2245
 58/200 [=======>......................] - ETA: 1s - loss: 12913.8237 - KL_divergence: 9.1474
 64/200 [========>.....................] - ETA: 1s - loss: 12924.0567 - KL_divergence: 9.2146
 70/200 [=========>....................] - ETA: 1s - loss: 12948.5182 - KL_divergence: 9.1676
 76/200 [==========>...................] - ETA: 1s - loss: 12932.0557 - KL_divergence: 9.1729
 82/200 [===========>..................] - ETA: 1s - loss: 12946.3872 - KL_divergence: 9.1744
 89/200 [============>.................] - ETA: 0s - loss: 12961.7812 - KL_divergence: 9.1896
 96/200 [=============>................] - ETA: 0s - loss: 12960.0416 - KL_divergence: 9.2115
102/200 [==============>...............] - ETA: 0s - loss: 12962.6136 - KL_divergence: 9.2216
109/200 [===============>..............] - ETA: 0s - loss: 12959.8288 - KL_divergence: 9.2601
116/200 [================>.............] - ETA: 0s - loss: 12965.5931 - KL_divergence: 9.2484
123/200 [=================>............] - ETA: 0s - loss: 12969.2798 - KL_divergence: 9.2401
129/200 [==================>...........] - ETA: 0s - loss: 12968.0759 - KL_divergence: 9.2451
135/200 [===================>..........] - ETA: 0s - loss: 12981.5586 - KL_divergence: 9.2229
141/200 [====================>.........] - ETA: 0s - loss: 12963.4219 - KL_divergence: 9.2323
147/200 [=====================>........] - ETA: 0s - loss: 12931.8059 - KL_divergence: 9.2775
153/200 [=====================>........] - ETA: 0s - loss: 12942.1316 - KL_divergence: 9.2742
160/200 [=======================>......] - ETA: 0s - loss: 12930.7925 - KL_divergence: 9.3077
166/200 [=======================>......] - ETA: 0s - loss: 12922.3717 - KL_divergence: 9.3102
172/200 [========================>.....] - ETA: 0s - loss: 12909.8843 - KL_divergence: 9.3250
178/200 [=========================>....] - ETA: 0s - loss: 12896.6315 - KL_divergence: 9.3435
184/200 [==========================>...] - ETA: 0s - loss: 12901.0651 - KL_divergence: 9.3306
190/200 [===========================>..] - ETA: 0s - loss: 12904.6802 - KL_divergence: 9.3281
196/200 [============================>.] - ETA: 0s - loss: 12894.2724 - KL_divergence: 9.3398
200/200 [==============================] - 2s 10ms/step - loss: 12890.6211 - KL_divergence: 9.3505 - val_loss: 12984.2505 - val_KL_divergence: 9.4862
Epoch 29/100

  1/200 [..............................] - ETA: 1s - loss: 13621.7852 - KL_divergence: 8.7518
  7/200 [>.............................] - ETA: 1s - loss: 12922.8313 - KL_divergence: 9.6157
 12/200 [>.............................] - ETA: 1s - loss: 13000.7314 - KL_divergence: 9.2946
 18/200 [=>............................] - ETA: 1s - loss: 13079.7723 - KL_divergence: 9.0778
 24/200 [==>...........................] - ETA: 1s - loss: 13091.4673 - KL_divergence: 9.1364
 30/200 [===>..........................] - ETA: 1s - loss: 13046.6298 - KL_divergence: 9.1922
 36/200 [====>.........................] - ETA: 1s - loss: 13004.9468 - KL_divergence: 9.3418
 42/200 [=====>........................] - ETA: 1s - loss: 12977.1958 - KL_divergence: 9.3605
 49/200 [======>.......................] - ETA: 1s - loss: 13001.4402 - KL_divergence: 9.3199
 55/200 [=======>......................] - ETA: 1s - loss: 13039.7821 - KL_divergence: 9.3171
 61/200 [========>.....................] - ETA: 1s - loss: 13038.9352 - KL_divergence: 9.2684
 67/200 [=========>....................] - ETA: 1s - loss: 13026.0254 - KL_divergence: 9.3003
 73/200 [=========>....................] - ETA: 1s - loss: 13005.9698 - KL_divergence: 9.3343
 79/200 [==========>...................] - ETA: 1s - loss: 13026.0469 - KL_divergence: 9.3211
 85/200 [===========>..................] - ETA: 1s - loss: 12993.7853 - KL_divergence: 9.3571
 91/200 [============>.................] - ETA: 0s - loss: 12994.3884 - KL_divergence: 9.3370
 97/200 [=============>................] - ETA: 0s - loss: 12979.5761 - KL_divergence: 9.4284
103/200 [==============>...............] - ETA: 0s - loss: 12964.6671 - KL_divergence: 9.4370
109/200 [===============>..............] - ETA: 0s - loss: 12970.9061 - KL_divergence: 9.4057
115/200 [================>.............] - ETA: 0s - loss: 12972.5301 - KL_divergence: 9.3950
121/200 [=================>............] - ETA: 0s - loss: 12993.5945 - KL_divergence: 9.3766
127/200 [==================>...........] - ETA: 0s - loss: 13010.3521 - KL_divergence: 9.3635
133/200 [==================>...........] - ETA: 0s - loss: 13021.0830 - KL_divergence: 9.3497
139/200 [===================>..........] - ETA: 0s - loss: 13027.8023 - KL_divergence: 9.3258
145/200 [====================>.........] - ETA: 0s - loss: 13023.7390 - KL_divergence: 9.3226
151/200 [=====================>........] - ETA: 0s - loss: 13022.9251 - KL_divergence: 9.3140
157/200 [======================>.......] - ETA: 0s - loss: 13019.3744 - KL_divergence: 9.3265
163/200 [=======================>......] - ETA: 0s - loss: 13000.5364 - KL_divergence: 9.3300
169/200 [========================>.....] - ETA: 0s - loss: 12998.8021 - KL_divergence: 9.3361
175/200 [=========================>....] - ETA: 0s - loss: 13000.6777 - KL_divergence: 9.3360
181/200 [==========================>...] - ETA: 0s - loss: 12999.1433 - KL_divergence: 9.3585
187/200 [===========================>..] - ETA: 0s - loss: 12995.4878 - KL_divergence: 9.3645
193/200 [===========================>..] - ETA: 0s - loss: 12998.8797 - KL_divergence: 9.3577
199/200 [============================>.] - ETA: 0s - loss: 13002.0852 - KL_divergence: 9.3353
200/200 [==============================] - 2s 10ms/step - loss: 12999.2456 - KL_divergence: 9.3316 - val_loss: 12975.0438 - val_KL_divergence: 9.5200
Epoch 30/100

  1/200 [..............................] - ETA: 1s - loss: 11856.6592 - KL_divergence: 10.5513
  7/200 [>.............................] - ETA: 1s - loss: 12331.9118 - KL_divergence: 10.0153
 13/200 [>.............................] - ETA: 1s - loss: 12529.8756 - KL_divergence: 9.9331 
 19/200 [=>............................] - ETA: 1s - loss: 12731.7498 - KL_divergence: 9.7111
 25/200 [==>...........................] - ETA: 1s - loss: 12834.9681 - KL_divergence: 9.5403
 31/200 [===>..........................] - ETA: 1s - loss: 12927.2765 - KL_divergence: 9.5931
 37/200 [====>.........................] - ETA: 1s - loss: 12903.4281 - KL_divergence: 9.6162
 43/200 [=====>........................] - ETA: 1s - loss: 12890.5866 - KL_divergence: 9.5171
 49/200 [======>.......................] - ETA: 1s - loss: 12924.6085 - KL_divergence: 9.5069
 55/200 [=======>......................] - ETA: 1s - loss: 12941.5355 - KL_divergence: 9.5002
 61/200 [========>.....................] - ETA: 1s - loss: 12963.9550 - KL_divergence: 9.4732
 67/200 [=========>....................] - ETA: 1s - loss: 12936.0317 - KL_divergence: 9.4992
 73/200 [=========>....................] - ETA: 1s - loss: 12944.8888 - KL_divergence: 9.4787
 79/200 [==========>...................] - ETA: 1s - loss: 12945.8920 - KL_divergence: 9.4502
 85/200 [===========>..................] - ETA: 1s - loss: 12947.9838 - KL_divergence: 9.4250
 91/200 [============>.................] - ETA: 1s - loss: 12937.4399 - KL_divergence: 9.4135
 97/200 [=============>................] - ETA: 0s - loss: 12928.9240 - KL_divergence: 9.4325
103/200 [==============>...............] - ETA: 0s - loss: 12932.2758 - KL_divergence: 9.4225
109/200 [===============>..............] - ETA: 0s - loss: 12927.6602 - KL_divergence: 9.3849
115/200 [================>.............] - ETA: 0s - loss: 12924.5857 - KL_divergence: 9.3788
121/200 [=================>............] - ETA: 0s - loss: 12907.9409 - KL_divergence: 9.4195
127/200 [==================>...........] - ETA: 0s - loss: 12891.8620 - KL_divergence: 9.4406
133/200 [==================>...........] - ETA: 0s - loss: 12898.8466 - KL_divergence: 9.4100
139/200 [===================>..........] - ETA: 0s - loss: 12885.5966 - KL_divergence: 9.4478
145/200 [====================>.........] - ETA: 0s - loss: 12884.9339 - KL_divergence: 9.4542
151/200 [=====================>........] - ETA: 0s - loss: 12867.5270 - KL_divergence: 9.4735
157/200 [======================>.......] - ETA: 0s - loss: 12863.8115 - KL_divergence: 9.4752
163/200 [=======================>......] - ETA: 0s - loss: 12860.1009 - KL_divergence: 9.4628
169/200 [========================>.....] - ETA: 0s - loss: 12862.2083 - KL_divergence: 9.4642
175/200 [=========================>....] - ETA: 0s - loss: 12863.3301 - KL_divergence: 9.4702
181/200 [==========================>...] - ETA: 0s - loss: 12863.4297 - KL_divergence: 9.4695
187/200 [===========================>..] - ETA: 0s - loss: 12859.8675 - KL_divergence: 9.4802
193/200 [===========================>..] - ETA: 0s - loss: 12870.1722 - KL_divergence: 9.4670
199/200 [============================>.] - ETA: 0s - loss: 12880.2579 - KL_divergence: 9.4494
200/200 [==============================] - 2s 10ms/step - loss: 12877.3030 - KL_divergence: 9.4541 - val_loss: 13050.1854 - val_KL_divergence: 9.2024
Epoch 31/100

  1/200 [..............................] - ETA: 1s - loss: 12623.3486 - KL_divergence: 9.1810
  6/200 [..............................] - ETA: 1s - loss: 12465.7199 - KL_divergence: 9.8352
 12/200 [>.............................] - ETA: 1s - loss: 12622.3153 - KL_divergence: 9.8235
 18/200 [=>............................] - ETA: 1s - loss: 12754.5963 - KL_divergence: 9.6149
 24/200 [==>...........................] - ETA: 1s - loss: 12728.2664 - KL_divergence: 9.5268
 30/200 [===>..........................] - ETA: 1s - loss: 12731.0207 - KL_divergence: 9.7118
 36/200 [====>.........................] - ETA: 1s - loss: 12735.7898 - KL_divergence: 9.6823
 42/200 [=====>........................] - ETA: 1s - loss: 12769.5281 - KL_divergence: 9.6187
 48/200 [======>.......................] - ETA: 1s - loss: 12768.0546 - KL_divergence: 9.6887
 54/200 [=======>......................] - ETA: 1s - loss: 12761.9892 - KL_divergence: 9.6067
 60/200 [========>.....................] - ETA: 1s - loss: 12761.2111 - KL_divergence: 9.5958
 67/200 [=========>....................] - ETA: 1s - loss: 12760.3440 - KL_divergence: 9.6627
 73/200 [=========>....................] - ETA: 1s - loss: 12779.9957 - KL_divergence: 9.6234
 79/200 [==========>...................] - ETA: 1s - loss: 12781.5949 - KL_divergence: 9.6870
 85/200 [===========>..................] - ETA: 1s - loss: 12775.9125 - KL_divergence: 9.7020
 91/200 [============>.................] - ETA: 1s - loss: 12767.1988 - KL_divergence: 9.7328
 97/200 [=============>................] - ETA: 0s - loss: 12804.9564 - KL_divergence: 9.6710
103/200 [==============>...............] - ETA: 0s - loss: 12798.2605 - KL_divergence: 9.6454
109/200 [===============>..............] - ETA: 0s - loss: 12809.0442 - KL_divergence: 9.6031
115/200 [================>.............] - ETA: 0s - loss: 12824.7932 - KL_divergence: 9.5486
121/200 [=================>............] - ETA: 0s - loss: 12826.6179 - KL_divergence: 9.5154
127/200 [==================>...........] - ETA: 0s - loss: 12823.3986 - KL_divergence: 9.5104
133/200 [==================>...........] - ETA: 0s - loss: 12832.7446 - KL_divergence: 9.4747
139/200 [===================>..........] - ETA: 0s - loss: 12806.2417 - KL_divergence: 9.4960
145/200 [====================>.........] - ETA: 0s - loss: 12820.8108 - KL_divergence: 9.4609
151/200 [=====================>........] - ETA: 0s - loss: 12821.5216 - KL_divergence: 9.4369
157/200 [======================>.......] - ETA: 0s - loss: 12832.6792 - KL_divergence: 9.4071
163/200 [=======================>......] - ETA: 0s - loss: 12826.6825 - KL_divergence: 9.3906
169/200 [========================>.....] - ETA: 0s - loss: 12818.7012 - KL_divergence: 9.3847
175/200 [=========================>....] - ETA: 0s - loss: 12822.5282 - KL_divergence: 9.3748
181/200 [==========================>...] - ETA: 0s - loss: 12833.5650 - KL_divergence: 9.3794
187/200 [===========================>..] - ETA: 0s - loss: 12840.6243 - KL_divergence: 9.3860
193/200 [===========================>..] - ETA: 0s - loss: 12839.4991 - KL_divergence: 9.3920
199/200 [============================>.] - ETA: 0s - loss: 12824.8745 - KL_divergence: 9.4011
200/200 [==============================] - 2s 10ms/step - loss: 12824.4429 - KL_divergence: 9.3976 - val_loss: 12902.3312 - val_KL_divergence: 9.3594
Epoch 32/100

  1/200 [..............................] - ETA: 1s - loss: 12854.5225 - KL_divergence: 8.8255
  7/200 [>.............................] - ETA: 1s - loss: 13001.5857 - KL_divergence: 8.9832
 13/200 [>.............................] - ETA: 1s - loss: 13010.5219 - KL_divergence: 9.0588
 19/200 [=>............................] - ETA: 1s - loss: 13021.8026 - KL_divergence: 9.0231
 25/200 [==>...........................] - ETA: 1s - loss: 12972.9404 - KL_divergence: 8.9909
 31/200 [===>..........................] - ETA: 1s - loss: 12951.4773 - KL_divergence: 9.0823
 37/200 [====>.........................] - ETA: 1s - loss: 12917.8537 - KL_divergence: 9.1911
 43/200 [=====>........................] - ETA: 1s - loss: 12909.7870 - KL_divergence: 9.1586
 49/200 [======>.......................] - ETA: 1s - loss: 12858.8047 - KL_divergence: 9.2441
 54/200 [=======>......................] - ETA: 1s - loss: 12894.8593 - KL_divergence: 9.1485
 59/200 [=======>......................] - ETA: 1s - loss: 12890.9934 - KL_divergence: 9.1330
 65/200 [========>.....................] - ETA: 1s - loss: 12891.3121 - KL_divergence: 9.2041
 71/200 [=========>....................] - ETA: 1s - loss: 12867.8417 - KL_divergence: 9.1721
 77/200 [==========>...................] - ETA: 1s - loss: 12877.6147 - KL_divergence: 9.1499
 83/200 [===========>..................] - ETA: 1s - loss: 12888.6191 - KL_divergence: 9.1484
 89/200 [============>.................] - ETA: 1s - loss: 12871.4019 - KL_divergence: 9.1579
 95/200 [=============>................] - ETA: 0s - loss: 12896.1081 - KL_divergence: 9.1217
101/200 [==============>...............] - ETA: 0s - loss: 12891.6795 - KL_divergence: 9.0922
107/200 [===============>..............] - ETA: 0s - loss: 12896.9340 - KL_divergence: 9.0828
113/200 [===============>..............] - ETA: 0s - loss: 12899.8292 - KL_divergence: 9.0924
119/200 [================>.............] - ETA: 0s - loss: 12898.6104 - KL_divergence: 9.0762
125/200 [=================>............] - ETA: 0s - loss: 12905.0568 - KL_divergence: 9.0743
131/200 [==================>...........] - ETA: 0s - loss: 12905.4514 - KL_divergence: 9.1071
137/200 [===================>..........] - ETA: 0s - loss: 12915.3934 - KL_divergence: 9.1549
143/200 [====================>.........] - ETA: 0s - loss: 12916.2735 - KL_divergence: 9.1685
149/200 [=====================>........] - ETA: 0s - loss: 12906.5851 - KL_divergence: 9.1814
155/200 [======================>.......] - ETA: 0s - loss: 12902.3496 - KL_divergence: 9.2127
161/200 [=======================>......] - ETA: 0s - loss: 12904.3544 - KL_divergence: 9.2269
167/200 [========================>.....] - ETA: 0s - loss: 12891.1491 - KL_divergence: 9.2738
173/200 [========================>.....] - ETA: 0s - loss: 12886.1653 - KL_divergence: 9.2796
179/200 [=========================>....] - ETA: 0s - loss: 12888.2862 - KL_divergence: 9.2697
185/200 [==========================>...] - ETA: 0s - loss: 12886.9560 - KL_divergence: 9.2780
191/200 [===========================>..] - ETA: 0s - loss: 12889.3216 - KL_divergence: 9.3018
197/200 [============================>.] - ETA: 0s - loss: 12895.9273 - KL_divergence: 9.3006
200/200 [==============================] - 2s 10ms/step - loss: 12896.6747 - KL_divergence: 9.2975 - val_loss: 12933.2582 - val_KL_divergence: 9.3228
Epoch 33/100

  1/200 [..............................] - ETA: 1s - loss: 12204.0654 - KL_divergence: 9.9552
  7/200 [>.............................] - ETA: 1s - loss: 12777.9528 - KL_divergence: 9.5768
 13/200 [>.............................] - ETA: 1s - loss: 12792.5087 - KL_divergence: 9.4661
 20/200 [==>...........................] - ETA: 1s - loss: 12780.6082 - KL_divergence: 9.5161
 26/200 [==>...........................] - ETA: 1s - loss: 12860.6576 - KL_divergence: 9.4004
 32/200 [===>..........................] - ETA: 1s - loss: 12861.5338 - KL_divergence: 9.3101
 39/200 [====>.........................] - ETA: 1s - loss: 12894.2559 - KL_divergence: 9.3263
 46/200 [=====>........................] - ETA: 1s - loss: 12817.0800 - KL_divergence: 9.4665
 52/200 [======>.......................] - ETA: 1s - loss: 12813.5756 - KL_divergence: 9.4812
 58/200 [=======>......................] - ETA: 1s - loss: 12782.2841 - KL_divergence: 9.4841
 64/200 [========>.....................] - ETA: 1s - loss: 12817.7580 - KL_divergence: 9.4990
 70/200 [=========>....................] - ETA: 1s - loss: 12857.5643 - KL_divergence: 9.4894
 76/200 [==========>...................] - ETA: 1s - loss: 12859.8739 - KL_divergence: 9.5418
 82/200 [===========>..................] - ETA: 1s - loss: 12882.6549 - KL_divergence: 9.5153
 88/200 [============>.................] - ETA: 0s - loss: 12887.6884 - KL_divergence: 9.5363
 94/200 [=============>................] - ETA: 0s - loss: 12902.5143 - KL_divergence: 9.5528
100/200 [==============>...............] - ETA: 0s - loss: 12890.7914 - KL_divergence: 9.5919
106/200 [==============>...............] - ETA: 0s - loss: 12874.2152 - KL_divergence: 9.5660
112/200 [===============>..............] - ETA: 0s - loss: 12859.5758 - KL_divergence: 9.5970
118/200 [================>.............] - ETA: 0s - loss: 12865.3258 - KL_divergence: 9.5732
124/200 [=================>............] - ETA: 0s - loss: 12862.9083 - KL_divergence: 9.5503
130/200 [==================>...........] - ETA: 0s - loss: 12888.1538 - KL_divergence: 9.5211
136/200 [===================>..........] - ETA: 0s - loss: 12889.8617 - KL_divergence: 9.4937
142/200 [====================>.........] - ETA: 0s - loss: 12899.2141 - KL_divergence: 9.4909
148/200 [=====================>........] - ETA: 0s - loss: 12885.0765 - KL_divergence: 9.4848
154/200 [======================>.......] - ETA: 0s - loss: 12873.5956 - KL_divergence: 9.4948
161/200 [=======================>......] - ETA: 0s - loss: 12861.0752 - KL_divergence: 9.5136
167/200 [========================>.....] - ETA: 0s - loss: 12854.7164 - KL_divergence: 9.4924
173/200 [========================>.....] - ETA: 0s - loss: 12867.3409 - KL_divergence: 9.5005
179/200 [=========================>....] - ETA: 0s - loss: 12870.2859 - KL_divergence: 9.4914
185/200 [==========================>...] - ETA: 0s - loss: 12869.3403 - KL_divergence: 9.4821
191/200 [===========================>..] - ETA: 0s - loss: 12868.6353 - KL_divergence: 9.4906
197/200 [============================>.] - ETA: 0s - loss: 12867.5264 - KL_divergence: 9.4934
200/200 [==============================] - 2s 10ms/step - loss: 12860.7397 - KL_divergence: 9.4922 - val_loss: 12882.4027 - val_KL_divergence: 9.4252
Epoch 34/100

  1/200 [..............................] - ETA: 1s - loss: 12120.8252 - KL_divergence: 10.9178
  7/200 [>.............................] - ETA: 1s - loss: 12817.3903 - KL_divergence: 9.2917 
 13/200 [>.............................] - ETA: 1s - loss: 12902.1944 - KL_divergence: 9.1215
 19/200 [=>............................] - ETA: 1s - loss: 12783.8413 - KL_divergence: 9.3098
 25/200 [==>...........................] - ETA: 1s - loss: 12701.8434 - KL_divergence: 9.3964
 30/200 [===>..........................] - ETA: 1s - loss: 12688.2937 - KL_divergence: 9.4911
 36/200 [====>.........................] - ETA: 1s - loss: 12737.8081 - KL_divergence: 9.3827
 42/200 [=====>........................] - ETA: 1s - loss: 12711.3206 - KL_divergence: 9.5187
 48/200 [======>.......................] - ETA: 1s - loss: 12727.8343 - KL_divergence: 9.4712
 54/200 [=======>......................] - ETA: 1s - loss: 12712.3118 - KL_divergence: 9.4951
 60/200 [========>.....................] - ETA: 1s - loss: 12734.4125 - KL_divergence: 9.4956
 66/200 [========>.....................] - ETA: 1s - loss: 12754.0518 - KL_divergence: 9.5033
 72/200 [=========>....................] - ETA: 1s - loss: 12751.4645 - KL_divergence: 9.4847
 78/200 [==========>...................] - ETA: 1s - loss: 12777.3893 - KL_divergence: 9.4590
 84/200 [===========>..................] - ETA: 1s - loss: 12764.0799 - KL_divergence: 9.4749
 90/200 [============>.................] - ETA: 1s - loss: 12757.9691 - KL_divergence: 9.4606
 96/200 [=============>................] - ETA: 0s - loss: 12774.2815 - KL_divergence: 9.4252
102/200 [==============>...............] - ETA: 0s - loss: 12768.5192 - KL_divergence: 9.4210
108/200 [===============>..............] - ETA: 0s - loss: 12774.3702 - KL_divergence: 9.4136
114/200 [================>.............] - ETA: 0s - loss: 12774.9682 - KL_divergence: 9.4154
120/200 [=================>............] - ETA: 0s - loss: 12785.2144 - KL_divergence: 9.4214
126/200 [=================>............] - ETA: 0s - loss: 12794.7634 - KL_divergence: 9.4189
132/200 [==================>...........] - ETA: 0s - loss: 12794.6082 - KL_divergence: 9.4001
138/200 [===================>..........] - ETA: 0s - loss: 12787.4672 - KL_divergence: 9.4329
144/200 [====================>.........] - ETA: 0s - loss: 12799.2061 - KL_divergence: 9.4270
150/200 [=====================>........] - ETA: 0s - loss: 12806.6542 - KL_divergence: 9.4060
156/200 [======================>.......] - ETA: 0s - loss: 12803.0816 - KL_divergence: 9.4068
163/200 [=======================>......] - ETA: 0s - loss: 12793.1183 - KL_divergence: 9.4346
170/200 [========================>.....] - ETA: 0s - loss: 12808.5879 - KL_divergence: 9.4280
176/200 [=========================>....] - ETA: 0s - loss: 12821.1688 - KL_divergence: 9.4060
183/200 [==========================>...] - ETA: 0s - loss: 12830.3538 - KL_divergence: 9.3988
190/200 [===========================>..] - ETA: 0s - loss: 12838.7670 - KL_divergence: 9.4082
197/200 [============================>.] - ETA: 0s - loss: 12853.6818 - KL_divergence: 9.4008
200/200 [==============================] - 2s 10ms/step - loss: 12862.0031 - KL_divergence: 9.3990 - val_loss: 12967.9499 - val_KL_divergence: 9.9015
Epoch 35/100

  1/200 [..............................] - ETA: 1s - loss: 12894.4463 - KL_divergence: 9.4085
  7/200 [>.............................] - ETA: 1s - loss: 12891.5929 - KL_divergence: 9.5800
 13/200 [>.............................] - ETA: 1s - loss: 12882.3433 - KL_divergence: 9.5428
 19/200 [=>............................] - ETA: 1s - loss: 12862.9893 - KL_divergence: 9.5280
 25/200 [==>...........................] - ETA: 1s - loss: 12880.3671 - KL_divergence: 9.4404
 32/200 [===>..........................] - ETA: 1s - loss: 12910.2575 - KL_divergence: 9.4796
 38/200 [====>.........................] - ETA: 1s - loss: 12947.4381 - KL_divergence: 9.4120
 44/200 [=====>........................] - ETA: 1s - loss: 12974.7396 - KL_divergence: 9.3365
 50/200 [======>.......................] - ETA: 1s - loss: 12919.3236 - KL_divergence: 9.4119
 56/200 [=======>......................] - ETA: 1s - loss: 12919.3590 - KL_divergence: 9.4353
 62/200 [========>.....................] - ETA: 1s - loss: 12914.9252 - KL_divergence: 9.3626
 67/200 [=========>....................] - ETA: 1s - loss: 12921.1838 - KL_divergence: 9.3499
 73/200 [=========>....................] - ETA: 1s - loss: 12882.6348 - KL_divergence: 9.4260
 79/200 [==========>...................] - ETA: 1s - loss: 12877.0034 - KL_divergence: 9.4401
 86/200 [===========>..................] - ETA: 1s - loss: 12850.6617 - KL_divergence: 9.4848
 92/200 [============>.................] - ETA: 0s - loss: 12844.4872 - KL_divergence: 9.5211
 98/200 [=============>................] - ETA: 0s - loss: 12835.5905 - KL_divergence: 9.5446
104/200 [==============>...............] - ETA: 0s - loss: 12848.9204 - KL_divergence: 9.5012
110/200 [===============>..............] - ETA: 0s - loss: 12867.4050 - KL_divergence: 9.4871
116/200 [================>.............] - ETA: 0s - loss: 12853.3824 - KL_divergence: 9.5301
122/200 [=================>............] - ETA: 0s - loss: 12856.1990 - KL_divergence: 9.5641
128/200 [==================>...........] - ETA: 0s - loss: 12877.8732 - KL_divergence: 9.5664
134/200 [===================>..........] - ETA: 0s - loss: 12873.0871 - KL_divergence: 9.5610
141/200 [====================>.........] - ETA: 0s - loss: 12868.4458 - KL_divergence: 9.6065
147/200 [=====================>........] - ETA: 0s - loss: 12856.7731 - KL_divergence: 9.6354
153/200 [=====================>........] - ETA: 0s - loss: 12861.5161 - KL_divergence: 9.6197
159/200 [======================>.......] - ETA: 0s - loss: 12852.3667 - KL_divergence: 9.6510
165/200 [=======================>......] - ETA: 0s - loss: 12845.5730 - KL_divergence: 9.6705
171/200 [========================>.....] - ETA: 0s - loss: 12854.4529 - KL_divergence: 9.6762
177/200 [=========================>....] - ETA: 0s - loss: 12855.4114 - KL_divergence: 9.6582
183/200 [==========================>...] - ETA: 0s - loss: 12845.1352 - KL_divergence: 9.6802
189/200 [===========================>..] - ETA: 0s - loss: 12849.9366 - KL_divergence: 9.6886
195/200 [============================>.] - ETA: 0s - loss: 12846.9275 - KL_divergence: 9.7022
200/200 [==============================] - 2s 10ms/step - loss: 12844.6128 - KL_divergence: 9.7171 - val_loss: 13102.0331 - val_KL_divergence: 9.6963
Epoch 36/100

  1/200 [..............................] - ETA: 1s - loss: 13489.7363 - KL_divergence: 10.1849
  7/200 [>.............................] - ETA: 1s - loss: 12910.9948 - KL_divergence: 10.3082
 13/200 [>.............................] - ETA: 1s - loss: 12837.7976 - KL_divergence: 9.9322 
 19/200 [=>............................] - ETA: 1s - loss: 12988.4598 - KL_divergence: 9.8546
 25/200 [==>...........................] - ETA: 1s - loss: 13005.7155 - KL_divergence: 9.7778
 31/200 [===>..........................] - ETA: 1s - loss: 12891.6303 - KL_divergence: 9.9389
 37/200 [====>.........................] - ETA: 1s - loss: 12905.8491 - KL_divergence: 9.9484
 43/200 [=====>........................] - ETA: 1s - loss: 12892.2499 - KL_divergence: 9.9636
 49/200 [======>.......................] - ETA: 1s - loss: 12877.4478 - KL_divergence: 9.8848
 55/200 [=======>......................] - ETA: 1s - loss: 12873.5792 - KL_divergence: 9.7893
 61/200 [========>.....................] - ETA: 1s - loss: 12857.7164 - KL_divergence: 9.7759
 67/200 [=========>....................] - ETA: 1s - loss: 12866.8643 - KL_divergence: 9.7463
 73/200 [=========>....................] - ETA: 1s - loss: 12814.5785 - KL_divergence: 9.8400
 79/200 [==========>...................] - ETA: 1s - loss: 12830.6635 - KL_divergence: 9.8481
 85/200 [===========>..................] - ETA: 1s - loss: 12817.1422 - KL_divergence: 9.8121
 91/200 [============>.................] - ETA: 1s - loss: 12801.1089 - KL_divergence: 9.8190
 97/200 [=============>................] - ETA: 0s - loss: 12793.6546 - KL_divergence: 9.8109
103/200 [==============>...............] - ETA: 0s - loss: 12795.9962 - KL_divergence: 9.8097
109/200 [===============>..............] - ETA: 0s - loss: 12799.3098 - KL_divergence: 9.8106
115/200 [================>.............] - ETA: 0s - loss: 12800.0761 - KL_divergence: 9.8063
121/200 [=================>............] - ETA: 0s - loss: 12793.6028 - KL_divergence: 9.8137
127/200 [==================>...........] - ETA: 0s - loss: 12802.4876 - KL_divergence: 9.7899
133/200 [==================>...........] - ETA: 0s - loss: 12814.3841 - KL_divergence: 9.7512
139/200 [===================>..........] - ETA: 0s - loss: 12818.9879 - KL_divergence: 9.7284
145/200 [====================>.........] - ETA: 0s - loss: 12805.2768 - KL_divergence: 9.7436
151/200 [=====================>........] - ETA: 0s - loss: 12805.8394 - KL_divergence: 9.7508
158/200 [======================>.......] - ETA: 0s - loss: 12814.3796 - KL_divergence: 9.7535
164/200 [=======================>......] - ETA: 0s - loss: 12819.9646 - KL_divergence: 9.7603
170/200 [========================>.....] - ETA: 0s - loss: 12818.3820 - KL_divergence: 9.7516
176/200 [=========================>....] - ETA: 0s - loss: 12822.2044 - KL_divergence: 9.7589
182/200 [==========================>...] - ETA: 0s - loss: 12822.8652 - KL_divergence: 9.7613
188/200 [===========================>..] - ETA: 0s - loss: 12826.2274 - KL_divergence: 9.7628
195/200 [============================>.] - ETA: 0s - loss: 12831.9189 - KL_divergence: 9.7623
200/200 [==============================] - 2s 10ms/step - loss: 12830.5719 - KL_divergence: 9.7834 - val_loss: 12961.5271 - val_KL_divergence: 9.7433
Epoch 37/100

  1/200 [..............................] - ETA: 1s - loss: 13584.0059 - KL_divergence: 8.7114
  7/200 [>.............................] - ETA: 1s - loss: 13009.7342 - KL_divergence: 9.3785
 13/200 [>.............................] - ETA: 1s - loss: 13231.1747 - KL_divergence: 9.6802
 19/200 [=>............................] - ETA: 1s - loss: 13015.4574 - KL_divergence: 9.9145
 25/200 [==>...........................] - ETA: 1s - loss: 12941.5328 - KL_divergence: 9.7301
 31/200 [===>..........................] - ETA: 1s - loss: 12875.0202 - KL_divergence: 9.7967
 37/200 [====>.........................] - ETA: 1s - loss: 12848.6022 - KL_divergence: 9.7262
 43/200 [=====>........................] - ETA: 1s - loss: 12841.9960 - KL_divergence: 9.7117
 49/200 [======>.......................] - ETA: 1s - loss: 12836.6547 - KL_divergence: 9.7073
 55/200 [=======>......................] - ETA: 1s - loss: 12818.3164 - KL_divergence: 9.7054
 62/200 [========>.....................] - ETA: 1s - loss: 12805.6396 - KL_divergence: 9.6715
 68/200 [=========>....................] - ETA: 1s - loss: 12814.8650 - KL_divergence: 9.5880
 74/200 [==========>...................] - ETA: 1s - loss: 12786.9353 - KL_divergence: 9.5794
 80/200 [===========>..................] - ETA: 1s - loss: 12792.7224 - KL_divergence: 9.5555
 86/200 [===========>..................] - ETA: 1s - loss: 12782.7634 - KL_divergence: 9.5506
 92/200 [============>.................] - ETA: 1s - loss: 12778.5113 - KL_divergence: 9.5866
 98/200 [=============>................] - ETA: 0s - loss: 12780.0348 - KL_divergence: 9.5678
104/200 [==============>...............] - ETA: 0s - loss: 12809.9639 - KL_divergence: 9.5200
110/200 [===============>..............] - ETA: 0s - loss: 12811.4207 - KL_divergence: 9.4922
116/200 [================>.............] - ETA: 0s - loss: 12789.4590 - KL_divergence: 9.4947
122/200 [=================>............] - ETA: 0s - loss: 12766.0588 - KL_divergence: 9.4842
127/200 [==================>...........] - ETA: 0s - loss: 12757.9439 - KL_divergence: 9.4703
133/200 [==================>...........] - ETA: 0s - loss: 12762.3668 - KL_divergence: 9.4509
139/200 [===================>..........] - ETA: 0s - loss: 12764.5651 - KL_divergence: 9.4517
145/200 [====================>.........] - ETA: 0s - loss: 12759.3498 - KL_divergence: 9.4530
151/200 [=====================>........] - ETA: 0s - loss: 12763.7079 - KL_divergence: 9.4385
157/200 [======================>.......] - ETA: 0s - loss: 12763.4367 - KL_divergence: 9.4444
163/200 [=======================>......] - ETA: 0s - loss: 12758.9859 - KL_divergence: 9.4377
169/200 [========================>.....] - ETA: 0s - loss: 12759.5054 - KL_divergence: 9.4293
175/200 [=========================>....] - ETA: 0s - loss: 12741.7948 - KL_divergence: 9.4485
181/200 [==========================>...] - ETA: 0s - loss: 12735.7322 - KL_divergence: 9.4393
187/200 [===========================>..] - ETA: 0s - loss: 12734.5422 - KL_divergence: 9.4248
193/200 [===========================>..] - ETA: 0s - loss: 12730.3442 - KL_divergence: 9.4162
199/200 [============================>.] - ETA: 0s - loss: 12723.8026 - KL_divergence: 9.4234
200/200 [==============================] - 2s 10ms/step - loss: 12721.8337 - KL_divergence: 9.4198 - val_loss: 12818.5139 - val_KL_divergence: 9.6111
Epoch 38/100

  1/200 [..............................] - ETA: 1s - loss: 12710.4258 - KL_divergence: 9.3435
  7/200 [>.............................] - ETA: 1s - loss: 12624.9863 - KL_divergence: 9.4522
 13/200 [>.............................] - ETA: 1s - loss: 12654.8843 - KL_divergence: 9.3660
 19/200 [=>............................] - ETA: 1s - loss: 12767.7380 - KL_divergence: 9.2275
 25/200 [==>...........................] - ETA: 1s - loss: 12728.8932 - KL_divergence: 9.3449
 31/200 [===>..........................] - ETA: 1s - loss: 12726.3300 - KL_divergence: 9.2202
 37/200 [====>.........................] - ETA: 1s - loss: 12710.8705 - KL_divergence: 9.3641
 43/200 [=====>........................] - ETA: 1s - loss: 12718.4774 - KL_divergence: 9.3571
 49/200 [======>.......................] - ETA: 1s - loss: 12738.3353 - KL_divergence: 9.3988
 55/200 [=======>......................] - ETA: 1s - loss: 12716.5688 - KL_divergence: 9.4588
 61/200 [========>.....................] - ETA: 1s - loss: 12686.4429 - KL_divergence: 9.5075
 67/200 [=========>....................] - ETA: 1s - loss: 12706.5127 - KL_divergence: 9.4526
 73/200 [=========>....................] - ETA: 1s - loss: 12699.3328 - KL_divergence: 9.4443
 79/200 [==========>...................] - ETA: 1s - loss: 12690.7702 - KL_divergence: 9.4370
 85/200 [===========>..................] - ETA: 1s - loss: 12699.7971 - KL_divergence: 9.4520
 91/200 [============>.................] - ETA: 0s - loss: 12687.6057 - KL_divergence: 9.4585
 97/200 [=============>................] - ETA: 0s - loss: 12680.5669 - KL_divergence: 9.4781
103/200 [==============>...............] - ETA: 0s - loss: 12679.6010 - KL_divergence: 9.4915
109/200 [===============>..............] - ETA: 0s - loss: 12676.8180 - KL_divergence: 9.5036
115/200 [================>.............] - ETA: 0s - loss: 12685.3257 - KL_divergence: 9.5159
121/200 [=================>............] - ETA: 0s - loss: 12684.2389 - KL_divergence: 9.4874
127/200 [==================>...........] - ETA: 0s - loss: 12685.6982 - KL_divergence: 9.4880
133/200 [==================>...........] - ETA: 0s - loss: 12702.3338 - KL_divergence: 9.5008
139/200 [===================>..........] - ETA: 0s - loss: 12698.3851 - KL_divergence: 9.5189
145/200 [====================>.........] - ETA: 0s - loss: 12705.5663 - KL_divergence: 9.5167
152/200 [=====================>........] - ETA: 0s - loss: 12708.0970 - KL_divergence: 9.5051
158/200 [======================>.......] - ETA: 0s - loss: 12708.2183 - KL_divergence: 9.4895
165/200 [=======================>......] - ETA: 0s - loss: 12719.0747 - KL_divergence: 9.4594
172/200 [========================>.....] - ETA: 0s - loss: 12701.5218 - KL_divergence: 9.5104
178/200 [=========================>....] - ETA: 0s - loss: 12698.0744 - KL_divergence: 9.5028
185/200 [==========================>...] - ETA: 0s - loss: 12696.4229 - KL_divergence: 9.4895
192/200 [===========================>..] - ETA: 0s - loss: 12692.3430 - KL_divergence: 9.4973
199/200 [============================>.] - ETA: 0s - loss: 12699.5620 - KL_divergence: 9.4870
200/200 [==============================] - 2s 10ms/step - loss: 12698.9118 - KL_divergence: 9.4815 - val_loss: 12744.2777 - val_KL_divergence: 9.5483
Epoch 39/100

  1/200 [..............................] - ETA: 1s - loss: 12443.6260 - KL_divergence: 9.0227
  8/200 [>.............................] - ETA: 1s - loss: 12862.8243 - KL_divergence: 8.8312
 14/200 [=>............................] - ETA: 1s - loss: 12832.3223 - KL_divergence: 8.9558
 20/200 [==>...........................] - ETA: 1s - loss: 12764.4257 - KL_divergence: 8.9854
 26/200 [==>...........................] - ETA: 1s - loss: 12649.5804 - KL_divergence: 9.1660
 32/200 [===>..........................] - ETA: 1s - loss: 12623.4510 - KL_divergence: 9.2105
 38/200 [====>.........................] - ETA: 1s - loss: 12634.4193 - KL_divergence: 9.2796
 44/200 [=====>........................] - ETA: 1s - loss: 12697.2549 - KL_divergence: 9.3023
 50/200 [======>.......................] - ETA: 1s - loss: 12741.3942 - KL_divergence: 9.2726
 56/200 [=======>......................] - ETA: 1s - loss: 12757.9103 - KL_divergence: 9.2567
 63/200 [========>.....................] - ETA: 1s - loss: 12753.5007 - KL_divergence: 9.2398
 69/200 [=========>....................] - ETA: 1s - loss: 12778.8797 - KL_divergence: 9.2615
 75/200 [==========>...................] - ETA: 1s - loss: 12767.8099 - KL_divergence: 9.2587
 81/200 [===========>..................] - ETA: 1s - loss: 12764.6525 - KL_divergence: 9.2855
 87/200 [============>.................] - ETA: 1s - loss: 12770.2268 - KL_divergence: 9.2487
 94/200 [=============>................] - ETA: 0s - loss: 12771.5690 - KL_divergence: 9.2391
100/200 [==============>...............] - ETA: 0s - loss: 12776.4374 - KL_divergence: 9.2273
106/200 [==============>...............] - ETA: 0s - loss: 12776.6280 - KL_divergence: 9.2602
112/200 [===============>..............] - ETA: 0s - loss: 12768.5078 - KL_divergence: 9.2504
118/200 [================>.............] - ETA: 0s - loss: 12759.1342 - KL_divergence: 9.2565
124/200 [=================>............] - ETA: 0s - loss: 12741.5117 - KL_divergence: 9.2818
130/200 [==================>...........] - ETA: 0s - loss: 12731.0557 - KL_divergence: 9.2932
136/200 [===================>..........] - ETA: 0s - loss: 12735.6866 - KL_divergence: 9.2796
142/200 [====================>.........] - ETA: 0s - loss: 12733.6145 - KL_divergence: 9.2843
149/200 [=====================>........] - ETA: 0s - loss: 12725.8166 - KL_divergence: 9.2982
155/200 [======================>.......] - ETA: 0s - loss: 12727.2918 - KL_divergence: 9.2987
161/200 [=======================>......] - ETA: 0s - loss: 12733.6862 - KL_divergence: 9.2822
167/200 [========================>.....] - ETA: 0s - loss: 12739.0571 - KL_divergence: 9.2731
173/200 [========================>.....] - ETA: 0s - loss: 12737.3576 - KL_divergence: 9.2626
179/200 [=========================>....] - ETA: 0s - loss: 12736.0466 - KL_divergence: 9.2733
185/200 [==========================>...] - ETA: 0s - loss: 12732.5884 - KL_divergence: 9.2631
191/200 [===========================>..] - ETA: 0s - loss: 12729.1563 - KL_divergence: 9.2894
197/200 [============================>.] - ETA: 0s - loss: 12717.2559 - KL_divergence: 9.3165
200/200 [==============================] - 2s 10ms/step - loss: 12717.3771 - KL_divergence: 9.3186 - val_loss: 12844.9656 - val_KL_divergence: 9.4420
Epoch 40/100

  1/200 [..............................] - ETA: 1s - loss: 12441.0088 - KL_divergence: 9.5472
  7/200 [>.............................] - ETA: 1s - loss: 12720.0375 - KL_divergence: 9.0611
 13/200 [>.............................] - ETA: 1s - loss: 12628.1328 - KL_divergence: 9.2226
 19/200 [=>............................] - ETA: 1s - loss: 12623.2547 - KL_divergence: 9.3985
 26/200 [==>...........................] - ETA: 1s - loss: 12585.9835 - KL_divergence: 9.3841
 32/200 [===>..........................] - ETA: 1s - loss: 12534.0982 - KL_divergence: 9.4642
 38/200 [====>.........................] - ETA: 1s - loss: 12570.7493 - KL_divergence: 9.3735
 44/200 [=====>........................] - ETA: 1s - loss: 12572.8862 - KL_divergence: 9.3889
 50/200 [======>.......................] - ETA: 1s - loss: 12590.2510 - KL_divergence: 9.3544
 56/200 [=======>......................] - ETA: 1s - loss: 12613.7644 - KL_divergence: 9.3551
 62/200 [========>.....................] - ETA: 1s - loss: 12647.5074 - KL_divergence: 9.3364
 68/200 [=========>....................] - ETA: 1s - loss: 12646.8893 - KL_divergence: 9.3308
 74/200 [==========>...................] - ETA: 1s - loss: 12622.6333 - KL_divergence: 9.4155
 80/200 [===========>..................] - ETA: 1s - loss: 12653.8125 - KL_divergence: 9.3957
 86/200 [===========>..................] - ETA: 0s - loss: 12658.2272 - KL_divergence: 9.3918
 92/200 [============>.................] - ETA: 0s - loss: 12668.3934 - KL_divergence: 9.3576
 98/200 [=============>................] - ETA: 0s - loss: 12659.0445 - KL_divergence: 9.3530
104/200 [==============>...............] - ETA: 0s - loss: 12659.2529 - KL_divergence: 9.3579
110/200 [===============>..............] - ETA: 0s - loss: 12669.5312 - KL_divergence: 9.3558
116/200 [================>.............] - ETA: 0s - loss: 12672.5512 - KL_divergence: 9.3807
122/200 [=================>............] - ETA: 0s - loss: 12670.7684 - KL_divergence: 9.3658
128/200 [==================>...........] - ETA: 0s - loss: 12680.7493 - KL_divergence: 9.3511
134/200 [===================>..........] - ETA: 0s - loss: 12664.9281 - KL_divergence: 9.3834
140/200 [====================>.........] - ETA: 0s - loss: 12677.0363 - KL_divergence: 9.3702
146/200 [====================>.........] - ETA: 0s - loss: 12662.2684 - KL_divergence: 9.4103
152/200 [=====================>........] - ETA: 0s - loss: 12675.2058 - KL_divergence: 9.4057
158/200 [======================>.......] - ETA: 0s - loss: 12668.8253 - KL_divergence: 9.4320
164/200 [=======================>......] - ETA: 0s - loss: 12668.8194 - KL_divergence: 9.4186
170/200 [========================>.....] - ETA: 0s - loss: 12665.2181 - KL_divergence: 9.4378
176/200 [=========================>....] - ETA: 0s - loss: 12662.3009 - KL_divergence: 9.4541
182/200 [==========================>...] - ETA: 0s - loss: 12660.0945 - KL_divergence: 9.4721
188/200 [===========================>..] - ETA: 0s - loss: 12659.8887 - KL_divergence: 9.4912
194/200 [============================>.] - ETA: 0s - loss: 12655.5261 - KL_divergence: 9.5085
200/200 [==============================] - 2s 10ms/step - loss: 12661.7404 - KL_divergence: 9.4874 - val_loss: 12780.4794 - val_KL_divergence: 9.7052
Epoch 41/100

  1/200 [..............................] - ETA: 1s - loss: 12570.0342 - KL_divergence: 9.7171
  7/200 [>.............................] - ETA: 1s - loss: 12381.1004 - KL_divergence: 9.4852
 13/200 [>.............................] - ETA: 1s - loss: 12448.9961 - KL_divergence: 9.3966
 19/200 [=>............................] - ETA: 1s - loss: 12417.5977 - KL_divergence: 9.2599
 25/200 [==>...........................] - ETA: 1s - loss: 12484.8407 - KL_divergence: 9.4189
 31/200 [===>..........................] - ETA: 1s - loss: 12543.9676 - KL_divergence: 9.2765
 37/200 [====>.........................] - ETA: 1s - loss: 12551.4232 - KL_divergence: 9.2251
 44/200 [=====>........................] - ETA: 1s - loss: 12613.9529 - KL_divergence: 9.2874
 50/200 [======>.......................] - ETA: 1s - loss: 12634.9916 - KL_divergence: 9.2366
 56/200 [=======>......................] - ETA: 1s - loss: 12619.6598 - KL_divergence: 9.2924
 62/200 [========>.....................] - ETA: 1s - loss: 12616.3700 - KL_divergence: 9.2812
 68/200 [=========>....................] - ETA: 1s - loss: 12604.6392 - KL_divergence: 9.3132
 74/200 [==========>...................] - ETA: 1s - loss: 12606.5395 - KL_divergence: 9.3257
 80/200 [===========>..................] - ETA: 1s - loss: 12607.9570 - KL_divergence: 9.3389
 86/200 [===========>..................] - ETA: 1s - loss: 12602.6489 - KL_divergence: 9.3244
 92/200 [============>.................] - ETA: 0s - loss: 12612.6434 - KL_divergence: 9.3161
 99/200 [=============>................] - ETA: 0s - loss: 12608.1665 - KL_divergence: 9.3208
105/200 [==============>...............] - ETA: 0s - loss: 12612.7495 - KL_divergence: 9.3246
111/200 [===============>..............] - ETA: 0s - loss: 12625.6172 - KL_divergence: 9.3089
117/200 [================>.............] - ETA: 0s - loss: 12640.2974 - KL_divergence: 9.2994
123/200 [=================>............] - ETA: 0s - loss: 12637.0147 - KL_divergence: 9.3231
129/200 [==================>...........] - ETA: 0s - loss: 12655.6133 - KL_divergence: 9.3082
135/200 [===================>..........] - ETA: 0s - loss: 12646.8536 - KL_divergence: 9.3272
141/200 [====================>.........] - ETA: 0s - loss: 12644.2641 - KL_divergence: 9.3403
147/200 [=====================>........] - ETA: 0s - loss: 12647.6545 - KL_divergence: 9.3561
153/200 [=====================>........] - ETA: 0s - loss: 12638.0554 - KL_divergence: 9.3795
159/200 [======================>.......] - ETA: 0s - loss: 12635.1832 - KL_divergence: 9.3728
165/200 [=======================>......] - ETA: 0s - loss: 12642.3888 - KL_divergence: 9.3828
171/200 [========================>.....] - ETA: 0s - loss: 12642.4814 - KL_divergence: 9.3773
177/200 [=========================>....] - ETA: 0s - loss: 12642.1916 - KL_divergence: 9.3727
183/200 [==========================>...] - ETA: 0s - loss: 12635.3199 - KL_divergence: 9.3677
189/200 [===========================>..] - ETA: 0s - loss: 12637.1985 - KL_divergence: 9.3649
196/200 [============================>.] - ETA: 0s - loss: 12631.6251 - KL_divergence: 9.3489
200/200 [==============================] - 2s 10ms/step - loss: 12628.0588 - KL_divergence: 9.3536 - val_loss: 12869.8898 - val_KL_divergence: 9.1494
Epoch 42/100

  1/200 [..............................] - ETA: 1s - loss: 12902.9697 - KL_divergence: 8.9634
  7/200 [>.............................] - ETA: 1s - loss: 12546.2642 - KL_divergence: 9.0419
 13/200 [>.............................] - ETA: 1s - loss: 12757.8670 - KL_divergence: 8.9574
 19/200 [=>............................] - ETA: 1s - loss: 12754.2148 - KL_divergence: 9.1722
 25/200 [==>...........................] - ETA: 1s - loss: 12742.6529 - KL_divergence: 9.2449
 31/200 [===>..........................] - ETA: 1s - loss: 12752.7638 - KL_divergence: 9.2132
 37/200 [====>.........................] - ETA: 1s - loss: 12744.8870 - KL_divergence: 9.2566
 43/200 [=====>........................] - ETA: 1s - loss: 12728.8971 - KL_divergence: 9.2491
 49/200 [======>.......................] - ETA: 1s - loss: 12723.8219 - KL_divergence: 9.3282
 55/200 [=======>......................] - ETA: 1s - loss: 12706.6937 - KL_divergence: 9.3475
 61/200 [========>.....................] - ETA: 1s - loss: 12698.1539 - KL_divergence: 9.4333
 67/200 [=========>....................] - ETA: 1s - loss: 12665.8322 - KL_divergence: 9.4452
 73/200 [=========>....................] - ETA: 1s - loss: 12686.8463 - KL_divergence: 9.4233
 79/200 [==========>...................] - ETA: 1s - loss: 12683.1599 - KL_divergence: 9.4792
 85/200 [===========>..................] - ETA: 1s - loss: 12673.8379 - KL_divergence: 9.4834
 91/200 [============>.................] - ETA: 0s - loss: 12661.9352 - KL_divergence: 9.5143
 97/200 [=============>................] - ETA: 0s - loss: 12658.5059 - KL_divergence: 9.4818
103/200 [==============>...............] - ETA: 0s - loss: 12637.8841 - KL_divergence: 9.5182
109/200 [===============>..............] - ETA: 0s - loss: 12636.4995 - KL_divergence: 9.5229
115/200 [================>.............] - ETA: 0s - loss: 12628.0728 - KL_divergence: 9.5710
120/200 [=================>............] - ETA: 0s - loss: 12622.8746 - KL_divergence: 9.5807
126/200 [=================>............] - ETA: 0s - loss: 12631.7645 - KL_divergence: 9.5456
132/200 [==================>...........] - ETA: 0s - loss: 12648.3153 - KL_divergence: 9.5161
138/200 [===================>..........] - ETA: 0s - loss: 12642.5093 - KL_divergence: 9.5269
144/200 [====================>.........] - ETA: 0s - loss: 12641.4602 - KL_divergence: 9.5352
150/200 [=====================>........] - ETA: 0s - loss: 12633.7337 - KL_divergence: 9.5116
156/200 [======================>.......] - ETA: 0s - loss: 12640.8448 - KL_divergence: 9.5125
162/200 [=======================>......] - ETA: 0s - loss: 12650.4461 - KL_divergence: 9.5041
168/200 [========================>.....] - ETA: 0s - loss: 12652.6727 - KL_divergence: 9.5072
175/200 [=========================>....] - ETA: 0s - loss: 12656.9617 - KL_divergence: 9.4828
181/200 [==========================>...] - ETA: 0s - loss: 12651.2783 - KL_divergence: 9.4865
187/200 [===========================>..] - ETA: 0s - loss: 12642.9020 - KL_divergence: 9.5019
193/200 [===========================>..] - ETA: 0s - loss: 12651.4244 - KL_divergence: 9.4748
199/200 [============================>.] - ETA: 0s - loss: 12641.1293 - KL_divergence: 9.5000
200/200 [==============================] - 2s 10ms/step - loss: 12638.6664 - KL_divergence: 9.5022 - val_loss: 12838.4684 - val_KL_divergence: 9.4071
Epoch 43/100

  1/200 [..............................] - ETA: 1s - loss: 12516.3613 - KL_divergence: 8.5126
  8/200 [>.............................] - ETA: 1s - loss: 12443.7045 - KL_divergence: 9.5331
 14/200 [=>............................] - ETA: 1s - loss: 12302.8011 - KL_divergence: 9.8093
 20/200 [==>...........................] - ETA: 1s - loss: 12437.6444 - KL_divergence: 9.6648
 26/200 [==>...........................] - ETA: 1s - loss: 12410.6831 - KL_divergence: 9.9855
 33/200 [===>..........................] - ETA: 1s - loss: 12352.8968 - KL_divergence: 10.0294
 39/200 [====>.........................] - ETA: 1s - loss: 12374.9971 - KL_divergence: 9.9398 
 45/200 [=====>........................] - ETA: 1s - loss: 12396.3422 - KL_divergence: 9.8459
 51/200 [======>.......................] - ETA: 1s - loss: 12341.9335 - KL_divergence: 9.8564
 58/200 [=======>......................] - ETA: 1s - loss: 12350.1900 - KL_divergence: 9.7802
 64/200 [========>.....................] - ETA: 1s - loss: 12403.0110 - KL_divergence: 9.7581
 70/200 [=========>....................] - ETA: 1s - loss: 12416.1885 - KL_divergence: 9.7034
 76/200 [==========>...................] - ETA: 1s - loss: 12439.1881 - KL_divergence: 9.7100
 82/200 [===========>..................] - ETA: 1s - loss: 12468.5375 - KL_divergence: 9.6584
 87/200 [============>.................] - ETA: 0s - loss: 12499.0002 - KL_divergence: 9.5965
 93/200 [============>.................] - ETA: 0s - loss: 12482.1639 - KL_divergence: 9.6222
 99/200 [=============>................] - ETA: 0s - loss: 12500.3451 - KL_divergence: 9.6229
105/200 [==============>...............] - ETA: 0s - loss: 12525.3136 - KL_divergence: 9.5967
112/200 [===============>..............] - ETA: 0s - loss: 12528.6466 - KL_divergence: 9.6148
118/200 [================>.............] - ETA: 0s - loss: 12527.7778 - KL_divergence: 9.5894
124/200 [=================>............] - ETA: 0s - loss: 12518.1237 - KL_divergence: 9.5872
131/200 [==================>...........] - ETA: 0s - loss: 12529.2534 - KL_divergence: 9.5715
138/200 [===================>..........] - ETA: 0s - loss: 12509.6357 - KL_divergence: 9.5794
144/200 [====================>.........] - ETA: 0s - loss: 12514.1681 - KL_divergence: 9.5562
150/200 [=====================>........] - ETA: 0s - loss: 12523.6818 - KL_divergence: 9.5469
156/200 [======================>.......] - ETA: 0s - loss: 12519.9505 - KL_divergence: 9.5412
162/200 [=======================>......] - ETA: 0s - loss: 12536.2558 - KL_divergence: 9.5319
168/200 [========================>.....] - ETA: 0s - loss: 12534.9999 - KL_divergence: 9.5399
174/200 [=========================>....] - ETA: 0s - loss: 12534.1240 - KL_divergence: 9.5290
180/200 [==========================>...] - ETA: 0s - loss: 12535.9518 - KL_divergence: 9.5380
186/200 [==========================>...] - ETA: 0s - loss: 12551.0809 - KL_divergence: 9.5516
192/200 [===========================>..] - ETA: 0s - loss: 12556.6391 - KL_divergence: 9.5438
199/200 [============================>.] - ETA: 0s - loss: 12556.1189 - KL_divergence: 9.5399
200/200 [==============================] - 2s 10ms/step - loss: 12556.3178 - KL_divergence: 9.5413 - val_loss: 12782.4982 - val_KL_divergence: 9.3938
Epoch 44/100

  1/200 [..............................] - ETA: 1s - loss: 13215.6260 - KL_divergence: 9.8995
  7/200 [>.............................] - ETA: 1s - loss: 12816.3436 - KL_divergence: 9.7120
 13/200 [>.............................] - ETA: 1s - loss: 12673.4986 - KL_divergence: 9.7442
 19/200 [=>............................] - ETA: 1s - loss: 12564.6885 - KL_divergence: 9.7272
 25/200 [==>...........................] - ETA: 1s - loss: 12640.4421 - KL_divergence: 9.5198
 31/200 [===>..........................] - ETA: 1s - loss: 12686.2464 - KL_divergence: 9.5527
 37/200 [====>.........................] - ETA: 1s - loss: 12665.0600 - KL_divergence: 9.5326
 43/200 [=====>........................] - ETA: 1s - loss: 12670.9404 - KL_divergence: 9.5400
 49/200 [======>.......................] - ETA: 1s - loss: 12666.1367 - KL_divergence: 9.5361
 55/200 [=======>......................] - ETA: 1s - loss: 12676.1329 - KL_divergence: 9.4931
 61/200 [========>.....................] - ETA: 1s - loss: 12672.8873 - KL_divergence: 9.4532
 67/200 [=========>....................] - ETA: 1s - loss: 12650.2669 - KL_divergence: 9.4948
 73/200 [=========>....................] - ETA: 1s - loss: 12666.1575 - KL_divergence: 9.4628
 79/200 [==========>...................] - ETA: 1s - loss: 12667.7753 - KL_divergence: 9.4700
 85/200 [===========>..................] - ETA: 1s - loss: 12656.0868 - KL_divergence: 9.4542
 91/200 [============>.................] - ETA: 0s - loss: 12639.1910 - KL_divergence: 9.5066
 97/200 [=============>................] - ETA: 0s - loss: 12634.2357 - KL_divergence: 9.4812
103/200 [==============>...............] - ETA: 0s - loss: 12636.0283 - KL_divergence: 9.4284
109/200 [===============>..............] - ETA: 0s - loss: 12633.7151 - KL_divergence: 9.4069
115/200 [================>.............] - ETA: 0s - loss: 12613.3697 - KL_divergence: 9.4189
121/200 [=================>............] - ETA: 0s - loss: 12603.7148 - KL_divergence: 9.4216
127/200 [==================>...........] - ETA: 0s - loss: 12592.7741 - KL_divergence: 9.4325
133/200 [==================>...........] - ETA: 0s - loss: 12595.0564 - KL_divergence: 9.4374
139/200 [===================>..........] - ETA: 0s - loss: 12593.3770 - KL_divergence: 9.4281
145/200 [====================>.........] - ETA: 0s - loss: 12596.5964 - KL_divergence: 9.4297
151/200 [=====================>........] - ETA: 0s - loss: 12600.9338 - KL_divergence: 9.4355
157/200 [======================>.......] - ETA: 0s - loss: 12585.9399 - KL_divergence: 9.4345
163/200 [=======================>......] - ETA: 0s - loss: 12577.6024 - KL_divergence: 9.4436
169/200 [========================>.....] - ETA: 0s - loss: 12582.5830 - KL_divergence: 9.4256
175/200 [=========================>....] - ETA: 0s - loss: 12580.1246 - KL_divergence: 9.4305
181/200 [==========================>...] - ETA: 0s - loss: 12579.6281 - KL_divergence: 9.4409
187/200 [===========================>..] - ETA: 0s - loss: 12576.5367 - KL_divergence: 9.4396
193/200 [===========================>..] - ETA: 0s - loss: 12575.7773 - KL_divergence: 9.4511
199/200 [============================>.] - ETA: 0s - loss: 12577.7207 - KL_divergence: 9.4569
200/200 [==============================] - 2s 10ms/step - loss: 12581.1665 - KL_divergence: 9.4590 - val_loss: 12689.7286 - val_KL_divergence: 9.3062
Epoch 45/100

  1/200 [..............................] - ETA: 1s - loss: 12698.0889 - KL_divergence: 9.1223
  7/200 [>.............................] - ETA: 1s - loss: 12832.4626 - KL_divergence: 9.7536
 13/200 [>.............................] - ETA: 1s - loss: 12678.5962 - KL_divergence: 9.9129
 19/200 [=>............................] - ETA: 1s - loss: 12596.0200 - KL_divergence: 9.9421
 25/200 [==>...........................] - ETA: 1s - loss: 12575.3972 - KL_divergence: 9.8942
 31/200 [===>..........................] - ETA: 1s - loss: 12602.3850 - KL_divergence: 9.9469
 37/200 [====>.........................] - ETA: 1s - loss: 12662.8347 - KL_divergence: 9.8852
 43/200 [=====>........................] - ETA: 1s - loss: 12719.9018 - KL_divergence: 9.7567
 49/200 [======>.......................] - ETA: 1s - loss: 12676.8775 - KL_divergence: 9.7608
 55/200 [=======>......................] - ETA: 1s - loss: 12678.3966 - KL_divergence: 9.7275
 61/200 [========>.....................] - ETA: 1s - loss: 12700.3196 - KL_divergence: 9.7131
 67/200 [=========>....................] - ETA: 1s - loss: 12703.6999 - KL_divergence: 9.7573
 73/200 [=========>....................] - ETA: 1s - loss: 12714.7358 - KL_divergence: 9.7331
 79/200 [==========>...................] - ETA: 1s - loss: 12703.3635 - KL_divergence: 9.7420
 85/200 [===========>..................] - ETA: 1s - loss: 12701.2985 - KL_divergence: 9.7115
 91/200 [============>.................] - ETA: 0s - loss: 12711.0033 - KL_divergence: 9.7205
 97/200 [=============>................] - ETA: 0s - loss: 12712.1136 - KL_divergence: 9.7383
103/200 [==============>...............] - ETA: 0s - loss: 12713.5181 - KL_divergence: 9.7027
110/200 [===============>..............] - ETA: 0s - loss: 12695.6968 - KL_divergence: 9.7191
116/200 [================>.............] - ETA: 0s - loss: 12679.8764 - KL_divergence: 9.7026
122/200 [=================>............] - ETA: 0s - loss: 12642.0706 - KL_divergence: 9.7263
129/200 [==================>...........] - ETA: 0s - loss: 12634.0753 - KL_divergence: 9.6886
135/200 [===================>..........] - ETA: 0s - loss: 12620.2842 - KL_divergence: 9.6826
141/200 [====================>.........] - ETA: 0s - loss: 12637.7392 - KL_divergence: 9.6393
147/200 [=====================>........] - ETA: 0s - loss: 12632.6908 - KL_divergence: 9.6408
154/200 [======================>.......] - ETA: 0s - loss: 12639.3356 - KL_divergence: 9.6130
161/200 [=======================>......] - ETA: 0s - loss: 12639.4579 - KL_divergence: 9.6062
167/200 [========================>.....] - ETA: 0s - loss: 12643.9891 - KL_divergence: 9.5963
174/200 [=========================>....] - ETA: 0s - loss: 12639.7093 - KL_divergence: 9.5821
180/200 [==========================>...] - ETA: 0s - loss: 12641.6751 - KL_divergence: 9.5926
186/200 [==========================>...] - ETA: 0s - loss: 12634.1553 - KL_divergence: 9.5922
192/200 [===========================>..] - ETA: 0s - loss: 12635.7879 - KL_divergence: 9.6091
198/200 [============================>.] - ETA: 0s - loss: 12638.5224 - KL_divergence: 9.6093
200/200 [==============================] - 2s 10ms/step - loss: 12637.5876 - KL_divergence: 9.5985 - val_loss: 12683.1218 - val_KL_divergence: 9.0888
Epoch 46/100

  1/200 [..............................] - ETA: 1s - loss: 11973.2402 - KL_divergence: 9.8003
  7/200 [>.............................] - ETA: 1s - loss: 12268.9600 - KL_divergence: 9.8366
 12/200 [>.............................] - ETA: 1s - loss: 12485.0374 - KL_divergence: 9.6583
 18/200 [=>............................] - ETA: 1s - loss: 12504.4185 - KL_divergence: 9.6230
 24/200 [==>...........................] - ETA: 1s - loss: 12500.7778 - KL_divergence: 9.6291
 30/200 [===>..........................] - ETA: 1s - loss: 12549.3273 - KL_divergence: 9.5876
 36/200 [====>.........................] - ETA: 1s - loss: 12590.7401 - KL_divergence: 9.5396
 42/200 [=====>........................] - ETA: 1s - loss: 12580.4167 - KL_divergence: 9.5898
 48/200 [======>.......................] - ETA: 1s - loss: 12552.0466 - KL_divergence: 9.5420
 54/200 [=======>......................] - ETA: 1s - loss: 12561.2259 - KL_divergence: 9.5111
 60/200 [========>.....................] - ETA: 1s - loss: 12564.4800 - KL_divergence: 9.5178
 66/200 [========>.....................] - ETA: 1s - loss: 12554.4816 - KL_divergence: 9.5952
 72/200 [=========>....................] - ETA: 1s - loss: 12571.5621 - KL_divergence: 9.6064
 77/200 [==========>...................] - ETA: 1s - loss: 12582.3196 - KL_divergence: 9.5739
 83/200 [===========>..................] - ETA: 1s - loss: 12556.2998 - KL_divergence: 9.6192
 90/200 [============>.................] - ETA: 1s - loss: 12556.6271 - KL_divergence: 9.6095
 96/200 [=============>................] - ETA: 0s - loss: 12573.0827 - KL_divergence: 9.5291
102/200 [==============>...............] - ETA: 0s - loss: 12572.1137 - KL_divergence: 9.5335
108/200 [===============>..............] - ETA: 0s - loss: 12568.5567 - KL_divergence: 9.5354
113/200 [===============>..............] - ETA: 0s - loss: 12559.9867 - KL_divergence: 9.5285
118/200 [================>.............] - ETA: 0s - loss: 12549.7267 - KL_divergence: 9.5300
124/200 [=================>............] - ETA: 0s - loss: 12547.8494 - KL_divergence: 9.5343
130/200 [==================>...........] - ETA: 0s - loss: 12550.8291 - KL_divergence: 9.5286
136/200 [===================>..........] - ETA: 0s - loss: 12555.7042 - KL_divergence: 9.5155
142/200 [====================>.........] - ETA: 0s - loss: 12549.1044 - KL_divergence: 9.5017
148/200 [=====================>........] - ETA: 0s - loss: 12548.1338 - KL_divergence: 9.4854
154/200 [======================>.......] - ETA: 0s - loss: 12548.2050 - KL_divergence: 9.4603
159/200 [======================>.......] - ETA: 0s - loss: 12545.8890 - KL_divergence: 9.4733
166/200 [=======================>......] - ETA: 0s - loss: 12555.0739 - KL_divergence: 9.4647
172/200 [========================>.....] - ETA: 0s - loss: 12561.7839 - KL_divergence: 9.4332
178/200 [=========================>....] - ETA: 0s - loss: 12559.9311 - KL_divergence: 9.4378
184/200 [==========================>...] - ETA: 0s - loss: 12558.3897 - KL_divergence: 9.4578
190/200 [===========================>..] - ETA: 0s - loss: 12542.7532 - KL_divergence: 9.4753
196/200 [============================>.] - ETA: 0s - loss: 12541.7186 - KL_divergence: 9.4728
200/200 [==============================] - 2s 10ms/step - loss: 12552.5216 - KL_divergence: 9.4682 - val_loss: 12758.2301 - val_KL_divergence: 9.4469
Epoch 47/100

  1/200 [..............................] - ETA: 1s - loss: 12414.0254 - KL_divergence: 9.7626
  7/200 [>.............................] - ETA: 1s - loss: 12763.1745 - KL_divergence: 9.1225
 13/200 [>.............................] - ETA: 1s - loss: 12689.6092 - KL_divergence: 9.3190
 19/200 [=>............................] - ETA: 1s - loss: 12595.7777 - KL_divergence: 9.4538
 25/200 [==>...........................] - ETA: 1s - loss: 12658.2293 - KL_divergence: 9.4513
 31/200 [===>..........................] - ETA: 1s - loss: 12611.7300 - KL_divergence: 9.4779
 37/200 [====>.........................] - ETA: 1s - loss: 12625.8001 - KL_divergence: 9.4598
 43/200 [=====>........................] - ETA: 1s - loss: 12634.5716 - KL_divergence: 9.5016
 49/200 [======>.......................] - ETA: 1s - loss: 12660.6966 - KL_divergence: 9.4605
 55/200 [=======>......................] - ETA: 1s - loss: 12676.0541 - KL_divergence: 9.4257
 61/200 [========>.....................] - ETA: 1s - loss: 12680.3218 - KL_divergence: 9.4829
 68/200 [=========>....................] - ETA: 1s - loss: 12708.7155 - KL_divergence: 9.4284
 75/200 [==========>...................] - ETA: 1s - loss: 12702.8298 - KL_divergence: 9.4709
 81/200 [===========>..................] - ETA: 1s - loss: 12714.5154 - KL_divergence: 9.4386
 87/200 [============>.................] - ETA: 1s - loss: 12693.8697 - KL_divergence: 9.4706
 93/200 [============>.................] - ETA: 0s - loss: 12668.8461 - KL_divergence: 9.5169
 99/200 [=============>................] - ETA: 0s - loss: 12647.8243 - KL_divergence: 9.5244
105/200 [==============>...............] - ETA: 0s - loss: 12643.5806 - KL_divergence: 9.5373
111/200 [===============>..............] - ETA: 0s - loss: 12625.1438 - KL_divergence: 9.5299
117/200 [================>.............] - ETA: 0s - loss: 12618.5946 - KL_divergence: 9.5363
123/200 [=================>............] - ETA: 0s - loss: 12597.1261 - KL_divergence: 9.5442
129/200 [==================>...........] - ETA: 0s - loss: 12606.4753 - KL_divergence: 9.5292
135/200 [===================>..........] - ETA: 0s - loss: 12586.3756 - KL_divergence: 9.5446
141/200 [====================>.........] - ETA: 0s - loss: 12580.5253 - KL_divergence: 9.5425
147/200 [=====================>........] - ETA: 0s - loss: 12579.2124 - KL_divergence: 9.5734
153/200 [=====================>........] - ETA: 0s - loss: 12575.3835 - KL_divergence: 9.5867
159/200 [======================>.......] - ETA: 0s - loss: 12578.3040 - KL_divergence: 9.5797
165/200 [=======================>......] - ETA: 0s - loss: 12585.1593 - KL_divergence: 9.5545
171/200 [========================>.....] - ETA: 0s - loss: 12597.5994 - KL_divergence: 9.5502
177/200 [=========================>....] - ETA: 0s - loss: 12606.7027 - KL_divergence: 9.5244
183/200 [==========================>...] - ETA: 0s - loss: 12606.2553 - KL_divergence: 9.5034
189/200 [===========================>..] - ETA: 0s - loss: 12613.8619 - KL_divergence: 9.4904
195/200 [============================>.] - ETA: 0s - loss: 12624.5533 - KL_divergence: 9.4719
200/200 [==============================] - 2s 10ms/step - loss: 12616.0039 - KL_divergence: 9.4937 - val_loss: 12631.7209 - val_KL_divergence: 9.5496
Epoch 48/100

  1/200 [..............................] - ETA: 1s - loss: 13116.4238 - KL_divergence: 10.8760
  7/200 [>.............................] - ETA: 1s - loss: 12733.9290 - KL_divergence: 9.5497 
 12/200 [>.............................] - ETA: 1s - loss: 12676.3553 - KL_divergence: 9.2659
 18/200 [=>............................] - ETA: 1s - loss: 12680.9345 - KL_divergence: 9.4824
 23/200 [==>...........................] - ETA: 1s - loss: 12640.8538 - KL_divergence: 9.4617
 29/200 [===>..........................] - ETA: 1s - loss: 12663.4453 - KL_divergence: 9.4161
 34/200 [====>.........................] - ETA: 1s - loss: 12626.0573 - KL_divergence: 9.4597
 40/200 [=====>........................] - ETA: 1s - loss: 12656.6890 - KL_divergence: 9.5349
 46/200 [=====>........................] - ETA: 1s - loss: 12649.6031 - KL_divergence: 9.4550
 52/200 [======>.......................] - ETA: 1s - loss: 12659.6952 - KL_divergence: 9.4058
 58/200 [=======>......................] - ETA: 1s - loss: 12643.4647 - KL_divergence: 9.3967
 65/200 [========>.....................] - ETA: 1s - loss: 12616.0071 - KL_divergence: 9.4783
 71/200 [=========>....................] - ETA: 1s - loss: 12602.0365 - KL_divergence: 9.5471
 77/200 [==========>...................] - ETA: 1s - loss: 12608.6380 - KL_divergence: 9.5258
 83/200 [===========>..................] - ETA: 1s - loss: 12609.1607 - KL_divergence: 9.5565
 89/200 [============>.................] - ETA: 1s - loss: 12601.3789 - KL_divergence: 9.6115
 95/200 [=============>................] - ETA: 0s - loss: 12596.2635 - KL_divergence: 9.6166
101/200 [==============>...............] - ETA: 0s - loss: 12590.9735 - KL_divergence: 9.6198
107/200 [===============>..............] - ETA: 0s - loss: 12576.5554 - KL_divergence: 9.6655
113/200 [===============>..............] - ETA: 0s - loss: 12604.7479 - KL_divergence: 9.6188
119/200 [================>.............] - ETA: 0s - loss: 12590.1387 - KL_divergence: 9.6630
125/200 [=================>............] - ETA: 0s - loss: 12592.8059 - KL_divergence: 9.6685
131/200 [==================>...........] - ETA: 0s - loss: 12593.8906 - KL_divergence: 9.6835
137/200 [===================>..........] - ETA: 0s - loss: 12590.4526 - KL_divergence: 9.7066
143/200 [====================>.........] - ETA: 0s - loss: 12587.8470 - KL_divergence: 9.7280
149/200 [=====================>........] - ETA: 0s - loss: 12598.3292 - KL_divergence: 9.7362
155/200 [======================>.......] - ETA: 0s - loss: 12596.6416 - KL_divergence: 9.7599
161/200 [=======================>......] - ETA: 0s - loss: 12598.4380 - KL_divergence: 9.7824
167/200 [========================>.....] - ETA: 0s - loss: 12602.8485 - KL_divergence: 9.7777
173/200 [========================>.....] - ETA: 0s - loss: 12605.5179 - KL_divergence: 9.7781
179/200 [=========================>....] - ETA: 0s - loss: 12608.5960 - KL_divergence: 9.7821
185/200 [==========================>...] - ETA: 0s - loss: 12601.4037 - KL_divergence: 9.8089
191/200 [===========================>..] - ETA: 0s - loss: 12605.1600 - KL_divergence: 9.8338
197/200 [============================>.] - ETA: 0s - loss: 12606.9571 - KL_divergence: 9.8351
200/200 [==============================] - 2s 10ms/step - loss: 12600.3080 - KL_divergence: 9.8780 - val_loss: 12716.2919 - val_KL_divergence: 10.2904
Epoch 49/100

  1/200 [..............................] - ETA: 1s - loss: 12178.3340 - KL_divergence: 11.2512
  7/200 [>.............................] - ETA: 1s - loss: 12550.2024 - KL_divergence: 10.3170
 13/200 [>.............................] - ETA: 1s - loss: 12562.8658 - KL_divergence: 10.2845
 19/200 [=>............................] - ETA: 1s - loss: 12547.5816 - KL_divergence: 10.1264
 25/200 [==>...........................] - ETA: 1s - loss: 12607.6698 - KL_divergence: 10.0020
 31/200 [===>..........................] - ETA: 1s - loss: 12572.9724 - KL_divergence: 10.0568
 37/200 [====>.........................] - ETA: 1s - loss: 12522.2471 - KL_divergence: 9.9813 
 44/200 [=====>........................] - ETA: 1s - loss: 12561.8733 - KL_divergence: 10.0037
 50/200 [======>.......................] - ETA: 1s - loss: 12552.1181 - KL_divergence: 9.9610 
 56/200 [=======>......................] - ETA: 1s - loss: 12550.5161 - KL_divergence: 10.0874
 62/200 [========>.....................] - ETA: 1s - loss: 12517.2390 - KL_divergence: 10.0773
 68/200 [=========>....................] - ETA: 1s - loss: 12496.6856 - KL_divergence: 10.0951
 74/200 [==========>...................] - ETA: 1s - loss: 12512.1024 - KL_divergence: 10.0697
 80/200 [===========>..................] - ETA: 1s - loss: 12533.4353 - KL_divergence: 10.0415
 86/200 [===========>..................] - ETA: 1s - loss: 12520.9607 - KL_divergence: 10.0385
 92/200 [============>.................] - ETA: 0s - loss: 12521.3985 - KL_divergence: 10.0725
 98/200 [=============>................] - ETA: 0s - loss: 12549.5679 - KL_divergence: 10.0127
104/200 [==============>...............] - ETA: 0s - loss: 12541.7562 - KL_divergence: 10.0632
110/200 [===============>..............] - ETA: 0s - loss: 12535.5081 - KL_divergence: 10.0685
116/200 [================>.............] - ETA: 0s - loss: 12538.6418 - KL_divergence: 10.0645
122/200 [=================>............] - ETA: 0s - loss: 12554.7641 - KL_divergence: 10.0337
128/200 [==================>...........] - ETA: 0s - loss: 12567.1961 - KL_divergence: 10.0324
134/200 [===================>..........] - ETA: 0s - loss: 12579.9651 - KL_divergence: 10.0003
140/200 [====================>.........] - ETA: 0s - loss: 12566.8108 - KL_divergence: 10.0203
146/200 [====================>.........] - ETA: 0s - loss: 12559.8919 - KL_divergence: 10.0461
152/200 [=====================>........] - ETA: 0s - loss: 12557.8465 - KL_divergence: 10.0653
158/200 [======================>.......] - ETA: 0s - loss: 12574.1961 - KL_divergence: 10.0455
165/200 [=======================>......] - ETA: 0s - loss: 12579.8580 - KL_divergence: 10.0416
172/200 [========================>.....] - ETA: 0s - loss: 12585.1440 - KL_divergence: 10.0309
178/200 [=========================>....] - ETA: 0s - loss: 12577.6885 - KL_divergence: 10.0252
184/200 [==========================>...] - ETA: 0s - loss: 12581.9806 - KL_divergence: 10.0215
190/200 [===========================>..] - ETA: 0s - loss: 12586.0951 - KL_divergence: 10.0141
196/200 [============================>.] - ETA: 0s - loss: 12589.0125 - KL_divergence: 10.0179
200/200 [==============================] - 2s 10ms/step - loss: 12592.8995 - KL_divergence: 10.0065 - val_loss: 12901.1524 - val_KL_divergence: 9.6439
Epoch 50/100

  1/200 [..............................] - ETA: 1s - loss: 12455.1387 - KL_divergence: 10.8638
  7/200 [>.............................] - ETA: 1s - loss: 12564.2614 - KL_divergence: 9.6316 
 13/200 [>.............................] - ETA: 1s - loss: 12636.9624 - KL_divergence: 9.8308
 19/200 [=>............................] - ETA: 1s - loss: 12586.2614 - KL_divergence: 9.9847
 25/200 [==>...........................] - ETA: 1s - loss: 12569.1806 - KL_divergence: 10.1358
 31/200 [===>..........................] - ETA: 1s - loss: 12636.3925 - KL_divergence: 10.0749
 37/200 [====>.........................] - ETA: 1s - loss: 12632.3904 - KL_divergence: 10.0189
 43/200 [=====>........................] - ETA: 1s - loss: 12646.2678 - KL_divergence: 10.0848
 49/200 [======>.......................] - ETA: 1s - loss: 12648.0705 - KL_divergence: 10.0152
 55/200 [=======>......................] - ETA: 1s - loss: 12643.9460 - KL_divergence: 10.0534
 61/200 [========>.....................] - ETA: 1s - loss: 12623.7390 - KL_divergence: 10.0138
 67/200 [=========>....................] - ETA: 1s - loss: 12639.1103 - KL_divergence: 10.0173
 73/200 [=========>....................] - ETA: 1s - loss: 12633.3764 - KL_divergence: 10.0259
 79/200 [==========>...................] - ETA: 1s - loss: 12632.9549 - KL_divergence: 10.0069
 85/200 [===========>..................] - ETA: 1s - loss: 12625.8209 - KL_divergence: 10.0414
 91/200 [============>.................] - ETA: 0s - loss: 12614.7282 - KL_divergence: 10.0673
 97/200 [=============>................] - ETA: 0s - loss: 12600.7830 - KL_divergence: 10.0372
103/200 [==============>...............] - ETA: 0s - loss: 12610.2622 - KL_divergence: 10.0377
109/200 [===============>..............] - ETA: 0s - loss: 12611.0663 - KL_divergence: 9.9928 
115/200 [================>.............] - ETA: 0s - loss: 12600.0158 - KL_divergence: 9.9782
120/200 [=================>............] - ETA: 0s - loss: 12603.0265 - KL_divergence: 9.9772
126/200 [=================>............] - ETA: 0s - loss: 12598.9008 - KL_divergence: 9.9819
132/200 [==================>...........] - ETA: 0s - loss: 12608.8339 - KL_divergence: 9.9493
138/200 [===================>..........] - ETA: 0s - loss: 12602.4885 - KL_divergence: 9.9548
144/200 [====================>.........] - ETA: 0s - loss: 12597.3831 - KL_divergence: 9.9608
150/200 [=====================>........] - ETA: 0s - loss: 12605.6171 - KL_divergence: 9.9552
156/200 [======================>.......] - ETA: 0s - loss: 12608.3520 - KL_divergence: 9.9323
162/200 [=======================>......] - ETA: 0s - loss: 12611.9101 - KL_divergence: 9.9303
168/200 [========================>.....] - ETA: 0s - loss: 12609.1525 - KL_divergence: 9.9140
174/200 [=========================>....] - ETA: 0s - loss: 12608.0178 - KL_divergence: 9.9065
180/200 [==========================>...] - ETA: 0s - loss: 12610.0414 - KL_divergence: 9.9149
186/200 [==========================>...] - ETA: 0s - loss: 12597.3448 - KL_divergence: 9.9129
192/200 [===========================>..] - ETA: 0s - loss: 12594.6406 - KL_divergence: 9.8952
198/200 [============================>.] - ETA: 0s - loss: 12597.1074 - KL_divergence: 9.8930
200/200 [==============================] - 2s 10ms/step - loss: 12600.2532 - KL_divergence: 9.9004 - val_loss: 12625.0570 - val_KL_divergence: 9.4938
Epoch 51/100

  1/200 [..............................] - ETA: 1s - loss: 13039.8164 - KL_divergence: 8.2444
  7/200 [>.............................] - ETA: 1s - loss: 12363.2755 - KL_divergence: 9.6287
 13/200 [>.............................] - ETA: 1s - loss: 12436.4899 - KL_divergence: 9.7806
 19/200 [=>............................] - ETA: 1s - loss: 12450.4257 - KL_divergence: 9.8946
 25/200 [==>...........................] - ETA: 1s - loss: 12421.4175 - KL_divergence: 9.9754
 31/200 [===>..........................] - ETA: 1s - loss: 12463.1980 - KL_divergence: 9.9818
 37/200 [====>.........................] - ETA: 1s - loss: 12451.9328 - KL_divergence: 9.9291
 43/200 [=====>........................] - ETA: 1s - loss: 12454.0173 - KL_divergence: 9.9019
 50/200 [======>.......................] - ETA: 1s - loss: 12411.5623 - KL_divergence: 9.9286
 56/200 [=======>......................] - ETA: 1s - loss: 12409.1088 - KL_divergence: 9.9255
 62/200 [========>.....................] - ETA: 1s - loss: 12411.9425 - KL_divergence: 9.9222
 68/200 [=========>....................] - ETA: 1s - loss: 12391.3298 - KL_divergence: 9.9172
 74/200 [==========>...................] - ETA: 1s - loss: 12433.4271 - KL_divergence: 9.9007
 80/200 [===========>..................] - ETA: 1s - loss: 12416.9176 - KL_divergence: 9.8988
 86/200 [===========>..................] - ETA: 1s - loss: 12425.5637 - KL_divergence: 9.8930
 92/200 [============>.................] - ETA: 0s - loss: 12429.7066 - KL_divergence: 9.8582
 98/200 [=============>................] - ETA: 0s - loss: 12438.9836 - KL_divergence: 9.8705
104/200 [==============>...............] - ETA: 0s - loss: 12441.5781 - KL_divergence: 9.8951
110/200 [===============>..............] - ETA: 0s - loss: 12423.5541 - KL_divergence: 9.9490
116/200 [================>.............] - ETA: 0s - loss: 12437.7001 - KL_divergence: 9.8954
122/200 [=================>............] - ETA: 0s - loss: 12448.6394 - KL_divergence: 9.9061
128/200 [==================>...........] - ETA: 0s - loss: 12448.8439 - KL_divergence: 9.9195
133/200 [==================>...........] - ETA: 0s - loss: 12442.8740 - KL_divergence: 9.9182
139/200 [===================>..........] - ETA: 0s - loss: 12439.5592 - KL_divergence: 9.9451
145/200 [====================>.........] - ETA: 0s - loss: 12457.5628 - KL_divergence: 9.9271
151/200 [=====================>........] - ETA: 0s - loss: 12456.4798 - KL_divergence: 9.9101
157/200 [======================>.......] - ETA: 0s - loss: 12467.5385 - KL_divergence: 9.9031
163/200 [=======================>......] - ETA: 0s - loss: 12478.0891 - KL_divergence: 9.9115
170/200 [========================>.....] - ETA: 0s - loss: 12481.3794 - KL_divergence: 9.9092
176/200 [=========================>....] - ETA: 0s - loss: 12495.4862 - KL_divergence: 9.9090
182/200 [==========================>...] - ETA: 0s - loss: 12495.2081 - KL_divergence: 9.9186
188/200 [===========================>..] - ETA: 0s - loss: 12486.8230 - KL_divergence: 9.9333
194/200 [============================>.] - ETA: 0s - loss: 12478.9422 - KL_divergence: 9.9580
200/200 [==============================] - 2s 10ms/step - loss: 12478.6069 - KL_divergence: 9.9420 - val_loss: 12749.4434 - val_KL_divergence: 9.8461
Epoch 52/100

  1/200 [..............................] - ETA: 1s - loss: 11866.2910 - KL_divergence: 9.6585
  7/200 [>.............................] - ETA: 1s - loss: 12359.9944 - KL_divergence: 9.7256
 13/200 [>.............................] - ETA: 1s - loss: 12511.0161 - KL_divergence: 9.6470
 19/200 [=>............................] - ETA: 1s - loss: 12601.2819 - KL_divergence: 9.6055
 25/200 [==>...........................] - ETA: 1s - loss: 12681.6210 - KL_divergence: 9.4827
 31/200 [===>..........................] - ETA: 1s - loss: 12579.6604 - KL_divergence: 9.7174
 37/200 [====>.........................] - ETA: 1s - loss: 12540.6936 - KL_divergence: 9.7608
 43/200 [=====>........................] - ETA: 1s - loss: 12521.5683 - KL_divergence: 9.8203
 49/200 [======>.......................] - ETA: 1s - loss: 12538.1076 - KL_divergence: 9.8129
 55/200 [=======>......................] - ETA: 1s - loss: 12515.6455 - KL_divergence: 9.8582
 61/200 [========>.....................] - ETA: 1s - loss: 12484.5402 - KL_divergence: 9.8111
 67/200 [=========>....................] - ETA: 1s - loss: 12503.3150 - KL_divergence: 9.8053
 73/200 [=========>....................] - ETA: 1s - loss: 12523.9433 - KL_divergence: 9.7762
 79/200 [==========>...................] - ETA: 1s - loss: 12501.1851 - KL_divergence: 9.7794
 85/200 [===========>..................] - ETA: 1s - loss: 12506.9859 - KL_divergence: 9.7779
 91/200 [============>.................] - ETA: 0s - loss: 12503.4462 - KL_divergence: 9.7921
 97/200 [=============>................] - ETA: 0s - loss: 12495.6872 - KL_divergence: 9.8391
103/200 [==============>...............] - ETA: 0s - loss: 12506.7644 - KL_divergence: 9.8569
109/200 [===============>..............] - ETA: 0s - loss: 12526.7251 - KL_divergence: 9.8723
115/200 [================>.............] - ETA: 0s - loss: 12529.2800 - KL_divergence: 9.8547
121/200 [=================>............] - ETA: 0s - loss: 12536.7294 - KL_divergence: 9.8513
127/200 [==================>...........] - ETA: 0s - loss: 12523.3642 - KL_divergence: 9.8441
133/200 [==================>...........] - ETA: 0s - loss: 12502.7574 - KL_divergence: 9.8516
139/200 [===================>..........] - ETA: 0s - loss: 12506.6279 - KL_divergence: 9.8619
145/200 [====================>.........] - ETA: 0s - loss: 12512.1813 - KL_divergence: 9.8787
151/200 [=====================>........] - ETA: 0s - loss: 12502.9765 - KL_divergence: 9.9009
157/200 [======================>.......] - ETA: 0s - loss: 12510.4264 - KL_divergence: 9.8885
163/200 [=======================>......] - ETA: 0s - loss: 12505.5245 - KL_divergence: 9.8969
169/200 [========================>.....] - ETA: 0s - loss: 12510.8012 - KL_divergence: 9.8670
175/200 [=========================>....] - ETA: 0s - loss: 12521.6293 - KL_divergence: 9.8386
181/200 [==========================>...] - ETA: 0s - loss: 12528.5519 - KL_divergence: 9.8150
187/200 [===========================>..] - ETA: 0s - loss: 12534.2153 - KL_divergence: 9.8148
193/200 [===========================>..] - ETA: 0s - loss: 12534.7395 - KL_divergence: 9.8200
199/200 [============================>.] - ETA: 0s - loss: 12535.8034 - KL_divergence: 9.8154
200/200 [==============================] - 2s 10ms/step - loss: 12536.3655 - KL_divergence: 9.8171 - val_loss: 12686.3763 - val_KL_divergence: 10.0637
Epoch 53/100

  1/200 [..............................] - ETA: 1s - loss: 12462.4150 - KL_divergence: 8.9428
  7/200 [>.............................] - ETA: 1s - loss: 12521.7581 - KL_divergence: 9.4418
 13/200 [>.............................] - ETA: 1s - loss: 12544.0793 - KL_divergence: 9.6807
 19/200 [=>............................] - ETA: 1s - loss: 12466.9633 - KL_divergence: 9.6242
 25/200 [==>...........................] - ETA: 1s - loss: 12457.0446 - KL_divergence: 9.6438
 31/200 [===>..........................] - ETA: 1s - loss: 12459.7484 - KL_divergence: 9.5478
 37/200 [====>.........................] - ETA: 1s - loss: 12446.5661 - KL_divergence: 9.5754
 43/200 [=====>........................] - ETA: 1s - loss: 12484.5440 - KL_divergence: 9.5393
 49/200 [======>.......................] - ETA: 1s - loss: 12467.7705 - KL_divergence: 9.6667
 55/200 [=======>......................] - ETA: 1s - loss: 12461.0273 - KL_divergence: 9.6846
 61/200 [========>.....................] - ETA: 1s - loss: 12470.0723 - KL_divergence: 9.6799
 67/200 [=========>....................] - ETA: 1s - loss: 12465.2830 - KL_divergence: 9.7321
 73/200 [=========>....................] - ETA: 1s - loss: 12422.3210 - KL_divergence: 9.8157
 79/200 [==========>...................] - ETA: 1s - loss: 12422.7950 - KL_divergence: 9.8126
 85/200 [===========>..................] - ETA: 1s - loss: 12431.5273 - KL_divergence: 9.8256
 91/200 [============>.................] - ETA: 0s - loss: 12410.5686 - KL_divergence: 9.8212
 97/200 [=============>................] - ETA: 0s - loss: 12397.1609 - KL_divergence: 9.7915
103/200 [==============>...............] - ETA: 0s - loss: 12395.4341 - KL_divergence: 9.7794
108/200 [===============>..............] - ETA: 0s - loss: 12392.3762 - KL_divergence: 9.7866
114/200 [================>.............] - ETA: 0s - loss: 12399.3731 - KL_divergence: 9.7657
120/200 [=================>............] - ETA: 0s - loss: 12409.7815 - KL_divergence: 9.7264
126/200 [=================>............] - ETA: 0s - loss: 12405.0912 - KL_divergence: 9.7093
132/200 [==================>...........] - ETA: 0s - loss: 12392.9015 - KL_divergence: 9.7360
138/200 [===================>..........] - ETA: 0s - loss: 12386.4341 - KL_divergence: 9.7544
144/200 [====================>.........] - ETA: 0s - loss: 12394.5884 - KL_divergence: 9.7545
150/200 [=====================>........] - ETA: 0s - loss: 12399.1518 - KL_divergence: 9.7359
156/200 [======================>.......] - ETA: 0s - loss: 12386.9550 - KL_divergence: 9.7232
162/200 [=======================>......] - ETA: 0s - loss: 12393.4139 - KL_divergence: 9.7279
168/200 [========================>.....] - ETA: 0s - loss: 12407.9149 - KL_divergence: 9.6982
174/200 [=========================>....] - ETA: 0s - loss: 12410.7492 - KL_divergence: 9.6888
180/200 [==========================>...] - ETA: 0s - loss: 12413.9183 - KL_divergence: 9.6797
186/200 [==========================>...] - ETA: 0s - loss: 12410.7575 - KL_divergence: 9.6910
192/200 [===========================>..] - ETA: 0s - loss: 12412.7045 - KL_divergence: 9.6698
199/200 [============================>.] - ETA: 0s - loss: 12402.1106 - KL_divergence: 9.6958
200/200 [==============================] - 2s 10ms/step - loss: 12399.8840 - KL_divergence: 9.6918 - val_loss: 12781.0706 - val_KL_divergence: 9.8791
Epoch 54/100

  1/200 [..............................] - ETA: 1s - loss: 12641.8887 - KL_divergence: 9.9981
  7/200 [>.............................] - ETA: 1s - loss: 12594.2840 - KL_divergence: 10.2231
 13/200 [>.............................] - ETA: 1s - loss: 12609.9650 - KL_divergence: 9.9170 
 19/200 [=>............................] - ETA: 1s - loss: 12570.3151 - KL_divergence: 9.7687
 25/200 [==>...........................] - ETA: 1s - loss: 12544.9301 - KL_divergence: 9.6785
 31/200 [===>..........................] - ETA: 1s - loss: 12526.6096 - KL_divergence: 9.6458
 37/200 [====>.........................] - ETA: 1s - loss: 12540.8495 - KL_divergence: 9.6722
 43/200 [=====>........................] - ETA: 1s - loss: 12526.0019 - KL_divergence: 9.7299
 49/200 [======>.......................] - ETA: 1s - loss: 12502.5802 - KL_divergence: 9.8621
 55/200 [=======>......................] - ETA: 1s - loss: 12473.5444 - KL_divergence: 9.9110
 62/200 [========>.....................] - ETA: 1s - loss: 12463.6247 - KL_divergence: 10.0032
 68/200 [=========>....................] - ETA: 1s - loss: 12498.2073 - KL_divergence: 9.9533 
 74/200 [==========>...................] - ETA: 1s - loss: 12502.1573 - KL_divergence: 9.9884
 80/200 [===========>..................] - ETA: 1s - loss: 12513.3422 - KL_divergence: 9.9661
 86/200 [===========>..................] - ETA: 0s - loss: 12515.0730 - KL_divergence: 9.9631
 92/200 [============>.................] - ETA: 0s - loss: 12498.4614 - KL_divergence: 10.0041
 98/200 [=============>................] - ETA: 0s - loss: 12500.8123 - KL_divergence: 10.0239
104/200 [==============>...............] - ETA: 0s - loss: 12529.5539 - KL_divergence: 9.9779 
110/200 [===============>..............] - ETA: 0s - loss: 12543.2326 - KL_divergence: 10.0038
116/200 [================>.............] - ETA: 0s - loss: 12560.2965 - KL_divergence: 9.9838 
122/200 [=================>............] - ETA: 0s - loss: 12560.0184 - KL_divergence: 9.9802
128/200 [==================>...........] - ETA: 0s - loss: 12554.4865 - KL_divergence: 9.9851
135/200 [===================>..........] - ETA: 0s - loss: 12552.0735 - KL_divergence: 9.9454
141/200 [====================>.........] - ETA: 0s - loss: 12545.2769 - KL_divergence: 9.9241
147/200 [=====================>........] - ETA: 0s - loss: 12551.4489 - KL_divergence: 9.8894
154/200 [======================>.......] - ETA: 0s - loss: 12531.4502 - KL_divergence: 9.9191
160/200 [=======================>......] - ETA: 0s - loss: 12523.1869 - KL_divergence: 9.9019
166/200 [=======================>......] - ETA: 0s - loss: 12508.2928 - KL_divergence: 9.8825
173/200 [========================>.....] - ETA: 0s - loss: 12499.2602 - KL_divergence: 9.8702
180/200 [==========================>...] - ETA: 0s - loss: 12497.1728 - KL_divergence: 9.8792
187/200 [===========================>..] - ETA: 0s - loss: 12491.6853 - KL_divergence: 9.8661
194/200 [============================>.] - ETA: 0s - loss: 12502.6797 - KL_divergence: 9.8579
200/200 [==============================] - 2s 9ms/step - loss: 12507.9591 - KL_divergence: 9.8483 - val_loss: 12582.9290 - val_KL_divergence: 9.8173
Epoch 55/100

  1/200 [..............................] - ETA: 1s - loss: 12370.2002 - KL_divergence: 8.0505
  7/200 [>.............................] - ETA: 1s - loss: 12495.5791 - KL_divergence: 9.3183
 13/200 [>.............................] - ETA: 1s - loss: 12464.9815 - KL_divergence: 9.6645
 19/200 [=>............................] - ETA: 1s - loss: 12441.6896 - KL_divergence: 9.6165
 25/200 [==>...........................] - ETA: 1s - loss: 12344.4865 - KL_divergence: 9.6736
 31/200 [===>..........................] - ETA: 1s - loss: 12356.7440 - KL_divergence: 9.7146
 37/200 [====>.........................] - ETA: 1s - loss: 12371.6707 - KL_divergence: 9.6344
 43/200 [=====>........................] - ETA: 1s - loss: 12364.6617 - KL_divergence: 9.6192
 49/200 [======>.......................] - ETA: 1s - loss: 12377.3104 - KL_divergence: 9.6047
 55/200 [=======>......................] - ETA: 1s - loss: 12417.6692 - KL_divergence: 9.6194
 61/200 [========>.....................] - ETA: 1s - loss: 12412.2520 - KL_divergence: 9.5810
 67/200 [=========>....................] - ETA: 1s - loss: 12435.4736 - KL_divergence: 9.5917
 73/200 [=========>....................] - ETA: 1s - loss: 12441.8280 - KL_divergence: 9.6044
 79/200 [==========>...................] - ETA: 1s - loss: 12440.9936 - KL_divergence: 9.6329
 85/200 [===========>..................] - ETA: 1s - loss: 12454.1602 - KL_divergence: 9.6103
 91/200 [============>.................] - ETA: 0s - loss: 12457.0185 - KL_divergence: 9.6078
 97/200 [=============>................] - ETA: 0s - loss: 12454.0398 - KL_divergence: 9.5760
103/200 [==============>...............] - ETA: 0s - loss: 12457.6677 - KL_divergence: 9.5819
109/200 [===============>..............] - ETA: 0s - loss: 12454.4468 - KL_divergence: 9.6075
115/200 [================>.............] - ETA: 0s - loss: 12418.7742 - KL_divergence: 9.6614
121/200 [=================>............] - ETA: 0s - loss: 12418.1558 - KL_divergence: 9.6403
127/200 [==================>...........] - ETA: 0s - loss: 12423.2179 - KL_divergence: 9.6525
133/200 [==================>...........] - ETA: 0s - loss: 12424.3726 - KL_divergence: 9.6180
139/200 [===================>..........] - ETA: 0s - loss: 12423.3902 - KL_divergence: 9.6266
145/200 [====================>.........] - ETA: 0s - loss: 12416.0446 - KL_divergence: 9.6781
151/200 [=====================>........] - ETA: 0s - loss: 12415.0780 - KL_divergence: 9.7199
157/200 [======================>.......] - ETA: 0s - loss: 12416.0574 - KL_divergence: 9.6924
163/200 [=======================>......] - ETA: 0s - loss: 12409.9062 - KL_divergence: 9.7285
169/200 [========================>.....] - ETA: 0s - loss: 12404.9065 - KL_divergence: 9.7249
175/200 [=========================>....] - ETA: 0s - loss: 12405.3121 - KL_divergence: 9.7530
181/200 [==========================>...] - ETA: 0s - loss: 12410.1718 - KL_divergence: 9.7317
187/200 [===========================>..] - ETA: 0s - loss: 12414.5222 - KL_divergence: 9.7269
193/200 [===========================>..] - ETA: 0s - loss: 12408.3755 - KL_divergence: 9.7557
199/200 [============================>.] - ETA: 0s - loss: 12410.2760 - KL_divergence: 9.7659
200/200 [==============================] - 2s 10ms/step - loss: 12411.6426 - KL_divergence: 9.7676 - val_loss: 12817.2439 - val_KL_divergence: 9.7091
Epoch 56/100

  1/200 [..............................] - ETA: 1s - loss: 12561.1240 - KL_divergence: 8.9426
  7/200 [>.............................] - ETA: 1s - loss: 12320.3422 - KL_divergence: 9.8658
 13/200 [>.............................] - ETA: 1s - loss: 12447.7872 - KL_divergence: 9.8310
 19/200 [=>............................] - ETA: 1s - loss: 12554.5904 - KL_divergence: 9.7130
 25/200 [==>...........................] - ETA: 1s - loss: 12601.7980 - KL_divergence: 9.7108
 31/200 [===>..........................] - ETA: 1s - loss: 12568.5730 - KL_divergence: 9.8547
 37/200 [====>.........................] - ETA: 1s - loss: 12561.1741 - KL_divergence: 9.8471
 43/200 [=====>........................] - ETA: 1s - loss: 12544.0670 - KL_divergence: 9.7996
 49/200 [======>.......................] - ETA: 1s - loss: 12517.6736 - KL_divergence: 9.7963
 55/200 [=======>......................] - ETA: 1s - loss: 12536.0357 - KL_divergence: 9.7444
 62/200 [========>.....................] - ETA: 1s - loss: 12500.7552 - KL_divergence: 9.7253
 68/200 [=========>....................] - ETA: 1s - loss: 12505.6856 - KL_divergence: 9.6708
 74/200 [==========>...................] - ETA: 1s - loss: 12524.5841 - KL_divergence: 9.6137
 80/200 [===========>..................] - ETA: 1s - loss: 12523.0977 - KL_divergence: 9.6269
 86/200 [===========>..................] - ETA: 1s - loss: 12522.3998 - KL_divergence: 9.6726
 92/200 [============>.................] - ETA: 0s - loss: 12493.7510 - KL_divergence: 9.7480
 98/200 [=============>................] - ETA: 0s - loss: 12484.2428 - KL_divergence: 9.7831
104/200 [==============>...............] - ETA: 0s - loss: 12489.4587 - KL_divergence: 9.7850
110/200 [===============>..............] - ETA: 0s - loss: 12498.2015 - KL_divergence: 9.7838
116/200 [================>.............] - ETA: 0s - loss: 12496.5105 - KL_divergence: 9.7650
122/200 [=================>............] - ETA: 0s - loss: 12487.4282 - KL_divergence: 9.7442
128/200 [==================>...........] - ETA: 0s - loss: 12483.9904 - KL_divergence: 9.7747
134/200 [===================>..........] - ETA: 0s - loss: 12469.1937 - KL_divergence: 9.7925
140/200 [====================>.........] - ETA: 0s - loss: 12474.4439 - KL_divergence: 9.7988
146/200 [====================>.........] - ETA: 0s - loss: 12466.1470 - KL_divergence: 9.8297
152/200 [=====================>........] - ETA: 0s - loss: 12455.7131 - KL_divergence: 9.8240
158/200 [======================>.......] - ETA: 0s - loss: 12458.5739 - KL_divergence: 9.8091
164/200 [=======================>......] - ETA: 0s - loss: 12461.3941 - KL_divergence: 9.7939
170/200 [========================>.....] - ETA: 0s - loss: 12444.9693 - KL_divergence: 9.8077
176/200 [=========================>....] - ETA: 0s - loss: 12440.4889 - KL_divergence: 9.8267
182/200 [==========================>...] - ETA: 0s - loss: 12442.0982 - KL_divergence: 9.8332
188/200 [===========================>..] - ETA: 0s - loss: 12440.3117 - KL_divergence: 9.8487
194/200 [============================>.] - ETA: 0s - loss: 12440.4372 - KL_divergence: 9.8434
200/200 [==============================] - 2s 10ms/step - loss: 12446.6396 - KL_divergence: 9.8524 - val_loss: 12629.2627 - val_KL_divergence: 10.1919
Epoch 57/100

  1/200 [..............................] - ETA: 1s - loss: 11808.1035 - KL_divergence: 10.8711
  7/200 [>.............................] - ETA: 1s - loss: 12404.2051 - KL_divergence: 9.7544 
 13/200 [>.............................] - ETA: 1s - loss: 12550.0395 - KL_divergence: 9.5252
 19/200 [=>............................] - ETA: 1s - loss: 12460.7239 - KL_divergence: 9.6905
 25/200 [==>...........................] - ETA: 1s - loss: 12448.1421 - KL_divergence: 9.6333
 31/200 [===>..........................] - ETA: 1s - loss: 12498.2794 - KL_divergence: 9.4453
 37/200 [====>.........................] - ETA: 1s - loss: 12520.6791 - KL_divergence: 9.4403
 43/200 [=====>........................] - ETA: 1s - loss: 12497.0198 - KL_divergence: 9.4753
 49/200 [======>.......................] - ETA: 1s - loss: 12521.5224 - KL_divergence: 9.5174
 55/200 [=======>......................] - ETA: 1s - loss: 12517.7862 - KL_divergence: 9.5384
 60/200 [========>.....................] - ETA: 1s - loss: 12483.3677 - KL_divergence: 9.5980
 66/200 [========>.....................] - ETA: 1s - loss: 12488.8736 - KL_divergence: 9.7073
 72/200 [=========>....................] - ETA: 1s - loss: 12483.5772 - KL_divergence: 9.6352
 78/200 [==========>...................] - ETA: 1s - loss: 12456.1680 - KL_divergence: 9.6994
 84/200 [===========>..................] - ETA: 1s - loss: 12463.7304 - KL_divergence: 9.6723
 90/200 [============>.................] - ETA: 1s - loss: 12457.1661 - KL_divergence: 9.7331
 96/200 [=============>................] - ETA: 0s - loss: 12437.9261 - KL_divergence: 9.7276
102/200 [==============>...............] - ETA: 0s - loss: 12408.7444 - KL_divergence: 9.7493
108/200 [===============>..............] - ETA: 0s - loss: 12404.4254 - KL_divergence: 9.7502
114/200 [================>.............] - ETA: 0s - loss: 12393.2282 - KL_divergence: 9.7689
120/200 [=================>............] - ETA: 0s - loss: 12400.6790 - KL_divergence: 9.7515
126/200 [=================>............] - ETA: 0s - loss: 12408.5209 - KL_divergence: 9.7782
133/200 [==================>...........] - ETA: 0s - loss: 12397.6084 - KL_divergence: 9.8129
139/200 [===================>..........] - ETA: 0s - loss: 12387.9411 - KL_divergence: 9.8309
146/200 [====================>.........] - ETA: 0s - loss: 12385.7984 - KL_divergence: 9.8204
152/200 [=====================>........] - ETA: 0s - loss: 12382.1985 - KL_divergence: 9.8206
158/200 [======================>.......] - ETA: 0s - loss: 12381.3819 - KL_divergence: 9.8167
164/200 [=======================>......] - ETA: 0s - loss: 12376.5160 - KL_divergence: 9.8128
170/200 [========================>.....] - ETA: 0s - loss: 12381.0287 - KL_divergence: 9.7977
176/200 [=========================>....] - ETA: 0s - loss: 12391.8808 - KL_divergence: 9.7977
183/200 [==========================>...] - ETA: 0s - loss: 12395.9371 - KL_divergence: 9.7965
190/200 [===========================>..] - ETA: 0s - loss: 12404.3664 - KL_divergence: 9.7917
196/200 [============================>.] - ETA: 0s - loss: 12420.3176 - KL_divergence: 9.8069
200/200 [==============================] - 2s 10ms/step - loss: 12422.8002 - KL_divergence: 9.8053 - val_loss: 12580.1789 - val_KL_divergence: 9.8536
Epoch 58/100

  1/200 [..............................] - ETA: 1s - loss: 12403.8535 - KL_divergence: 9.2355
  7/200 [>.............................] - ETA: 1s - loss: 12631.1842 - KL_divergence: 9.0466
 13/200 [>.............................] - ETA: 1s - loss: 12593.0351 - KL_divergence: 9.4212
 19/200 [=>............................] - ETA: 1s - loss: 12450.6534 - KL_divergence: 9.6331
 25/200 [==>...........................] - ETA: 1s - loss: 12488.6726 - KL_divergence: 9.7127
 31/200 [===>..........................] - ETA: 1s - loss: 12497.2081 - KL_divergence: 9.6781
 37/200 [====>.........................] - ETA: 1s - loss: 12495.8883 - KL_divergence: 9.6762
 43/200 [=====>........................] - ETA: 1s - loss: 12484.3803 - KL_divergence: 9.7012
 49/200 [======>.......................] - ETA: 1s - loss: 12454.0707 - KL_divergence: 9.7896
 55/200 [=======>......................] - ETA: 1s - loss: 12418.7585 - KL_divergence: 9.8148
 61/200 [========>.....................] - ETA: 1s - loss: 12403.6828 - KL_divergence: 9.8258
 67/200 [=========>....................] - ETA: 1s - loss: 12403.2138 - KL_divergence: 9.8987
 73/200 [=========>....................] - ETA: 1s - loss: 12382.7195 - KL_divergence: 9.9051
 79/200 [==========>...................] - ETA: 1s - loss: 12393.2661 - KL_divergence: 9.9044
 85/200 [===========>..................] - ETA: 1s - loss: 12380.9401 - KL_divergence: 9.8870
 92/200 [============>.................] - ETA: 0s - loss: 12386.3851 - KL_divergence: 9.8476
 99/200 [=============>................] - ETA: 0s - loss: 12409.3780 - KL_divergence: 9.8408
105/200 [==============>...............] - ETA: 0s - loss: 12407.6054 - KL_divergence: 9.8337
111/200 [===============>..............] - ETA: 0s - loss: 12400.4981 - KL_divergence: 9.8458
117/200 [================>.............] - ETA: 0s - loss: 12388.5734 - KL_divergence: 9.8736
123/200 [=================>............] - ETA: 0s - loss: 12391.3221 - KL_divergence: 9.8619
128/200 [==================>...........] - ETA: 0s - loss: 12392.6015 - KL_divergence: 9.8935
134/200 [===================>..........] - ETA: 0s - loss: 12402.3405 - KL_divergence: 9.8752
140/200 [====================>.........] - ETA: 0s - loss: 12409.4624 - KL_divergence: 9.8688
146/200 [====================>.........] - ETA: 0s - loss: 12403.2818 - KL_divergence: 9.8749
152/200 [=====================>........] - ETA: 0s - loss: 12407.5713 - KL_divergence: 9.8483
158/200 [======================>.......] - ETA: 0s - loss: 12401.2079 - KL_divergence: 9.8545
164/200 [=======================>......] - ETA: 0s - loss: 12405.6910 - KL_divergence: 9.8332
170/200 [========================>.....] - ETA: 0s - loss: 12403.4226 - KL_divergence: 9.8443
176/200 [=========================>....] - ETA: 0s - loss: 12403.9207 - KL_divergence: 9.8429
182/200 [==========================>...] - ETA: 0s - loss: 12413.2970 - KL_divergence: 9.8357
188/200 [===========================>..] - ETA: 0s - loss: 12416.8336 - KL_divergence: 9.8345
194/200 [============================>.] - ETA: 0s - loss: 12418.1172 - KL_divergence: 9.8178
200/200 [==============================] - 2s 10ms/step - loss: 12406.5855 - KL_divergence: 9.8305 - val_loss: 12731.0576 - val_KL_divergence: 9.4830
Epoch 59/100

  1/200 [..............................] - ETA: 1s - loss: 12069.6904 - KL_divergence: 9.8877
  7/200 [>.............................] - ETA: 1s - loss: 12371.0551 - KL_divergence: 9.6035
 13/200 [>.............................] - ETA: 1s - loss: 12395.2891 - KL_divergence: 9.6127
 19/200 [=>............................] - ETA: 1s - loss: 12354.7141 - KL_divergence: 9.6161
 25/200 [==>...........................] - ETA: 1s - loss: 12291.4861 - KL_divergence: 9.7324
 31/200 [===>..........................] - ETA: 1s - loss: 12263.9845 - KL_divergence: 9.7692
 37/200 [====>.........................] - ETA: 1s - loss: 12245.0866 - KL_divergence: 9.8288
 43/200 [=====>........................] - ETA: 1s - loss: 12249.9132 - KL_divergence: 9.7659
 49/200 [======>.......................] - ETA: 1s - loss: 12247.8421 - KL_divergence: 9.7558
 56/200 [=======>......................] - ETA: 1s - loss: 12303.8233 - KL_divergence: 9.7558
 63/200 [========>.....................] - ETA: 1s - loss: 12301.4205 - KL_divergence: 9.8256
 69/200 [=========>....................] - ETA: 1s - loss: 12332.4084 - KL_divergence: 9.7765
 76/200 [==========>...................] - ETA: 1s - loss: 12326.5792 - KL_divergence: 9.7630
 83/200 [===========>..................] - ETA: 1s - loss: 12361.4224 - KL_divergence: 9.7088
 89/200 [============>.................] - ETA: 0s - loss: 12330.8475 - KL_divergence: 9.7377
 95/200 [=============>................] - ETA: 0s - loss: 12333.8284 - KL_divergence: 9.6850
101/200 [==============>...............] - ETA: 0s - loss: 12329.4161 - KL_divergence: 9.6973
107/200 [===============>..............] - ETA: 0s - loss: 12320.6993 - KL_divergence: 9.6879
113/200 [===============>..............] - ETA: 0s - loss: 12344.1630 - KL_divergence: 9.6863
119/200 [================>.............] - ETA: 0s - loss: 12345.6936 - KL_divergence: 9.7104
125/200 [=================>............] - ETA: 0s - loss: 12350.1822 - KL_divergence: 9.7067
131/200 [==================>...........] - ETA: 0s - loss: 12359.5550 - KL_divergence: 9.7123
137/200 [===================>..........] - ETA: 0s - loss: 12363.4228 - KL_divergence: 9.7371
143/200 [====================>.........] - ETA: 0s - loss: 12359.4197 - KL_divergence: 9.7549
149/200 [=====================>........] - ETA: 0s - loss: 12359.3127 - KL_divergence: 9.7715
155/200 [======================>.......] - ETA: 0s - loss: 12348.4178 - KL_divergence: 9.7963
161/200 [=======================>......] - ETA: 0s - loss: 12353.6086 - KL_divergence: 9.7776
167/200 [========================>.....] - ETA: 0s - loss: 12348.8692 - KL_divergence: 9.7967
173/200 [========================>.....] - ETA: 0s - loss: 12354.1742 - KL_divergence: 9.8002
179/200 [=========================>....] - ETA: 0s - loss: 12364.7175 - KL_divergence: 9.7845
185/200 [==========================>...] - ETA: 0s - loss: 12372.4062 - KL_divergence: 9.7880
191/200 [===========================>..] - ETA: 0s - loss: 12366.2563 - KL_divergence: 9.8031
197/200 [============================>.] - ETA: 0s - loss: 12370.3028 - KL_divergence: 9.8028
200/200 [==============================] - 2s 10ms/step - loss: 12360.3044 - KL_divergence: 9.8011 - val_loss: 12575.1695 - val_KL_divergence: 9.5453
Epoch 60/100

  1/200 [..............................] - ETA: 1s - loss: 12703.3936 - KL_divergence: 9.3200
  7/200 [>.............................] - ETA: 1s - loss: 12905.3217 - KL_divergence: 9.2161
 13/200 [>.............................] - ETA: 1s - loss: 12635.5959 - KL_divergence: 9.2556
 18/200 [=>............................] - ETA: 1s - loss: 12524.8446 - KL_divergence: 9.3527
 24/200 [==>...........................] - ETA: 1s - loss: 12433.1569 - KL_divergence: 9.5307
 30/200 [===>..........................] - ETA: 1s - loss: 12453.1078 - KL_divergence: 9.5624
 36/200 [====>.........................] - ETA: 1s - loss: 12463.5514 - KL_divergence: 9.4894
 42/200 [=====>........................] - ETA: 1s - loss: 12449.0210 - KL_divergence: 9.5660
 48/200 [======>.......................] - ETA: 1s - loss: 12392.3238 - KL_divergence: 9.6991
 54/200 [=======>......................] - ETA: 1s - loss: 12381.8811 - KL_divergence: 9.6976
 60/200 [========>.....................] - ETA: 1s - loss: 12359.6244 - KL_divergence: 9.7411
 66/200 [========>.....................] - ETA: 1s - loss: 12388.5708 - KL_divergence: 9.7393
 72/200 [=========>....................] - ETA: 1s - loss: 12393.1413 - KL_divergence: 9.7585
 78/200 [==========>...................] - ETA: 1s - loss: 12421.6923 - KL_divergence: 9.7345
 84/200 [===========>..................] - ETA: 1s - loss: 12414.4072 - KL_divergence: 9.7251
 90/200 [============>.................] - ETA: 1s - loss: 12393.4809 - KL_divergence: 9.7735
 96/200 [=============>................] - ETA: 0s - loss: 12392.4652 - KL_divergence: 9.8050
102/200 [==============>...............] - ETA: 0s - loss: 12383.3692 - KL_divergence: 9.8028
108/200 [===============>..............] - ETA: 0s - loss: 12372.8497 - KL_divergence: 9.8158
114/200 [================>.............] - ETA: 0s - loss: 12373.4385 - KL_divergence: 9.8467
120/200 [=================>............] - ETA: 0s - loss: 12373.9441 - KL_divergence: 9.8580
126/200 [=================>............] - ETA: 0s - loss: 12378.3919 - KL_divergence: 9.8335
132/200 [==================>...........] - ETA: 0s - loss: 12391.6204 - KL_divergence: 9.8333
138/200 [===================>..........] - ETA: 0s - loss: 12393.8093 - KL_divergence: 9.8329
144/200 [====================>.........] - ETA: 0s - loss: 12409.8278 - KL_divergence: 9.8102
150/200 [=====================>........] - ETA: 0s - loss: 12409.7908 - KL_divergence: 9.8318
157/200 [======================>.......] - ETA: 0s - loss: 12404.3528 - KL_divergence: 9.8352
164/200 [=======================>......] - ETA: 0s - loss: 12417.5137 - KL_divergence: 9.8275
171/200 [========================>.....] - ETA: 0s - loss: 12420.9400 - KL_divergence: 9.8255
177/200 [=========================>....] - ETA: 0s - loss: 12421.7949 - KL_divergence: 9.8323
183/200 [==========================>...] - ETA: 0s - loss: 12426.0802 - KL_divergence: 9.8248
189/200 [===========================>..] - ETA: 0s - loss: 12422.0995 - KL_divergence: 9.8390
194/200 [============================>.] - ETA: 0s - loss: 12416.3040 - KL_divergence: 9.8557
200/200 [==============================] - 2s 10ms/step - loss: 12415.9835 - KL_divergence: 9.8457 - val_loss: 12660.2447 - val_KL_divergence: 9.3493
Epoch 61/100

  1/200 [..............................] - ETA: 1s - loss: 11162.5283 - KL_divergence: 9.0434
  6/200 [..............................] - ETA: 1s - loss: 12444.5881 - KL_divergence: 8.8553
 12/200 [>.............................] - ETA: 1s - loss: 12371.1280 - KL_divergence: 9.2743
 18/200 [=>............................] - ETA: 1s - loss: 12318.3596 - KL_divergence: 9.3105
 24/200 [==>...........................] - ETA: 1s - loss: 12323.3726 - KL_divergence: 9.2900
 30/200 [===>..........................] - ETA: 1s - loss: 12282.3301 - KL_divergence: 9.3973
 36/200 [====>.........................] - ETA: 1s - loss: 12240.6115 - KL_divergence: 9.6425
 42/200 [=====>........................] - ETA: 1s - loss: 12257.6362 - KL_divergence: 9.7321
 48/200 [======>.......................] - ETA: 1s - loss: 12279.9921 - KL_divergence: 9.6891
 54/200 [=======>......................] - ETA: 1s - loss: 12357.5110 - KL_divergence: 9.6266
 60/200 [========>.....................] - ETA: 1s - loss: 12348.1516 - KL_divergence: 9.6208
 66/200 [========>.....................] - ETA: 1s - loss: 12362.1577 - KL_divergence: 9.6031
 72/200 [=========>....................] - ETA: 1s - loss: 12343.4660 - KL_divergence: 9.6016
 78/200 [==========>...................] - ETA: 1s - loss: 12356.0081 - KL_divergence: 9.5641
 84/200 [===========>..................] - ETA: 1s - loss: 12335.0035 - KL_divergence: 9.5422
 90/200 [============>.................] - ETA: 1s - loss: 12333.6154 - KL_divergence: 9.5345
 96/200 [=============>................] - ETA: 0s - loss: 12312.7427 - KL_divergence: 9.5554
103/200 [==============>...............] - ETA: 0s - loss: 12317.4916 - KL_divergence: 9.5566
109/200 [===============>..............] - ETA: 0s - loss: 12332.5353 - KL_divergence: 9.5431
115/200 [================>.............] - ETA: 0s - loss: 12319.9763 - KL_divergence: 9.5502
121/200 [=================>............] - ETA: 0s - loss: 12332.4171 - KL_divergence: 9.5363
127/200 [==================>...........] - ETA: 0s - loss: 12330.5247 - KL_divergence: 9.5674
133/200 [==================>...........] - ETA: 0s - loss: 12338.2807 - KL_divergence: 9.6013
139/200 [===================>..........] - ETA: 0s - loss: 12357.9591 - KL_divergence: 9.6072
145/200 [====================>.........] - ETA: 0s - loss: 12363.5839 - KL_divergence: 9.6163
152/200 [=====================>........] - ETA: 0s - loss: 12369.2531 - KL_divergence: 9.5980
158/200 [======================>.......] - ETA: 0s - loss: 12368.4542 - KL_divergence: 9.6009
164/200 [=======================>......] - ETA: 0s - loss: 12366.8443 - KL_divergence: 9.6201
170/200 [========================>.....] - ETA: 0s - loss: 12361.2330 - KL_divergence: 9.6164
176/200 [=========================>....] - ETA: 0s - loss: 12355.2512 - KL_divergence: 9.6054
182/200 [==========================>...] - ETA: 0s - loss: 12345.0950 - KL_divergence: 9.6154
188/200 [===========================>..] - ETA: 0s - loss: 12350.2640 - KL_divergence: 9.6340
194/200 [============================>.] - ETA: 0s - loss: 12355.5501 - KL_divergence: 9.6483
200/200 [==============================] - 2s 10ms/step - loss: 12351.8944 - KL_divergence: 9.6500 - val_loss: 12697.1785 - val_KL_divergence: 9.7120
Epoch 62/100

  1/200 [..............................] - ETA: 1s - loss: 12478.5859 - KL_divergence: 9.7311
  7/200 [>.............................] - ETA: 1s - loss: 12442.7884 - KL_divergence: 9.8009
 13/200 [>.............................] - ETA: 1s - loss: 12438.4505 - KL_divergence: 9.8041
 19/200 [=>............................] - ETA: 1s - loss: 12436.4620 - KL_divergence: 9.9319
 25/200 [==>...........................] - ETA: 1s - loss: 12429.6221 - KL_divergence: 10.0904
 31/200 [===>..........................] - ETA: 1s - loss: 12450.7694 - KL_divergence: 10.1209
 37/200 [====>.........................] - ETA: 1s - loss: 12493.5638 - KL_divergence: 10.0721
 43/200 [=====>........................] - ETA: 1s - loss: 12450.3420 - KL_divergence: 10.1458
 49/200 [======>.......................] - ETA: 1s - loss: 12425.5895 - KL_divergence: 10.0608
 55/200 [=======>......................] - ETA: 1s - loss: 12449.0437 - KL_divergence: 9.9827 
 62/200 [========>.....................] - ETA: 1s - loss: 12434.8847 - KL_divergence: 9.8867
 68/200 [=========>....................] - ETA: 1s - loss: 12427.9101 - KL_divergence: 9.8974
 75/200 [==========>...................] - ETA: 1s - loss: 12411.6027 - KL_divergence: 9.8807
 81/200 [===========>..................] - ETA: 1s - loss: 12417.9876 - KL_divergence: 9.8440
 87/200 [============>.................] - ETA: 0s - loss: 12445.5850 - KL_divergence: 9.8058
 93/200 [============>.................] - ETA: 0s - loss: 12448.6057 - KL_divergence: 9.7870
 99/200 [=============>................] - ETA: 0s - loss: 12432.3492 - KL_divergence: 9.7839
105/200 [==============>...............] - ETA: 0s - loss: 12423.6330 - KL_divergence: 9.8082
111/200 [===============>..............] - ETA: 0s - loss: 12410.7436 - KL_divergence: 9.8018
117/200 [================>.............] - ETA: 0s - loss: 12399.5285 - KL_divergence: 9.8440
123/200 [=================>............] - ETA: 0s - loss: 12400.6400 - KL_divergence: 9.8347
129/200 [==================>...........] - ETA: 0s - loss: 12404.8852 - KL_divergence: 9.8075
135/200 [===================>..........] - ETA: 0s - loss: 12403.0764 - KL_divergence: 9.7993
141/200 [====================>.........] - ETA: 0s - loss: 12411.2774 - KL_divergence: 9.7983
148/200 [=====================>........] - ETA: 0s - loss: 12402.1046 - KL_divergence: 9.7897
154/200 [======================>.......] - ETA: 0s - loss: 12393.7137 - KL_divergence: 9.8080
160/200 [=======================>......] - ETA: 0s - loss: 12398.5557 - KL_divergence: 9.8024
166/200 [=======================>......] - ETA: 0s - loss: 12384.1111 - KL_divergence: 9.8355
173/200 [========================>.....] - ETA: 0s - loss: 12382.2024 - KL_divergence: 9.8273
179/200 [=========================>....] - ETA: 0s - loss: 12383.7883 - KL_divergence: 9.8239
185/200 [==========================>...] - ETA: 0s - loss: 12378.7493 - KL_divergence: 9.8281
191/200 [===========================>..] - ETA: 0s - loss: 12379.1315 - KL_divergence: 9.8298
197/200 [============================>.] - ETA: 0s - loss: 12384.4660 - KL_divergence: 9.8241
200/200 [==============================] - 2s 10ms/step - loss: 12390.6490 - KL_divergence: 9.8112 - val_loss: 12514.9660 - val_KL_divergence: 9.5917
Epoch 63/100

  1/200 [..............................] - ETA: 1s - loss: 11784.9229 - KL_divergence: 10.2285
  7/200 [>.............................] - ETA: 1s - loss: 12186.7626 - KL_divergence: 9.4076 
 14/200 [=>............................] - ETA: 1s - loss: 12408.5508 - KL_divergence: 9.3417
 21/200 [==>...........................] - ETA: 1s - loss: 12365.5680 - KL_divergence: 9.6439
 28/200 [===>..........................] - ETA: 1s - loss: 12388.3407 - KL_divergence: 9.5434
 35/200 [====>.........................] - ETA: 1s - loss: 12361.6538 - KL_divergence: 9.6968
 42/200 [=====>........................] - ETA: 1s - loss: 12404.3115 - KL_divergence: 9.6800
 49/200 [======>.......................] - ETA: 1s - loss: 12381.3053 - KL_divergence: 9.6769
 55/200 [=======>......................] - ETA: 1s - loss: 12400.7531 - KL_divergence: 9.6781
 61/200 [========>.....................] - ETA: 1s - loss: 12391.7207 - KL_divergence: 9.6186
 67/200 [=========>....................] - ETA: 1s - loss: 12431.3236 - KL_divergence: 9.6067
 74/200 [==========>...................] - ETA: 1s - loss: 12428.3326 - KL_divergence: 9.5939
 80/200 [===========>..................] - ETA: 0s - loss: 12423.1709 - KL_divergence: 9.6421
 87/200 [============>.................] - ETA: 0s - loss: 12408.6042 - KL_divergence: 9.6720
 94/200 [=============>................] - ETA: 0s - loss: 12391.9451 - KL_divergence: 9.6989
100/200 [==============>...............] - ETA: 0s - loss: 12417.5033 - KL_divergence: 9.6817
106/200 [==============>...............] - ETA: 0s - loss: 12419.7064 - KL_divergence: 9.6887
112/200 [===============>..............] - ETA: 0s - loss: 12424.6040 - KL_divergence: 9.6816
118/200 [================>.............] - ETA: 0s - loss: 12410.8187 - KL_divergence: 9.6819
124/200 [=================>............] - ETA: 0s - loss: 12416.3945 - KL_divergence: 9.6962
130/200 [==================>...........] - ETA: 0s - loss: 12410.3490 - KL_divergence: 9.7071
136/200 [===================>..........] - ETA: 0s - loss: 12422.7454 - KL_divergence: 9.6980
142/200 [====================>.........] - ETA: 0s - loss: 12412.7883 - KL_divergence: 9.7258
149/200 [=====================>........] - ETA: 0s - loss: 12410.6288 - KL_divergence: 9.7266
156/200 [======================>.......] - ETA: 0s - loss: 12393.1133 - KL_divergence: 9.7679
162/200 [=======================>......] - ETA: 0s - loss: 12386.9601 - KL_divergence: 9.8173
168/200 [========================>.....] - ETA: 0s - loss: 12383.6293 - KL_divergence: 9.8167
175/200 [=========================>....] - ETA: 0s - loss: 12402.9215 - KL_divergence: 9.7785
182/200 [==========================>...] - ETA: 0s - loss: 12398.5166 - KL_divergence: 9.7939
188/200 [===========================>..] - ETA: 0s - loss: 12402.4709 - KL_divergence: 9.8090
194/200 [============================>.] - ETA: 0s - loss: 12408.3928 - KL_divergence: 9.7848
200/200 [==============================] - 2s 10ms/step - loss: 12406.3300 - KL_divergence: 9.7890 - val_loss: 12611.4214 - val_KL_divergence: 9.7954
Epoch 64/100

  1/200 [..............................] - ETA: 1s - loss: 12972.1924 - KL_divergence: 9.6044
  7/200 [>.............................] - ETA: 1s - loss: 12352.2959 - KL_divergence: 10.0705
 12/200 [>.............................] - ETA: 1s - loss: 12287.1733 - KL_divergence: 10.1178
 18/200 [=>............................] - ETA: 1s - loss: 12202.1028 - KL_divergence: 10.1565
 24/200 [==>...........................] - ETA: 1s - loss: 12190.6670 - KL_divergence: 10.3230
 30/200 [===>..........................] - ETA: 1s - loss: 12149.2413 - KL_divergence: 10.3135
 36/200 [====>.........................] - ETA: 1s - loss: 12143.0076 - KL_divergence: 10.2113
 42/200 [=====>........................] - ETA: 1s - loss: 12163.5996 - KL_divergence: 10.2015
 48/200 [======>.......................] - ETA: 1s - loss: 12159.4529 - KL_divergence: 10.1647
 54/200 [=======>......................] - ETA: 1s - loss: 12198.5379 - KL_divergence: 10.0926
 61/200 [========>.....................] - ETA: 1s - loss: 12219.9335 - KL_divergence: 10.0273
 67/200 [=========>....................] - ETA: 1s - loss: 12235.0882 - KL_divergence: 10.1144
 73/200 [=========>....................] - ETA: 1s - loss: 12265.7550 - KL_divergence: 10.0577
 79/200 [==========>...................] - ETA: 1s - loss: 12278.7693 - KL_divergence: 10.0448
 85/200 [===========>..................] - ETA: 1s - loss: 12281.5214 - KL_divergence: 10.0447
 91/200 [============>.................] - ETA: 0s - loss: 12301.8938 - KL_divergence: 10.0322
 97/200 [=============>................] - ETA: 0s - loss: 12301.6490 - KL_divergence: 9.9982 
103/200 [==============>...............] - ETA: 0s - loss: 12306.9621 - KL_divergence: 9.9797
109/200 [===============>..............] - ETA: 0s - loss: 12315.5282 - KL_divergence: 9.9288
115/200 [================>.............] - ETA: 0s - loss: 12304.6198 - KL_divergence: 9.9082
121/200 [=================>............] - ETA: 0s - loss: 12308.1161 - KL_divergence: 9.8759
127/200 [==================>...........] - ETA: 0s - loss: 12301.7855 - KL_divergence: 9.8634
133/200 [==================>...........] - ETA: 0s - loss: 12299.0170 - KL_divergence: 9.8273
139/200 [===================>..........] - ETA: 0s - loss: 12300.8091 - KL_divergence: 9.7973
145/200 [====================>.........] - ETA: 0s - loss: 12313.6831 - KL_divergence: 9.7560
151/200 [=====================>........] - ETA: 0s - loss: 12326.0285 - KL_divergence: 9.7468
157/200 [======================>.......] - ETA: 0s - loss: 12315.8955 - KL_divergence: 9.7493
163/200 [=======================>......] - ETA: 0s - loss: 12317.7357 - KL_divergence: 9.7515
169/200 [========================>.....] - ETA: 0s - loss: 12319.1781 - KL_divergence: 9.7692
175/200 [=========================>....] - ETA: 0s - loss: 12314.9981 - KL_divergence: 9.7608
181/200 [==========================>...] - ETA: 0s - loss: 12317.4082 - KL_divergence: 9.7556
187/200 [===========================>..] - ETA: 0s - loss: 12311.3888 - KL_divergence: 9.7656
193/200 [===========================>..] - ETA: 0s - loss: 12303.3376 - KL_divergence: 9.7949
199/200 [============================>.] - ETA: 0s - loss: 12308.8301 - KL_divergence: 9.7844
200/200 [==============================] - 2s 10ms/step - loss: 12308.2400 - KL_divergence: 9.7879 - val_loss: 12556.0266 - val_KL_divergence: 9.5649
Epoch 65/100

  1/200 [..............................] - ETA: 1s - loss: 12040.3154 - KL_divergence: 10.7179
  7/200 [>.............................] - ETA: 1s - loss: 12247.7497 - KL_divergence: 9.8930 
 13/200 [>.............................] - ETA: 1s - loss: 12276.9810 - KL_divergence: 9.7651
 19/200 [=>............................] - ETA: 1s - loss: 12288.5785 - KL_divergence: 9.8396
 25/200 [==>...........................] - ETA: 1s - loss: 12222.2186 - KL_divergence: 10.0569
 31/200 [===>..........................] - ETA: 1s - loss: 12267.4102 - KL_divergence: 9.8848 
 37/200 [====>.........................] - ETA: 1s - loss: 12243.1424 - KL_divergence: 9.8319
 43/200 [=====>........................] - ETA: 1s - loss: 12240.4776 - KL_divergence: 9.8902
 49/200 [======>.......................] - ETA: 1s - loss: 12219.7595 - KL_divergence: 9.9277
 55/200 [=======>......................] - ETA: 1s - loss: 12238.1388 - KL_divergence: 9.8767
 61/200 [========>.....................] - ETA: 1s - loss: 12231.3402 - KL_divergence: 9.8991
 67/200 [=========>....................] - ETA: 1s - loss: 12258.4014 - KL_divergence: 9.8657
 73/200 [=========>....................] - ETA: 1s - loss: 12268.3319 - KL_divergence: 9.8556
 79/200 [==========>...................] - ETA: 1s - loss: 12273.7029 - KL_divergence: 9.8821
 84/200 [===========>..................] - ETA: 1s - loss: 12277.5462 - KL_divergence: 9.8584
 90/200 [============>.................] - ETA: 0s - loss: 12274.5295 - KL_divergence: 9.8680
 96/200 [=============>................] - ETA: 0s - loss: 12274.2134 - KL_divergence: 9.8373
102/200 [==============>...............] - ETA: 0s - loss: 12275.5768 - KL_divergence: 9.8489
108/200 [===============>..............] - ETA: 0s - loss: 12292.7784 - KL_divergence: 9.8418
114/200 [================>.............] - ETA: 0s - loss: 12287.5714 - KL_divergence: 9.8390
120/200 [=================>............] - ETA: 0s - loss: 12288.8326 - KL_divergence: 9.8409
126/200 [=================>............] - ETA: 0s - loss: 12306.1010 - KL_divergence: 9.8601
132/200 [==================>...........] - ETA: 0s - loss: 12332.3852 - KL_divergence: 9.8152
138/200 [===================>..........] - ETA: 0s - loss: 12327.5789 - KL_divergence: 9.8239
144/200 [====================>.........] - ETA: 0s - loss: 12328.0093 - KL_divergence: 9.8439
150/200 [=====================>........] - ETA: 0s - loss: 12332.7549 - KL_divergence: 9.8379
156/200 [======================>.......] - ETA: 0s - loss: 12345.8007 - KL_divergence: 9.8239
162/200 [=======================>......] - ETA: 0s - loss: 12361.5979 - KL_divergence: 9.7844
168/200 [========================>.....] - ETA: 0s - loss: 12361.2502 - KL_divergence: 9.7612
175/200 [=========================>....] - ETA: 0s - loss: 12355.3234 - KL_divergence: 9.7461
181/200 [==========================>...] - ETA: 0s - loss: 12362.2913 - KL_divergence: 9.7213
187/200 [===========================>..] - ETA: 0s - loss: 12367.7012 - KL_divergence: 9.7093
193/200 [===========================>..] - ETA: 0s - loss: 12359.1722 - KL_divergence: 9.7021
199/200 [============================>.] - ETA: 0s - loss: 12363.6214 - KL_divergence: 9.7028
200/200 [==============================] - 2s 10ms/step - loss: 12364.2625 - KL_divergence: 9.7035 - val_loss: 12523.2027 - val_KL_divergence: 9.5321
Epoch 66/100

  1/200 [..............................] - ETA: 1s - loss: 12681.9648 - KL_divergence: 9.2422
  7/200 [>.............................] - ETA: 1s - loss: 12662.7501 - KL_divergence: 9.2043
 13/200 [>.............................] - ETA: 1s - loss: 12520.2172 - KL_divergence: 9.5410
 19/200 [=>............................] - ETA: 1s - loss: 12463.1263 - KL_divergence: 9.5122
 25/200 [==>...........................] - ETA: 1s - loss: 12502.9315 - KL_divergence: 9.4278
 31/200 [===>..........................] - ETA: 1s - loss: 12459.4091 - KL_divergence: 9.5101
 37/200 [====>.........................] - ETA: 1s - loss: 12463.8678 - KL_divergence: 9.5575
 43/200 [=====>........................] - ETA: 1s - loss: 12461.1877 - KL_divergence: 9.4738
 49/200 [======>.......................] - ETA: 1s - loss: 12434.6805 - KL_divergence: 9.5741
 55/200 [=======>......................] - ETA: 1s - loss: 12450.9939 - KL_divergence: 9.5271
 61/200 [========>.....................] - ETA: 1s - loss: 12416.7409 - KL_divergence: 9.5179
 67/200 [=========>....................] - ETA: 1s - loss: 12420.3763 - KL_divergence: 9.5651
 73/200 [=========>....................] - ETA: 1s - loss: 12421.5813 - KL_divergence: 9.5637
 79/200 [==========>...................] - ETA: 1s - loss: 12390.5997 - KL_divergence: 9.5762
 85/200 [===========>..................] - ETA: 1s - loss: 12388.2394 - KL_divergence: 9.5695
 91/200 [============>.................] - ETA: 0s - loss: 12386.4852 - KL_divergence: 9.5669
 97/200 [=============>................] - ETA: 0s - loss: 12412.3494 - KL_divergence: 9.5378
102/200 [==============>...............] - ETA: 0s - loss: 12428.8821 - KL_divergence: 9.5040
108/200 [===============>..............] - ETA: 0s - loss: 12415.0409 - KL_divergence: 9.5280
114/200 [================>.............] - ETA: 0s - loss: 12396.4295 - KL_divergence: 9.5612
120/200 [=================>............] - ETA: 0s - loss: 12392.0528 - KL_divergence: 9.5589
126/200 [=================>............] - ETA: 0s - loss: 12393.0303 - KL_divergence: 9.5841
132/200 [==================>...........] - ETA: 0s - loss: 12395.9314 - KL_divergence: 9.5745
138/200 [===================>..........] - ETA: 0s - loss: 12397.8586 - KL_divergence: 9.5879
144/200 [====================>.........] - ETA: 0s - loss: 12404.2259 - KL_divergence: 9.6085
150/200 [=====================>........] - ETA: 0s - loss: 12408.5620 - KL_divergence: 9.5981
156/200 [======================>.......] - ETA: 0s - loss: 12404.9773 - KL_divergence: 9.6249
162/200 [=======================>......] - ETA: 0s - loss: 12389.3462 - KL_divergence: 9.6346
168/200 [========================>.....] - ETA: 0s - loss: 12399.5547 - KL_divergence: 9.6141
174/200 [=========================>....] - ETA: 0s - loss: 12395.2031 - KL_divergence: 9.6064
180/200 [==========================>...] - ETA: 0s - loss: 12392.8885 - KL_divergence: 9.6145
186/200 [==========================>...] - ETA: 0s - loss: 12383.8303 - KL_divergence: 9.6148
192/200 [===========================>..] - ETA: 0s - loss: 12367.3207 - KL_divergence: 9.6135
198/200 [============================>.] - ETA: 0s - loss: 12365.9259 - KL_divergence: 9.6104
200/200 [==============================] - 2s 10ms/step - loss: 12366.3896 - KL_divergence: 9.6124 - val_loss: 12522.4660 - val_KL_divergence: 9.3407
Epoch 67/100

  1/200 [..............................] - ETA: 1s - loss: 12926.4199 - KL_divergence: 8.8463
  7/200 [>.............................] - ETA: 1s - loss: 12768.0858 - KL_divergence: 9.3673
 13/200 [>.............................] - ETA: 1s - loss: 12302.8365 - KL_divergence: 10.1428
 19/200 [=>............................] - ETA: 1s - loss: 12271.1076 - KL_divergence: 10.2374
 25/200 [==>...........................] - ETA: 1s - loss: 12316.5773 - KL_divergence: 10.0377
 31/200 [===>..........................] - ETA: 1s - loss: 12281.2847 - KL_divergence: 10.0992
 37/200 [====>.........................] - ETA: 1s - loss: 12290.1059 - KL_divergence: 9.9965 
 43/200 [=====>........................] - ETA: 1s - loss: 12272.3397 - KL_divergence: 9.9940
 49/200 [======>.......................] - ETA: 1s - loss: 12289.7169 - KL_divergence: 10.0234
 55/200 [=======>......................] - ETA: 1s - loss: 12297.0686 - KL_divergence: 9.9216 
 61/200 [========>.....................] - ETA: 1s - loss: 12264.2102 - KL_divergence: 9.9570
 67/200 [=========>....................] - ETA: 1s - loss: 12227.6467 - KL_divergence: 10.0004
 73/200 [=========>....................] - ETA: 1s - loss: 12212.4530 - KL_divergence: 9.9736 
 79/200 [==========>...................] - ETA: 1s - loss: 12217.8621 - KL_divergence: 9.9858
 85/200 [===========>..................] - ETA: 1s - loss: 12207.9823 - KL_divergence: 9.9642
 91/200 [============>.................] - ETA: 1s - loss: 12230.5474 - KL_divergence: 9.9068
 97/200 [=============>................] - ETA: 0s - loss: 12227.5917 - KL_divergence: 9.8776
103/200 [==============>...............] - ETA: 0s - loss: 12193.1868 - KL_divergence: 9.8855
109/200 [===============>..............] - ETA: 0s - loss: 12201.4453 - KL_divergence: 9.8389
115/200 [================>.............] - ETA: 0s - loss: 12194.1119 - KL_divergence: 9.7884
121/200 [=================>............] - ETA: 0s - loss: 12202.4849 - KL_divergence: 9.7763
127/200 [==================>...........] - ETA: 0s - loss: 12201.9987 - KL_divergence: 9.7641
133/200 [==================>...........] - ETA: 0s - loss: 12186.7552 - KL_divergence: 9.7831
139/200 [===================>..........] - ETA: 0s - loss: 12205.1864 - KL_divergence: 9.8061
145/200 [====================>.........] - ETA: 0s - loss: 12206.9064 - KL_divergence: 9.8351
151/200 [=====================>........] - ETA: 0s - loss: 12218.9911 - KL_divergence: 9.8082
156/200 [======================>.......] - ETA: 0s - loss: 12221.4776 - KL_divergence: 9.7947
162/200 [=======================>......] - ETA: 0s - loss: 12224.2657 - KL_divergence: 9.7647
168/200 [========================>.....] - ETA: 0s - loss: 12215.7858 - KL_divergence: 9.7830
174/200 [=========================>....] - ETA: 0s - loss: 12221.4053 - KL_divergence: 9.7674
180/200 [==========================>...] - ETA: 0s - loss: 12230.8885 - KL_divergence: 9.7447
186/200 [==========================>...] - ETA: 0s - loss: 12222.8108 - KL_divergence: 9.7538
192/200 [===========================>..] - ETA: 0s - loss: 12224.7683 - KL_divergence: 9.7677
198/200 [============================>.] - ETA: 0s - loss: 12225.2351 - KL_divergence: 9.7895
200/200 [==============================] - 2s 10ms/step - loss: 12227.3429 - KL_divergence: 9.7883 - val_loss: 12488.5200 - val_KL_divergence: 9.7129
Epoch 68/100

  1/200 [..............................] - ETA: 1s - loss: 12282.2061 - KL_divergence: 10.1228
  7/200 [>.............................] - ETA: 1s - loss: 12346.3397 - KL_divergence: 9.8268 
 13/200 [>.............................] - ETA: 1s - loss: 12187.3097 - KL_divergence: 9.9839
 19/200 [=>............................] - ETA: 1s - loss: 12199.6855 - KL_divergence: 10.0020
 25/200 [==>...........................] - ETA: 1s - loss: 12276.9541 - KL_divergence: 9.8445 
 31/200 [===>..........................] - ETA: 1s - loss: 12251.8853 - KL_divergence: 9.7708
 37/200 [====>.........................] - ETA: 1s - loss: 12241.7504 - KL_divergence: 9.8071
 43/200 [=====>........................] - ETA: 1s - loss: 12236.5698 - KL_divergence: 9.7692
 49/200 [======>.......................] - ETA: 1s - loss: 12256.9068 - KL_divergence: 9.7947
 55/200 [=======>......................] - ETA: 1s - loss: 12284.3569 - KL_divergence: 9.7987
 61/200 [========>.....................] - ETA: 1s - loss: 12271.1049 - KL_divergence: 9.8772
 67/200 [=========>....................] - ETA: 1s - loss: 12309.8171 - KL_divergence: 9.8527
 73/200 [=========>....................] - ETA: 1s - loss: 12309.6079 - KL_divergence: 9.8667
 79/200 [==========>...................] - ETA: 1s - loss: 12310.6782 - KL_divergence: 9.8104
 84/200 [===========>..................] - ETA: 1s - loss: 12334.2032 - KL_divergence: 9.7993
 90/200 [============>.................] - ETA: 1s - loss: 12340.2372 - KL_divergence: 9.8105
 96/200 [=============>................] - ETA: 0s - loss: 12338.5044 - KL_divergence: 9.7824
102/200 [==============>...............] - ETA: 0s - loss: 12357.0818 - KL_divergence: 9.7534
108/200 [===============>..............] - ETA: 0s - loss: 12362.4405 - KL_divergence: 9.7785
114/200 [================>.............] - ETA: 0s - loss: 12346.7887 - KL_divergence: 9.7841
120/200 [=================>............] - ETA: 0s - loss: 12328.9657 - KL_divergence: 9.8134
126/200 [=================>............] - ETA: 0s - loss: 12346.5923 - KL_divergence: 9.7889
133/200 [==================>...........] - ETA: 0s - loss: 12341.1262 - KL_divergence: 9.7822
139/200 [===================>..........] - ETA: 0s - loss: 12331.2053 - KL_divergence: 9.8207
145/200 [====================>.........] - ETA: 0s - loss: 12334.2673 - KL_divergence: 9.8453
151/200 [=====================>........] - ETA: 0s - loss: 12342.2305 - KL_divergence: 9.8185
157/200 [======================>.......] - ETA: 0s - loss: 12329.1404 - KL_divergence: 9.8275
163/200 [=======================>......] - ETA: 0s - loss: 12333.2927 - KL_divergence: 9.7939
169/200 [========================>.....] - ETA: 0s - loss: 12329.2717 - KL_divergence: 9.7933
175/200 [=========================>....] - ETA: 0s - loss: 12327.8730 - KL_divergence: 9.7923
181/200 [==========================>...] - ETA: 0s - loss: 12327.6047 - KL_divergence: 9.7874
187/200 [===========================>..] - ETA: 0s - loss: 12330.9500 - KL_divergence: 9.7956
193/200 [===========================>..] - ETA: 0s - loss: 12328.3894 - KL_divergence: 9.8067
199/200 [============================>.] - ETA: 0s - loss: 12326.0354 - KL_divergence: 9.8068
200/200 [==============================] - 2s 10ms/step - loss: 12325.1898 - KL_divergence: 9.8049 - val_loss: 12494.8415 - val_KL_divergence: 9.6045
Epoch 69/100

  1/200 [..............................] - ETA: 1s - loss: 13030.4287 - KL_divergence: 9.2939
  7/200 [>.............................] - ETA: 1s - loss: 12356.0730 - KL_divergence: 9.7146
 13/200 [>.............................] - ETA: 1s - loss: 12296.3893 - KL_divergence: 9.5535
 19/200 [=>............................] - ETA: 1s - loss: 12155.9882 - KL_divergence: 9.5827
 25/200 [==>...........................] - ETA: 1s - loss: 12253.6266 - KL_divergence: 9.4904
 31/200 [===>..........................] - ETA: 1s - loss: 12273.4799 - KL_divergence: 9.4177
 37/200 [====>.........................] - ETA: 1s - loss: 12294.6939 - KL_divergence: 9.3656
 43/200 [=====>........................] - ETA: 1s - loss: 12313.4493 - KL_divergence: 9.4401
 49/200 [======>.......................] - ETA: 1s - loss: 12298.2159 - KL_divergence: 9.5365
 55/200 [=======>......................] - ETA: 1s - loss: 12309.6567 - KL_divergence: 9.5437
 61/200 [========>.....................] - ETA: 1s - loss: 12291.2216 - KL_divergence: 9.5581
 67/200 [=========>....................] - ETA: 1s - loss: 12301.4108 - KL_divergence: 9.6307
 73/200 [=========>....................] - ETA: 1s - loss: 12324.0780 - KL_divergence: 9.6202
 79/200 [==========>...................] - ETA: 1s - loss: 12325.6612 - KL_divergence: 9.6065
 85/200 [===========>..................] - ETA: 1s - loss: 12316.8905 - KL_divergence: 9.6609
 91/200 [============>.................] - ETA: 0s - loss: 12339.3109 - KL_divergence: 9.6785
 97/200 [=============>................] - ETA: 0s - loss: 12328.8864 - KL_divergence: 9.7372
103/200 [==============>...............] - ETA: 0s - loss: 12330.1224 - KL_divergence: 9.7382
109/200 [===============>..............] - ETA: 0s - loss: 12322.5398 - KL_divergence: 9.7216
115/200 [================>.............] - ETA: 0s - loss: 12345.1731 - KL_divergence: 9.6825
120/200 [=================>............] - ETA: 0s - loss: 12342.6904 - KL_divergence: 9.6865
126/200 [=================>............] - ETA: 0s - loss: 12340.0725 - KL_divergence: 9.6867
132/200 [==================>...........] - ETA: 0s - loss: 12343.8879 - KL_divergence: 9.6929
138/200 [===================>..........] - ETA: 0s - loss: 12354.4642 - KL_divergence: 9.6865
144/200 [====================>.........] - ETA: 0s - loss: 12354.2252 - KL_divergence: 9.6802
150/200 [=====================>........] - ETA: 0s - loss: 12344.7257 - KL_divergence: 9.6716
156/200 [======================>.......] - ETA: 0s - loss: 12344.3251 - KL_divergence: 9.6526
163/200 [=======================>......] - ETA: 0s - loss: 12353.3484 - KL_divergence: 9.6681
170/200 [========================>.....] - ETA: 0s - loss: 12348.9887 - KL_divergence: 9.6563
176/200 [=========================>....] - ETA: 0s - loss: 12344.2127 - KL_divergence: 9.6556
182/200 [==========================>...] - ETA: 0s - loss: 12338.6177 - KL_divergence: 9.6523
188/200 [===========================>..] - ETA: 0s - loss: 12338.1276 - KL_divergence: 9.6395
194/200 [============================>.] - ETA: 0s - loss: 12340.5202 - KL_divergence: 9.6225
200/200 [==============================] - 2s 10ms/step - loss: 12336.9908 - KL_divergence: 9.6411 - val_loss: 12517.4597 - val_KL_divergence: 9.7466
Epoch 70/100

  1/200 [..............................] - ETA: 1s - loss: 12376.2061 - KL_divergence: 10.1797
  7/200 [>.............................] - ETA: 1s - loss: 12232.3322 - KL_divergence: 9.8639 
 13/200 [>.............................] - ETA: 1s - loss: 12294.0329 - KL_divergence: 9.8060
 19/200 [=>............................] - ETA: 1s - loss: 12149.2478 - KL_divergence: 10.0195
 25/200 [==>...........................] - ETA: 1s - loss: 12158.2950 - KL_divergence: 9.9657 
 31/200 [===>..........................] - ETA: 1s - loss: 12248.5920 - KL_divergence: 9.8366
 37/200 [====>.........................] - ETA: 1s - loss: 12257.2186 - KL_divergence: 9.8222
 43/200 [=====>........................] - ETA: 1s - loss: 12265.9689 - KL_divergence: 9.8359
 50/200 [======>.......................] - ETA: 1s - loss: 12301.0708 - KL_divergence: 9.7969
 56/200 [=======>......................] - ETA: 1s - loss: 12311.1432 - KL_divergence: 9.8262
 62/200 [========>.....................] - ETA: 1s - loss: 12293.4462 - KL_divergence: 9.7961
 68/200 [=========>....................] - ETA: 1s - loss: 12305.8864 - KL_divergence: 9.7542
 74/200 [==========>...................] - ETA: 1s - loss: 12292.4846 - KL_divergence: 9.7603
 80/200 [===========>..................] - ETA: 1s - loss: 12314.4442 - KL_divergence: 9.7747
 86/200 [===========>..................] - ETA: 1s - loss: 12302.6672 - KL_divergence: 9.8030
 92/200 [============>.................] - ETA: 0s - loss: 12306.9480 - KL_divergence: 9.7967
 98/200 [=============>................] - ETA: 0s - loss: 12297.9073 - KL_divergence: 9.7689
104/200 [==============>...............] - ETA: 0s - loss: 12303.2808 - KL_divergence: 9.7469
110/200 [===============>..............] - ETA: 0s - loss: 12301.5988 - KL_divergence: 9.7094
116/200 [================>.............] - ETA: 0s - loss: 12281.4368 - KL_divergence: 9.6992
122/200 [=================>............] - ETA: 0s - loss: 12259.3478 - KL_divergence: 9.7243
128/200 [==================>...........] - ETA: 0s - loss: 12263.9148 - KL_divergence: 9.7022
134/200 [===================>..........] - ETA: 0s - loss: 12276.7562 - KL_divergence: 9.6791
140/200 [====================>.........] - ETA: 0s - loss: 12286.5952 - KL_divergence: 9.6522
146/200 [====================>.........] - ETA: 0s - loss: 12283.3987 - KL_divergence: 9.6286
153/200 [=====================>........] - ETA: 0s - loss: 12276.8169 - KL_divergence: 9.6375
160/200 [=======================>......] - ETA: 0s - loss: 12268.2578 - KL_divergence: 9.6484
166/200 [=======================>......] - ETA: 0s - loss: 12255.3173 - KL_divergence: 9.6542
173/200 [========================>.....] - ETA: 0s - loss: 12254.0965 - KL_divergence: 9.6413
180/200 [==========================>...] - ETA: 0s - loss: 12259.5744 - KL_divergence: 9.6396
186/200 [==========================>...] - ETA: 0s - loss: 12250.6452 - KL_divergence: 9.6533
192/200 [===========================>..] - ETA: 0s - loss: 12249.7233 - KL_divergence: 9.6537
198/200 [============================>.] - ETA: 0s - loss: 12247.2400 - KL_divergence: 9.6551
200/200 [==============================] - 2s 10ms/step - loss: 12243.7236 - KL_divergence: 9.6736 - val_loss: 12507.7502 - val_KL_divergence: 9.8013
Epoch 71/100

  1/200 [..............................] - ETA: 1s - loss: 12537.9697 - KL_divergence: 10.2564
  7/200 [>.............................] - ETA: 1s - loss: 12579.4563 - KL_divergence: 10.3785
 13/200 [>.............................] - ETA: 1s - loss: 12481.5980 - KL_divergence: 9.9293 
 19/200 [=>............................] - ETA: 1s - loss: 12435.1668 - KL_divergence: 9.7256
 25/200 [==>...........................] - ETA: 1s - loss: 12423.0341 - KL_divergence: 9.6682
 31/200 [===>..........................] - ETA: 1s - loss: 12401.4879 - KL_divergence: 9.7070
 37/200 [====>.........................] - ETA: 1s - loss: 12346.3878 - KL_divergence: 9.6857
 43/200 [=====>........................] - ETA: 1s - loss: 12303.3570 - KL_divergence: 9.7729
 49/200 [======>.......................] - ETA: 1s - loss: 12298.5584 - KL_divergence: 9.7926
 55/200 [=======>......................] - ETA: 1s - loss: 12294.2401 - KL_divergence: 9.7753
 61/200 [========>.....................] - ETA: 1s - loss: 12290.2542 - KL_divergence: 9.7614
 67/200 [=========>....................] - ETA: 1s - loss: 12286.9752 - KL_divergence: 9.7372
 73/200 [=========>....................] - ETA: 1s - loss: 12316.3259 - KL_divergence: 9.6604
 79/200 [==========>...................] - ETA: 1s - loss: 12298.4742 - KL_divergence: 9.6829
 85/200 [===========>..................] - ETA: 1s - loss: 12284.1922 - KL_divergence: 9.6592
 91/200 [============>.................] - ETA: 0s - loss: 12267.1437 - KL_divergence: 9.6605
 97/200 [=============>................] - ETA: 0s - loss: 12290.5388 - KL_divergence: 9.6744
103/200 [==============>...............] - ETA: 0s - loss: 12291.7054 - KL_divergence: 9.6597
109/200 [===============>..............] - ETA: 0s - loss: 12306.2064 - KL_divergence: 9.6455
115/200 [================>.............] - ETA: 0s - loss: 12310.8644 - KL_divergence: 9.6376
121/200 [=================>............] - ETA: 0s - loss: 12322.6972 - KL_divergence: 9.6394
127/200 [==================>...........] - ETA: 0s - loss: 12317.7989 - KL_divergence: 9.6735
134/200 [===================>..........] - ETA: 0s - loss: 12318.4346 - KL_divergence: 9.6682
140/200 [====================>.........] - ETA: 0s - loss: 12303.5124 - KL_divergence: 9.6775
146/200 [====================>.........] - ETA: 0s - loss: 12296.8402 - KL_divergence: 9.6475
152/200 [=====================>........] - ETA: 0s - loss: 12296.0528 - KL_divergence: 9.6378
158/200 [======================>.......] - ETA: 0s - loss: 12290.4690 - KL_divergence: 9.6503
164/200 [=======================>......] - ETA: 0s - loss: 12292.5548 - KL_divergence: 9.6517
170/200 [========================>.....] - ETA: 0s - loss: 12290.6184 - KL_divergence: 9.6493
176/200 [=========================>....] - ETA: 0s - loss: 12293.7228 - KL_divergence: 9.6497
182/200 [==========================>...] - ETA: 0s - loss: 12290.3484 - KL_divergence: 9.6590
188/200 [===========================>..] - ETA: 0s - loss: 12286.0771 - KL_divergence: 9.6629
194/200 [============================>.] - ETA: 0s - loss: 12278.6568 - KL_divergence: 9.6576
200/200 [==============================] - 2s 10ms/step - loss: 12285.0575 - KL_divergence: 9.6518 - val_loss: 12473.6954 - val_KL_divergence: 9.9553
Epoch 72/100

  1/200 [..............................] - ETA: 1s - loss: 11164.1113 - KL_divergence: 11.1152
  7/200 [>.............................] - ETA: 1s - loss: 11969.8817 - KL_divergence: 10.4391
 13/200 [>.............................] - ETA: 1s - loss: 12237.1626 - KL_divergence: 9.7476 
 19/200 [=>............................] - ETA: 1s - loss: 12244.9881 - KL_divergence: 9.8389
 25/200 [==>...........................] - ETA: 1s - loss: 12213.5966 - KL_divergence: 9.8515
 31/200 [===>..........................] - ETA: 1s - loss: 12163.8008 - KL_divergence: 9.9003
 37/200 [====>.........................] - ETA: 1s - loss: 12188.7235 - KL_divergence: 9.8293
 43/200 [=====>........................] - ETA: 1s - loss: 12189.8234 - KL_divergence: 9.8295
 49/200 [======>.......................] - ETA: 1s - loss: 12199.5246 - KL_divergence: 9.7888
 55/200 [=======>......................] - ETA: 1s - loss: 12167.2403 - KL_divergence: 9.7601
 61/200 [========>.....................] - ETA: 1s - loss: 12157.7942 - KL_divergence: 9.6961
 67/200 [=========>....................] - ETA: 1s - loss: 12164.7237 - KL_divergence: 9.6494
 73/200 [=========>....................] - ETA: 1s - loss: 12207.2524 - KL_divergence: 9.6303
 79/200 [==========>...................] - ETA: 1s - loss: 12227.7713 - KL_divergence: 9.6123
 85/200 [===========>..................] - ETA: 1s - loss: 12219.3894 - KL_divergence: 9.5809
 91/200 [============>.................] - ETA: 0s - loss: 12241.4945 - KL_divergence: 9.5415
 97/200 [=============>................] - ETA: 0s - loss: 12242.3029 - KL_divergence: 9.5230
103/200 [==============>...............] - ETA: 0s - loss: 12215.8495 - KL_divergence: 9.5493
109/200 [===============>..............] - ETA: 0s - loss: 12227.5443 - KL_divergence: 9.5223
115/200 [================>.............] - ETA: 0s - loss: 12218.7199 - KL_divergence: 9.5275
121/200 [=================>............] - ETA: 0s - loss: 12209.5318 - KL_divergence: 9.5534
127/200 [==================>...........] - ETA: 0s - loss: 12211.0450 - KL_divergence: 9.5552
133/200 [==================>...........] - ETA: 0s - loss: 12212.7721 - KL_divergence: 9.5792
140/200 [====================>.........] - ETA: 0s - loss: 12202.9101 - KL_divergence: 9.5998
146/200 [====================>.........] - ETA: 0s - loss: 12206.5977 - KL_divergence: 9.6065
152/200 [=====================>........] - ETA: 0s - loss: 12215.6230 - KL_divergence: 9.5867
158/200 [======================>.......] - ETA: 0s - loss: 12220.9398 - KL_divergence: 9.6227
164/200 [=======================>......] - ETA: 0s - loss: 12226.1561 - KL_divergence: 9.6238
170/200 [========================>.....] - ETA: 0s - loss: 12224.4621 - KL_divergence: 9.6159
176/200 [=========================>....] - ETA: 0s - loss: 12224.1244 - KL_divergence: 9.6179
182/200 [==========================>...] - ETA: 0s - loss: 12222.0442 - KL_divergence: 9.6105
188/200 [===========================>..] - ETA: 0s - loss: 12218.9245 - KL_divergence: 9.5979
194/200 [============================>.] - ETA: 0s - loss: 12212.0805 - KL_divergence: 9.6105
200/200 [==============================] - 2s 10ms/step - loss: 12218.7172 - KL_divergence: 9.6179 - val_loss: 12443.9135 - val_KL_divergence: 9.7980
Epoch 73/100

  1/200 [..............................] - ETA: 1s - loss: 12092.6348 - KL_divergence: 10.0908
  7/200 [>.............................] - ETA: 1s - loss: 12153.0730 - KL_divergence: 10.5289
 13/200 [>.............................] - ETA: 1s - loss: 12167.4534 - KL_divergence: 10.0786
 19/200 [=>............................] - ETA: 1s - loss: 12100.3364 - KL_divergence: 9.9006 
 25/200 [==>...........................] - ETA: 1s - loss: 12090.6250 - KL_divergence: 9.7446
 31/200 [===>..........................] - ETA: 1s - loss: 12057.0924 - KL_divergence: 9.9332
 37/200 [====>.........................] - ETA: 1s - loss: 12109.3339 - KL_divergence: 9.8533
 43/200 [=====>........................] - ETA: 1s - loss: 12119.3596 - KL_divergence: 9.7942
 49/200 [======>.......................] - ETA: 1s - loss: 12112.8874 - KL_divergence: 9.7993
 55/200 [=======>......................] - ETA: 1s - loss: 12111.4987 - KL_divergence: 9.7882
 60/200 [========>.....................] - ETA: 1s - loss: 12095.5944 - KL_divergence: 9.7631
 66/200 [========>.....................] - ETA: 1s - loss: 12112.3039 - KL_divergence: 9.7740
 72/200 [=========>....................] - ETA: 1s - loss: 12100.7602 - KL_divergence: 9.7561
 77/200 [==========>...................] - ETA: 1s - loss: 12108.9593 - KL_divergence: 9.7351
 83/200 [===========>..................] - ETA: 1s - loss: 12118.4299 - KL_divergence: 9.7103
 89/200 [============>.................] - ETA: 1s - loss: 12132.6540 - KL_divergence: 9.6905
 95/200 [=============>................] - ETA: 0s - loss: 12141.5309 - KL_divergence: 9.7004
101/200 [==============>...............] - ETA: 0s - loss: 12168.4593 - KL_divergence: 9.6644
107/200 [===============>..............] - ETA: 0s - loss: 12172.2051 - KL_divergence: 9.6674
113/200 [===============>..............] - ETA: 0s - loss: 12179.6251 - KL_divergence: 9.6575
119/200 [================>.............] - ETA: 0s - loss: 12198.1801 - KL_divergence: 9.6243
125/200 [=================>............] - ETA: 0s - loss: 12190.5628 - KL_divergence: 9.5857
131/200 [==================>...........] - ETA: 0s - loss: 12191.5514 - KL_divergence: 9.5903
137/200 [===================>..........] - ETA: 0s - loss: 12202.7022 - KL_divergence: 9.5740
143/200 [====================>.........] - ETA: 0s - loss: 12203.7616 - KL_divergence: 9.5916
149/200 [=====================>........] - ETA: 0s - loss: 12204.9653 - KL_divergence: 9.5786
155/200 [======================>.......] - ETA: 0s - loss: 12199.8128 - KL_divergence: 9.6105
161/200 [=======================>......] - ETA: 0s - loss: 12200.7871 - KL_divergence: 9.6132
167/200 [========================>.....] - ETA: 0s - loss: 12197.0768 - KL_divergence: 9.6110
174/200 [=========================>....] - ETA: 0s - loss: 12202.2980 - KL_divergence: 9.5996
181/200 [==========================>...] - ETA: 0s - loss: 12201.5347 - KL_divergence: 9.6031
187/200 [===========================>..] - ETA: 0s - loss: 12201.8862 - KL_divergence: 9.6217
193/200 [===========================>..] - ETA: 0s - loss: 12201.2910 - KL_divergence: 9.6536
200/200 [==============================] - 2s 10ms/step - loss: 12206.1721 - KL_divergence: 9.6547 - val_loss: 12506.0732 - val_KL_divergence: 10.1364
Epoch 74/100

  1/200 [..............................] - ETA: 1s - loss: 11612.0127 - KL_divergence: 11.0304
  7/200 [>.............................] - ETA: 1s - loss: 12204.0505 - KL_divergence: 9.7465 
 13/200 [>.............................] - ETA: 1s - loss: 12171.9435 - KL_divergence: 9.7313
 19/200 [=>............................] - ETA: 1s - loss: 12259.8618 - KL_divergence: 9.5329
 25/200 [==>...........................] - ETA: 1s - loss: 12185.6595 - KL_divergence: 9.6356
 31/200 [===>..........................] - ETA: 1s - loss: 12199.8392 - KL_divergence: 9.6336
 37/200 [====>.........................] - ETA: 1s - loss: 12202.9292 - KL_divergence: 9.7223
 43/200 [=====>........................] - ETA: 1s - loss: 12192.8065 - KL_divergence: 9.8081
 49/200 [======>.......................] - ETA: 1s - loss: 12194.4457 - KL_divergence: 9.8161
 55/200 [=======>......................] - ETA: 1s - loss: 12179.8028 - KL_divergence: 9.8001
 61/200 [========>.....................] - ETA: 1s - loss: 12188.6874 - KL_divergence: 9.7974
 66/200 [========>.....................] - ETA: 1s - loss: 12177.4647 - KL_divergence: 9.7826
 71/200 [=========>....................] - ETA: 1s - loss: 12175.9944 - KL_divergence: 9.8167
 77/200 [==========>...................] - ETA: 1s - loss: 12180.3717 - KL_divergence: 9.7863
 83/200 [===========>..................] - ETA: 1s - loss: 12201.9635 - KL_divergence: 9.7823
 89/200 [============>.................] - ETA: 1s - loss: 12186.6464 - KL_divergence: 9.7594
 95/200 [=============>................] - ETA: 0s - loss: 12201.1773 - KL_divergence: 9.7610
101/200 [==============>...............] - ETA: 0s - loss: 12202.8021 - KL_divergence: 9.7540
107/200 [===============>..............] - ETA: 0s - loss: 12197.5996 - KL_divergence: 9.7583
113/200 [===============>..............] - ETA: 0s - loss: 12191.1250 - KL_divergence: 9.7855
119/200 [================>.............] - ETA: 0s - loss: 12169.4478 - KL_divergence: 9.8037
125/200 [=================>............] - ETA: 0s - loss: 12183.6262 - KL_divergence: 9.7792
131/200 [==================>...........] - ETA: 0s - loss: 12187.7144 - KL_divergence: 9.7486
137/200 [===================>..........] - ETA: 0s - loss: 12181.1214 - KL_divergence: 9.7416
143/200 [====================>.........] - ETA: 0s - loss: 12182.9938 - KL_divergence: 9.7268
149/200 [=====================>........] - ETA: 0s - loss: 12180.2905 - KL_divergence: 9.7160
155/200 [======================>.......] - ETA: 0s - loss: 12185.6385 - KL_divergence: 9.7279
161/200 [=======================>......] - ETA: 0s - loss: 12180.2200 - KL_divergence: 9.7511
167/200 [========================>.....] - ETA: 0s - loss: 12181.7250 - KL_divergence: 9.7531
173/200 [========================>.....] - ETA: 0s - loss: 12181.6606 - KL_divergence: 9.7698
179/200 [=========================>....] - ETA: 0s - loss: 12189.9568 - KL_divergence: 9.7579
185/200 [==========================>...] - ETA: 0s - loss: 12199.9279 - KL_divergence: 9.7653
191/200 [===========================>..] - ETA: 0s - loss: 12198.1813 - KL_divergence: 9.7574
197/200 [============================>.] - ETA: 0s - loss: 12211.5002 - KL_divergence: 9.7505
200/200 [==============================] - 2s 10ms/step - loss: 12208.9654 - KL_divergence: 9.7679 - val_loss: 12524.1742 - val_KL_divergence: 9.8346
Epoch 75/100

  1/200 [..............................] - ETA: 1s - loss: 11514.7490 - KL_divergence: 12.2209
  7/200 [>.............................] - ETA: 1s - loss: 12272.1959 - KL_divergence: 9.5660 
 13/200 [>.............................] - ETA: 1s - loss: 12303.6105 - KL_divergence: 9.6552
 19/200 [=>............................] - ETA: 1s - loss: 12338.9272 - KL_divergence: 9.5830
 25/200 [==>...........................] - ETA: 1s - loss: 12286.9316 - KL_divergence: 9.6620
 31/200 [===>..........................] - ETA: 1s - loss: 12197.2279 - KL_divergence: 9.8198
 37/200 [====>.........................] - ETA: 1s - loss: 12261.5864 - KL_divergence: 9.7710
 43/200 [=====>........................] - ETA: 1s - loss: 12241.7515 - KL_divergence: 9.7612
 49/200 [======>.......................] - ETA: 1s - loss: 12273.0437 - KL_divergence: 9.6898
 55/200 [=======>......................] - ETA: 1s - loss: 12271.5529 - KL_divergence: 9.6961
 61/200 [========>.....................] - ETA: 1s - loss: 12254.4829 - KL_divergence: 9.6695
 67/200 [=========>....................] - ETA: 1s - loss: 12235.5606 - KL_divergence: 9.6616
 73/200 [=========>....................] - ETA: 1s - loss: 12241.5809 - KL_divergence: 9.6503
 79/200 [==========>...................] - ETA: 1s - loss: 12242.3862 - KL_divergence: 9.5888
 85/200 [===========>..................] - ETA: 1s - loss: 12235.3142 - KL_divergence: 9.6062
 91/200 [============>.................] - ETA: 0s - loss: 12245.3253 - KL_divergence: 9.5771
 98/200 [=============>................] - ETA: 0s - loss: 12254.6471 - KL_divergence: 9.5786
104/200 [==============>...............] - ETA: 0s - loss: 12250.5514 - KL_divergence: 9.5782
110/200 [===============>..............] - ETA: 0s - loss: 12250.6837 - KL_divergence: 9.5867
116/200 [================>.............] - ETA: 0s - loss: 12256.0855 - KL_divergence: 9.6158
122/200 [=================>............] - ETA: 0s - loss: 12255.6817 - KL_divergence: 9.6308
128/200 [==================>...........] - ETA: 0s - loss: 12261.9097 - KL_divergence: 9.6441
134/200 [===================>..........] - ETA: 0s - loss: 12265.5533 - KL_divergence: 9.6558
140/200 [====================>.........] - ETA: 0s - loss: 12266.8358 - KL_divergence: 9.6800
146/200 [====================>.........] - ETA: 0s - loss: 12278.4270 - KL_divergence: 9.7305
152/200 [=====================>........] - ETA: 0s - loss: 12284.3619 - KL_divergence: 9.7411
158/200 [======================>.......] - ETA: 0s - loss: 12292.6974 - KL_divergence: 9.7340
164/200 [=======================>......] - ETA: 0s - loss: 12285.4205 - KL_divergence: 9.7380
170/200 [========================>.....] - ETA: 0s - loss: 12282.0170 - KL_divergence: 9.7320
176/200 [=========================>....] - ETA: 0s - loss: 12283.6197 - KL_divergence: 9.7344
182/200 [==========================>...] - ETA: 0s - loss: 12278.8417 - KL_divergence: 9.7275
188/200 [===========================>..] - ETA: 0s - loss: 12291.8359 - KL_divergence: 9.7100
194/200 [============================>.] - ETA: 0s - loss: 12285.8677 - KL_divergence: 9.6954
200/200 [==============================] - 2s 10ms/step - loss: 12277.6179 - KL_divergence: 9.7012 - val_loss: 12498.4298 - val_KL_divergence: 9.6335
Epoch 76/100

  1/200 [..............................] - ETA: 1s - loss: 11437.6348 - KL_divergence: 9.2511
  7/200 [>.............................] - ETA: 1s - loss: 11925.6636 - KL_divergence: 9.7299
 13/200 [>.............................] - ETA: 1s - loss: 12178.8064 - KL_divergence: 9.6744
 19/200 [=>............................] - ETA: 1s - loss: 12140.6163 - KL_divergence: 9.6553
 25/200 [==>...........................] - ETA: 1s - loss: 12215.0155 - KL_divergence: 9.7076
 31/200 [===>..........................] - ETA: 1s - loss: 12233.9108 - KL_divergence: 9.6331
 37/200 [====>.........................] - ETA: 1s - loss: 12219.6400 - KL_divergence: 9.5446
 43/200 [=====>........................] - ETA: 1s - loss: 12257.6278 - KL_divergence: 9.4536
 49/200 [======>.......................] - ETA: 1s - loss: 12283.3532 - KL_divergence: 9.4627
 55/200 [=======>......................] - ETA: 1s - loss: 12271.0422 - KL_divergence: 9.5440
 61/200 [========>.....................] - ETA: 1s - loss: 12269.4797 - KL_divergence: 9.5073
 68/200 [=========>....................] - ETA: 1s - loss: 12276.7222 - KL_divergence: 9.5353
 75/200 [==========>...................] - ETA: 1s - loss: 12271.0538 - KL_divergence: 9.5376
 81/200 [===========>..................] - ETA: 1s - loss: 12265.9124 - KL_divergence: 9.5345
 87/200 [============>.................] - ETA: 1s - loss: 12249.3818 - KL_divergence: 9.5603
 93/200 [============>.................] - ETA: 0s - loss: 12234.1519 - KL_divergence: 9.6004
 99/200 [=============>................] - ETA: 0s - loss: 12239.9353 - KL_divergence: 9.5649
105/200 [==============>...............] - ETA: 0s - loss: 12229.6401 - KL_divergence: 9.5834
111/200 [===============>..............] - ETA: 0s - loss: 12235.5127 - KL_divergence: 9.5379
117/200 [================>.............] - ETA: 0s - loss: 12221.0344 - KL_divergence: 9.5577
123/200 [=================>............] - ETA: 0s - loss: 12208.9843 - KL_divergence: 9.5605
129/200 [==================>...........] - ETA: 0s - loss: 12203.5204 - KL_divergence: 9.5576
135/200 [===================>..........] - ETA: 0s - loss: 12198.6188 - KL_divergence: 9.5485
141/200 [====================>.........] - ETA: 0s - loss: 12181.3579 - KL_divergence: 9.5502
147/200 [=====================>........] - ETA: 0s - loss: 12172.4217 - KL_divergence: 9.5582
153/200 [=====================>........] - ETA: 0s - loss: 12179.2833 - KL_divergence: 9.5325
159/200 [======================>.......] - ETA: 0s - loss: 12178.7692 - KL_divergence: 9.5376
165/200 [=======================>......] - ETA: 0s - loss: 12168.4924 - KL_divergence: 9.5517
171/200 [========================>.....] - ETA: 0s - loss: 12159.1591 - KL_divergence: 9.5536
177/200 [=========================>....] - ETA: 0s - loss: 12165.1215 - KL_divergence: 9.5734
183/200 [==========================>...] - ETA: 0s - loss: 12183.8223 - KL_divergence: 9.5647
189/200 [===========================>..] - ETA: 0s - loss: 12174.1312 - KL_divergence: 9.6163
195/200 [============================>.] - ETA: 0s - loss: 12176.6137 - KL_divergence: 9.6245
200/200 [==============================] - 2s 10ms/step - loss: 12187.2794 - KL_divergence: 9.6153 - val_loss: 12482.9351 - val_KL_divergence: 9.7709
Epoch 77/100

  1/200 [..............................] - ETA: 2s - loss: 13048.2314 - KL_divergence: 9.5668
  7/200 [>.............................] - ETA: 1s - loss: 12399.5366 - KL_divergence: 10.0215
 13/200 [>.............................] - ETA: 1s - loss: 12351.6562 - KL_divergence: 9.7348 
 19/200 [=>............................] - ETA: 1s - loss: 12259.1170 - KL_divergence: 9.9179
 25/200 [==>...........................] - ETA: 1s - loss: 12193.8550 - KL_divergence: 9.7816
 31/200 [===>..........................] - ETA: 1s - loss: 12222.3850 - KL_divergence: 9.6757
 37/200 [====>.........................] - ETA: 1s - loss: 12231.2294 - KL_divergence: 9.6205
 43/200 [=====>........................] - ETA: 1s - loss: 12264.7839 - KL_divergence: 9.6221
 49/200 [======>.......................] - ETA: 1s - loss: 12260.0288 - KL_divergence: 9.6476
 55/200 [=======>......................] - ETA: 1s - loss: 12320.9466 - KL_divergence: 9.6022
 61/200 [========>.....................] - ETA: 1s - loss: 12324.4135 - KL_divergence: 9.5722
 67/200 [=========>....................] - ETA: 1s - loss: 12316.3862 - KL_divergence: 9.5611
 74/200 [==========>...................] - ETA: 1s - loss: 12303.8796 - KL_divergence: 9.5254
 81/200 [===========>..................] - ETA: 1s - loss: 12309.9863 - KL_divergence: 9.5241
 87/200 [============>.................] - ETA: 0s - loss: 12296.2602 - KL_divergence: 9.5788
 93/200 [============>.................] - ETA: 0s - loss: 12300.7051 - KL_divergence: 9.5802
 99/200 [=============>................] - ETA: 0s - loss: 12278.0508 - KL_divergence: 9.5941
105/200 [==============>...............] - ETA: 0s - loss: 12268.2108 - KL_divergence: 9.6475
111/200 [===============>..............] - ETA: 0s - loss: 12255.4900 - KL_divergence: 9.6507
117/200 [================>.............] - ETA: 0s - loss: 12247.2981 - KL_divergence: 9.6431
123/200 [=================>............] - ETA: 0s - loss: 12241.0946 - KL_divergence: 9.6372
129/200 [==================>...........] - ETA: 0s - loss: 12238.2841 - KL_divergence: 9.6397
135/200 [===================>..........] - ETA: 0s - loss: 12251.3747 - KL_divergence: 9.6465
141/200 [====================>.........] - ETA: 0s - loss: 12247.7068 - KL_divergence: 9.6282
147/200 [=====================>........] - ETA: 0s - loss: 12250.3252 - KL_divergence: 9.6097
153/200 [=====================>........] - ETA: 0s - loss: 12255.3698 - KL_divergence: 9.6303
158/200 [======================>.......] - ETA: 0s - loss: 12257.0017 - KL_divergence: 9.6359
164/200 [=======================>......] - ETA: 0s - loss: 12253.7873 - KL_divergence: 9.6350
170/200 [========================>.....] - ETA: 0s - loss: 12242.0168 - KL_divergence: 9.6487
176/200 [=========================>....] - ETA: 0s - loss: 12225.6808 - KL_divergence: 9.6603
182/200 [==========================>...] - ETA: 0s - loss: 12225.6698 - KL_divergence: 9.6437
188/200 [===========================>..] - ETA: 0s - loss: 12221.7901 - KL_divergence: 9.6533
194/200 [============================>.] - ETA: 0s - loss: 12225.2044 - KL_divergence: 9.6434
200/200 [==============================] - 2s 10ms/step - loss: 12226.5019 - KL_divergence: 9.6276 - val_loss: 12510.6887 - val_KL_divergence: 9.0778
Epoch 78/100

  1/200 [..............................] - ETA: 1s - loss: 12414.6592 - KL_divergence: 10.1091
  8/200 [>.............................] - ETA: 1s - loss: 12359.3073 - KL_divergence: 9.4018 
 15/200 [=>............................] - ETA: 1s - loss: 12167.7260 - KL_divergence: 9.6662
 21/200 [==>...........................] - ETA: 1s - loss: 12162.4048 - KL_divergence: 9.7603
 27/200 [===>..........................] - ETA: 1s - loss: 12221.5522 - KL_divergence: 9.6216
 33/200 [===>..........................] - ETA: 1s - loss: 12161.4218 - KL_divergence: 9.6606
 40/200 [=====>........................] - ETA: 1s - loss: 12172.8760 - KL_divergence: 9.6444
 47/200 [======>.......................] - ETA: 1s - loss: 12235.4160 - KL_divergence: 9.5342
 54/200 [=======>......................] - ETA: 1s - loss: 12266.2959 - KL_divergence: 9.5422
 60/200 [========>.....................] - ETA: 1s - loss: 12228.7949 - KL_divergence: 9.6632
 66/200 [========>.....................] - ETA: 1s - loss: 12183.7658 - KL_divergence: 9.7676
 72/200 [=========>....................] - ETA: 1s - loss: 12197.0318 - KL_divergence: 9.7660
 78/200 [==========>...................] - ETA: 1s - loss: 12222.4151 - KL_divergence: 9.7478
 84/200 [===========>..................] - ETA: 0s - loss: 12206.4866 - KL_divergence: 9.7913
 90/200 [============>.................] - ETA: 0s - loss: 12217.5914 - KL_divergence: 9.8211
 96/200 [=============>................] - ETA: 0s - loss: 12212.3433 - KL_divergence: 9.8177
102/200 [==============>...............] - ETA: 0s - loss: 12199.3343 - KL_divergence: 9.8768
108/200 [===============>..............] - ETA: 0s - loss: 12182.0926 - KL_divergence: 9.9163
114/200 [================>.............] - ETA: 0s - loss: 12189.8526 - KL_divergence: 9.9432
120/200 [=================>............] - ETA: 0s - loss: 12203.4979 - KL_divergence: 9.9352
126/200 [=================>............] - ETA: 0s - loss: 12204.5491 - KL_divergence: 9.9649
132/200 [==================>...........] - ETA: 0s - loss: 12190.4418 - KL_divergence: 9.9639
138/200 [===================>..........] - ETA: 0s - loss: 12177.6758 - KL_divergence: 10.0005
144/200 [====================>.........] - ETA: 0s - loss: 12175.6754 - KL_divergence: 9.9943 
149/200 [=====================>........] - ETA: 0s - loss: 12168.9454 - KL_divergence: 9.9726
155/200 [======================>.......] - ETA: 0s - loss: 12185.9999 - KL_divergence: 9.9602
161/200 [=======================>......] - ETA: 0s - loss: 12177.5529 - KL_divergence: 9.9670
167/200 [========================>.....] - ETA: 0s - loss: 12184.8136 - KL_divergence: 9.9303
173/200 [========================>.....] - ETA: 0s - loss: 12193.5123 - KL_divergence: 9.9133
179/200 [=========================>....] - ETA: 0s - loss: 12189.8803 - KL_divergence: 9.9081
185/200 [==========================>...] - ETA: 0s - loss: 12192.3376 - KL_divergence: 9.8870
191/200 [===========================>..] - ETA: 0s - loss: 12196.6054 - KL_divergence: 9.8802
197/200 [============================>.] - ETA: 0s - loss: 12205.2662 - KL_divergence: 9.8808
200/200 [==============================] - 2s 10ms/step - loss: 12207.6775 - KL_divergence: 9.8631 - val_loss: 12476.1552 - val_KL_divergence: 9.6109
Epoch 79/100

  1/200 [..............................] - ETA: 1s - loss: 10786.8164 - KL_divergence: 11.4914
  7/200 [>.............................] - ETA: 1s - loss: 11936.2765 - KL_divergence: 9.8225 
 14/200 [=>............................] - ETA: 1s - loss: 12047.5100 - KL_divergence: 10.2242
 21/200 [==>...........................] - ETA: 1s - loss: 12148.0371 - KL_divergence: 10.1001
 27/200 [===>..........................] - ETA: 1s - loss: 12123.1496 - KL_divergence: 10.0350
 33/200 [===>..........................] - ETA: 1s - loss: 12178.2441 - KL_divergence: 9.8343 
 39/200 [====>.........................] - ETA: 1s - loss: 12161.9236 - KL_divergence: 9.8970
 45/200 [=====>........................] - ETA: 1s - loss: 12173.5275 - KL_divergence: 9.9122
 51/200 [======>.......................] - ETA: 1s - loss: 12217.9763 - KL_divergence: 9.8826
 57/200 [=======>......................] - ETA: 1s - loss: 12206.9248 - KL_divergence: 9.8006
 63/200 [========>.....................] - ETA: 1s - loss: 12193.0586 - KL_divergence: 9.8464
 69/200 [=========>....................] - ETA: 1s - loss: 12188.8646 - KL_divergence: 9.8999
 75/200 [==========>...................] - ETA: 1s - loss: 12163.8620 - KL_divergence: 9.9781
 81/200 [===========>..................] - ETA: 1s - loss: 12167.1204 - KL_divergence: 9.9906
 87/200 [============>.................] - ETA: 0s - loss: 12157.6849 - KL_divergence: 10.0214
 93/200 [============>.................] - ETA: 0s - loss: 12167.4960 - KL_divergence: 10.0469
 99/200 [=============>................] - ETA: 0s - loss: 12193.5287 - KL_divergence: 10.0327
105/200 [==============>...............] - ETA: 0s - loss: 12209.2782 - KL_divergence: 10.0370
111/200 [===============>..............] - ETA: 0s - loss: 12203.2623 - KL_divergence: 10.0631
117/200 [================>.............] - ETA: 0s - loss: 12190.1270 - KL_divergence: 10.0980
123/200 [=================>............] - ETA: 0s - loss: 12196.1022 - KL_divergence: 10.0853
129/200 [==================>...........] - ETA: 0s - loss: 12210.9283 - KL_divergence: 10.0806
135/200 [===================>..........] - ETA: 0s - loss: 12220.3002 - KL_divergence: 10.0636
141/200 [====================>.........] - ETA: 0s - loss: 12213.8250 - KL_divergence: 10.0664
147/200 [=====================>........] - ETA: 0s - loss: 12215.4282 - KL_divergence: 10.0945
152/200 [=====================>........] - ETA: 0s - loss: 12213.6298 - KL_divergence: 10.0955
157/200 [======================>.......] - ETA: 0s - loss: 12229.1460 - KL_divergence: 10.1015
163/200 [=======================>......] - ETA: 0s - loss: 12223.0401 - KL_divergence: 10.1510
169/200 [========================>.....] - ETA: 0s - loss: 12223.4080 - KL_divergence: 10.1848
175/200 [=========================>....] - ETA: 0s - loss: 12226.0134 - KL_divergence: 10.2014
181/200 [==========================>...] - ETA: 0s - loss: 12219.9882 - KL_divergence: 10.2023
187/200 [===========================>..] - ETA: 0s - loss: 12224.5120 - KL_divergence: 10.2033
193/200 [===========================>..] - ETA: 0s - loss: 12242.0435 - KL_divergence: 10.2257
199/200 [============================>.] - ETA: 0s - loss: 12255.1832 - KL_divergence: 10.2427
200/200 [==============================] - 2s 10ms/step - loss: 12252.3469 - KL_divergence: 10.2477 - val_loss: 12782.5516 - val_KL_divergence: 9.6681
Epoch 80/100

  1/200 [..............................] - ETA: 1s - loss: 13121.8936 - KL_divergence: 9.3104
  7/200 [>.............................] - ETA: 1s - loss: 12616.3612 - KL_divergence: 9.8306
 14/200 [=>............................] - ETA: 1s - loss: 12616.1366 - KL_divergence: 10.2069
 20/200 [==>...........................] - ETA: 1s - loss: 12607.6023 - KL_divergence: 10.2461
 27/200 [===>..........................] - ETA: 1s - loss: 12632.2858 - KL_divergence: 9.9677 
 33/200 [===>..........................] - ETA: 1s - loss: 12576.4760 - KL_divergence: 10.1543
 39/200 [====>.........................] - ETA: 1s - loss: 12526.9194 - KL_divergence: 10.1849
 45/200 [=====>........................] - ETA: 1s - loss: 12490.2222 - KL_divergence: 10.2733
 51/200 [======>.......................] - ETA: 1s - loss: 12502.0634 - KL_divergence: 10.2461
 57/200 [=======>......................] - ETA: 1s - loss: 12439.9766 - KL_divergence: 10.2662
 63/200 [========>.....................] - ETA: 1s - loss: 12460.7523 - KL_divergence: 10.2846
 69/200 [=========>....................] - ETA: 1s - loss: 12423.7942 - KL_divergence: 10.3057
 75/200 [==========>...................] - ETA: 1s - loss: 12387.6251 - KL_divergence: 10.3299
 81/200 [===========>..................] - ETA: 1s - loss: 12386.3143 - KL_divergence: 10.2729
 87/200 [============>.................] - ETA: 1s - loss: 12386.2566 - KL_divergence: 10.3363
 93/200 [============>.................] - ETA: 0s - loss: 12369.6280 - KL_divergence: 10.3609
 99/200 [=============>................] - ETA: 0s - loss: 12362.2252 - KL_divergence: 10.2885
105/200 [==============>...............] - ETA: 0s - loss: 12363.4896 - KL_divergence: 10.2575
111/200 [===============>..............] - ETA: 0s - loss: 12369.4053 - KL_divergence: 10.2263
117/200 [================>.............] - ETA: 0s - loss: 12362.9013 - KL_divergence: 10.2143
123/200 [=================>............] - ETA: 0s - loss: 12358.8282 - KL_divergence: 10.1897
129/200 [==================>...........] - ETA: 0s - loss: 12345.9946 - KL_divergence: 10.1775
135/200 [===================>..........] - ETA: 0s - loss: 12338.1996 - KL_divergence: 10.1526
141/200 [====================>.........] - ETA: 0s - loss: 12333.1382 - KL_divergence: 10.1422
147/200 [=====================>........] - ETA: 0s - loss: 12329.2801 - KL_divergence: 10.1700
153/200 [=====================>........] - ETA: 0s - loss: 12335.8470 - KL_divergence: 10.1354
159/200 [======================>.......] - ETA: 0s - loss: 12339.1568 - KL_divergence: 10.1285
165/200 [=======================>......] - ETA: 0s - loss: 12346.9037 - KL_divergence: 10.0913
171/200 [========================>.....] - ETA: 0s - loss: 12340.0696 - KL_divergence: 10.0709
177/200 [=========================>....] - ETA: 0s - loss: 12334.6287 - KL_divergence: 10.1189
184/200 [==========================>...] - ETA: 0s - loss: 12337.6751 - KL_divergence: 10.0757
190/200 [===========================>..] - ETA: 0s - loss: 12332.2009 - KL_divergence: 10.0633
196/200 [============================>.] - ETA: 0s - loss: 12336.7704 - KL_divergence: 10.0459
200/200 [==============================] - 2s 10ms/step - loss: 12336.8962 - KL_divergence: 10.0300 - val_loss: 12597.0279 - val_KL_divergence: 9.9784
Epoch 81/100

  1/200 [..............................] - ETA: 1s - loss: 13002.9805 - KL_divergence: 8.1442
  7/200 [>.............................] - ETA: 1s - loss: 12289.6279 - KL_divergence: 9.3918
 13/200 [>.............................] - ETA: 1s - loss: 12427.7459 - KL_divergence: 9.6548
 19/200 [=>............................] - ETA: 1s - loss: 12370.0592 - KL_divergence: 9.9413
 25/200 [==>...........................] - ETA: 1s - loss: 12411.5898 - KL_divergence: 10.0265
 31/200 [===>..........................] - ETA: 1s - loss: 12445.4619 - KL_divergence: 9.9040 
 37/200 [====>.........................] - ETA: 1s - loss: 12423.6613 - KL_divergence: 9.8709
 43/200 [=====>........................] - ETA: 1s - loss: 12420.8524 - KL_divergence: 9.7898
 49/200 [======>.......................] - ETA: 1s - loss: 12375.9062 - KL_divergence: 9.8614
 55/200 [=======>......................] - ETA: 1s - loss: 12364.8646 - KL_divergence: 9.8001
 61/200 [========>.....................] - ETA: 1s - loss: 12347.4732 - KL_divergence: 9.8040
 67/200 [=========>....................] - ETA: 1s - loss: 12360.2607 - KL_divergence: 9.8435
 73/200 [=========>....................] - ETA: 1s - loss: 12346.8079 - KL_divergence: 9.8385
 79/200 [==========>...................] - ETA: 1s - loss: 12321.1022 - KL_divergence: 9.8090
 85/200 [===========>..................] - ETA: 1s - loss: 12310.3766 - KL_divergence: 9.7697
 91/200 [============>.................] - ETA: 0s - loss: 12327.8456 - KL_divergence: 9.7003
 97/200 [=============>................] - ETA: 0s - loss: 12322.9683 - KL_divergence: 9.6566
103/200 [==============>...............] - ETA: 0s - loss: 12311.9006 - KL_divergence: 9.6511
109/200 [===============>..............] - ETA: 0s - loss: 12285.3398 - KL_divergence: 9.6435
115/200 [================>.............] - ETA: 0s - loss: 12272.7207 - KL_divergence: 9.6691
121/200 [=================>............] - ETA: 0s - loss: 12273.3805 - KL_divergence: 9.6914
127/200 [==================>...........] - ETA: 0s - loss: 12268.4268 - KL_divergence: 9.7204
133/200 [==================>...........] - ETA: 0s - loss: 12252.6140 - KL_divergence: 9.7500
139/200 [===================>..........] - ETA: 0s - loss: 12244.3613 - KL_divergence: 9.7258
145/200 [====================>.........] - ETA: 0s - loss: 12236.9555 - KL_divergence: 9.7569
151/200 [=====================>........] - ETA: 0s - loss: 12242.4727 - KL_divergence: 9.7542
157/200 [======================>.......] - ETA: 0s - loss: 12234.6471 - KL_divergence: 9.7730
163/200 [=======================>......] - ETA: 0s - loss: 12235.5541 - KL_divergence: 9.8074
169/200 [========================>.....] - ETA: 0s - loss: 12240.5870 - KL_divergence: 9.8369
175/200 [=========================>....] - ETA: 0s - loss: 12244.3102 - KL_divergence: 9.8406
181/200 [==========================>...] - ETA: 0s - loss: 12238.2938 - KL_divergence: 9.8559
187/200 [===========================>..] - ETA: 0s - loss: 12240.6733 - KL_divergence: 9.8717
193/200 [===========================>..] - ETA: 0s - loss: 12242.6577 - KL_divergence: 9.8698
199/200 [============================>.] - ETA: 0s - loss: 12243.3718 - KL_divergence: 9.8732
200/200 [==============================] - 2s 10ms/step - loss: 12244.3987 - KL_divergence: 9.8791 - val_loss: 12616.1181 - val_KL_divergence: 10.0298
Epoch 82/100

  1/200 [..............................] - ETA: 1s - loss: 12182.8652 - KL_divergence: 9.1555
  7/200 [>.............................] - ETA: 1s - loss: 12552.8842 - KL_divergence: 9.3696
 13/200 [>.............................] - ETA: 1s - loss: 12431.3524 - KL_divergence: 10.3057
 19/200 [=>............................] - ETA: 1s - loss: 12377.2255 - KL_divergence: 10.6835
 25/200 [==>...........................] - ETA: 1s - loss: 12387.2607 - KL_divergence: 10.4654
 31/200 [===>..........................] - ETA: 1s - loss: 12403.6299 - KL_divergence: 10.5403
 37/200 [====>.........................] - ETA: 1s - loss: 12412.2442 - KL_divergence: 10.6380
 42/200 [=====>........................] - ETA: 1s - loss: 12384.8082 - KL_divergence: 10.6190
 48/200 [======>.......................] - ETA: 1s - loss: 12376.2715 - KL_divergence: 10.4964
 54/200 [=======>......................] - ETA: 1s - loss: 12436.7792 - KL_divergence: 10.4495
 60/200 [========>.....................] - ETA: 1s - loss: 12399.5023 - KL_divergence: 10.5555
 67/200 [=========>....................] - ETA: 1s - loss: 12387.7351 - KL_divergence: 10.5815
 73/200 [=========>....................] - ETA: 1s - loss: 12407.9881 - KL_divergence: 10.5269
 79/200 [==========>...................] - ETA: 1s - loss: 12400.5167 - KL_divergence: 10.5546
 85/200 [===========>..................] - ETA: 1s - loss: 12422.1223 - KL_divergence: 10.4836
 91/200 [============>.................] - ETA: 1s - loss: 12426.5426 - KL_divergence: 10.4465
 96/200 [=============>................] - ETA: 0s - loss: 12420.4689 - KL_divergence: 10.4261
102/200 [==============>...............] - ETA: 0s - loss: 12422.7083 - KL_divergence: 10.4009
108/200 [===============>..............] - ETA: 0s - loss: 12398.5733 - KL_divergence: 10.4416
114/200 [================>.............] - ETA: 0s - loss: 12380.7966 - KL_divergence: 10.4001
120/200 [=================>............] - ETA: 0s - loss: 12373.6790 - KL_divergence: 10.3740
127/200 [==================>...........] - ETA: 0s - loss: 12381.6160 - KL_divergence: 10.3501
133/200 [==================>...........] - ETA: 0s - loss: 12385.1217 - KL_divergence: 10.2918
139/200 [===================>..........] - ETA: 0s - loss: 12378.1585 - KL_divergence: 10.2727
146/200 [====================>.........] - ETA: 0s - loss: 12376.2719 - KL_divergence: 10.2692
152/200 [=====================>........] - ETA: 0s - loss: 12381.5268 - KL_divergence: 10.2339
158/200 [======================>.......] - ETA: 0s - loss: 12365.4150 - KL_divergence: 10.2313
164/200 [=======================>......] - ETA: 0s - loss: 12348.9884 - KL_divergence: 10.2188
170/200 [========================>.....] - ETA: 0s - loss: 12344.3943 - KL_divergence: 10.2164
176/200 [=========================>....] - ETA: 0s - loss: 12340.0821 - KL_divergence: 10.2194
182/200 [==========================>...] - ETA: 0s - loss: 12341.5451 - KL_divergence: 10.1879
188/200 [===========================>..] - ETA: 0s - loss: 12351.1820 - KL_divergence: 10.1661
194/200 [============================>.] - ETA: 0s - loss: 12341.1453 - KL_divergence: 10.1779
200/200 [==============================] - 2s 10ms/step - loss: 12320.8973 - KL_divergence: 10.2000 - val_loss: 12539.9682 - val_KL_divergence: 9.8119
Epoch 83/100

  1/200 [..............................] - ETA: 1s - loss: 11099.1602 - KL_divergence: 11.2925
  7/200 [>.............................] - ETA: 1s - loss: 12108.1551 - KL_divergence: 10.4793
 13/200 [>.............................] - ETA: 1s - loss: 12132.6288 - KL_divergence: 10.5285
 19/200 [=>............................] - ETA: 1s - loss: 12223.9027 - KL_divergence: 10.1573
 25/200 [==>...........................] - ETA: 1s - loss: 12214.7068 - KL_divergence: 10.0120
 32/200 [===>..........................] - ETA: 1s - loss: 12271.5666 - KL_divergence: 9.8550 
 38/200 [====>.........................] - ETA: 1s - loss: 12291.0804 - KL_divergence: 9.7981
 44/200 [=====>........................] - ETA: 1s - loss: 12304.2343 - KL_divergence: 9.7706
 50/200 [======>.......................] - ETA: 1s - loss: 12302.1622 - KL_divergence: 9.7848
 56/200 [=======>......................] - ETA: 1s - loss: 12272.7973 - KL_divergence: 9.7732
 62/200 [========>.....................] - ETA: 1s - loss: 12262.9071 - KL_divergence: 9.7290
 68/200 [=========>....................] - ETA: 1s - loss: 12296.5084 - KL_divergence: 9.7170
 74/200 [==========>...................] - ETA: 1s - loss: 12310.6796 - KL_divergence: 9.7415
 80/200 [===========>..................] - ETA: 1s - loss: 12294.1011 - KL_divergence: 9.7352
 86/200 [===========>..................] - ETA: 1s - loss: 12266.9048 - KL_divergence: 9.7769
 92/200 [============>.................] - ETA: 0s - loss: 12268.9691 - KL_divergence: 9.7809
 98/200 [=============>................] - ETA: 0s - loss: 12271.8959 - KL_divergence: 9.8044
104/200 [==============>...............] - ETA: 0s - loss: 12252.9060 - KL_divergence: 9.8409
110/200 [===============>..............] - ETA: 0s - loss: 12254.5971 - KL_divergence: 9.8673
116/200 [================>.............] - ETA: 0s - loss: 12227.6139 - KL_divergence: 9.9379
122/200 [=================>............] - ETA: 0s - loss: 12214.5038 - KL_divergence: 9.9555
128/200 [==================>...........] - ETA: 0s - loss: 12207.7468 - KL_divergence: 9.9737
134/200 [===================>..........] - ETA: 0s - loss: 12206.4878 - KL_divergence: 9.9616
140/200 [====================>.........] - ETA: 0s - loss: 12188.9107 - KL_divergence: 9.9938
146/200 [====================>.........] - ETA: 0s - loss: 12186.3668 - KL_divergence: 10.0366
152/200 [=====================>........] - ETA: 0s - loss: 12187.6914 - KL_divergence: 10.0323
158/200 [======================>.......] - ETA: 0s - loss: 12181.7530 - KL_divergence: 10.0025
164/200 [=======================>......] - ETA: 0s - loss: 12185.4853 - KL_divergence: 9.9827 
170/200 [========================>.....] - ETA: 0s - loss: 12190.1301 - KL_divergence: 9.9601
176/200 [=========================>....] - ETA: 0s - loss: 12199.9106 - KL_divergence: 9.9596
182/200 [==========================>...] - ETA: 0s - loss: 12201.3701 - KL_divergence: 9.9475
188/200 [===========================>..] - ETA: 0s - loss: 12200.1810 - KL_divergence: 9.9825
194/200 [============================>.] - ETA: 0s - loss: 12197.4862 - KL_divergence: 9.9794
200/200 [==============================] - 2s 10ms/step - loss: 12196.3630 - KL_divergence: 9.9812 - val_loss: 12389.2981 - val_KL_divergence: 9.9114
Epoch 84/100

  1/200 [..............................] - ETA: 1s - loss: 12163.7617 - KL_divergence: 9.9904
  7/200 [>.............................] - ETA: 1s - loss: 12167.4439 - KL_divergence: 10.2773
 13/200 [>.............................] - ETA: 1s - loss: 12008.0837 - KL_divergence: 10.5997
 19/200 [=>............................] - ETA: 1s - loss: 12074.6473 - KL_divergence: 10.4457
 25/200 [==>...........................] - ETA: 1s - loss: 12096.3721 - KL_divergence: 10.4406
 32/200 [===>..........................] - ETA: 1s - loss: 12162.0904 - KL_divergence: 10.5456
 38/200 [====>.........................] - ETA: 1s - loss: 12145.7326 - KL_divergence: 10.5943
 44/200 [=====>........................] - ETA: 1s - loss: 12147.1414 - KL_divergence: 10.5880
 51/200 [======>.......................] - ETA: 1s - loss: 12124.1994 - KL_divergence: 10.5461
 57/200 [=======>......................] - ETA: 1s - loss: 12146.8211 - KL_divergence: 10.4456
 63/200 [========>.....................] - ETA: 1s - loss: 12154.2931 - KL_divergence: 10.3462
 69/200 [=========>....................] - ETA: 1s - loss: 12148.8042 - KL_divergence: 10.2773
 75/200 [==========>...................] - ETA: 1s - loss: 12190.1378 - KL_divergence: 10.2454
 81/200 [===========>..................] - ETA: 1s - loss: 12212.0605 - KL_divergence: 10.1965
 87/200 [============>.................] - ETA: 1s - loss: 12210.9621 - KL_divergence: 10.1864
 93/200 [============>.................] - ETA: 0s - loss: 12197.9964 - KL_divergence: 10.1742
 99/200 [=============>................] - ETA: 0s - loss: 12204.3547 - KL_divergence: 10.1356
105/200 [==============>...............] - ETA: 0s - loss: 12195.0298 - KL_divergence: 10.1370
111/200 [===============>..............] - ETA: 0s - loss: 12199.2381 - KL_divergence: 10.1240
117/200 [================>.............] - ETA: 0s - loss: 12206.6033 - KL_divergence: 10.1218
123/200 [=================>............] - ETA: 0s - loss: 12197.0293 - KL_divergence: 10.1542
129/200 [==================>...........] - ETA: 0s - loss: 12199.2056 - KL_divergence: 10.1485
135/200 [===================>..........] - ETA: 0s - loss: 12204.2475 - KL_divergence: 10.1258
141/200 [====================>.........] - ETA: 0s - loss: 12215.2503 - KL_divergence: 10.1218
147/200 [=====================>........] - ETA: 0s - loss: 12220.9461 - KL_divergence: 10.0980
153/200 [=====================>........] - ETA: 0s - loss: 12214.2560 - KL_divergence: 10.1050
159/200 [======================>.......] - ETA: 0s - loss: 12204.3690 - KL_divergence: 10.0996
165/200 [=======================>......] - ETA: 0s - loss: 12208.2025 - KL_divergence: 10.0827
171/200 [========================>.....] - ETA: 0s - loss: 12198.6528 - KL_divergence: 10.0958
177/200 [=========================>....] - ETA: 0s - loss: 12203.3544 - KL_divergence: 10.1093
183/200 [==========================>...] - ETA: 0s - loss: 12202.5275 - KL_divergence: 10.1013
189/200 [===========================>..] - ETA: 0s - loss: 12204.0471 - KL_divergence: 10.0861
195/200 [============================>.] - ETA: 0s - loss: 12205.1106 - KL_divergence: 10.0979
200/200 [==============================] - 2s 10ms/step - loss: 12220.3394 - KL_divergence: 10.0857 - val_loss: 12396.2137 - val_KL_divergence: 10.2494
Epoch 85/100

  1/200 [..............................] - ETA: 1s - loss: 12001.0576 - KL_divergence: 9.4690
  7/200 [>.............................] - ETA: 1s - loss: 12023.0085 - KL_divergence: 9.7436
 13/200 [>.............................] - ETA: 1s - loss: 12133.6798 - KL_divergence: 10.1446
 19/200 [=>............................] - ETA: 1s - loss: 12222.0108 - KL_divergence: 10.0289
 26/200 [==>...........................] - ETA: 1s - loss: 12207.7805 - KL_divergence: 10.1667
 32/200 [===>..........................] - ETA: 1s - loss: 12265.7435 - KL_divergence: 10.1234
 38/200 [====>.........................] - ETA: 1s - loss: 12269.6282 - KL_divergence: 9.9468 
 44/200 [=====>........................] - ETA: 1s - loss: 12205.9831 - KL_divergence: 9.9317
 50/200 [======>.......................] - ETA: 1s - loss: 12192.2324 - KL_divergence: 10.0662
 56/200 [=======>......................] - ETA: 1s - loss: 12178.7923 - KL_divergence: 10.0967
 62/200 [========>.....................] - ETA: 1s - loss: 12154.7099 - KL_divergence: 10.0808
 68/200 [=========>....................] - ETA: 1s - loss: 12141.2257 - KL_divergence: 10.1392
 74/200 [==========>...................] - ETA: 1s - loss: 12149.5225 - KL_divergence: 10.1267
 80/200 [===========>..................] - ETA: 1s - loss: 12161.9424 - KL_divergence: 10.1398
 86/200 [===========>..................] - ETA: 1s - loss: 12159.7220 - KL_divergence: 10.1403
 92/200 [============>.................] - ETA: 0s - loss: 12176.5602 - KL_divergence: 10.1459
 98/200 [=============>................] - ETA: 0s - loss: 12200.1142 - KL_divergence: 10.1624
104/200 [==============>...............] - ETA: 0s - loss: 12205.1032 - KL_divergence: 10.2113
110/200 [===============>..............] - ETA: 0s - loss: 12203.4978 - KL_divergence: 10.2608
116/200 [================>.............] - ETA: 0s - loss: 12197.9228 - KL_divergence: 10.3008
122/200 [=================>............] - ETA: 0s - loss: 12190.6049 - KL_divergence: 10.3311
128/200 [==================>...........] - ETA: 0s - loss: 12199.0565 - KL_divergence: 10.3321
134/200 [===================>..........] - ETA: 0s - loss: 12191.5421 - KL_divergence: 10.3502
140/200 [====================>.........] - ETA: 0s - loss: 12191.3843 - KL_divergence: 10.3558
146/200 [====================>.........] - ETA: 0s - loss: 12190.8981 - KL_divergence: 10.3661
152/200 [=====================>........] - ETA: 0s - loss: 12188.0628 - KL_divergence: 10.3853
158/200 [======================>.......] - ETA: 0s - loss: 12179.9070 - KL_divergence: 10.3861
164/200 [=======================>......] - ETA: 0s - loss: 12171.1461 - KL_divergence: 10.3914
170/200 [========================>.....] - ETA: 0s - loss: 12168.2937 - KL_divergence: 10.3747
176/200 [=========================>....] - ETA: 0s - loss: 12156.8343 - KL_divergence: 10.3745
182/200 [==========================>...] - ETA: 0s - loss: 12159.5145 - KL_divergence: 10.3590
188/200 [===========================>..] - ETA: 0s - loss: 12171.0534 - KL_divergence: 10.3505
195/200 [============================>.] - ETA: 0s - loss: 12169.3136 - KL_divergence: 10.3489
200/200 [==============================] - 2s 10ms/step - loss: 12170.1842 - KL_divergence: 10.3528 - val_loss: 12503.6176 - val_KL_divergence: 10.9824
Epoch 86/100

  1/200 [..............................] - ETA: 1s - loss: 12055.5742 - KL_divergence: 9.3669
  7/200 [>.............................] - ETA: 1s - loss: 12434.7190 - KL_divergence: 10.3441
 12/200 [>.............................] - ETA: 1s - loss: 12441.5092 - KL_divergence: 10.0809
 17/200 [=>............................] - ETA: 1s - loss: 12334.1366 - KL_divergence: 10.1533
 23/200 [==>...........................] - ETA: 1s - loss: 12258.2845 - KL_divergence: 10.3086
 29/200 [===>..........................] - ETA: 1s - loss: 12247.8507 - KL_divergence: 10.3171
 35/200 [====>.........................] - ETA: 1s - loss: 12215.3846 - KL_divergence: 10.6011
 41/200 [=====>........................] - ETA: 1s - loss: 12189.3291 - KL_divergence: 10.5555
 47/200 [======>.......................] - ETA: 1s - loss: 12194.5952 - KL_divergence: 10.5111
 53/200 [======>.......................] - ETA: 1s - loss: 12209.4262 - KL_divergence: 10.4428
 59/200 [=======>......................] - ETA: 1s - loss: 12225.1923 - KL_divergence: 10.4505
 66/200 [========>.....................] - ETA: 1s - loss: 12227.4168 - KL_divergence: 10.3828
 73/200 [=========>....................] - ETA: 1s - loss: 12201.6650 - KL_divergence: 10.3331
 79/200 [==========>...................] - ETA: 1s - loss: 12190.2476 - KL_divergence: 10.3393
 85/200 [===========>..................] - ETA: 1s - loss: 12196.5527 - KL_divergence: 10.3438
 91/200 [============>.................] - ETA: 0s - loss: 12196.5436 - KL_divergence: 10.2657
 97/200 [=============>................] - ETA: 0s - loss: 12196.6464 - KL_divergence: 10.2705
103/200 [==============>...............] - ETA: 0s - loss: 12200.7564 - KL_divergence: 10.2583
109/200 [===============>..............] - ETA: 0s - loss: 12203.6010 - KL_divergence: 10.2534
115/200 [================>.............] - ETA: 0s - loss: 12200.7303 - KL_divergence: 10.2711
121/200 [=================>............] - ETA: 0s - loss: 12204.5040 - KL_divergence: 10.2917
127/200 [==================>...........] - ETA: 0s - loss: 12201.2024 - KL_divergence: 10.2615
133/200 [==================>...........] - ETA: 0s - loss: 12186.8741 - KL_divergence: 10.2593
139/200 [===================>..........] - ETA: 0s - loss: 12181.7785 - KL_divergence: 10.2444
146/200 [====================>.........] - ETA: 0s - loss: 12182.2432 - KL_divergence: 10.2528
152/200 [=====================>........] - ETA: 0s - loss: 12183.1138 - KL_divergence: 10.2471
158/200 [======================>.......] - ETA: 0s - loss: 12187.7075 - KL_divergence: 10.2414
164/200 [=======================>......] - ETA: 0s - loss: 12206.4408 - KL_divergence: 10.2189
171/200 [========================>.....] - ETA: 0s - loss: 12199.7316 - KL_divergence: 10.2450
177/200 [=========================>....] - ETA: 0s - loss: 12191.3746 - KL_divergence: 10.2620
183/200 [==========================>...] - ETA: 0s - loss: 12190.4768 - KL_divergence: 10.2540
188/200 [===========================>..] - ETA: 0s - loss: 12194.3381 - KL_divergence: 10.2342
194/200 [============================>.] - ETA: 0s - loss: 12181.8150 - KL_divergence: 10.2294
200/200 [==============================] - 2s 10ms/step - loss: 12176.5930 - KL_divergence: 10.2298 - val_loss: 12400.0549 - val_KL_divergence: 9.9301
Epoch 87/100

  1/200 [..............................] - ETA: 1s - loss: 11781.6035 - KL_divergence: 9.2816
  7/200 [>.............................] - ETA: 1s - loss: 12100.9311 - KL_divergence: 10.2736
 12/200 [>.............................] - ETA: 1s - loss: 12019.5554 - KL_divergence: 10.3813
 17/200 [=>............................] - ETA: 1s - loss: 12098.8323 - KL_divergence: 10.1711
 23/200 [==>...........................] - ETA: 1s - loss: 12135.2903 - KL_divergence: 10.1093
 29/200 [===>..........................] - ETA: 1s - loss: 12107.7157 - KL_divergence: 9.9497 
 35/200 [====>.........................] - ETA: 1s - loss: 12147.9754 - KL_divergence: 9.8652
 41/200 [=====>........................] - ETA: 1s - loss: 12137.8892 - KL_divergence: 9.7960
 47/200 [======>.......................] - ETA: 1s - loss: 12146.7877 - KL_divergence: 9.7506
 52/200 [======>.......................] - ETA: 1s - loss: 12102.5282 - KL_divergence: 9.7366
 58/200 [=======>......................] - ETA: 1s - loss: 12107.4169 - KL_divergence: 9.7096
 64/200 [========>.....................] - ETA: 1s - loss: 12096.7490 - KL_divergence: 9.7347
 70/200 [=========>....................] - ETA: 1s - loss: 12097.7579 - KL_divergence: 9.7695
 76/200 [==========>...................] - ETA: 1s - loss: 12092.3136 - KL_divergence: 9.8457
 82/200 [===========>..................] - ETA: 1s - loss: 12099.2727 - KL_divergence: 9.8335
 88/200 [============>.................] - ETA: 1s - loss: 12108.2954 - KL_divergence: 9.8458
 94/200 [=============>................] - ETA: 0s - loss: 12110.2727 - KL_divergence: 9.8559
100/200 [==============>...............] - ETA: 0s - loss: 12111.3332 - KL_divergence: 9.8427
106/200 [==============>...............] - ETA: 0s - loss: 12097.4084 - KL_divergence: 9.8907
112/200 [===============>..............] - ETA: 0s - loss: 12103.3538 - KL_divergence: 9.9384
118/200 [================>.............] - ETA: 0s - loss: 12109.4616 - KL_divergence: 9.9482
124/200 [=================>............] - ETA: 0s - loss: 12115.5255 - KL_divergence: 9.9570
130/200 [==================>...........] - ETA: 0s - loss: 12116.9673 - KL_divergence: 9.9740
136/200 [===================>..........] - ETA: 0s - loss: 12126.7633 - KL_divergence: 9.9667
142/200 [====================>.........] - ETA: 0s - loss: 12128.9254 - KL_divergence: 9.9713
148/200 [=====================>........] - ETA: 0s - loss: 12124.1036 - KL_divergence: 9.9925
154/200 [======================>.......] - ETA: 0s - loss: 12124.1617 - KL_divergence: 9.9885
160/200 [=======================>......] - ETA: 0s - loss: 12134.0565 - KL_divergence: 9.9737
166/200 [=======================>......] - ETA: 0s - loss: 12132.2604 - KL_divergence: 9.9485
172/200 [========================>.....] - ETA: 0s - loss: 12135.1511 - KL_divergence: 9.9400
178/200 [=========================>....] - ETA: 0s - loss: 12144.1413 - KL_divergence: 9.9262
184/200 [==========================>...] - ETA: 0s - loss: 12145.3129 - KL_divergence: 9.9332
190/200 [===========================>..] - ETA: 0s - loss: 12142.6091 - KL_divergence: 9.9967
196/200 [============================>.] - ETA: 0s - loss: 12151.8568 - KL_divergence: 10.0104
200/200 [==============================] - 2s 10ms/step - loss: 12151.9203 - KL_divergence: 10.0109 - val_loss: 12767.1737 - val_KL_divergence: 10.4438
Epoch 88/100

  1/200 [..............................] - ETA: 1s - loss: 13396.5010 - KL_divergence: 7.9045
  7/200 [>.............................] - ETA: 1s - loss: 12281.4492 - KL_divergence: 10.4890
 13/200 [>.............................] - ETA: 1s - loss: 12207.5798 - KL_divergence: 10.7957
 19/200 [=>............................] - ETA: 1s - loss: 12253.5294 - KL_divergence: 10.7980
 25/200 [==>...........................] - ETA: 1s - loss: 12301.3913 - KL_divergence: 10.9022
 31/200 [===>..........................] - ETA: 1s - loss: 12295.6844 - KL_divergence: 10.6129
 37/200 [====>.........................] - ETA: 1s - loss: 12324.6441 - KL_divergence: 10.6993
 43/200 [=====>........................] - ETA: 1s - loss: 12338.7130 - KL_divergence: 10.7252
 49/200 [======>.......................] - ETA: 1s - loss: 12337.1914 - KL_divergence: 10.6225
 55/200 [=======>......................] - ETA: 1s - loss: 12317.6258 - KL_divergence: 10.5437
 61/200 [========>.....................] - ETA: 1s - loss: 12300.9821 - KL_divergence: 10.4778
 67/200 [=========>....................] - ETA: 1s - loss: 12266.0036 - KL_divergence: 10.5029
 73/200 [=========>....................] - ETA: 1s - loss: 12240.8544 - KL_divergence: 10.4781
 79/200 [==========>...................] - ETA: 1s - loss: 12228.5869 - KL_divergence: 10.5229
 85/200 [===========>..................] - ETA: 1s - loss: 12214.2763 - KL_divergence: 10.4725
 91/200 [============>.................] - ETA: 0s - loss: 12217.2360 - KL_divergence: 10.4720
 97/200 [=============>................] - ETA: 0s - loss: 12200.2541 - KL_divergence: 10.5390
103/200 [==============>...............] - ETA: 0s - loss: 12205.4139 - KL_divergence: 10.5266
108/200 [===============>..............] - ETA: 0s - loss: 12219.8107 - KL_divergence: 10.5144
114/200 [================>.............] - ETA: 0s - loss: 12196.5478 - KL_divergence: 10.5074
120/200 [=================>............] - ETA: 0s - loss: 12199.8407 - KL_divergence: 10.4666
126/200 [=================>............] - ETA: 0s - loss: 12206.0085 - KL_divergence: 10.4521
132/200 [==================>...........] - ETA: 0s - loss: 12195.1612 - KL_divergence: 10.4427
138/200 [===================>..........] - ETA: 0s - loss: 12192.7342 - KL_divergence: 10.4032
144/200 [====================>.........] - ETA: 0s - loss: 12209.9474 - KL_divergence: 10.4265
150/200 [=====================>........] - ETA: 0s - loss: 12216.2819 - KL_divergence: 10.4806
156/200 [======================>.......] - ETA: 0s - loss: 12220.8982 - KL_divergence: 10.5147
162/200 [=======================>......] - ETA: 0s - loss: 12230.7912 - KL_divergence: 10.4791
168/200 [========================>.....] - ETA: 0s - loss: 12229.5186 - KL_divergence: 10.4471
174/200 [=========================>....] - ETA: 0s - loss: 12218.6689 - KL_divergence: 10.4494
180/200 [==========================>...] - ETA: 0s - loss: 12227.1103 - KL_divergence: 10.4269
186/200 [==========================>...] - ETA: 0s - loss: 12229.6076 - KL_divergence: 10.4260
192/200 [===========================>..] - ETA: 0s - loss: 12213.8810 - KL_divergence: 10.4484
198/200 [============================>.] - ETA: 0s - loss: 12209.9826 - KL_divergence: 10.4784
200/200 [==============================] - 2s 10ms/step - loss: 12208.1058 - KL_divergence: 10.4848 - val_loss: 12505.9901 - val_KL_divergence: 9.9738
Epoch 89/100

  1/200 [..............................] - ETA: 1s - loss: 12521.0527 - KL_divergence: 10.1691
  7/200 [>.............................] - ETA: 1s - loss: 12358.7114 - KL_divergence: 10.4511
 13/200 [>.............................] - ETA: 1s - loss: 12473.9322 - KL_divergence: 10.3253
 19/200 [=>............................] - ETA: 1s - loss: 12473.0711 - KL_divergence: 10.1290
 25/200 [==>...........................] - ETA: 1s - loss: 12386.8273 - KL_divergence: 10.1773
 31/200 [===>..........................] - ETA: 1s - loss: 12317.5573 - KL_divergence: 10.3112
 37/200 [====>.........................] - ETA: 1s - loss: 12298.7565 - KL_divergence: 10.2625
 43/200 [=====>........................] - ETA: 1s - loss: 12318.2688 - KL_divergence: 10.1091
 49/200 [======>.......................] - ETA: 1s - loss: 12314.3008 - KL_divergence: 10.0731
 55/200 [=======>......................] - ETA: 1s - loss: 12346.9230 - KL_divergence: 10.0752
 61/200 [========>.....................] - ETA: 1s - loss: 12354.2480 - KL_divergence: 10.0679
 67/200 [=========>....................] - ETA: 1s - loss: 12346.7398 - KL_divergence: 10.0855
 73/200 [=========>....................] - ETA: 1s - loss: 12351.4885 - KL_divergence: 10.1395
 79/200 [==========>...................] - ETA: 1s - loss: 12341.8583 - KL_divergence: 10.1527
 85/200 [===========>..................] - ETA: 1s - loss: 12328.3152 - KL_divergence: 10.2018
 91/200 [============>.................] - ETA: 1s - loss: 12331.8832 - KL_divergence: 10.2402
 97/200 [=============>................] - ETA: 0s - loss: 12332.7004 - KL_divergence: 10.2502
103/200 [==============>...............] - ETA: 0s - loss: 12333.2087 - KL_divergence: 10.2248
109/200 [===============>..............] - ETA: 0s - loss: 12313.3660 - KL_divergence: 10.2378
115/200 [================>.............] - ETA: 0s - loss: 12319.5637 - KL_divergence: 10.2209
121/200 [=================>............] - ETA: 0s - loss: 12315.2262 - KL_divergence: 10.2366
127/200 [==================>...........] - ETA: 0s - loss: 12294.2681 - KL_divergence: 10.2977
133/200 [==================>...........] - ETA: 0s - loss: 12301.2956 - KL_divergence: 10.3084
139/200 [===================>..........] - ETA: 0s - loss: 12286.8541 - KL_divergence: 10.3232
145/200 [====================>.........] - ETA: 0s - loss: 12283.5595 - KL_divergence: 10.3207
151/200 [=====================>........] - ETA: 0s - loss: 12273.7570 - KL_divergence: 10.2991
157/200 [======================>.......] - ETA: 0s - loss: 12265.1000 - KL_divergence: 10.2944
163/200 [=======================>......] - ETA: 0s - loss: 12266.9445 - KL_divergence: 10.2836
170/200 [========================>.....] - ETA: 0s - loss: 12254.2042 - KL_divergence: 10.2951
176/200 [=========================>....] - ETA: 0s - loss: 12242.7882 - KL_divergence: 10.3092
182/200 [==========================>...] - ETA: 0s - loss: 12250.1401 - KL_divergence: 10.3018
188/200 [===========================>..] - ETA: 0s - loss: 12253.7314 - KL_divergence: 10.2782
194/200 [============================>.] - ETA: 0s - loss: 12243.8185 - KL_divergence: 10.2812
200/200 [==============================] - 2s 10ms/step - loss: 12236.8484 - KL_divergence: 10.2588 - val_loss: 12477.5337 - val_KL_divergence: 10.2538
Epoch 90/100

  1/200 [..............................] - ETA: 1s - loss: 11966.0654 - KL_divergence: 10.6182
  7/200 [>.............................] - ETA: 1s - loss: 12155.3274 - KL_divergence: 10.6110
 13/200 [>.............................] - ETA: 1s - loss: 12141.1583 - KL_divergence: 10.6487
 19/200 [=>............................] - ETA: 1s - loss: 12103.2217 - KL_divergence: 10.7557
 25/200 [==>...........................] - ETA: 1s - loss: 12068.0150 - KL_divergence: 10.7795
 31/200 [===>..........................] - ETA: 1s - loss: 12066.6524 - KL_divergence: 10.7050
 37/200 [====>.........................] - ETA: 1s - loss: 12036.7375 - KL_divergence: 10.6652
 43/200 [=====>........................] - ETA: 1s - loss: 12055.3126 - KL_divergence: 10.5976
 49/200 [======>.......................] - ETA: 1s - loss: 12049.6189 - KL_divergence: 10.6291
 55/200 [=======>......................] - ETA: 1s - loss: 12107.8766 - KL_divergence: 10.5556
 61/200 [========>.....................] - ETA: 1s - loss: 12091.4014 - KL_divergence: 10.5508
 67/200 [=========>....................] - ETA: 1s - loss: 12087.9871 - KL_divergence: 10.5512
 73/200 [=========>....................] - ETA: 1s - loss: 12077.0861 - KL_divergence: 10.5234
 79/200 [==========>...................] - ETA: 1s - loss: 12125.1201 - KL_divergence: 10.4669
 85/200 [===========>..................] - ETA: 1s - loss: 12128.9173 - KL_divergence: 10.4663
 91/200 [============>.................] - ETA: 0s - loss: 12118.3854 - KL_divergence: 10.4535
 97/200 [=============>................] - ETA: 0s - loss: 12120.4201 - KL_divergence: 10.4074
103/200 [==============>...............] - ETA: 0s - loss: 12118.2148 - KL_divergence: 10.3763
109/200 [===============>..............] - ETA: 0s - loss: 12122.2588 - KL_divergence: 10.3368
115/200 [================>.............] - ETA: 0s - loss: 12119.5231 - KL_divergence: 10.3320
121/200 [=================>............] - ETA: 0s - loss: 12127.2075 - KL_divergence: 10.3217
127/200 [==================>...........] - ETA: 0s - loss: 12116.4416 - KL_divergence: 10.3347
133/200 [==================>...........] - ETA: 0s - loss: 12123.2270 - KL_divergence: 10.3182
139/200 [===================>..........] - ETA: 0s - loss: 12124.6751 - KL_divergence: 10.3097
145/200 [====================>.........] - ETA: 0s - loss: 12121.0918 - KL_divergence: 10.2813
151/200 [=====================>........] - ETA: 0s - loss: 12139.9297 - KL_divergence: 10.2374
157/200 [======================>.......] - ETA: 0s - loss: 12136.0328 - KL_divergence: 10.2407
163/200 [=======================>......] - ETA: 0s - loss: 12143.4926 - KL_divergence: 10.2137
169/200 [========================>.....] - ETA: 0s - loss: 12147.9807 - KL_divergence: 10.2279
175/200 [=========================>....] - ETA: 0s - loss: 12154.5413 - KL_divergence: 10.2118
181/200 [==========================>...] - ETA: 0s - loss: 12160.6409 - KL_divergence: 10.1993
187/200 [===========================>..] - ETA: 0s - loss: 12167.0961 - KL_divergence: 10.2073
193/200 [===========================>..] - ETA: 0s - loss: 12175.9421 - KL_divergence: 10.2057
199/200 [============================>.] - ETA: 0s - loss: 12174.1521 - KL_divergence: 10.2122
200/200 [==============================] - 2s 10ms/step - loss: 12173.1883 - KL_divergence: 10.2181 - val_loss: 12408.9887 - val_KL_divergence: 10.9707
Epoch 91/100

  1/200 [..............................] - ETA: 1s - loss: 12225.0342 - KL_divergence: 9.4013
  7/200 [>.............................] - ETA: 1s - loss: 12083.6766 - KL_divergence: 10.4522
 13/200 [>.............................] - ETA: 1s - loss: 12119.7171 - KL_divergence: 10.0775
 19/200 [=>............................] - ETA: 1s - loss: 12138.5594 - KL_divergence: 10.2178
 25/200 [==>...........................] - ETA: 1s - loss: 12125.9676 - KL_divergence: 10.2377
 31/200 [===>..........................] - ETA: 1s - loss: 12129.2715 - KL_divergence: 10.2013
 37/200 [====>.........................] - ETA: 1s - loss: 12099.8263 - KL_divergence: 10.4229
 43/200 [=====>........................] - ETA: 1s - loss: 12084.8702 - KL_divergence: 10.4544
 49/200 [======>.......................] - ETA: 1s - loss: 12088.9546 - KL_divergence: 10.4846
 55/200 [=======>......................] - ETA: 1s - loss: 12096.5648 - KL_divergence: 10.4725
 61/200 [========>.....................] - ETA: 1s - loss: 12116.8867 - KL_divergence: 10.4569
 67/200 [=========>....................] - ETA: 1s - loss: 12117.1683 - KL_divergence: 10.4952
 73/200 [=========>....................] - ETA: 1s - loss: 12130.2464 - KL_divergence: 10.4031
 79/200 [==========>...................] - ETA: 1s - loss: 12136.5439 - KL_divergence: 10.3891
 85/200 [===========>..................] - ETA: 1s - loss: 12110.5211 - KL_divergence: 10.4296
 91/200 [============>.................] - ETA: 0s - loss: 12099.0936 - KL_divergence: 10.4385
 97/200 [=============>................] - ETA: 0s - loss: 12104.4522 - KL_divergence: 10.4397
103/200 [==============>...............] - ETA: 0s - loss: 12088.6275 - KL_divergence: 10.4507
110/200 [===============>..............] - ETA: 0s - loss: 12080.8695 - KL_divergence: 10.4157
116/200 [================>.............] - ETA: 0s - loss: 12094.5739 - KL_divergence: 10.4129
122/200 [=================>............] - ETA: 0s - loss: 12091.2788 - KL_divergence: 10.3684
128/200 [==================>...........] - ETA: 0s - loss: 12098.6698 - KL_divergence: 10.3847
134/200 [===================>..........] - ETA: 0s - loss: 12107.8594 - KL_divergence: 10.3674
140/200 [====================>.........] - ETA: 0s - loss: 12110.8486 - KL_divergence: 10.3494
146/200 [====================>.........] - ETA: 0s - loss: 12115.2082 - KL_divergence: 10.3372
152/200 [=====================>........] - ETA: 0s - loss: 12117.9493 - KL_divergence: 10.3274
158/200 [======================>.......] - ETA: 0s - loss: 12132.3814 - KL_divergence: 10.2923
164/200 [=======================>......] - ETA: 0s - loss: 12134.7729 - KL_divergence: 10.2923
170/200 [========================>.....] - ETA: 0s - loss: 12140.3110 - KL_divergence: 10.2810
176/200 [=========================>....] - ETA: 0s - loss: 12146.5010 - KL_divergence: 10.2937
182/200 [==========================>...] - ETA: 0s - loss: 12152.9364 - KL_divergence: 10.2689
188/200 [===========================>..] - ETA: 0s - loss: 12154.0283 - KL_divergence: 10.2490
194/200 [============================>.] - ETA: 0s - loss: 12152.1488 - KL_divergence: 10.2465
200/200 [==============================] - 2s 10ms/step - loss: 12149.8556 - KL_divergence: 10.2579 - val_loss: 12442.0463 - val_KL_divergence: 10.2606
Epoch 92/100

  1/200 [..............................] - ETA: 1s - loss: 12437.5664 - KL_divergence: 10.6408
  7/200 [>.............................] - ETA: 1s - loss: 12151.9964 - KL_divergence: 10.7514
 13/200 [>.............................] - ETA: 1s - loss: 12275.5735 - KL_divergence: 10.4212
 19/200 [=>............................] - ETA: 1s - loss: 12199.2256 - KL_divergence: 10.6196
 25/200 [==>...........................] - ETA: 1s - loss: 12148.6348 - KL_divergence: 10.7244
 31/200 [===>..........................] - ETA: 1s - loss: 12114.6482 - KL_divergence: 10.6606
 37/200 [====>.........................] - ETA: 1s - loss: 12150.4717 - KL_divergence: 10.6670
 43/200 [=====>........................] - ETA: 1s - loss: 12160.1948 - KL_divergence: 10.5697
 49/200 [======>.......................] - ETA: 1s - loss: 12164.2917 - KL_divergence: 10.5123
 55/200 [=======>......................] - ETA: 1s - loss: 12130.1466 - KL_divergence: 10.5089
 61/200 [========>.....................] - ETA: 1s - loss: 12141.4060 - KL_divergence: 10.5607
 67/200 [=========>....................] - ETA: 1s - loss: 12136.4432 - KL_divergence: 10.5720
 73/200 [=========>....................] - ETA: 1s - loss: 12155.3781 - KL_divergence: 10.5228
 79/200 [==========>...................] - ETA: 1s - loss: 12151.0360 - KL_divergence: 10.5368
 85/200 [===========>..................] - ETA: 1s - loss: 12148.3451 - KL_divergence: 10.5751
 91/200 [============>.................] - ETA: 1s - loss: 12169.4235 - KL_divergence: 10.5420
 97/200 [=============>................] - ETA: 0s - loss: 12190.4879 - KL_divergence: 10.5235
103/200 [==============>...............] - ETA: 0s - loss: 12192.4726 - KL_divergence: 10.5156
109/200 [===============>..............] - ETA: 0s - loss: 12184.4893 - KL_divergence: 10.4842
115/200 [================>.............] - ETA: 0s - loss: 12179.0128 - KL_divergence: 10.4866
121/200 [=================>............] - ETA: 0s - loss: 12172.8689 - KL_divergence: 10.4642
127/200 [==================>...........] - ETA: 0s - loss: 12178.8437 - KL_divergence: 10.4732
133/200 [==================>...........] - ETA: 0s - loss: 12174.9494 - KL_divergence: 10.4538
139/200 [===================>..........] - ETA: 0s - loss: 12178.8940 - KL_divergence: 10.4755
145/200 [====================>.........] - ETA: 0s - loss: 12188.1760 - KL_divergence: 10.4501
151/200 [=====================>........] - ETA: 0s - loss: 12182.8438 - KL_divergence: 10.4303
157/200 [======================>.......] - ETA: 0s - loss: 12167.7124 - KL_divergence: 10.4359
163/200 [=======================>......] - ETA: 0s - loss: 12166.9747 - KL_divergence: 10.4199
169/200 [========================>.....] - ETA: 0s - loss: 12156.8277 - KL_divergence: 10.3939
175/200 [=========================>....] - ETA: 0s - loss: 12155.7876 - KL_divergence: 10.4174
181/200 [==========================>...] - ETA: 0s - loss: 12161.7779 - KL_divergence: 10.4047
187/200 [===========================>..] - ETA: 0s - loss: 12173.1288 - KL_divergence: 10.3770
193/200 [===========================>..] - ETA: 0s - loss: 12169.9834 - KL_divergence: 10.4009
198/200 [============================>.] - ETA: 0s - loss: 12183.5585 - KL_divergence: 10.3700
200/200 [==============================] - 2s 10ms/step - loss: 12182.4503 - KL_divergence: 10.3718 - val_loss: 12439.7886 - val_KL_divergence: 10.0817
Epoch 93/100

  1/200 [..............................] - ETA: 1s - loss: 12211.0752 - KL_divergence: 9.4868
  7/200 [>.............................] - ETA: 1s - loss: 12088.0781 - KL_divergence: 10.0524
 13/200 [>.............................] - ETA: 1s - loss: 12158.4419 - KL_divergence: 10.2493
 19/200 [=>............................] - ETA: 1s - loss: 12093.1331 - KL_divergence: 10.5561
 25/200 [==>...........................] - ETA: 1s - loss: 12150.8240 - KL_divergence: 10.4364
 31/200 [===>..........................] - ETA: 1s - loss: 12172.7524 - KL_divergence: 10.2479
 37/200 [====>.........................] - ETA: 1s - loss: 12175.5302 - KL_divergence: 10.3070
 43/200 [=====>........................] - ETA: 1s - loss: 12198.8385 - KL_divergence: 10.2229
 49/200 [======>.......................] - ETA: 1s - loss: 12212.0548 - KL_divergence: 10.2111
 55/200 [=======>......................] - ETA: 1s - loss: 12215.8895 - KL_divergence: 10.1936
 60/200 [========>.....................] - ETA: 1s - loss: 12206.0178 - KL_divergence: 10.2320
 65/200 [========>.....................] - ETA: 1s - loss: 12189.7299 - KL_divergence: 10.2810
 71/200 [=========>....................] - ETA: 1s - loss: 12184.0305 - KL_divergence: 10.3261
 77/200 [==========>...................] - ETA: 1s - loss: 12177.3984 - KL_divergence: 10.3206
 83/200 [===========>..................] - ETA: 1s - loss: 12154.9316 - KL_divergence: 10.3050
 89/200 [============>.................] - ETA: 0s - loss: 12159.3092 - KL_divergence: 10.3401
 95/200 [=============>................] - ETA: 0s - loss: 12151.2442 - KL_divergence: 10.4133
101/200 [==============>...............] - ETA: 0s - loss: 12142.8498 - KL_divergence: 10.4104
107/200 [===============>..............] - ETA: 0s - loss: 12174.9108 - KL_divergence: 10.3403
113/200 [===============>..............] - ETA: 0s - loss: 12159.5402 - KL_divergence: 10.3081
119/200 [================>.............] - ETA: 0s - loss: 12170.0738 - KL_divergence: 10.2871
125/200 [=================>............] - ETA: 0s - loss: 12175.4176 - KL_divergence: 10.2991
131/200 [==================>...........] - ETA: 0s - loss: 12161.3047 - KL_divergence: 10.2918
137/200 [===================>..........] - ETA: 0s - loss: 12159.0349 - KL_divergence: 10.2938
143/200 [====================>.........] - ETA: 0s - loss: 12153.7721 - KL_divergence: 10.2854
149/200 [=====================>........] - ETA: 0s - loss: 12147.1321 - KL_divergence: 10.2850
155/200 [======================>.......] - ETA: 0s - loss: 12153.9223 - KL_divergence: 10.2694
161/200 [=======================>......] - ETA: 0s - loss: 12158.1619 - KL_divergence: 10.2334
167/200 [========================>.....] - ETA: 0s - loss: 12152.6662 - KL_divergence: 10.2470
173/200 [========================>.....] - ETA: 0s - loss: 12159.5305 - KL_divergence: 10.2585
179/200 [=========================>....] - ETA: 0s - loss: 12165.7486 - KL_divergence: 10.2419
185/200 [==========================>...] - ETA: 0s - loss: 12162.5565 - KL_divergence: 10.2320
191/200 [===========================>..] - ETA: 0s - loss: 12162.8413 - KL_divergence: 10.2236
198/200 [============================>.] - ETA: 0s - loss: 12167.4860 - KL_divergence: 10.2432
200/200 [==============================] - 2s 10ms/step - loss: 12169.1602 - KL_divergence: 10.2471 - val_loss: 12467.3717 - val_KL_divergence: 10.5630
Epoch 94/100

  1/200 [..............................] - ETA: 1s - loss: 11840.2939 - KL_divergence: 10.2115
  7/200 [>.............................] - ETA: 1s - loss: 11765.7277 - KL_divergence: 10.6312
 13/200 [>.............................] - ETA: 1s - loss: 11908.9853 - KL_divergence: 10.8608
 19/200 [=>............................] - ETA: 1s - loss: 11937.9592 - KL_divergence: 10.8742
 25/200 [==>...........................] - ETA: 1s - loss: 11915.0406 - KL_divergence: 10.8066
 31/200 [===>..........................] - ETA: 1s - loss: 11965.9891 - KL_divergence: 10.7859
 37/200 [====>.........................] - ETA: 1s - loss: 12015.4202 - KL_divergence: 10.8912
 43/200 [=====>........................] - ETA: 1s - loss: 12063.5708 - KL_divergence: 10.7719
 49/200 [======>.......................] - ETA: 1s - loss: 12027.2182 - KL_divergence: 10.8198
 55/200 [=======>......................] - ETA: 1s - loss: 12075.2176 - KL_divergence: 10.7667
 61/200 [========>.....................] - ETA: 1s - loss: 12070.2864 - KL_divergence: 10.7834
 67/200 [=========>....................] - ETA: 1s - loss: 12067.5368 - KL_divergence: 10.7129
 73/200 [=========>....................] - ETA: 1s - loss: 12066.1219 - KL_divergence: 10.6361
 79/200 [==========>...................] - ETA: 1s - loss: 12054.3553 - KL_divergence: 10.5564
 85/200 [===========>..................] - ETA: 1s - loss: 12039.7807 - KL_divergence: 10.6085
 91/200 [============>.................] - ETA: 0s - loss: 12037.5968 - KL_divergence: 10.5512
 97/200 [=============>................] - ETA: 0s - loss: 12039.8763 - KL_divergence: 10.5380
103/200 [==============>...............] - ETA: 0s - loss: 12057.3581 - KL_divergence: 10.4934
109/200 [===============>..............] - ETA: 0s - loss: 12032.5901 - KL_divergence: 10.5126
115/200 [================>.............] - ETA: 0s - loss: 12033.2996 - KL_divergence: 10.4866
121/200 [=================>............] - ETA: 0s - loss: 12029.5228 - KL_divergence: 10.4964
127/200 [==================>...........] - ETA: 0s - loss: 12033.6285 - KL_divergence: 10.4511
134/200 [===================>..........] - ETA: 0s - loss: 12017.0395 - KL_divergence: 10.4611
140/200 [====================>.........] - ETA: 0s - loss: 12020.7251 - KL_divergence: 10.4415
146/200 [====================>.........] - ETA: 0s - loss: 12016.0939 - KL_divergence: 10.4381
152/200 [=====================>........] - ETA: 0s - loss: 12017.6491 - KL_divergence: 10.4412
158/200 [======================>.......] - ETA: 0s - loss: 12018.2847 - KL_divergence: 10.4506
163/200 [=======================>......] - ETA: 0s - loss: 12035.1668 - KL_divergence: 10.4497
169/200 [========================>.....] - ETA: 0s - loss: 12041.0660 - KL_divergence: 10.4137
175/200 [=========================>....] - ETA: 0s - loss: 12038.9635 - KL_divergence: 10.4257
181/200 [==========================>...] - ETA: 0s - loss: 12036.4564 - KL_divergence: 10.4386
187/200 [===========================>..] - ETA: 0s - loss: 12035.9493 - KL_divergence: 10.4297
194/200 [============================>.] - ETA: 0s - loss: 12049.2217 - KL_divergence: 10.4395
200/200 [==============================] - 2s 10ms/step - loss: 12053.9713 - KL_divergence: 10.4489 - val_loss: 12443.1048 - val_KL_divergence: 10.7119
Epoch 95/100

  1/200 [..............................] - ETA: 1s - loss: 12059.2324 - KL_divergence: 12.0354
  7/200 [>.............................] - ETA: 1s - loss: 12014.5148 - KL_divergence: 10.8484
 13/200 [>.............................] - ETA: 1s - loss: 12083.5867 - KL_divergence: 11.2323
 19/200 [=>............................] - ETA: 1s - loss: 12066.4457 - KL_divergence: 11.2961
 24/200 [==>...........................] - ETA: 1s - loss: 12091.9539 - KL_divergence: 11.0609
 29/200 [===>..........................] - ETA: 1s - loss: 12082.3280 - KL_divergence: 10.9500
 35/200 [====>.........................] - ETA: 1s - loss: 12041.2934 - KL_divergence: 10.8745
 41/200 [=====>........................] - ETA: 1s - loss: 12033.1281 - KL_divergence: 10.7822
 47/200 [======>.......................] - ETA: 1s - loss: 12084.3028 - KL_divergence: 10.6787
 53/200 [======>.......................] - ETA: 1s - loss: 12128.3329 - KL_divergence: 10.6072
 59/200 [=======>......................] - ETA: 1s - loss: 12133.8548 - KL_divergence: 10.5456
 65/200 [========>.....................] - ETA: 1s - loss: 12125.2214 - KL_divergence: 10.5154
 70/200 [=========>....................] - ETA: 1s - loss: 12138.4281 - KL_divergence: 10.5078
 76/200 [==========>...................] - ETA: 1s - loss: 12134.0041 - KL_divergence: 10.4211
 82/200 [===========>..................] - ETA: 1s - loss: 12123.8916 - KL_divergence: 10.4334
 87/200 [============>.................] - ETA: 1s - loss: 12145.2010 - KL_divergence: 10.3512
 93/200 [============>.................] - ETA: 1s - loss: 12154.5528 - KL_divergence: 10.2942
 99/200 [=============>................] - ETA: 0s - loss: 12163.3981 - KL_divergence: 10.2538
105/200 [==============>...............] - ETA: 0s - loss: 12183.6426 - KL_divergence: 10.2036
111/200 [===============>..............] - ETA: 0s - loss: 12195.1365 - KL_divergence: 10.1648
117/200 [================>.............] - ETA: 0s - loss: 12196.5823 - KL_divergence: 10.1680
123/200 [=================>............] - ETA: 0s - loss: 12197.1054 - KL_divergence: 10.1654
129/200 [==================>...........] - ETA: 0s - loss: 12195.0483 - KL_divergence: 10.1893
135/200 [===================>..........] - ETA: 0s - loss: 12200.5760 - KL_divergence: 10.2080
141/200 [====================>.........] - ETA: 0s - loss: 12187.9660 - KL_divergence: 10.2054
147/200 [=====================>........] - ETA: 0s - loss: 12177.8218 - KL_divergence: 10.1995
153/200 [=====================>........] - ETA: 0s - loss: 12166.3847 - KL_divergence: 10.1981
159/200 [======================>.......] - ETA: 0s - loss: 12165.1450 - KL_divergence: 10.1939
164/200 [=======================>......] - ETA: 0s - loss: 12163.7023 - KL_divergence: 10.2260
170/200 [========================>.....] - ETA: 0s - loss: 12162.3117 - KL_divergence: 10.2435
176/200 [=========================>....] - ETA: 0s - loss: 12161.3891 - KL_divergence: 10.2685
182/200 [==========================>...] - ETA: 0s - loss: 12166.3007 - KL_divergence: 10.2657
188/200 [===========================>..] - ETA: 0s - loss: 12167.4683 - KL_divergence: 10.2737
194/200 [============================>.] - ETA: 0s - loss: 12161.7475 - KL_divergence: 10.2851
200/200 [==============================] - 2s 10ms/step - loss: 12162.2659 - KL_divergence: 10.2827 - val_loss: 12487.4801 - val_KL_divergence: 10.5146
Epoch 96/100

  1/200 [..............................] - ETA: 1s - loss: 12626.7012 - KL_divergence: 10.0103
  7/200 [>.............................] - ETA: 1s - loss: 12366.4993 - KL_divergence: 10.4090
 13/200 [>.............................] - ETA: 1s - loss: 12261.6416 - KL_divergence: 10.5572
 19/200 [=>............................] - ETA: 1s - loss: 12232.6392 - KL_divergence: 10.3324
 25/200 [==>...........................] - ETA: 1s - loss: 12264.2748 - KL_divergence: 10.2914
 31/200 [===>..........................] - ETA: 1s - loss: 12288.8360 - KL_divergence: 10.1398
 37/200 [====>.........................] - ETA: 1s - loss: 12236.5470 - KL_divergence: 10.2758
 43/200 [=====>........................] - ETA: 1s - loss: 12243.4929 - KL_divergence: 10.1622
 49/200 [======>.......................] - ETA: 1s - loss: 12233.7476 - KL_divergence: 10.1878
 55/200 [=======>......................] - ETA: 1s - loss: 12225.6506 - KL_divergence: 10.2421
 61/200 [========>.....................] - ETA: 1s - loss: 12237.1413 - KL_divergence: 10.3120
 67/200 [=========>....................] - ETA: 1s - loss: 12255.9579 - KL_divergence: 10.2630
 73/200 [=========>....................] - ETA: 1s - loss: 12227.7928 - KL_divergence: 10.2564
 79/200 [==========>...................] - ETA: 1s - loss: 12227.5835 - KL_divergence: 10.2272
 85/200 [===========>..................] - ETA: 1s - loss: 12239.8001 - KL_divergence: 10.2052
 91/200 [============>.................] - ETA: 0s - loss: 12227.7866 - KL_divergence: 10.2483
 97/200 [=============>................] - ETA: 0s - loss: 12224.4877 - KL_divergence: 10.2300
103/200 [==============>...............] - ETA: 0s - loss: 12232.7047 - KL_divergence: 10.2016
109/200 [===============>..............] - ETA: 0s - loss: 12238.2814 - KL_divergence: 10.1780
115/200 [================>.............] - ETA: 0s - loss: 12241.3976 - KL_divergence: 10.1445
121/200 [=================>............] - ETA: 0s - loss: 12238.8526 - KL_divergence: 10.1538
127/200 [==================>...........] - ETA: 0s - loss: 12233.9348 - KL_divergence: 10.1756
133/200 [==================>...........] - ETA: 0s - loss: 12236.0588 - KL_divergence: 10.1784
139/200 [===================>..........] - ETA: 0s - loss: 12222.9585 - KL_divergence: 10.1749
145/200 [====================>.........] - ETA: 0s - loss: 12222.5846 - KL_divergence: 10.1666
151/200 [=====================>........] - ETA: 0s - loss: 12218.8081 - KL_divergence: 10.1483
157/200 [======================>.......] - ETA: 0s - loss: 12213.5608 - KL_divergence: 10.1409
163/200 [=======================>......] - ETA: 0s - loss: 12210.7776 - KL_divergence: 10.1250
169/200 [========================>.....] - ETA: 0s - loss: 12209.9179 - KL_divergence: 10.1172
175/200 [=========================>....] - ETA: 0s - loss: 12206.5840 - KL_divergence: 10.0989
181/200 [==========================>...] - ETA: 0s - loss: 12196.2462 - KL_divergence: 10.0990
187/200 [===========================>..] - ETA: 0s - loss: 12193.6339 - KL_divergence: 10.0785
193/200 [===========================>..] - ETA: 0s - loss: 12188.6411 - KL_divergence: 10.0672
199/200 [============================>.] - ETA: 0s - loss: 12189.6645 - KL_divergence: 10.0811
200/200 [==============================] - 2s 10ms/step - loss: 12191.4736 - KL_divergence: 10.0864 - val_loss: 12513.9930 - val_KL_divergence: 10.9416
Epoch 97/100

  1/200 [..............................] - ETA: 1s - loss: 11668.5938 - KL_divergence: 13.6894
  7/200 [>.............................] - ETA: 1s - loss: 12201.6977 - KL_divergence: 10.7616
 13/200 [>.............................] - ETA: 1s - loss: 12160.5429 - KL_divergence: 10.7667
 19/200 [=>............................] - ETA: 1s - loss: 12173.6867 - KL_divergence: 10.3581
 25/200 [==>...........................] - ETA: 1s - loss: 12254.6617 - KL_divergence: 10.4825
 31/200 [===>..........................] - ETA: 1s - loss: 12189.8760 - KL_divergence: 10.5965
 37/200 [====>.........................] - ETA: 1s - loss: 12195.8910 - KL_divergence: 10.6309
 43/200 [=====>........................] - ETA: 1s - loss: 12174.2906 - KL_divergence: 10.6480
 49/200 [======>.......................] - ETA: 1s - loss: 12170.1969 - KL_divergence: 10.5425
 56/200 [=======>......................] - ETA: 1s - loss: 12169.2880 - KL_divergence: 10.6075
 62/200 [========>.....................] - ETA: 1s - loss: 12137.3196 - KL_divergence: 10.7166
 68/200 [=========>....................] - ETA: 1s - loss: 12130.3974 - KL_divergence: 10.6628
 74/200 [==========>...................] - ETA: 1s - loss: 12149.2145 - KL_divergence: 10.6550
 80/200 [===========>..................] - ETA: 1s - loss: 12140.7548 - KL_divergence: 10.6967
 86/200 [===========>..................] - ETA: 1s - loss: 12157.8053 - KL_divergence: 10.6913
 91/200 [============>.................] - ETA: 0s - loss: 12142.7018 - KL_divergence: 10.6743
 97/200 [=============>................] - ETA: 0s - loss: 12138.4385 - KL_divergence: 10.6445
103/200 [==============>...............] - ETA: 0s - loss: 12133.4574 - KL_divergence: 10.6423
109/200 [===============>..............] - ETA: 0s - loss: 12135.1813 - KL_divergence: 10.6473
115/200 [================>.............] - ETA: 0s - loss: 12133.0267 - KL_divergence: 10.6914
122/200 [=================>............] - ETA: 0s - loss: 12130.7443 - KL_divergence: 10.6785
129/200 [==================>...........] - ETA: 0s - loss: 12116.4689 - KL_divergence: 10.6173
135/200 [===================>..........] - ETA: 0s - loss: 12123.7052 - KL_divergence: 10.6061
141/200 [====================>.........] - ETA: 0s - loss: 12120.0645 - KL_divergence: 10.5555
147/200 [=====================>........] - ETA: 0s - loss: 12109.0546 - KL_divergence: 10.5675
153/200 [=====================>........] - ETA: 0s - loss: 12122.6924 - KL_divergence: 10.5813
159/200 [======================>.......] - ETA: 0s - loss: 12136.8078 - KL_divergence: 10.5754
165/200 [=======================>......] - ETA: 0s - loss: 12132.3224 - KL_divergence: 10.5804
171/200 [========================>.....] - ETA: 0s - loss: 12139.5472 - KL_divergence: 10.5785
177/200 [=========================>....] - ETA: 0s - loss: 12122.1673 - KL_divergence: 10.5586
183/200 [==========================>...] - ETA: 0s - loss: 12119.6673 - KL_divergence: 10.5505
189/200 [===========================>..] - ETA: 0s - loss: 12124.3527 - KL_divergence: 10.5414
195/200 [============================>.] - ETA: 0s - loss: 12122.9919 - KL_divergence: 10.5384
200/200 [==============================] - 2s 10ms/step - loss: 12130.2114 - KL_divergence: 10.5110 - val_loss: 12342.7841 - val_KL_divergence: 10.1356
Epoch 98/100

  1/200 [..............................] - ETA: 1s - loss: 12429.9912 - KL_divergence: 9.3296
  7/200 [>.............................] - ETA: 1s - loss: 12361.2235 - KL_divergence: 10.2321
 13/200 [>.............................] - ETA: 1s - loss: 12164.7968 - KL_divergence: 10.0631
 19/200 [=>............................] - ETA: 1s - loss: 12199.2865 - KL_divergence: 9.9871 
 24/200 [==>...........................] - ETA: 1s - loss: 12175.2358 - KL_divergence: 10.1169
 30/200 [===>..........................] - ETA: 1s - loss: 12181.3099 - KL_divergence: 10.2053
 36/200 [====>.........................] - ETA: 1s - loss: 12133.5770 - KL_divergence: 10.3741
 42/200 [=====>........................] - ETA: 1s - loss: 12162.2464 - KL_divergence: 10.2957
 48/200 [======>.......................] - ETA: 1s - loss: 12150.8233 - KL_divergence: 10.2240
 54/200 [=======>......................] - ETA: 1s - loss: 12105.7994 - KL_divergence: 10.1683
 60/200 [========>.....................] - ETA: 1s - loss: 12083.0024 - KL_divergence: 10.1709
 66/200 [========>.....................] - ETA: 1s - loss: 12077.1511 - KL_divergence: 10.2059
 72/200 [=========>....................] - ETA: 1s - loss: 12089.6382 - KL_divergence: 10.2039
 78/200 [==========>...................] - ETA: 1s - loss: 12112.6254 - KL_divergence: 10.1657
 84/200 [===========>..................] - ETA: 1s - loss: 12127.7510 - KL_divergence: 10.2154
 90/200 [============>.................] - ETA: 1s - loss: 12132.5580 - KL_divergence: 10.2600
 96/200 [=============>................] - ETA: 0s - loss: 12134.1627 - KL_divergence: 10.2441
102/200 [==============>...............] - ETA: 0s - loss: 12121.5713 - KL_divergence: 10.2910
107/200 [===============>..............] - ETA: 0s - loss: 12139.5778 - KL_divergence: 10.3207
113/200 [===============>..............] - ETA: 0s - loss: 12145.8257 - KL_divergence: 10.3848
119/200 [================>.............] - ETA: 0s - loss: 12151.9763 - KL_divergence: 10.4024
125/200 [=================>............] - ETA: 0s - loss: 12170.0628 - KL_divergence: 10.3917
131/200 [==================>...........] - ETA: 0s - loss: 12155.7844 - KL_divergence: 10.3945
137/200 [===================>..........] - ETA: 0s - loss: 12137.7192 - KL_divergence: 10.3841
143/200 [====================>.........] - ETA: 0s - loss: 12142.4608 - KL_divergence: 10.3966
149/200 [=====================>........] - ETA: 0s - loss: 12144.8883 - KL_divergence: 10.3821
155/200 [======================>.......] - ETA: 0s - loss: 12141.4248 - KL_divergence: 10.3313
161/200 [=======================>......] - ETA: 0s - loss: 12127.1218 - KL_divergence: 10.3571
167/200 [========================>.....] - ETA: 0s - loss: 12118.7963 - KL_divergence: 10.3751
173/200 [========================>.....] - ETA: 0s - loss: 12115.8991 - KL_divergence: 10.3637
179/200 [=========================>....] - ETA: 0s - loss: 12122.8652 - KL_divergence: 10.3723
185/200 [==========================>...] - ETA: 0s - loss: 12122.6158 - KL_divergence: 10.3619
191/200 [===========================>..] - ETA: 0s - loss: 12122.4247 - KL_divergence: 10.4098
196/200 [============================>.] - ETA: 0s - loss: 12121.4997 - KL_divergence: 10.3913
200/200 [==============================] - 2s 10ms/step - loss: 12112.2728 - KL_divergence: 10.3986 - val_loss: 12415.6531 - val_KL_divergence: 10.3077
Epoch 99/100

  1/200 [..............................] - ETA: 2s - loss: 11162.5264 - KL_divergence: 12.4709
  7/200 [>.............................] - ETA: 1s - loss: 12019.1341 - KL_divergence: 10.3025
 13/200 [>.............................] - ETA: 1s - loss: 12091.0163 - KL_divergence: 10.5843
 19/200 [=>............................] - ETA: 1s - loss: 12187.9966 - KL_divergence: 10.4627
 24/200 [==>...........................] - ETA: 1s - loss: 12312.6847 - KL_divergence: 10.3788
 29/200 [===>..........................] - ETA: 1s - loss: 12320.6242 - KL_divergence: 10.3524
 35/200 [====>.........................] - ETA: 1s - loss: 12272.7487 - KL_divergence: 10.3026
 41/200 [=====>........................] - ETA: 1s - loss: 12300.4910 - KL_divergence: 10.3123
 47/200 [======>.......................] - ETA: 1s - loss: 12252.6206 - KL_divergence: 10.3876
 53/200 [======>.......................] - ETA: 1s - loss: 12275.7693 - KL_divergence: 10.4386
 59/200 [=======>......................] - ETA: 1s - loss: 12252.0284 - KL_divergence: 10.4593
 65/200 [========>.....................] - ETA: 1s - loss: 12265.1721 - KL_divergence: 10.3883
 71/200 [=========>....................] - ETA: 1s - loss: 12251.9313 - KL_divergence: 10.3705
 76/200 [==========>...................] - ETA: 1s - loss: 12233.9558 - KL_divergence: 10.3644
 82/200 [===========>..................] - ETA: 1s - loss: 12241.5857 - KL_divergence: 10.3516
 88/200 [============>.................] - ETA: 1s - loss: 12214.7114 - KL_divergence: 10.3553
 94/200 [=============>................] - ETA: 0s - loss: 12205.5150 - KL_divergence: 10.3006
101/200 [==============>...............] - ETA: 0s - loss: 12209.0584 - KL_divergence: 10.3130
108/200 [===============>..............] - ETA: 0s - loss: 12199.0857 - KL_divergence: 10.3460
114/200 [================>.............] - ETA: 0s - loss: 12182.9008 - KL_divergence: 10.3391
120/200 [=================>............] - ETA: 0s - loss: 12178.4721 - KL_divergence: 10.3289
126/200 [=================>............] - ETA: 0s - loss: 12176.9188 - KL_divergence: 10.3002
132/200 [==================>...........] - ETA: 0s - loss: 12178.4397 - KL_divergence: 10.2858
138/200 [===================>..........] - ETA: 0s - loss: 12170.4672 - KL_divergence: 10.2841
144/200 [====================>.........] - ETA: 0s - loss: 12168.6082 - KL_divergence: 10.2457
150/200 [=====================>........] - ETA: 0s - loss: 12184.4767 - KL_divergence: 10.2134
156/200 [======================>.......] - ETA: 0s - loss: 12190.6873 - KL_divergence: 10.2076
162/200 [=======================>......] - ETA: 0s - loss: 12181.3315 - KL_divergence: 10.2165
168/200 [========================>.....] - ETA: 0s - loss: 12178.6208 - KL_divergence: 10.2187
174/200 [=========================>....] - ETA: 0s - loss: 12172.7951 - KL_divergence: 10.2163
180/200 [==========================>...] - ETA: 0s - loss: 12171.2213 - KL_divergence: 10.2031
186/200 [==========================>...] - ETA: 0s - loss: 12186.2224 - KL_divergence: 10.2032
192/200 [===========================>..] - ETA: 0s - loss: 12177.7388 - KL_divergence: 10.2045
198/200 [============================>.] - ETA: 0s - loss: 12182.9324 - KL_divergence: 10.1662
200/200 [==============================] - 2s 10ms/step - loss: 12184.5159 - KL_divergence: 10.1500 - val_loss: 12393.2294 - val_KL_divergence: 9.9656
Epoch 100/100

  1/200 [..............................] - ETA: 1s - loss: 11913.5967 - KL_divergence: 8.8354
  7/200 [>.............................] - ETA: 1s - loss: 12162.5498 - KL_divergence: 10.0273
 13/200 [>.............................] - ETA: 1s - loss: 12307.3857 - KL_divergence: 10.1442
 19/200 [=>............................] - ETA: 1s - loss: 12206.7565 - KL_divergence: 10.6530
 25/200 [==>...........................] - ETA: 1s - loss: 12180.1077 - KL_divergence: 10.4801
 31/200 [===>..........................] - ETA: 1s - loss: 12237.4436 - KL_divergence: 10.2926
 37/200 [====>.........................] - ETA: 1s - loss: 12184.7600 - KL_divergence: 10.3888
 43/200 [=====>........................] - ETA: 1s - loss: 12192.7697 - KL_divergence: 10.3820
 48/200 [======>.......................] - ETA: 1s - loss: 12202.1556 - KL_divergence: 10.4516
 54/200 [=======>......................] - ETA: 1s - loss: 12176.4283 - KL_divergence: 10.4294
 60/200 [========>.....................] - ETA: 1s - loss: 12190.4952 - KL_divergence: 10.4305
 65/200 [========>.....................] - ETA: 1s - loss: 12193.5166 - KL_divergence: 10.4198
 71/200 [=========>....................] - ETA: 1s - loss: 12214.1976 - KL_divergence: 10.4504
 76/200 [==========>...................] - ETA: 1s - loss: 12207.3226 - KL_divergence: 10.4173
 82/200 [===========>..................] - ETA: 1s - loss: 12214.3272 - KL_divergence: 10.3797
 88/200 [============>.................] - ETA: 1s - loss: 12202.0297 - KL_divergence: 10.3496
 94/200 [=============>................] - ETA: 0s - loss: 12200.7061 - KL_divergence: 10.3642
100/200 [==============>...............] - ETA: 0s - loss: 12226.0124 - KL_divergence: 10.3751
106/200 [==============>...............] - ETA: 0s - loss: 12227.9291 - KL_divergence: 10.3873
112/200 [===============>..............] - ETA: 0s - loss: 12243.4171 - KL_divergence: 10.3528
118/200 [================>.............] - ETA: 0s - loss: 12240.2595 - KL_divergence: 10.3426
123/200 [=================>............] - ETA: 0s - loss: 12239.4206 - KL_divergence: 10.2987
129/200 [==================>...........] - ETA: 0s - loss: 12251.3136 - KL_divergence: 10.2886
135/200 [===================>..........] - ETA: 0s - loss: 12252.2865 - KL_divergence: 10.3360
141/200 [====================>.........] - ETA: 0s - loss: 12249.6540 - KL_divergence: 10.3473
147/200 [=====================>........] - ETA: 0s - loss: 12254.4942 - KL_divergence: 10.3173
153/200 [=====================>........] - ETA: 0s - loss: 12258.1343 - KL_divergence: 10.3565
159/200 [======================>.......] - ETA: 0s - loss: 12271.3954 - KL_divergence: 10.3696
165/200 [=======================>......] - ETA: 0s - loss: 12269.7643 - KL_divergence: 10.3874
171/200 [========================>.....] - ETA: 0s - loss: 12262.0314 - KL_divergence: 10.4201
177/200 [=========================>....] - ETA: 0s - loss: 12281.6193 - KL_divergence: 10.4221
183/200 [==========================>...] - ETA: 0s - loss: 12281.4042 - KL_divergence: 10.4911
189/200 [===========================>..] - ETA: 0s - loss: 12292.0388 - KL_divergence: 10.4880
195/200 [============================>.] - ETA: 0s - loss: 12280.5986 - KL_divergence: 10.5492
200/200 [==============================] - 2s 10ms/step - loss: 12276.0820 - KL_divergence: 10.5888 - val_loss: 12477.9565 - val_KL_divergence: 10.6439
Saving the trained inference, generator and latent models...	
 1/50 [..............................] - ETA: 3s
22/50 [============>.................] - ETA: 0s
33/50 [==================>...........] - ETA: 0s
44/50 [=========================>....] - ETA: 0s
50/50 [==============================] - 0s 6ms/step
