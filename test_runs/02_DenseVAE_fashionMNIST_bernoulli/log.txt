Using TensorFlow backend.
WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

2019-10-30 16:04:35.356066: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-30 16:04:35.361524: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 16:04:35.493039: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x641ac80 executing computations on platform CUDA. Devices:
2019-10-30 16:04:35.493076: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2019-10-30 16:04:35.495073: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599260000 Hz
2019-10-30 16:04:35.495567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x648cc80 executing computations on platform Host. Devices:
2019-10-30 16:04:35.495585: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 16:04:35.496369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
2019-10-30 16:04:35.496654: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 16:04:35.498008: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 16:04:35.499182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 16:04:35.499511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 16:04:35.501118: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 16:04:35.502320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 16:04:35.506082: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 16:04:35.507797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 16:04:35.507888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 16:04:35.509351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 16:04:35.509369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 16:04:35.509378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 16:04:35.510709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7191 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-10-30 16:04:36.624013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
Training size : 60000 	 Test size : 10000
Shapes :  (60000, 28, 28, 1) 	 (10000, 28, 28, 1)
Label shaped :  (60000,) 	 (10000,)
Train set : 
Mean: 0.315, Standard Deviation: 0.464
Min: 0.000, Max: 1.000
Test set : 
Mean: 0.315, Standard Deviation: 0.465
Min: 0.000, Max: 1.000
Train SHAPE :  (60000, 28, 28, 1)
MEAN :  {0: 0.35255718, 1: 0.249598, 2: 0.4014664, 3: 0.28631845, 4: 0.4407281, 5: 0.13639201, 6: 0.3443259, 7: 0.17890157, 8: 0.40651298, 9: 0.34977743}
STD :  {0: 0.47776648, 1: 0.43278033, 2: 0.49019507, 3: 0.4520401, 4: 0.49647447, 5: 0.3432043, 6: 0.47514802, 7: 0.38326997, 8: 0.4911823, 9: 0.4768995}
Test SHAPE :  (10000, 28, 28, 1)
MEAN :  {0: 0.31800127, 1: 0.3231084, 2: 0.31288394, 3: 0.31742984, 4: 0.31886736, 5: 0.31390816, 6: 0.30803445, 7: 0.3102908, 8: 0.31357014, 9: 0.31692728}
STD :  {0: 0.46569994, 1: 0.46766368, 2: 0.46366748, 3: 0.46547624, 4: 0.4660374, 5: 0.4640796, 6: 0.4616809, 7: 0.46261266, 8: 0.4639438, 9: 0.46527877}
Training size : 60000 	 Test size : 10000
Shapes :  (60000, 28, 28, 1) 	 (10000, 28, 28, 1)
Label shaped :  (60000,) 	 (10000,)
Train set : 
Mean: 0.315, Standard Deviation: 0.464
Min: 0.000, Max: 1.000
Test set : 
Mean: 0.315, Standard Deviation: 0.465
Min: 0.000, Max: 1.000
Train set : 
Mean: 0.315, Standard Deviation: 0.464
Min: 0.000, Max: 1.000
Train SHAPE :  (60000, 28, 28, 1)
Test SHAPE :  (10000, 28, 28, 1)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (100, 784)           0                                            
__________________________________________________________________________________________________
dense_encoder (Model)           multiple             1788416     input_1[0][0]                    
__________________________________________________________________________________________________
mean (Dense)                    (100, 4)             1028        dense_encoder[1][0]              
__________________________________________________________________________________________________
log_sigma (Dense)               (100, 4)             1028        dense_encoder[1][0]              
__________________________________________________________________________________________________
sampling_z (Lambda)             (100, 4)             0           mean[0][0]                       
                                                                 log_sigma[0][0]                  
__________________________________________________________________________________________________
dense_decoder (Model)           multiple             5545744     sampling_z[0][0]                 
==================================================================================================
Total params: 7,336,216
Trainable params: 7,336,216
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

  1/200 [..............................] - ETA: 4:52 - loss: 54334.5859 - KL_divergence: 0.0292
  7/200 [>.............................] - ETA: 42s - loss: 50900.6451 - KL_divergence: 29.2091
 13/200 [>.............................] - ETA: 22s - loss: 48761.5676 - KL_divergence: 61.3651
 19/200 [=>............................] - ETA: 15s - loss: 46333.5919 - KL_divergence: 52.7761
 25/200 [==>...........................] - ETA: 11s - loss: 44646.4264 - KL_divergence: 47.8253
 31/200 [===>..........................] - ETA: 9s - loss: 43375.5799 - KL_divergence: 45.7073 
 37/200 [====>.........................] - ETA: 7s - loss: 42686.4177 - KL_divergence: 42.8677
 43/200 [=====>........................] - ETA: 6s - loss: 42097.9499 - KL_divergence: 39.8112
 49/200 [======>.......................] - ETA: 5s - loss: 41558.9195 - KL_divergence: 38.0041
 55/200 [=======>......................] - ETA: 5s - loss: 41044.0077 - KL_divergence: 37.4352
 61/200 [========>.....................] - ETA: 4s - loss: 40693.2909 - KL_divergence: 36.7898
 67/200 [=========>....................] - ETA: 4s - loss: 40256.3891 - KL_divergence: 38.0139
 73/200 [=========>....................] - ETA: 3s - loss: 39862.3294 - KL_divergence: 39.4233
 79/200 [==========>...................] - ETA: 3s - loss: 39348.3281 - KL_divergence: 42.2749
 85/200 [===========>..................] - ETA: 3s - loss: 38918.1326 - KL_divergence: 44.6431
 91/200 [============>.................] - ETA: 2s - loss: 38485.8855 - KL_divergence: 46.5544
 97/200 [=============>................] - ETA: 2s - loss: 38108.4886 - KL_divergence: 47.3856
103/200 [==============>...............] - ETA: 2s - loss: 37757.9607 - KL_divergence: 47.3325
109/200 [===============>..............] - ETA: 2s - loss: 37424.8224 - KL_divergence: 47.6216
115/200 [================>.............] - ETA: 1s - loss: 37119.1132 - KL_divergence: 47.5983
121/200 [=================>............] - ETA: 1s - loss: 36802.7823 - KL_divergence: 47.3614
127/200 [==================>...........] - ETA: 1s - loss: 36554.5890 - KL_divergence: 46.7568
133/200 [==================>...........] - ETA: 1s - loss: 36277.7200 - KL_divergence: 46.1828
139/200 [===================>..........] - ETA: 1s - loss: 36024.2874 - KL_divergence: 45.5760
145/200 [====================>.........] - ETA: 1s - loss: 35782.3106 - KL_divergence: 45.4163
151/200 [=====================>........] - ETA: 0s - loss: 35547.5059 - KL_divergence: 44.5965
157/200 [======================>.......] - ETA: 0s - loss: 35307.7992 - KL_divergence: 43.9660
163/200 [=======================>......] - ETA: 0s - loss: 35071.3915 - KL_divergence: 42.9389
169/200 [========================>.....] - ETA: 0s - loss: 34825.2112 - KL_divergence: 41.9183
175/200 [=========================>....] - ETA: 0s - loss: 34602.2994 - KL_divergence: 40.9045
181/200 [==========================>...] - ETA: 0s - loss: 34340.6019 - KL_divergence: 39.8568
187/200 [===========================>..] - ETA: 0s - loss: 34077.6489 - KL_divergence: 38.9160
193/200 [===========================>..] - ETA: 0s - loss: 33849.7850 - KL_divergence: 37.9474
199/200 [============================>.] - ETA: 0s - loss: 33639.1553 - KL_divergence: 37.0069
200/200 [==============================] - 4s 18ms/step - loss: 33593.9852 - KL_divergence: 36.8591 - val_loss: 24956.7767 - val_KL_divergence: 8.4279
Epoch 2/100

  1/200 [..............................] - ETA: 2s - loss: 24959.9922 - KL_divergence: 7.7512
  7/200 [>.............................] - ETA: 1s - loss: 24710.6532 - KL_divergence: 8.0688
 13/200 [>.............................] - ETA: 1s - loss: 24785.2544 - KL_divergence: 7.7025
 19/200 [=>............................] - ETA: 1s - loss: 24554.7423 - KL_divergence: 7.7211
 25/200 [==>...........................] - ETA: 1s - loss: 24494.7755 - KL_divergence: 7.6672
 31/200 [===>..........................] - ETA: 1s - loss: 24232.9819 - KL_divergence: 7.5837
 37/200 [====>.........................] - ETA: 1s - loss: 24117.8205 - KL_divergence: 7.6634
 43/200 [=====>........................] - ETA: 1s - loss: 24023.5516 - KL_divergence: 7.6590
 49/200 [======>.......................] - ETA: 1s - loss: 23863.5806 - KL_divergence: 7.6731
 55/200 [=======>......................] - ETA: 1s - loss: 23886.4293 - KL_divergence: 7.7117
 61/200 [========>.....................] - ETA: 1s - loss: 23704.0825 - KL_divergence: 7.7269
 67/200 [=========>....................] - ETA: 1s - loss: 23603.9811 - KL_divergence: 7.7635
 73/200 [=========>....................] - ETA: 1s - loss: 23558.1307 - KL_divergence: 7.7764
 79/200 [==========>...................] - ETA: 1s - loss: 23530.7678 - KL_divergence: 7.7431
 85/200 [===========>..................] - ETA: 1s - loss: 23517.6390 - KL_divergence: 7.7338
 91/200 [============>.................] - ETA: 1s - loss: 23461.3785 - KL_divergence: 7.7529
 97/200 [=============>................] - ETA: 0s - loss: 23388.5367 - KL_divergence: 7.7579
103/200 [==============>...............] - ETA: 0s - loss: 23289.2279 - KL_divergence: 7.7626
109/200 [===============>..............] - ETA: 0s - loss: 23254.3492 - KL_divergence: 7.7848
115/200 [================>.............] - ETA: 0s - loss: 23162.5181 - KL_divergence: 7.8221
121/200 [=================>............] - ETA: 0s - loss: 23140.5921 - KL_divergence: 7.8274
127/200 [==================>...........] - ETA: 0s - loss: 23050.5108 - KL_divergence: 7.8387
133/200 [==================>...........] - ETA: 0s - loss: 23015.4900 - KL_divergence: 7.8389
139/200 [===================>..........] - ETA: 0s - loss: 22950.1736 - KL_divergence: 7.8320
145/200 [====================>.........] - ETA: 0s - loss: 22895.2160 - KL_divergence: 7.8512
151/200 [=====================>........] - ETA: 0s - loss: 22825.4014 - KL_divergence: 7.8581
157/200 [======================>.......] - ETA: 0s - loss: 22824.1852 - KL_divergence: 7.8541
163/200 [=======================>......] - ETA: 0s - loss: 22774.7950 - KL_divergence: 7.8721
169/200 [========================>.....] - ETA: 0s - loss: 22721.3009 - KL_divergence: 7.8792
175/200 [=========================>....] - ETA: 0s - loss: 22681.8697 - KL_divergence: 7.8950
181/200 [==========================>...] - ETA: 0s - loss: 22670.4640 - KL_divergence: 7.8945
187/200 [===========================>..] - ETA: 0s - loss: 22617.9694 - KL_divergence: 7.9027
193/200 [===========================>..] - ETA: 0s - loss: 22610.1759 - KL_divergence: 7.9248
199/200 [============================>.] - ETA: 0s - loss: 22559.5642 - KL_divergence: 7.9358
200/200 [==============================] - 2s 10ms/step - loss: 22544.7482 - KL_divergence: 7.9448 - val_loss: 22881.9177 - val_KL_divergence: 8.3601
Epoch 3/100

  1/200 [..............................] - ETA: 1s - loss: 22958.6777 - KL_divergence: 8.2507
  7/200 [>.............................] - ETA: 1s - loss: 21090.4632 - KL_divergence: 8.3152
 13/200 [>.............................] - ETA: 1s - loss: 21287.8800 - KL_divergence: 8.5317
 19/200 [=>............................] - ETA: 1s - loss: 21327.9427 - KL_divergence: 8.5618
 25/200 [==>...........................] - ETA: 1s - loss: 21130.5975 - KL_divergence: 8.5014
 31/200 [===>..........................] - ETA: 1s - loss: 21278.3697 - KL_divergence: 8.5377
 37/200 [====>.........................] - ETA: 1s - loss: 21079.0089 - KL_divergence: 8.5331
 43/200 [=====>........................] - ETA: 1s - loss: 21130.0064 - KL_divergence: 8.5586
 49/200 [======>.......................] - ETA: 1s - loss: 21052.8290 - KL_divergence: 8.5780
 55/200 [=======>......................] - ETA: 1s - loss: 21046.2585 - KL_divergence: 8.5727
 61/200 [========>.....................] - ETA: 1s - loss: 21003.2484 - KL_divergence: 8.5750
 67/200 [=========>....................] - ETA: 1s - loss: 20992.1738 - KL_divergence: 8.5994
 73/200 [=========>....................] - ETA: 1s - loss: 20919.3164 - KL_divergence: 8.6087
 79/200 [==========>...................] - ETA: 1s - loss: 20873.9891 - KL_divergence: 8.6258
 85/200 [===========>..................] - ETA: 1s - loss: 20809.1049 - KL_divergence: 8.6412
 91/200 [============>.................] - ETA: 0s - loss: 20788.0377 - KL_divergence: 8.6641
 97/200 [=============>................] - ETA: 0s - loss: 20775.5735 - KL_divergence: 8.6580
103/200 [==============>...............] - ETA: 0s - loss: 20730.9478 - KL_divergence: 8.6865
109/200 [===============>..............] - ETA: 0s - loss: 20717.0671 - KL_divergence: 8.6766
115/200 [================>.............] - ETA: 0s - loss: 20652.3216 - KL_divergence: 8.7046
121/200 [=================>............] - ETA: 0s - loss: 20655.0964 - KL_divergence: 8.6970
127/200 [==================>...........] - ETA: 0s - loss: 20660.2287 - KL_divergence: 8.6724
133/200 [==================>...........] - ETA: 0s - loss: 20625.7780 - KL_divergence: 8.6813
139/200 [===================>..........] - ETA: 0s - loss: 20583.9683 - KL_divergence: 8.7050
145/200 [====================>.........] - ETA: 0s - loss: 20596.1775 - KL_divergence: 8.7311
151/200 [=====================>........] - ETA: 0s - loss: 20553.7456 - KL_divergence: 8.7241
157/200 [======================>.......] - ETA: 0s - loss: 20545.0281 - KL_divergence: 8.7464
163/200 [=======================>......] - ETA: 0s - loss: 20493.5996 - KL_divergence: 8.7578
169/200 [========================>.....] - ETA: 0s - loss: 20493.1792 - KL_divergence: 8.7603
175/200 [=========================>....] - ETA: 0s - loss: 20479.2001 - KL_divergence: 8.7612
181/200 [==========================>...] - ETA: 0s - loss: 20443.1303 - KL_divergence: 8.7708
187/200 [===========================>..] - ETA: 0s - loss: 20432.1720 - KL_divergence: 8.7709
193/200 [===========================>..] - ETA: 0s - loss: 20387.3922 - KL_divergence: 8.7763
199/200 [============================>.] - ETA: 0s - loss: 20364.6050 - KL_divergence: 8.7812
200/200 [==============================] - 2s 10ms/step - loss: 20356.3113 - KL_divergence: 8.7826 - val_loss: 18825.1138 - val_KL_divergence: 9.3843
Epoch 4/100

  1/200 [..............................] - ETA: 1s - loss: 19370.2109 - KL_divergence: 9.0971
  7/200 [>.............................] - ETA: 1s - loss: 19706.1699 - KL_divergence: 9.0508
 13/200 [>.............................] - ETA: 1s - loss: 19078.6460 - KL_divergence: 9.1843
 19/200 [=>............................] - ETA: 1s - loss: 19219.4022 - KL_divergence: 9.1694
 25/200 [==>...........................] - ETA: 1s - loss: 19506.5888 - KL_divergence: 9.0028
 31/200 [===>..........................] - ETA: 1s - loss: 19259.0694 - KL_divergence: 9.1182
 37/200 [====>.........................] - ETA: 1s - loss: 19118.6545 - KL_divergence: 9.2010
 43/200 [=====>........................] - ETA: 1s - loss: 19135.5097 - KL_divergence: 9.1469
 49/200 [======>.......................] - ETA: 1s - loss: 19130.5580 - KL_divergence: 9.1344
 55/200 [=======>......................] - ETA: 1s - loss: 19215.9980 - KL_divergence: 9.1257
 61/200 [========>.....................] - ETA: 1s - loss: 19205.0394 - KL_divergence: 9.0794
 67/200 [=========>....................] - ETA: 1s - loss: 19189.5851 - KL_divergence: 9.0568
 73/200 [=========>....................] - ETA: 1s - loss: 19135.9166 - KL_divergence: 9.0792
 79/200 [==========>...................] - ETA: 1s - loss: 19120.9659 - KL_divergence: 9.1058
 85/200 [===========>..................] - ETA: 1s - loss: 19128.5601 - KL_divergence: 9.0922
 91/200 [============>.................] - ETA: 0s - loss: 19126.2763 - KL_divergence: 9.1121
 97/200 [=============>................] - ETA: 0s - loss: 19103.1462 - KL_divergence: 9.1174
103/200 [==============>...............] - ETA: 0s - loss: 19088.9353 - KL_divergence: 9.1310
109/200 [===============>..............] - ETA: 0s - loss: 19077.4653 - KL_divergence: 9.1557
115/200 [================>.............] - ETA: 0s - loss: 19080.2565 - KL_divergence: 9.1438
121/200 [=================>............] - ETA: 0s - loss: 19048.9433 - KL_divergence: 9.1656
127/200 [==================>...........] - ETA: 0s - loss: 19052.8988 - KL_divergence: 9.1619
133/200 [==================>...........] - ETA: 0s - loss: 19042.9479 - KL_divergence: 9.1809
139/200 [===================>..........] - ETA: 0s - loss: 19027.8702 - KL_divergence: 9.1969
145/200 [====================>.........] - ETA: 0s - loss: 19026.7762 - KL_divergence: 9.2038
151/200 [=====================>........] - ETA: 0s - loss: 19009.2057 - KL_divergence: 9.1931
157/200 [======================>.......] - ETA: 0s - loss: 19001.4824 - KL_divergence: 9.2006
163/200 [=======================>......] - ETA: 0s - loss: 18989.2764 - KL_divergence: 9.2093
169/200 [========================>.....] - ETA: 0s - loss: 18956.6177 - KL_divergence: 9.2296
176/200 [=========================>....] - ETA: 0s - loss: 18945.8487 - KL_divergence: 9.2518
182/200 [==========================>...] - ETA: 0s - loss: 18943.4610 - KL_divergence: 9.2549
188/200 [===========================>..] - ETA: 0s - loss: 18923.4645 - KL_divergence: 9.2530
194/200 [============================>.] - ETA: 0s - loss: 18911.4467 - KL_divergence: 9.2705
200/200 [==============================] - 2s 10ms/step - loss: 18902.7863 - KL_divergence: 9.2717 - val_loss: 18985.9995 - val_KL_divergence: 10.1949
Epoch 5/100

  1/200 [..............................] - ETA: 1s - loss: 18577.1309 - KL_divergence: 9.7752
  7/200 [>.............................] - ETA: 1s - loss: 17949.8365 - KL_divergence: 9.3661
 13/200 [>.............................] - ETA: 1s - loss: 17978.7797 - KL_divergence: 9.6333
 19/200 [=>............................] - ETA: 1s - loss: 18121.8374 - KL_divergence: 9.5981
 25/200 [==>...........................] - ETA: 1s - loss: 18230.8148 - KL_divergence: 9.4990
 31/200 [===>..........................] - ETA: 1s - loss: 18259.6453 - KL_divergence: 9.5756
 37/200 [====>.........................] - ETA: 1s - loss: 18252.6431 - KL_divergence: 9.6736
 43/200 [=====>........................] - ETA: 1s - loss: 18260.4024 - KL_divergence: 9.6526
 50/200 [======>.......................] - ETA: 1s - loss: 18276.2760 - KL_divergence: 9.6122
 56/200 [=======>......................] - ETA: 1s - loss: 18243.7865 - KL_divergence: 9.6270
 62/200 [========>.....................] - ETA: 1s - loss: 18200.4045 - KL_divergence: 9.6117
 68/200 [=========>....................] - ETA: 1s - loss: 18135.6771 - KL_divergence: 9.6352
 75/200 [==========>...................] - ETA: 1s - loss: 18077.1498 - KL_divergence: 9.6508
 81/200 [===========>..................] - ETA: 1s - loss: 18092.8884 - KL_divergence: 9.6467
 87/200 [============>.................] - ETA: 1s - loss: 18066.7557 - KL_divergence: 9.6484
 93/200 [============>.................] - ETA: 0s - loss: 18055.6432 - KL_divergence: 9.6674
 99/200 [=============>................] - ETA: 0s - loss: 18000.3021 - KL_divergence: 9.6899
105/200 [==============>...............] - ETA: 0s - loss: 18032.4559 - KL_divergence: 9.6620
111/200 [===============>..............] - ETA: 0s - loss: 17990.6462 - KL_divergence: 9.6808
117/200 [================>.............] - ETA: 0s - loss: 17967.4335 - KL_divergence: 9.7011
123/200 [=================>............] - ETA: 0s - loss: 17934.3490 - KL_divergence: 9.7130
129/200 [==================>...........] - ETA: 0s - loss: 17912.6032 - KL_divergence: 9.7326
135/200 [===================>..........] - ETA: 0s - loss: 17937.3042 - KL_divergence: 9.7230
141/200 [====================>.........] - ETA: 0s - loss: 17940.6064 - KL_divergence: 9.7308
147/200 [=====================>........] - ETA: 0s - loss: 17939.6459 - KL_divergence: 9.7193
153/200 [=====================>........] - ETA: 0s - loss: 17943.1254 - KL_divergence: 9.7126
159/200 [======================>.......] - ETA: 0s - loss: 17935.4306 - KL_divergence: 9.6928
165/200 [=======================>......] - ETA: 0s - loss: 17921.3211 - KL_divergence: 9.6932
172/200 [========================>.....] - ETA: 0s - loss: 17912.5782 - KL_divergence: 9.6855
178/200 [=========================>....] - ETA: 0s - loss: 17901.8357 - KL_divergence: 9.6721
184/200 [==========================>...] - ETA: 0s - loss: 17877.7897 - KL_divergence: 9.6831
190/200 [===========================>..] - ETA: 0s - loss: 17870.5063 - KL_divergence: 9.6857
197/200 [============================>.] - ETA: 0s - loss: 17843.1354 - KL_divergence: 9.6964
200/200 [==============================] - 2s 10ms/step - loss: 17829.2852 - KL_divergence: 9.6943 - val_loss: 17472.0821 - val_KL_divergence: 10.0197
Epoch 6/100

  1/200 [..............................] - ETA: 1s - loss: 18578.6641 - KL_divergence: 10.1828
  7/200 [>.............................] - ETA: 1s - loss: 17662.0890 - KL_divergence: 9.6141 
 13/200 [>.............................] - ETA: 1s - loss: 17388.7857 - KL_divergence: 9.5664
 19/200 [=>............................] - ETA: 1s - loss: 17283.4433 - KL_divergence: 9.4322
 25/200 [==>...........................] - ETA: 1s - loss: 17313.5465 - KL_divergence: 9.5523
 31/200 [===>..........................] - ETA: 1s - loss: 17463.2505 - KL_divergence: 9.5266
 37/200 [====>.........................] - ETA: 1s - loss: 17474.2061 - KL_divergence: 9.3925
 43/200 [=====>........................] - ETA: 1s - loss: 17361.6855 - KL_divergence: 9.4300
 48/200 [======>.......................] - ETA: 1s - loss: 17369.0692 - KL_divergence: 9.4692
 54/200 [=======>......................] - ETA: 1s - loss: 17396.1906 - KL_divergence: 9.4856
 60/200 [========>.....................] - ETA: 1s - loss: 17401.6054 - KL_divergence: 9.4802
 67/200 [=========>....................] - ETA: 1s - loss: 17326.5498 - KL_divergence: 9.4987
 73/200 [=========>....................] - ETA: 1s - loss: 17342.4564 - KL_divergence: 9.4953
 79/200 [==========>...................] - ETA: 1s - loss: 17316.4315 - KL_divergence: 9.4941
 85/200 [===========>..................] - ETA: 1s - loss: 17303.3530 - KL_divergence: 9.4826
 92/200 [============>.................] - ETA: 0s - loss: 17292.1455 - KL_divergence: 9.4685
 99/200 [=============>................] - ETA: 0s - loss: 17287.7693 - KL_divergence: 9.4457
105/200 [==============>...............] - ETA: 0s - loss: 17276.3494 - KL_divergence: 9.4482
111/200 [===============>..............] - ETA: 0s - loss: 17262.5600 - KL_divergence: 9.4536
118/200 [================>.............] - ETA: 0s - loss: 17234.8574 - KL_divergence: 9.4499
124/200 [=================>............] - ETA: 0s - loss: 17225.3930 - KL_divergence: 9.4628
131/200 [==================>...........] - ETA: 0s - loss: 17247.5804 - KL_divergence: 9.4384
137/200 [===================>..........] - ETA: 0s - loss: 17257.5870 - KL_divergence: 9.4353
143/200 [====================>.........] - ETA: 0s - loss: 17234.4561 - KL_divergence: 9.4307
150/200 [=====================>........] - ETA: 0s - loss: 17248.5760 - KL_divergence: 9.4394
156/200 [======================>.......] - ETA: 0s - loss: 17240.6537 - KL_divergence: 9.4426
162/200 [=======================>......] - ETA: 0s - loss: 17220.0435 - KL_divergence: 9.4421
168/200 [========================>.....] - ETA: 0s - loss: 17183.0330 - KL_divergence: 9.4548
174/200 [=========================>....] - ETA: 0s - loss: 17204.4212 - KL_divergence: 9.4398
180/200 [==========================>...] - ETA: 0s - loss: 17180.9675 - KL_divergence: 9.4481
187/200 [===========================>..] - ETA: 0s - loss: 17180.7195 - KL_divergence: 9.4393
193/200 [===========================>..] - ETA: 0s - loss: 17188.3771 - KL_divergence: 9.4354
199/200 [============================>.] - ETA: 0s - loss: 17187.0773 - KL_divergence: 9.4358
200/200 [==============================] - 2s 10ms/step - loss: 17181.1664 - KL_divergence: 9.4352 - val_loss: 17529.4905 - val_KL_divergence: 8.9361
Epoch 7/100

  1/200 [..............................] - ETA: 1s - loss: 18900.7754 - KL_divergence: 8.0986
  7/200 [>.............................] - ETA: 1s - loss: 17267.7690 - KL_divergence: 9.3033
 13/200 [>.............................] - ETA: 1s - loss: 16872.6720 - KL_divergence: 9.4464
 19/200 [=>............................] - ETA: 1s - loss: 17064.9429 - KL_divergence: 9.3817
 25/200 [==>...........................] - ETA: 1s - loss: 17000.8493 - KL_divergence: 9.4207
 31/200 [===>..........................] - ETA: 1s - loss: 17014.6448 - KL_divergence: 9.4491
 37/200 [====>.........................] - ETA: 1s - loss: 16994.2683 - KL_divergence: 9.4344
 43/200 [=====>........................] - ETA: 1s - loss: 17027.7691 - KL_divergence: 9.4163
 49/200 [======>.......................] - ETA: 1s - loss: 16974.6365 - KL_divergence: 9.4292
 55/200 [=======>......................] - ETA: 1s - loss: 16996.3518 - KL_divergence: 9.4463
 61/200 [========>.....................] - ETA: 1s - loss: 16979.1554 - KL_divergence: 9.4522
 67/200 [=========>....................] - ETA: 1s - loss: 16948.4182 - KL_divergence: 9.5094
 73/200 [=========>....................] - ETA: 1s - loss: 16940.0829 - KL_divergence: 9.5112
 79/200 [==========>...................] - ETA: 1s - loss: 16961.8670 - KL_divergence: 9.5003
 85/200 [===========>..................] - ETA: 1s - loss: 16984.3609 - KL_divergence: 9.4585
 91/200 [============>.................] - ETA: 1s - loss: 16954.2941 - KL_divergence: 9.4691
 97/200 [=============>................] - ETA: 0s - loss: 16915.0283 - KL_divergence: 9.4699
103/200 [==============>...............] - ETA: 0s - loss: 16889.5256 - KL_divergence: 9.4524
109/200 [===============>..............] - ETA: 0s - loss: 16924.0006 - KL_divergence: 9.4307
115/200 [================>.............] - ETA: 0s - loss: 16898.2770 - KL_divergence: 9.4336
121/200 [=================>............] - ETA: 0s - loss: 16884.1675 - KL_divergence: 9.4424
127/200 [==================>...........] - ETA: 0s - loss: 16872.2123 - KL_divergence: 9.4190
133/200 [==================>...........] - ETA: 0s - loss: 16850.9656 - KL_divergence: 9.4510
139/200 [===================>..........] - ETA: 0s - loss: 16859.4068 - KL_divergence: 9.4323
145/200 [====================>.........] - ETA: 0s - loss: 16850.8528 - KL_divergence: 9.4230
151/200 [=====================>........] - ETA: 0s - loss: 16846.0966 - KL_divergence: 9.4301
157/200 [======================>.......] - ETA: 0s - loss: 16843.6472 - KL_divergence: 9.4197
163/200 [=======================>......] - ETA: 0s - loss: 16849.7419 - KL_divergence: 9.3979
169/200 [========================>.....] - ETA: 0s - loss: 16844.1803 - KL_divergence: 9.3863
175/200 [=========================>....] - ETA: 0s - loss: 16842.1140 - KL_divergence: 9.3791
181/200 [==========================>...] - ETA: 0s - loss: 16865.1381 - KL_divergence: 9.3622
187/200 [===========================>..] - ETA: 0s - loss: 16853.9571 - KL_divergence: 9.3515
193/200 [===========================>..] - ETA: 0s - loss: 16851.1456 - KL_divergence: 9.3489
199/200 [============================>.] - ETA: 0s - loss: 16843.1786 - KL_divergence: 9.3401
200/200 [==============================] - 2s 10ms/step - loss: 16842.9862 - KL_divergence: 9.3391 - val_loss: 17383.4901 - val_KL_divergence: 9.0944
Epoch 8/100

  1/200 [..............................] - ETA: 1s - loss: 17238.5781 - KL_divergence: 9.2515
  7/200 [>.............................] - ETA: 1s - loss: 16693.2367 - KL_divergence: 8.9968
 13/200 [>.............................] - ETA: 1s - loss: 16598.2096 - KL_divergence: 9.1790
 19/200 [=>............................] - ETA: 1s - loss: 16484.5143 - KL_divergence: 9.1859
 25/200 [==>...........................] - ETA: 1s - loss: 16676.8945 - KL_divergence: 9.1346
 31/200 [===>..........................] - ETA: 1s - loss: 16636.6192 - KL_divergence: 9.1734
 37/200 [====>.........................] - ETA: 1s - loss: 16668.8228 - KL_divergence: 9.1153
 43/200 [=====>........................] - ETA: 1s - loss: 16650.9494 - KL_divergence: 9.1439
 49/200 [======>.......................] - ETA: 1s - loss: 16603.1941 - KL_divergence: 9.1946
 55/200 [=======>......................] - ETA: 1s - loss: 16559.1906 - KL_divergence: 9.1478
 61/200 [========>.....................] - ETA: 1s - loss: 16547.1202 - KL_divergence: 9.1522
 67/200 [=========>....................] - ETA: 1s - loss: 16550.2902 - KL_divergence: 9.1916
 73/200 [=========>....................] - ETA: 1s - loss: 16503.3436 - KL_divergence: 9.1965
 79/200 [==========>...................] - ETA: 1s - loss: 16568.9170 - KL_divergence: 9.1669
 84/200 [===========>..................] - ETA: 1s - loss: 16612.7104 - KL_divergence: 9.1199
 90/200 [============>.................] - ETA: 1s - loss: 16570.9608 - KL_divergence: 9.1271
 96/200 [=============>................] - ETA: 0s - loss: 16518.2890 - KL_divergence: 9.1374
102/200 [==============>...............] - ETA: 0s - loss: 16534.7291 - KL_divergence: 9.1337
108/200 [===============>..............] - ETA: 0s - loss: 16545.7152 - KL_divergence: 9.1103
114/200 [================>.............] - ETA: 0s - loss: 16546.8036 - KL_divergence: 9.1125
120/200 [=================>............] - ETA: 0s - loss: 16565.7595 - KL_divergence: 9.0955
126/200 [=================>............] - ETA: 0s - loss: 16595.7922 - KL_divergence: 9.0807
132/200 [==================>...........] - ETA: 0s - loss: 16583.5366 - KL_divergence: 9.0573
138/200 [===================>..........] - ETA: 0s - loss: 16592.6530 - KL_divergence: 9.0481
144/200 [====================>.........] - ETA: 0s - loss: 16607.7698 - KL_divergence: 9.0368
150/200 [=====================>........] - ETA: 0s - loss: 16607.5462 - KL_divergence: 9.0481
156/200 [======================>.......] - ETA: 0s - loss: 16614.6500 - KL_divergence: 9.0452
162/200 [=======================>......] - ETA: 0s - loss: 16640.4382 - KL_divergence: 9.0360
168/200 [========================>.....] - ETA: 0s - loss: 16651.9049 - KL_divergence: 9.0320
174/200 [=========================>....] - ETA: 0s - loss: 16643.3722 - KL_divergence: 9.0190
180/200 [==========================>...] - ETA: 0s - loss: 16635.4747 - KL_divergence: 9.0212
186/200 [==========================>...] - ETA: 0s - loss: 16633.6540 - KL_divergence: 9.0279
192/200 [===========================>..] - ETA: 0s - loss: 16616.5657 - KL_divergence: 9.0275
198/200 [============================>.] - ETA: 0s - loss: 16613.8595 - KL_divergence: 9.0286
200/200 [==============================] - 2s 10ms/step - loss: 16610.3520 - KL_divergence: 9.0327 - val_loss: 16449.9333 - val_KL_divergence: 8.8166
Epoch 9/100

  1/200 [..............................] - ETA: 1s - loss: 16411.1211 - KL_divergence: 9.7054
  7/200 [>.............................] - ETA: 1s - loss: 16589.2743 - KL_divergence: 9.0599
 13/200 [>.............................] - ETA: 1s - loss: 16762.6751 - KL_divergence: 9.0511
 19/200 [=>............................] - ETA: 1s - loss: 16596.6713 - KL_divergence: 9.0355
 25/200 [==>...........................] - ETA: 1s - loss: 16675.7946 - KL_divergence: 8.9751
 31/200 [===>..........................] - ETA: 1s - loss: 16550.9554 - KL_divergence: 8.9186
 37/200 [====>.........................] - ETA: 1s - loss: 16447.2678 - KL_divergence: 8.9818
 43/200 [=====>........................] - ETA: 1s - loss: 16524.5629 - KL_divergence: 8.9258
 49/200 [======>.......................] - ETA: 1s - loss: 16565.1367 - KL_divergence: 8.8787
 56/200 [=======>......................] - ETA: 1s - loss: 16573.8040 - KL_divergence: 8.8688
 62/200 [========>.....................] - ETA: 1s - loss: 16563.1403 - KL_divergence: 8.8930
 67/200 [=========>....................] - ETA: 1s - loss: 16540.9668 - KL_divergence: 8.8867
 73/200 [=========>....................] - ETA: 1s - loss: 16567.3180 - KL_divergence: 8.8602
 79/200 [==========>...................] - ETA: 1s - loss: 16562.1099 - KL_divergence: 8.8586
 85/200 [===========>..................] - ETA: 1s - loss: 16573.0193 - KL_divergence: 8.8703
 91/200 [============>.................] - ETA: 0s - loss: 16537.6278 - KL_divergence: 8.8858
 97/200 [=============>................] - ETA: 0s - loss: 16530.2413 - KL_divergence: 8.8862
103/200 [==============>...............] - ETA: 0s - loss: 16549.0918 - KL_divergence: 8.8941
109/200 [===============>..............] - ETA: 0s - loss: 16522.4031 - KL_divergence: 8.8984
115/200 [================>.............] - ETA: 0s - loss: 16547.8045 - KL_divergence: 8.8973
121/200 [=================>............] - ETA: 0s - loss: 16521.5050 - KL_divergence: 8.8948
127/200 [==================>...........] - ETA: 0s - loss: 16530.5066 - KL_divergence: 8.8849
133/200 [==================>...........] - ETA: 0s - loss: 16508.9523 - KL_divergence: 8.8845
139/200 [===================>..........] - ETA: 0s - loss: 16489.1045 - KL_divergence: 8.9014
145/200 [====================>.........] - ETA: 0s - loss: 16470.8703 - KL_divergence: 8.9104
151/200 [=====================>........] - ETA: 0s - loss: 16472.6677 - KL_divergence: 8.9032
157/200 [======================>.......] - ETA: 0s - loss: 16453.2191 - KL_divergence: 8.9174
163/200 [=======================>......] - ETA: 0s - loss: 16447.6731 - KL_divergence: 8.9071
169/200 [========================>.....] - ETA: 0s - loss: 16421.5798 - KL_divergence: 8.9140
175/200 [=========================>....] - ETA: 0s - loss: 16422.8383 - KL_divergence: 8.9153
181/200 [==========================>...] - ETA: 0s - loss: 16417.3709 - KL_divergence: 8.9005
187/200 [===========================>..] - ETA: 0s - loss: 16393.8418 - KL_divergence: 8.9091
193/200 [===========================>..] - ETA: 0s - loss: 16400.0919 - KL_divergence: 8.8952
199/200 [============================>.] - ETA: 0s - loss: 16400.0155 - KL_divergence: 8.8861
200/200 [==============================] - 2s 10ms/step - loss: 16395.0256 - KL_divergence: 8.8926 - val_loss: 16492.8391 - val_KL_divergence: 8.8184
Epoch 10/100

  1/200 [..............................] - ETA: 1s - loss: 15877.4873 - KL_divergence: 9.2067
  7/200 [>.............................] - ETA: 1s - loss: 16510.0804 - KL_divergence: 8.7656
 13/200 [>.............................] - ETA: 1s - loss: 16555.5103 - KL_divergence: 8.7327
 19/200 [=>............................] - ETA: 1s - loss: 16363.8872 - KL_divergence: 8.8240
 25/200 [==>...........................] - ETA: 1s - loss: 16367.4461 - KL_divergence: 8.8167
 31/200 [===>..........................] - ETA: 1s - loss: 16404.7399 - KL_divergence: 8.8289
 37/200 [====>.........................] - ETA: 1s - loss: 16381.0220 - KL_divergence: 8.8327
 43/200 [=====>........................] - ETA: 1s - loss: 16371.4343 - KL_divergence: 8.7917
 49/200 [======>.......................] - ETA: 1s - loss: 16332.1395 - KL_divergence: 8.8002
 55/200 [=======>......................] - ETA: 1s - loss: 16340.0910 - KL_divergence: 8.8178
 61/200 [========>.....................] - ETA: 1s - loss: 16347.4808 - KL_divergence: 8.8002
 67/200 [=========>....................] - ETA: 1s - loss: 16328.8369 - KL_divergence: 8.8457
 73/200 [=========>....................] - ETA: 1s - loss: 16303.4220 - KL_divergence: 8.8441
 79/200 [==========>...................] - ETA: 1s - loss: 16306.0474 - KL_divergence: 8.8443
 85/200 [===========>..................] - ETA: 1s - loss: 16295.9098 - KL_divergence: 8.8309
 91/200 [============>.................] - ETA: 1s - loss: 16269.5852 - KL_divergence: 8.8127
 97/200 [=============>................] - ETA: 0s - loss: 16251.5110 - KL_divergence: 8.7999
104/200 [==============>...............] - ETA: 0s - loss: 16233.0869 - KL_divergence: 8.7732
110/200 [===============>..............] - ETA: 0s - loss: 16211.2618 - KL_divergence: 8.7807
116/200 [================>.............] - ETA: 0s - loss: 16183.4220 - KL_divergence: 8.7994
122/200 [=================>............] - ETA: 0s - loss: 16154.4714 - KL_divergence: 8.7911
128/200 [==================>...........] - ETA: 0s - loss: 16130.3981 - KL_divergence: 8.7873
134/200 [===================>..........] - ETA: 0s - loss: 16134.1470 - KL_divergence: 8.7907
140/200 [====================>.........] - ETA: 0s - loss: 16134.4849 - KL_divergence: 8.8031
146/200 [====================>.........] - ETA: 0s - loss: 16102.7464 - KL_divergence: 8.8127
152/200 [=====================>........] - ETA: 0s - loss: 16113.8552 - KL_divergence: 8.8121
159/200 [======================>.......] - ETA: 0s - loss: 16090.4243 - KL_divergence: 8.8140
165/200 [=======================>......] - ETA: 0s - loss: 16081.8537 - KL_divergence: 8.8210
171/200 [========================>.....] - ETA: 0s - loss: 16082.1209 - KL_divergence: 8.8175
177/200 [=========================>....] - ETA: 0s - loss: 16067.8994 - KL_divergence: 8.8258
183/200 [==========================>...] - ETA: 0s - loss: 16049.9060 - KL_divergence: 8.8337
189/200 [===========================>..] - ETA: 0s - loss: 16054.3077 - KL_divergence: 8.8298
195/200 [============================>.] - ETA: 0s - loss: 16069.0473 - KL_divergence: 8.8243
200/200 [==============================] - 2s 10ms/step - loss: 16073.3644 - KL_divergence: 8.8259 - val_loss: 16184.0450 - val_KL_divergence: 9.1522
Epoch 11/100

  1/200 [..............................] - ETA: 1s - loss: 14865.4717 - KL_divergence: 8.9997
  7/200 [>.............................] - ETA: 1s - loss: 15392.9515 - KL_divergence: 8.8715
 13/200 [>.............................] - ETA: 1s - loss: 15589.0319 - KL_divergence: 8.8714
 19/200 [=>............................] - ETA: 1s - loss: 15865.0770 - KL_divergence: 8.8491
 25/200 [==>...........................] - ETA: 1s - loss: 15720.5888 - KL_divergence: 8.8593
 31/200 [===>..........................] - ETA: 1s - loss: 15699.6184 - KL_divergence: 8.9323
 37/200 [====>.........................] - ETA: 1s - loss: 15739.9748 - KL_divergence: 8.9616
 43/200 [=====>........................] - ETA: 1s - loss: 15762.2290 - KL_divergence: 8.9405
 49/200 [======>.......................] - ETA: 1s - loss: 15830.6268 - KL_divergence: 8.9382
 55/200 [=======>......................] - ETA: 1s - loss: 15841.4523 - KL_divergence: 8.9391
 61/200 [========>.....................] - ETA: 1s - loss: 15818.7381 - KL_divergence: 8.9295
 67/200 [=========>....................] - ETA: 1s - loss: 15865.8851 - KL_divergence: 8.9260
 73/200 [=========>....................] - ETA: 1s - loss: 15914.4554 - KL_divergence: 8.9312
 80/200 [===========>..................] - ETA: 1s - loss: 15915.9345 - KL_divergence: 8.9069
 86/200 [===========>..................] - ETA: 0s - loss: 15878.3203 - KL_divergence: 8.9105
 93/200 [============>.................] - ETA: 0s - loss: 15894.8394 - KL_divergence: 8.8959
 99/200 [=============>................] - ETA: 0s - loss: 15926.9361 - KL_divergence: 8.8853
105/200 [==============>...............] - ETA: 0s - loss: 15943.6636 - KL_divergence: 8.8751
110/200 [===============>..............] - ETA: 0s - loss: 15948.3864 - KL_divergence: 8.8713
116/200 [================>.............] - ETA: 0s - loss: 15942.0009 - KL_divergence: 8.8844
122/200 [=================>............] - ETA: 0s - loss: 15927.9304 - KL_divergence: 8.8877
128/200 [==================>...........] - ETA: 0s - loss: 15928.9248 - KL_divergence: 8.8894
134/200 [===================>..........] - ETA: 0s - loss: 15919.3571 - KL_divergence: 8.9021
140/200 [====================>.........] - ETA: 0s - loss: 15899.9638 - KL_divergence: 8.9069
146/200 [====================>.........] - ETA: 0s - loss: 15903.2676 - KL_divergence: 8.9020
152/200 [=====================>........] - ETA: 0s - loss: 15917.4229 - KL_divergence: 8.9144
158/200 [======================>.......] - ETA: 0s - loss: 15894.2051 - KL_divergence: 8.9332
164/200 [=======================>......] - ETA: 0s - loss: 15902.6554 - KL_divergence: 8.9395
170/200 [========================>.....] - ETA: 0s - loss: 15889.5275 - KL_divergence: 8.9539
176/200 [=========================>....] - ETA: 0s - loss: 15877.6178 - KL_divergence: 8.9522
182/200 [==========================>...] - ETA: 0s - loss: 15864.0426 - KL_divergence: 8.9538
188/200 [===========================>..] - ETA: 0s - loss: 15854.8839 - KL_divergence: 8.9566
194/200 [============================>.] - ETA: 0s - loss: 15832.7812 - KL_divergence: 8.9716
200/200 [==============================] - 2s 10ms/step - loss: 15832.1158 - KL_divergence: 8.9665 - val_loss: 15633.1714 - val_KL_divergence: 8.8265
Epoch 12/100

  1/200 [..............................] - ETA: 1s - loss: 15310.2891 - KL_divergence: 9.4392
  8/200 [>.............................] - ETA: 1s - loss: 15627.9418 - KL_divergence: 8.9410
 14/200 [=>............................] - ETA: 1s - loss: 15726.3751 - KL_divergence: 8.9375
 20/200 [==>...........................] - ETA: 1s - loss: 15801.7358 - KL_divergence: 8.9616
 26/200 [==>...........................] - ETA: 1s - loss: 15692.4316 - KL_divergence: 8.9568
 32/200 [===>..........................] - ETA: 1s - loss: 15613.0478 - KL_divergence: 9.0199
 38/200 [====>.........................] - ETA: 1s - loss: 15602.0642 - KL_divergence: 9.0140
 44/200 [=====>........................] - ETA: 1s - loss: 15527.5773 - KL_divergence: 9.0839
 50/200 [======>.......................] - ETA: 1s - loss: 15545.6546 - KL_divergence: 9.0747
 56/200 [=======>......................] - ETA: 1s - loss: 15508.1921 - KL_divergence: 9.0808
 62/200 [========>.....................] - ETA: 1s - loss: 15528.9074 - KL_divergence: 9.0652
 68/200 [=========>....................] - ETA: 1s - loss: 15449.0246 - KL_divergence: 9.1317
 74/200 [==========>...................] - ETA: 1s - loss: 15474.1611 - KL_divergence: 9.1498
 80/200 [===========>..................] - ETA: 1s - loss: 15446.0916 - KL_divergence: 9.1694
 86/200 [===========>..................] - ETA: 1s - loss: 15417.4604 - KL_divergence: 9.2124
 92/200 [============>.................] - ETA: 0s - loss: 15455.9332 - KL_divergence: 9.2169
 98/200 [=============>................] - ETA: 0s - loss: 15504.5298 - KL_divergence: 9.2006
104/200 [==============>...............] - ETA: 0s - loss: 15494.1638 - KL_divergence: 9.2017
110/200 [===============>..............] - ETA: 0s - loss: 15484.0481 - KL_divergence: 9.2204
116/200 [================>.............] - ETA: 0s - loss: 15467.6951 - KL_divergence: 9.2535
122/200 [=================>............] - ETA: 0s - loss: 15438.0177 - KL_divergence: 9.2488
128/200 [==================>...........] - ETA: 0s - loss: 15434.7371 - KL_divergence: 9.2661
134/200 [===================>..........] - ETA: 0s - loss: 15422.4281 - KL_divergence: 9.2620
140/200 [====================>.........] - ETA: 0s - loss: 15410.1659 - KL_divergence: 9.2650
146/200 [====================>.........] - ETA: 0s - loss: 15389.1180 - KL_divergence: 9.2692
152/200 [=====================>........] - ETA: 0s - loss: 15381.6728 - KL_divergence: 9.2675
158/200 [======================>.......] - ETA: 0s - loss: 15395.4786 - KL_divergence: 9.2699
164/200 [=======================>......] - ETA: 0s - loss: 15374.7579 - KL_divergence: 9.2779
170/200 [========================>.....] - ETA: 0s - loss: 15376.1642 - KL_divergence: 9.2756
176/200 [=========================>....] - ETA: 0s - loss: 15374.6353 - KL_divergence: 9.2746
182/200 [==========================>...] - ETA: 0s - loss: 15372.8171 - KL_divergence: 9.2726
188/200 [===========================>..] - ETA: 0s - loss: 15342.1152 - KL_divergence: 9.2909
194/200 [============================>.] - ETA: 0s - loss: 15327.9986 - KL_divergence: 9.3079
200/200 [==============================] - 2s 10ms/step - loss: 15330.0451 - KL_divergence: 9.3078 - val_loss: 15253.0822 - val_KL_divergence: 9.1810
Epoch 13/100

  1/200 [..............................] - ETA: 1s - loss: 14765.3525 - KL_divergence: 9.0353
  7/200 [>.............................] - ETA: 1s - loss: 14643.6302 - KL_divergence: 9.3408
 13/200 [>.............................] - ETA: 1s - loss: 14884.9107 - KL_divergence: 9.2433
 19/200 [=>............................] - ETA: 1s - loss: 15160.2081 - KL_divergence: 9.2280
 25/200 [==>...........................] - ETA: 1s - loss: 15192.4728 - KL_divergence: 9.2419
 31/200 [===>..........................] - ETA: 1s - loss: 15230.1415 - KL_divergence: 9.2728
 37/200 [====>.........................] - ETA: 1s - loss: 15107.3753 - KL_divergence: 9.3450
 43/200 [=====>........................] - ETA: 1s - loss: 15119.8353 - KL_divergence: 9.3585
 49/200 [======>.......................] - ETA: 1s - loss: 15110.3440 - KL_divergence: 9.3841
 55/200 [=======>......................] - ETA: 1s - loss: 15137.5264 - KL_divergence: 9.3916
 61/200 [========>.....................] - ETA: 1s - loss: 15151.7522 - KL_divergence: 9.3620
 67/200 [=========>....................] - ETA: 1s - loss: 15117.3951 - KL_divergence: 9.3794
 73/200 [=========>....................] - ETA: 1s - loss: 15119.9688 - KL_divergence: 9.3792
 79/200 [==========>...................] - ETA: 1s - loss: 15135.0564 - KL_divergence: 9.3604
 85/200 [===========>..................] - ETA: 1s - loss: 15128.9412 - KL_divergence: 9.3864
 91/200 [============>.................] - ETA: 0s - loss: 15114.2611 - KL_divergence: 9.4251
 97/200 [=============>................] - ETA: 0s - loss: 15071.9876 - KL_divergence: 9.4290
104/200 [==============>...............] - ETA: 0s - loss: 15077.5051 - KL_divergence: 9.4284
110/200 [===============>..............] - ETA: 0s - loss: 15062.6318 - KL_divergence: 9.4244
116/200 [================>.............] - ETA: 0s - loss: 15069.4763 - KL_divergence: 9.4244
122/200 [=================>............] - ETA: 0s - loss: 15101.9552 - KL_divergence: 9.4131
128/200 [==================>...........] - ETA: 0s - loss: 15097.5962 - KL_divergence: 9.4149
134/200 [===================>..........] - ETA: 0s - loss: 15091.9226 - KL_divergence: 9.4232
140/200 [====================>.........] - ETA: 0s - loss: 15100.5857 - KL_divergence: 9.4255
146/200 [====================>.........] - ETA: 0s - loss: 15110.5267 - KL_divergence: 9.4030
152/200 [=====================>........] - ETA: 0s - loss: 15098.1651 - KL_divergence: 9.4085
158/200 [======================>.......] - ETA: 0s - loss: 15089.1593 - KL_divergence: 9.3998
164/200 [=======================>......] - ETA: 0s - loss: 15069.5281 - KL_divergence: 9.4061
170/200 [========================>.....] - ETA: 0s - loss: 15066.0556 - KL_divergence: 9.4000
176/200 [=========================>....] - ETA: 0s - loss: 15083.0345 - KL_divergence: 9.3965
183/200 [==========================>...] - ETA: 0s - loss: 15082.3515 - KL_divergence: 9.3899
190/200 [===========================>..] - ETA: 0s - loss: 15092.2871 - KL_divergence: 9.3893
197/200 [============================>.] - ETA: 0s - loss: 15073.5403 - KL_divergence: 9.3930
200/200 [==============================] - 2s 10ms/step - loss: 15088.2357 - KL_divergence: 9.3902 - val_loss: 14921.7862 - val_KL_divergence: 9.2292
Epoch 14/100

  1/200 [..............................] - ETA: 1s - loss: 14127.1826 - KL_divergence: 9.6836
  7/200 [>.............................] - ETA: 1s - loss: 14705.2412 - KL_divergence: 9.5673
 13/200 [>.............................] - ETA: 1s - loss: 14749.0126 - KL_divergence: 9.4306
 19/200 [=>............................] - ETA: 1s - loss: 14636.7055 - KL_divergence: 9.5257
 25/200 [==>...........................] - ETA: 1s - loss: 14838.3903 - KL_divergence: 9.5227
 31/200 [===>..........................] - ETA: 1s - loss: 14773.7055 - KL_divergence: 9.5232
 37/200 [====>.........................] - ETA: 1s - loss: 14919.6981 - KL_divergence: 9.5219
 43/200 [=====>........................] - ETA: 1s - loss: 14888.9752 - KL_divergence: 9.5432
 49/200 [======>.......................] - ETA: 1s - loss: 14918.7048 - KL_divergence: 9.5528
 54/200 [=======>......................] - ETA: 1s - loss: 14868.4296 - KL_divergence: 9.5869
 60/200 [========>.....................] - ETA: 1s - loss: 14863.9803 - KL_divergence: 9.5620
 66/200 [========>.....................] - ETA: 1s - loss: 14819.7084 - KL_divergence: 9.5870
 72/200 [=========>....................] - ETA: 1s - loss: 14771.7975 - KL_divergence: 9.6180
 78/200 [==========>...................] - ETA: 1s - loss: 14822.2790 - KL_divergence: 9.5852
 84/200 [===========>..................] - ETA: 1s - loss: 14841.9921 - KL_divergence: 9.5680
 90/200 [============>.................] - ETA: 1s - loss: 14860.7927 - KL_divergence: 9.5566
 96/200 [=============>................] - ETA: 0s - loss: 14866.7325 - KL_divergence: 9.5663
102/200 [==============>...............] - ETA: 0s - loss: 14839.9112 - KL_divergence: 9.5722
108/200 [===============>..............] - ETA: 0s - loss: 14829.3297 - KL_divergence: 9.5561
114/200 [================>.............] - ETA: 0s - loss: 14817.6930 - KL_divergence: 9.5641
121/200 [=================>............] - ETA: 0s - loss: 14847.6493 - KL_divergence: 9.5439
127/200 [==================>...........] - ETA: 0s - loss: 14870.8726 - KL_divergence: 9.5198
134/200 [===================>..........] - ETA: 0s - loss: 14858.2097 - KL_divergence: 9.5099
140/200 [====================>.........] - ETA: 0s - loss: 14838.3917 - KL_divergence: 9.5097
146/200 [====================>.........] - ETA: 0s - loss: 14838.6549 - KL_divergence: 9.5146
152/200 [=====================>........] - ETA: 0s - loss: 14836.6811 - KL_divergence: 9.5059
158/200 [======================>.......] - ETA: 0s - loss: 14830.5832 - KL_divergence: 9.5028
164/200 [=======================>......] - ETA: 0s - loss: 14812.8849 - KL_divergence: 9.5056
171/200 [========================>.....] - ETA: 0s - loss: 14818.4923 - KL_divergence: 9.5002
177/200 [=========================>....] - ETA: 0s - loss: 14827.8412 - KL_divergence: 9.4920
184/200 [==========================>...] - ETA: 0s - loss: 14816.8831 - KL_divergence: 9.4947
190/200 [===========================>..] - ETA: 0s - loss: 14816.4704 - KL_divergence: 9.4897
196/200 [============================>.] - ETA: 0s - loss: 14805.1994 - KL_divergence: 9.4971
200/200 [==============================] - 2s 10ms/step - loss: 14809.4965 - KL_divergence: 9.5031 - val_loss: 14975.8799 - val_KL_divergence: 9.4853
Epoch 15/100

  1/200 [..............................] - ETA: 1s - loss: 14952.5996 - KL_divergence: 8.7390
  8/200 [>.............................] - ETA: 1s - loss: 15003.2201 - KL_divergence: 9.3163
 15/200 [=>............................] - ETA: 1s - loss: 15033.8382 - KL_divergence: 9.2784
 22/200 [==>...........................] - ETA: 1s - loss: 14924.1689 - KL_divergence: 9.4111
 28/200 [===>..........................] - ETA: 1s - loss: 14883.5461 - KL_divergence: 9.4231
 34/200 [====>.........................] - ETA: 1s - loss: 14830.1694 - KL_divergence: 9.4921
 41/200 [=====>........................] - ETA: 1s - loss: 14874.6577 - KL_divergence: 9.5020
 47/200 [======>.......................] - ETA: 1s - loss: 14889.6220 - KL_divergence: 9.4849
 53/200 [======>.......................] - ETA: 1s - loss: 14763.0723 - KL_divergence: 9.5345
 59/200 [=======>......................] - ETA: 1s - loss: 14764.9037 - KL_divergence: 9.5248
 65/200 [========>.....................] - ETA: 1s - loss: 14772.0854 - KL_divergence: 9.5067
 72/200 [=========>....................] - ETA: 1s - loss: 14739.5024 - KL_divergence: 9.5004
 78/200 [==========>...................] - ETA: 1s - loss: 14760.7287 - KL_divergence: 9.4921
 85/200 [===========>..................] - ETA: 0s - loss: 14801.5703 - KL_divergence: 9.4689
 91/200 [============>.................] - ETA: 0s - loss: 14770.9822 - KL_divergence: 9.4913
 97/200 [=============>................] - ETA: 0s - loss: 14753.2229 - KL_divergence: 9.4850
103/200 [==============>...............] - ETA: 0s - loss: 14740.4300 - KL_divergence: 9.4895
109/200 [===============>..............] - ETA: 0s - loss: 14738.5473 - KL_divergence: 9.4751
115/200 [================>.............] - ETA: 0s - loss: 14706.6723 - KL_divergence: 9.4962
121/200 [=================>............] - ETA: 0s - loss: 14716.5599 - KL_divergence: 9.4983
127/200 [==================>...........] - ETA: 0s - loss: 14730.5317 - KL_divergence: 9.4749
133/200 [==================>...........] - ETA: 0s - loss: 14730.1161 - KL_divergence: 9.4769
139/200 [===================>..........] - ETA: 0s - loss: 14738.3954 - KL_divergence: 9.4731
146/200 [====================>.........] - ETA: 0s - loss: 14746.3704 - KL_divergence: 9.4703
152/200 [=====================>........] - ETA: 0s - loss: 14731.7748 - KL_divergence: 9.4726
158/200 [======================>.......] - ETA: 0s - loss: 14745.2819 - KL_divergence: 9.4679
164/200 [=======================>......] - ETA: 0s - loss: 14720.9440 - KL_divergence: 9.4822
170/200 [========================>.....] - ETA: 0s - loss: 14701.4477 - KL_divergence: 9.4926
176/200 [=========================>....] - ETA: 0s - loss: 14702.8860 - KL_divergence: 9.5018
182/200 [==========================>...] - ETA: 0s - loss: 14706.2057 - KL_divergence: 9.5046
188/200 [===========================>..] - ETA: 0s - loss: 14710.6023 - KL_divergence: 9.5070
194/200 [============================>.] - ETA: 0s - loss: 14701.0983 - KL_divergence: 9.5147
200/200 [==============================] - 2s 10ms/step - loss: 14711.4460 - KL_divergence: 9.5043 - val_loss: 14811.9184 - val_KL_divergence: 9.5426
Epoch 16/100

  1/200 [..............................] - ETA: 1s - loss: 14219.9551 - KL_divergence: 9.9456
  8/200 [>.............................] - ETA: 1s - loss: 14268.6128 - KL_divergence: 9.7130
 14/200 [=>............................] - ETA: 1s - loss: 14709.9875 - KL_divergence: 9.5125
 21/200 [==>...........................] - ETA: 1s - loss: 14526.9290 - KL_divergence: 9.4932
 27/200 [===>..........................] - ETA: 1s - loss: 14589.4332 - KL_divergence: 9.4821
 34/200 [====>.........................] - ETA: 1s - loss: 14689.4833 - KL_divergence: 9.4285
 41/200 [=====>........................] - ETA: 1s - loss: 14624.0352 - KL_divergence: 9.4639
 47/200 [======>.......................] - ETA: 1s - loss: 14587.0535 - KL_divergence: 9.5315
 53/200 [======>.......................] - ETA: 1s - loss: 14506.4349 - KL_divergence: 9.5973
 60/200 [========>.....................] - ETA: 1s - loss: 14536.7295 - KL_divergence: 9.5687
 67/200 [=========>....................] - ETA: 1s - loss: 14535.7379 - KL_divergence: 9.5485
 73/200 [=========>....................] - ETA: 1s - loss: 14484.4304 - KL_divergence: 9.5752
 79/200 [==========>...................] - ETA: 1s - loss: 14504.4025 - KL_divergence: 9.5777
 85/200 [===========>..................] - ETA: 0s - loss: 14494.6627 - KL_divergence: 9.5752
 91/200 [============>.................] - ETA: 0s - loss: 14556.1008 - KL_divergence: 9.5467
 97/200 [=============>................] - ETA: 0s - loss: 14518.4799 - KL_divergence: 9.5551
103/200 [==============>...............] - ETA: 0s - loss: 14501.0145 - KL_divergence: 9.5609
109/200 [===============>..............] - ETA: 0s - loss: 14509.2120 - KL_divergence: 9.5530
115/200 [================>.............] - ETA: 0s - loss: 14479.0590 - KL_divergence: 9.5623
121/200 [=================>............] - ETA: 0s - loss: 14478.1419 - KL_divergence: 9.5616
127/200 [==================>...........] - ETA: 0s - loss: 14496.5582 - KL_divergence: 9.5537
133/200 [==================>...........] - ETA: 0s - loss: 14496.8712 - KL_divergence: 9.5457
139/200 [===================>..........] - ETA: 0s - loss: 14480.2273 - KL_divergence: 9.5495
145/200 [====================>.........] - ETA: 0s - loss: 14491.9598 - KL_divergence: 9.5266
151/200 [=====================>........] - ETA: 0s - loss: 14498.0792 - KL_divergence: 9.5341
157/200 [======================>.......] - ETA: 0s - loss: 14492.5508 - KL_divergence: 9.5323
163/200 [=======================>......] - ETA: 0s - loss: 14479.2045 - KL_divergence: 9.5316
169/200 [========================>.....] - ETA: 0s - loss: 14486.2046 - KL_divergence: 9.5223
176/200 [=========================>....] - ETA: 0s - loss: 14496.0202 - KL_divergence: 9.5124
182/200 [==========================>...] - ETA: 0s - loss: 14502.0806 - KL_divergence: 9.5101
189/200 [===========================>..] - ETA: 0s - loss: 14517.5340 - KL_divergence: 9.5012
196/200 [============================>.] - ETA: 0s - loss: 14518.1851 - KL_divergence: 9.5016
200/200 [==============================] - 2s 9ms/step - loss: 14517.4081 - KL_divergence: 9.5016 - val_loss: 14397.7310 - val_KL_divergence: 9.2583
Epoch 17/100

  1/200 [..............................] - ETA: 1s - loss: 15384.0801 - KL_divergence: 9.3880
  8/200 [>.............................] - ETA: 1s - loss: 14708.1283 - KL_divergence: 9.5148
 14/200 [=>............................] - ETA: 1s - loss: 14509.5555 - KL_divergence: 9.5712
 20/200 [==>...........................] - ETA: 1s - loss: 14331.3967 - KL_divergence: 9.6777
 26/200 [==>...........................] - ETA: 1s - loss: 14342.0818 - KL_divergence: 9.6591
 32/200 [===>..........................] - ETA: 1s - loss: 14389.9461 - KL_divergence: 9.6685
 38/200 [====>.........................] - ETA: 1s - loss: 14394.7624 - KL_divergence: 9.6850
 44/200 [=====>........................] - ETA: 1s - loss: 14446.1571 - KL_divergence: 9.6194
 50/200 [======>.......................] - ETA: 1s - loss: 14409.6543 - KL_divergence: 9.6396
 56/200 [=======>......................] - ETA: 1s - loss: 14388.6675 - KL_divergence: 9.6533
 62/200 [========>.....................] - ETA: 1s - loss: 14393.4340 - KL_divergence: 9.6464
 68/200 [=========>....................] - ETA: 1s - loss: 14384.6180 - KL_divergence: 9.6425
 74/200 [==========>...................] - ETA: 1s - loss: 14384.7709 - KL_divergence: 9.6362
 80/200 [===========>..................] - ETA: 1s - loss: 14360.8188 - KL_divergence: 9.6569
 86/200 [===========>..................] - ETA: 1s - loss: 14388.7444 - KL_divergence: 9.6429
 93/200 [============>.................] - ETA: 0s - loss: 14403.0280 - KL_divergence: 9.6525
 99/200 [=============>................] - ETA: 0s - loss: 14426.8765 - KL_divergence: 9.6338
104/200 [==============>...............] - ETA: 0s - loss: 14435.1635 - KL_divergence: 9.6203
110/200 [===============>..............] - ETA: 0s - loss: 14433.2523 - KL_divergence: 9.6160
116/200 [================>.............] - ETA: 0s - loss: 14444.7531 - KL_divergence: 9.5961
122/200 [=================>............] - ETA: 0s - loss: 14422.9960 - KL_divergence: 9.6043
128/200 [==================>...........] - ETA: 0s - loss: 14421.6018 - KL_divergence: 9.6080
134/200 [===================>..........] - ETA: 0s - loss: 14439.6872 - KL_divergence: 9.6008
140/200 [====================>.........] - ETA: 0s - loss: 14433.8835 - KL_divergence: 9.6085
146/200 [====================>.........] - ETA: 0s - loss: 14434.2767 - KL_divergence: 9.6120
152/200 [=====================>........] - ETA: 0s - loss: 14435.3943 - KL_divergence: 9.6124
158/200 [======================>.......] - ETA: 0s - loss: 14407.9795 - KL_divergence: 9.6183
164/200 [=======================>......] - ETA: 0s - loss: 14407.2593 - KL_divergence: 9.6020
170/200 [========================>.....] - ETA: 0s - loss: 14399.8357 - KL_divergence: 9.5957
176/200 [=========================>....] - ETA: 0s - loss: 14395.9730 - KL_divergence: 9.5900
182/200 [==========================>...] - ETA: 0s - loss: 14403.5690 - KL_divergence: 9.5751
189/200 [===========================>..] - ETA: 0s - loss: 14393.1941 - KL_divergence: 9.5724
195/200 [============================>.] - ETA: 0s - loss: 14392.0078 - KL_divergence: 9.5705
200/200 [==============================] - 2s 10ms/step - loss: 14389.0100 - KL_divergence: 9.5658 - val_loss: 14564.0609 - val_KL_divergence: 9.4923
Epoch 18/100

  1/200 [..............................] - ETA: 1s - loss: 13342.0088 - KL_divergence: 10.4482
  7/200 [>.............................] - ETA: 1s - loss: 14477.5379 - KL_divergence: 9.4392 
 13/200 [>.............................] - ETA: 1s - loss: 14449.6557 - KL_divergence: 9.3978
 19/200 [=>............................] - ETA: 1s - loss: 14259.2962 - KL_divergence: 9.4318
 25/200 [==>...........................] - ETA: 1s - loss: 14265.9822 - KL_divergence: 9.3820
 31/200 [===>..........................] - ETA: 1s - loss: 14405.7038 - KL_divergence: 9.4261
 37/200 [====>.........................] - ETA: 1s - loss: 14374.8976 - KL_divergence: 9.5090
 43/200 [=====>........................] - ETA: 1s - loss: 14383.9096 - KL_divergence: 9.4744
 49/200 [======>.......................] - ETA: 1s - loss: 14357.7788 - KL_divergence: 9.4876
 55/200 [=======>......................] - ETA: 1s - loss: 14363.1831 - KL_divergence: 9.4789
 61/200 [========>.....................] - ETA: 1s - loss: 14434.3419 - KL_divergence: 9.4459
 67/200 [=========>....................] - ETA: 1s - loss: 14409.7940 - KL_divergence: 9.4584
 73/200 [=========>....................] - ETA: 1s - loss: 14397.1879 - KL_divergence: 9.4611
 79/200 [==========>...................] - ETA: 1s - loss: 14426.0899 - KL_divergence: 9.4372
 85/200 [===========>..................] - ETA: 1s - loss: 14425.7075 - KL_divergence: 9.4498
 91/200 [============>.................] - ETA: 0s - loss: 14413.6667 - KL_divergence: 9.4575
 97/200 [=============>................] - ETA: 0s - loss: 14395.9400 - KL_divergence: 9.4530
103/200 [==============>...............] - ETA: 0s - loss: 14418.4901 - KL_divergence: 9.4409
109/200 [===============>..............] - ETA: 0s - loss: 14388.8356 - KL_divergence: 9.4397
115/200 [================>.............] - ETA: 0s - loss: 14363.3521 - KL_divergence: 9.4541
121/200 [=================>............] - ETA: 0s - loss: 14362.1928 - KL_divergence: 9.4541
127/200 [==================>...........] - ETA: 0s - loss: 14346.6208 - KL_divergence: 9.4643
133/200 [==================>...........] - ETA: 0s - loss: 14358.0194 - KL_divergence: 9.4601
139/200 [===================>..........] - ETA: 0s - loss: 14340.3796 - KL_divergence: 9.4695
145/200 [====================>.........] - ETA: 0s - loss: 14351.0724 - KL_divergence: 9.4690
151/200 [=====================>........] - ETA: 0s - loss: 14357.0399 - KL_divergence: 9.4698
157/200 [======================>.......] - ETA: 0s - loss: 14358.9969 - KL_divergence: 9.4800
163/200 [=======================>......] - ETA: 0s - loss: 14376.9165 - KL_divergence: 9.4615
169/200 [========================>.....] - ETA: 0s - loss: 14398.0000 - KL_divergence: 9.4517
175/200 [=========================>....] - ETA: 0s - loss: 14412.4439 - KL_divergence: 9.4454
181/200 [==========================>...] - ETA: 0s - loss: 14409.9446 - KL_divergence: 9.4479
187/200 [===========================>..] - ETA: 0s - loss: 14396.3543 - KL_divergence: 9.4548
193/200 [===========================>..] - ETA: 0s - loss: 14402.9472 - KL_divergence: 9.4534
199/200 [============================>.] - ETA: 0s - loss: 14385.1302 - KL_divergence: 9.4555
200/200 [==============================] - 2s 10ms/step - loss: 14379.4534 - KL_divergence: 9.4563 - val_loss: 14548.8643 - val_KL_divergence: 9.7589
Epoch 19/100

  1/200 [..............................] - ETA: 1s - loss: 14658.1348 - KL_divergence: 10.2050
  7/200 [>.............................] - ETA: 1s - loss: 14392.4395 - KL_divergence: 9.5458 
 13/200 [>.............................] - ETA: 1s - loss: 14385.7063 - KL_divergence: 9.3645
 19/200 [=>............................] - ETA: 1s - loss: 14339.6843 - KL_divergence: 9.4200
 25/200 [==>...........................] - ETA: 1s - loss: 14334.8227 - KL_divergence: 9.3772
 31/200 [===>..........................] - ETA: 1s - loss: 14304.0371 - KL_divergence: 9.3919
 37/200 [====>.........................] - ETA: 1s - loss: 14211.4712 - KL_divergence: 9.4917
 44/200 [=====>........................] - ETA: 1s - loss: 14209.5258 - KL_divergence: 9.4883
 50/200 [======>.......................] - ETA: 1s - loss: 14201.3176 - KL_divergence: 9.4539
 56/200 [=======>......................] - ETA: 1s - loss: 14224.3781 - KL_divergence: 9.4486
 62/200 [========>.....................] - ETA: 1s - loss: 14230.3298 - KL_divergence: 9.4447
 68/200 [=========>....................] - ETA: 1s - loss: 14207.9969 - KL_divergence: 9.4418
 74/200 [==========>...................] - ETA: 1s - loss: 14254.4970 - KL_divergence: 9.4168
 80/200 [===========>..................] - ETA: 1s - loss: 14207.3536 - KL_divergence: 9.4384
 87/200 [============>.................] - ETA: 1s - loss: 14213.4298 - KL_divergence: 9.4429
 94/200 [=============>................] - ETA: 0s - loss: 14175.5537 - KL_divergence: 9.4429
100/200 [==============>...............] - ETA: 0s - loss: 14188.0170 - KL_divergence: 9.4602
106/200 [==============>...............] - ETA: 0s - loss: 14194.6024 - KL_divergence: 9.4768
112/200 [===============>..............] - ETA: 0s - loss: 14199.4108 - KL_divergence: 9.4842
118/200 [================>.............] - ETA: 0s - loss: 14210.3712 - KL_divergence: 9.4735
124/200 [=================>............] - ETA: 0s - loss: 14217.3810 - KL_divergence: 9.4586
130/200 [==================>...........] - ETA: 0s - loss: 14242.0401 - KL_divergence: 9.4535
136/200 [===================>..........] - ETA: 0s - loss: 14209.8512 - KL_divergence: 9.4649
142/200 [====================>.........] - ETA: 0s - loss: 14182.0798 - KL_divergence: 9.4823
148/200 [=====================>........] - ETA: 0s - loss: 14185.4019 - KL_divergence: 9.4736
154/200 [======================>.......] - ETA: 0s - loss: 14192.6019 - KL_divergence: 9.4632
160/200 [=======================>......] - ETA: 0s - loss: 14187.4107 - KL_divergence: 9.4654
166/200 [=======================>......] - ETA: 0s - loss: 14206.6391 - KL_divergence: 9.4577
172/200 [========================>.....] - ETA: 0s - loss: 14211.5109 - KL_divergence: 9.4530
178/200 [=========================>....] - ETA: 0s - loss: 14206.4392 - KL_divergence: 9.4701
184/200 [==========================>...] - ETA: 0s - loss: 14192.6818 - KL_divergence: 9.4731
190/200 [===========================>..] - ETA: 0s - loss: 14193.0292 - KL_divergence: 9.4770
196/200 [============================>.] - ETA: 0s - loss: 14197.9479 - KL_divergence: 9.4731
200/200 [==============================] - 2s 10ms/step - loss: 14211.6105 - KL_divergence: 9.4686 - val_loss: 14325.6420 - val_KL_divergence: 9.4237
Epoch 20/100

  1/200 [..............................] - ETA: 1s - loss: 12932.5088 - KL_divergence: 9.6521
  7/200 [>.............................] - ETA: 1s - loss: 14067.0416 - KL_divergence: 9.5341
 12/200 [>.............................] - ETA: 1s - loss: 14132.8112 - KL_divergence: 9.4890
 17/200 [=>............................] - ETA: 1s - loss: 14081.3467 - KL_divergence: 9.4928
 23/200 [==>...........................] - ETA: 1s - loss: 13987.1396 - KL_divergence: 9.5230
 29/200 [===>..........................] - ETA: 1s - loss: 14004.7228 - KL_divergence: 9.5115
 35/200 [====>.........................] - ETA: 1s - loss: 13979.2106 - KL_divergence: 9.5462
 41/200 [=====>........................] - ETA: 1s - loss: 14038.5478 - KL_divergence: 9.5363
 47/200 [======>.......................] - ETA: 1s - loss: 14058.0759 - KL_divergence: 9.5278
 53/200 [======>.......................] - ETA: 1s - loss: 14214.6945 - KL_divergence: 9.4961
 59/200 [=======>......................] - ETA: 1s - loss: 14228.8826 - KL_divergence: 9.4632
 65/200 [========>.....................] - ETA: 1s - loss: 14229.7193 - KL_divergence: 9.4528
 72/200 [=========>....................] - ETA: 1s - loss: 14166.0127 - KL_divergence: 9.4962
 78/200 [==========>...................] - ETA: 1s - loss: 14165.9284 - KL_divergence: 9.5059
 84/200 [===========>..................] - ETA: 1s - loss: 14215.1900 - KL_divergence: 9.4525
 90/200 [============>.................] - ETA: 0s - loss: 14222.8012 - KL_divergence: 9.4541
 96/200 [=============>................] - ETA: 0s - loss: 14207.9034 - KL_divergence: 9.4485
102/200 [==============>...............] - ETA: 0s - loss: 14197.8589 - KL_divergence: 9.4384
108/200 [===============>..............] - ETA: 0s - loss: 14212.0665 - KL_divergence: 9.4216
114/200 [================>.............] - ETA: 0s - loss: 14197.2090 - KL_divergence: 9.4185
120/200 [=================>............] - ETA: 0s - loss: 14194.2424 - KL_divergence: 9.4279
126/200 [=================>............] - ETA: 0s - loss: 14202.6269 - KL_divergence: 9.4289
132/200 [==================>...........] - ETA: 0s - loss: 14205.9922 - KL_divergence: 9.4339
138/200 [===================>..........] - ETA: 0s - loss: 14182.9689 - KL_divergence: 9.4386
144/200 [====================>.........] - ETA: 0s - loss: 14145.2126 - KL_divergence: 9.4517
150/200 [=====================>........] - ETA: 0s - loss: 14142.5796 - KL_divergence: 9.4564
156/200 [======================>.......] - ETA: 0s - loss: 14145.9514 - KL_divergence: 9.4506
162/200 [=======================>......] - ETA: 0s - loss: 14145.5362 - KL_divergence: 9.4526
168/200 [========================>.....] - ETA: 0s - loss: 14140.4347 - KL_divergence: 9.4554
174/200 [=========================>....] - ETA: 0s - loss: 14145.6390 - KL_divergence: 9.4575
180/200 [==========================>...] - ETA: 0s - loss: 14149.7434 - KL_divergence: 9.4473
186/200 [==========================>...] - ETA: 0s - loss: 14153.4420 - KL_divergence: 9.4307
192/200 [===========================>..] - ETA: 0s - loss: 14144.7868 - KL_divergence: 9.4332
198/200 [============================>.] - ETA: 0s - loss: 14149.2787 - KL_divergence: 9.4306
200/200 [==============================] - 2s 10ms/step - loss: 14150.3367 - KL_divergence: 9.4336 - val_loss: 14660.0332 - val_KL_divergence: 9.3413
Epoch 21/100

  1/200 [..............................] - ETA: 1s - loss: 15006.8750 - KL_divergence: 8.7102
  7/200 [>.............................] - ETA: 1s - loss: 14446.6881 - KL_divergence: 8.9682
 13/200 [>.............................] - ETA: 1s - loss: 14516.1952 - KL_divergence: 9.0059
 19/200 [=>............................] - ETA: 1s - loss: 14336.9290 - KL_divergence: 9.1147
 25/200 [==>...........................] - ETA: 1s - loss: 14251.7047 - KL_divergence: 9.1428
 31/200 [===>..........................] - ETA: 1s - loss: 14194.1614 - KL_divergence: 9.2392
 37/200 [====>.........................] - ETA: 1s - loss: 14175.8907 - KL_divergence: 9.2705
 43/200 [=====>........................] - ETA: 1s - loss: 14156.8505 - KL_divergence: 9.2866
 49/200 [======>.......................] - ETA: 1s - loss: 14112.4958 - KL_divergence: 9.2955
 55/200 [=======>......................] - ETA: 1s - loss: 14111.1096 - KL_divergence: 9.3112
 61/200 [========>.....................] - ETA: 1s - loss: 14139.3344 - KL_divergence: 9.3218
 67/200 [=========>....................] - ETA: 1s - loss: 14141.9087 - KL_divergence: 9.3196
 73/200 [=========>....................] - ETA: 1s - loss: 14085.0558 - KL_divergence: 9.3203
 79/200 [==========>...................] - ETA: 1s - loss: 14129.9545 - KL_divergence: 9.3090
 85/200 [===========>..................] - ETA: 1s - loss: 14168.0229 - KL_divergence: 9.3076
 91/200 [============>.................] - ETA: 0s - loss: 14147.2655 - KL_divergence: 9.3134
 97/200 [=============>................] - ETA: 0s - loss: 14156.4075 - KL_divergence: 9.3093
103/200 [==============>...............] - ETA: 0s - loss: 14143.8714 - KL_divergence: 9.3201
109/200 [===============>..............] - ETA: 0s - loss: 14133.3722 - KL_divergence: 9.3330
116/200 [================>.............] - ETA: 0s - loss: 14123.6255 - KL_divergence: 9.3272
122/200 [=================>............] - ETA: 0s - loss: 14112.9608 - KL_divergence: 9.3341
128/200 [==================>...........] - ETA: 0s - loss: 14085.5908 - KL_divergence: 9.3440
134/200 [===================>..........] - ETA: 0s - loss: 14079.4108 - KL_divergence: 9.3468
140/200 [====================>.........] - ETA: 0s - loss: 14088.4171 - KL_divergence: 9.3474
146/200 [====================>.........] - ETA: 0s - loss: 14094.5146 - KL_divergence: 9.3386
152/200 [=====================>........] - ETA: 0s - loss: 14084.2014 - KL_divergence: 9.3437
158/200 [======================>.......] - ETA: 0s - loss: 14081.4467 - KL_divergence: 9.3474
164/200 [=======================>......] - ETA: 0s - loss: 14091.4183 - KL_divergence: 9.3444
170/200 [========================>.....] - ETA: 0s - loss: 14069.8621 - KL_divergence: 9.3548
176/200 [=========================>....] - ETA: 0s - loss: 14069.5716 - KL_divergence: 9.3523
182/200 [==========================>...] - ETA: 0s - loss: 14062.1510 - KL_divergence: 9.3720
189/200 [===========================>..] - ETA: 0s - loss: 14063.0591 - KL_divergence: 9.3647
195/200 [============================>.] - ETA: 0s - loss: 14066.2428 - KL_divergence: 9.3650
200/200 [==============================] - 2s 10ms/step - loss: 14063.7674 - KL_divergence: 9.3730 - val_loss: 14213.3064 - val_KL_divergence: 9.5076
Epoch 22/100

  1/200 [..............................] - ETA: 1s - loss: 13789.4629 - KL_divergence: 9.6881
  7/200 [>.............................] - ETA: 1s - loss: 14021.7527 - KL_divergence: 9.1423
 13/200 [>.............................] - ETA: 1s - loss: 13974.6614 - KL_divergence: 9.3396
 19/200 [=>............................] - ETA: 1s - loss: 14015.7920 - KL_divergence: 9.4119
 25/200 [==>...........................] - ETA: 1s - loss: 14066.4391 - KL_divergence: 9.4476
 31/200 [===>..........................] - ETA: 1s - loss: 13961.3787 - KL_divergence: 9.4538
 37/200 [====>.........................] - ETA: 1s - loss: 14053.7028 - KL_divergence: 9.4020
 43/200 [=====>........................] - ETA: 1s - loss: 14079.3785 - KL_divergence: 9.3769
 49/200 [======>.......................] - ETA: 1s - loss: 14073.9290 - KL_divergence: 9.3730
 55/200 [=======>......................] - ETA: 1s - loss: 14032.2325 - KL_divergence: 9.3737
 61/200 [========>.....................] - ETA: 1s - loss: 14021.2750 - KL_divergence: 9.3846
 67/200 [=========>....................] - ETA: 1s - loss: 14020.6742 - KL_divergence: 9.4070
 73/200 [=========>....................] - ETA: 1s - loss: 14063.7603 - KL_divergence: 9.3853
 79/200 [==========>...................] - ETA: 1s - loss: 14036.6965 - KL_divergence: 9.3627
 85/200 [===========>..................] - ETA: 1s - loss: 14035.4906 - KL_divergence: 9.3613
 91/200 [============>.................] - ETA: 0s - loss: 14047.8701 - KL_divergence: 9.3468
 97/200 [=============>................] - ETA: 0s - loss: 14036.0516 - KL_divergence: 9.3788
103/200 [==============>...............] - ETA: 0s - loss: 14044.5414 - KL_divergence: 9.3753
109/200 [===============>..............] - ETA: 0s - loss: 14055.5392 - KL_divergence: 9.3767
116/200 [================>.............] - ETA: 0s - loss: 14074.0887 - KL_divergence: 9.3932
123/200 [=================>............] - ETA: 0s - loss: 14072.9631 - KL_divergence: 9.3978
130/200 [==================>...........] - ETA: 0s - loss: 14084.7794 - KL_divergence: 9.3842
136/200 [===================>..........] - ETA: 0s - loss: 14075.0534 - KL_divergence: 9.3851
143/200 [====================>.........] - ETA: 0s - loss: 14068.4254 - KL_divergence: 9.3800
149/200 [=====================>........] - ETA: 0s - loss: 14066.3547 - KL_divergence: 9.3821
155/200 [======================>.......] - ETA: 0s - loss: 14070.1024 - KL_divergence: 9.3756
161/200 [=======================>......] - ETA: 0s - loss: 14077.5060 - KL_divergence: 9.3676
168/200 [========================>.....] - ETA: 0s - loss: 14050.5833 - KL_divergence: 9.3818
174/200 [=========================>....] - ETA: 0s - loss: 14063.2752 - KL_divergence: 9.3812
180/200 [==========================>...] - ETA: 0s - loss: 14048.9959 - KL_divergence: 9.3787
186/200 [==========================>...] - ETA: 0s - loss: 14031.5836 - KL_divergence: 9.3903
192/200 [===========================>..] - ETA: 0s - loss: 14027.1190 - KL_divergence: 9.3912
198/200 [============================>.] - ETA: 0s - loss: 14025.3817 - KL_divergence: 9.3917
200/200 [==============================] - 2s 10ms/step - loss: 14027.8214 - KL_divergence: 9.3971 - val_loss: 14081.3909 - val_KL_divergence: 9.1948
Epoch 23/100

  1/200 [..............................] - ETA: 1s - loss: 13311.5264 - KL_divergence: 9.2821
  7/200 [>.............................] - ETA: 1s - loss: 13803.3051 - KL_divergence: 9.6039
 13/200 [>.............................] - ETA: 1s - loss: 14020.9917 - KL_divergence: 9.5214
 19/200 [=>............................] - ETA: 1s - loss: 14154.5350 - KL_divergence: 9.4216
 25/200 [==>...........................] - ETA: 1s - loss: 14068.5260 - KL_divergence: 9.4094
 31/200 [===>..........................] - ETA: 1s - loss: 14055.3145 - KL_divergence: 9.4247
 37/200 [====>.........................] - ETA: 1s - loss: 14091.9293 - KL_divergence: 9.3863
 43/200 [=====>........................] - ETA: 1s - loss: 14077.7720 - KL_divergence: 9.3716
 49/200 [======>.......................] - ETA: 1s - loss: 14088.2046 - KL_divergence: 9.3305
 55/200 [=======>......................] - ETA: 1s - loss: 14007.9248 - KL_divergence: 9.3639
 61/200 [========>.....................] - ETA: 1s - loss: 14058.6106 - KL_divergence: 9.3527
 67/200 [=========>....................] - ETA: 1s - loss: 14009.4201 - KL_divergence: 9.3869
 73/200 [=========>....................] - ETA: 1s - loss: 13970.2691 - KL_divergence: 9.3699
 79/200 [==========>...................] - ETA: 1s - loss: 13959.2702 - KL_divergence: 9.3718
 85/200 [===========>..................] - ETA: 1s - loss: 13944.7339 - KL_divergence: 9.3828
 91/200 [============>.................] - ETA: 0s - loss: 13887.4481 - KL_divergence: 9.4121
 97/200 [=============>................] - ETA: 0s - loss: 13894.9463 - KL_divergence: 9.4269
103/200 [==============>...............] - ETA: 0s - loss: 13908.7422 - KL_divergence: 9.4215
109/200 [===============>..............] - ETA: 0s - loss: 13903.6551 - KL_divergence: 9.4216
115/200 [================>.............] - ETA: 0s - loss: 13895.4699 - KL_divergence: 9.4238
121/200 [=================>............] - ETA: 0s - loss: 13896.7959 - KL_divergence: 9.4366
127/200 [==================>...........] - ETA: 0s - loss: 13899.6942 - KL_divergence: 9.4389
133/200 [==================>...........] - ETA: 0s - loss: 13895.8829 - KL_divergence: 9.4461
139/200 [===================>..........] - ETA: 0s - loss: 13897.5760 - KL_divergence: 9.4383
145/200 [====================>.........] - ETA: 0s - loss: 13898.4329 - KL_divergence: 9.4303
151/200 [=====================>........] - ETA: 0s - loss: 13913.2337 - KL_divergence: 9.4299
157/200 [======================>.......] - ETA: 0s - loss: 13891.8101 - KL_divergence: 9.4515
163/200 [=======================>......] - ETA: 0s - loss: 13898.6385 - KL_divergence: 9.4461
169/200 [========================>.....] - ETA: 0s - loss: 13886.9856 - KL_divergence: 9.4449
175/200 [=========================>....] - ETA: 0s - loss: 13891.1247 - KL_divergence: 9.4426
181/200 [==========================>...] - ETA: 0s - loss: 13875.6594 - KL_divergence: 9.4550
187/200 [===========================>..] - ETA: 0s - loss: 13888.9224 - KL_divergence: 9.4613
193/200 [===========================>..] - ETA: 0s - loss: 13887.3056 - KL_divergence: 9.4568
199/200 [============================>.] - ETA: 0s - loss: 13890.5789 - KL_divergence: 9.4532
200/200 [==============================] - 2s 10ms/step - loss: 13888.7768 - KL_divergence: 9.4529 - val_loss: 14284.9842 - val_KL_divergence: 9.3181
Epoch 24/100

  1/200 [..............................] - ETA: 1s - loss: 12909.2939 - KL_divergence: 10.0615
  7/200 [>.............................] - ETA: 1s - loss: 13620.8510 - KL_divergence: 9.5379 
 13/200 [>.............................] - ETA: 1s - loss: 13833.9265 - KL_divergence: 9.5402
 19/200 [=>............................] - ETA: 1s - loss: 13777.8163 - KL_divergence: 9.5305
 25/200 [==>...........................] - ETA: 1s - loss: 13865.2309 - KL_divergence: 9.5330
 31/200 [===>..........................] - ETA: 1s - loss: 13849.7448 - KL_divergence: 9.4964
 37/200 [====>.........................] - ETA: 1s - loss: 13809.6661 - KL_divergence: 9.4547
 43/200 [=====>........................] - ETA: 1s - loss: 13910.4940 - KL_divergence: 9.4258
 49/200 [======>.......................] - ETA: 1s - loss: 13839.9459 - KL_divergence: 9.4703
 55/200 [=======>......................] - ETA: 1s - loss: 13893.3626 - KL_divergence: 9.4295
 61/200 [========>.....................] - ETA: 1s - loss: 13885.7782 - KL_divergence: 9.4477
 67/200 [=========>....................] - ETA: 1s - loss: 13869.0903 - KL_divergence: 9.4591
 73/200 [=========>....................] - ETA: 1s - loss: 13837.5226 - KL_divergence: 9.4741
 79/200 [==========>...................] - ETA: 1s - loss: 13806.4964 - KL_divergence: 9.4662
 85/200 [===========>..................] - ETA: 1s - loss: 13801.4448 - KL_divergence: 9.4612
 91/200 [============>.................] - ETA: 0s - loss: 13836.6796 - KL_divergence: 9.4214
 97/200 [=============>................] - ETA: 0s - loss: 13841.8064 - KL_divergence: 9.4128
103/200 [==============>...............] - ETA: 0s - loss: 13839.5357 - KL_divergence: 9.4193
109/200 [===============>..............] - ETA: 0s - loss: 13847.5665 - KL_divergence: 9.4147
115/200 [================>.............] - ETA: 0s - loss: 13844.0847 - KL_divergence: 9.4095
121/200 [=================>............] - ETA: 0s - loss: 13839.8558 - KL_divergence: 9.4157
127/200 [==================>...........] - ETA: 0s - loss: 13864.7162 - KL_divergence: 9.3996
133/200 [==================>...........] - ETA: 0s - loss: 13862.1433 - KL_divergence: 9.4050
139/200 [===================>..........] - ETA: 0s - loss: 13883.5157 - KL_divergence: 9.3907
145/200 [====================>.........] - ETA: 0s - loss: 13894.8256 - KL_divergence: 9.3766
151/200 [=====================>........] - ETA: 0s - loss: 13872.9248 - KL_divergence: 9.3879
157/200 [======================>.......] - ETA: 0s - loss: 13874.8099 - KL_divergence: 9.3882
163/200 [=======================>......] - ETA: 0s - loss: 13865.7070 - KL_divergence: 9.3968
169/200 [========================>.....] - ETA: 0s - loss: 13875.9549 - KL_divergence: 9.3783
175/200 [=========================>....] - ETA: 0s - loss: 13865.3959 - KL_divergence: 9.3750
181/200 [==========================>...] - ETA: 0s - loss: 13861.2484 - KL_divergence: 9.3776
187/200 [===========================>..] - ETA: 0s - loss: 13874.7795 - KL_divergence: 9.3705
193/200 [===========================>..] - ETA: 0s - loss: 13870.5446 - KL_divergence: 9.3676
199/200 [============================>.] - ETA: 0s - loss: 13876.8546 - KL_divergence: 9.3708
200/200 [==============================] - 2s 10ms/step - loss: 13873.6367 - KL_divergence: 9.3752 - val_loss: 14023.5142 - val_KL_divergence: 8.7301
Epoch 25/100

  1/200 [..............................] - ETA: 1s - loss: 12608.9023 - KL_divergence: 9.5950
  7/200 [>.............................] - ETA: 1s - loss: 13343.9824 - KL_divergence: 9.4798
 13/200 [>.............................] - ETA: 1s - loss: 13745.3804 - KL_divergence: 9.3306
 19/200 [=>............................] - ETA: 1s - loss: 13817.9057 - KL_divergence: 9.3522
 25/200 [==>...........................] - ETA: 1s - loss: 13887.7280 - KL_divergence: 9.3724
 31/200 [===>..........................] - ETA: 1s - loss: 13857.2691 - KL_divergence: 9.4124
 37/200 [====>.........................] - ETA: 1s - loss: 13884.5571 - KL_divergence: 9.4200
 43/200 [=====>........................] - ETA: 1s - loss: 13930.7188 - KL_divergence: 9.4005
 49/200 [======>.......................] - ETA: 1s - loss: 13889.8810 - KL_divergence: 9.3948
 55/200 [=======>......................] - ETA: 1s - loss: 13887.4757 - KL_divergence: 9.3816
 61/200 [========>.....................] - ETA: 1s - loss: 13875.9423 - KL_divergence: 9.3820
 67/200 [=========>....................] - ETA: 1s - loss: 13882.7971 - KL_divergence: 9.4044
 73/200 [=========>....................] - ETA: 1s - loss: 13802.0316 - KL_divergence: 9.4390
 79/200 [==========>...................] - ETA: 1s - loss: 13799.7547 - KL_divergence: 9.4573
 85/200 [===========>..................] - ETA: 1s - loss: 13787.3640 - KL_divergence: 9.4641
 91/200 [============>.................] - ETA: 1s - loss: 13767.8511 - KL_divergence: 9.4723
 97/200 [=============>................] - ETA: 0s - loss: 13740.7511 - KL_divergence: 9.4921
103/200 [==============>...............] - ETA: 0s - loss: 13760.3058 - KL_divergence: 9.4697
109/200 [===============>..............] - ETA: 0s - loss: 13768.9538 - KL_divergence: 9.4694
115/200 [================>.............] - ETA: 0s - loss: 13756.5649 - KL_divergence: 9.4763
121/200 [=================>............] - ETA: 0s - loss: 13753.4831 - KL_divergence: 9.4764
127/200 [==================>...........] - ETA: 0s - loss: 13739.1123 - KL_divergence: 9.4827
133/200 [==================>...........] - ETA: 0s - loss: 13755.7584 - KL_divergence: 9.4805
139/200 [===================>..........] - ETA: 0s - loss: 13736.9897 - KL_divergence: 9.4780
145/200 [====================>.........] - ETA: 0s - loss: 13736.6856 - KL_divergence: 9.4737
151/200 [=====================>........] - ETA: 0s - loss: 13723.7470 - KL_divergence: 9.4657
157/200 [======================>.......] - ETA: 0s - loss: 13703.4733 - KL_divergence: 9.4644
163/200 [=======================>......] - ETA: 0s - loss: 13697.9893 - KL_divergence: 9.4616
169/200 [========================>.....] - ETA: 0s - loss: 13718.1070 - KL_divergence: 9.4450
175/200 [=========================>....] - ETA: 0s - loss: 13723.7170 - KL_divergence: 9.4264
181/200 [==========================>...] - ETA: 0s - loss: 13721.7571 - KL_divergence: 9.4119
187/200 [===========================>..] - ETA: 0s - loss: 13733.0217 - KL_divergence: 9.4059
193/200 [===========================>..] - ETA: 0s - loss: 13742.8947 - KL_divergence: 9.4016
200/200 [==============================] - 2s 10ms/step - loss: 13726.2551 - KL_divergence: 9.3956 - val_loss: 13878.4662 - val_KL_divergence: 9.2695
Epoch 26/100

  1/200 [..............................] - ETA: 1s - loss: 13068.5889 - KL_divergence: 9.6924
  7/200 [>.............................] - ETA: 1s - loss: 13445.2238 - KL_divergence: 9.2886
 13/200 [>.............................] - ETA: 1s - loss: 13748.2783 - KL_divergence: 9.1295
 19/200 [=>............................] - ETA: 1s - loss: 13966.2721 - KL_divergence: 9.1611
 25/200 [==>...........................] - ETA: 1s - loss: 13869.4034 - KL_divergence: 9.1958
 31/200 [===>..........................] - ETA: 1s - loss: 13781.5284 - KL_divergence: 9.2178
 37/200 [====>.........................] - ETA: 1s - loss: 13721.9783 - KL_divergence: 9.2879
 44/200 [=====>........................] - ETA: 1s - loss: 13719.5434 - KL_divergence: 9.2825
 50/200 [======>.......................] - ETA: 1s - loss: 13701.3227 - KL_divergence: 9.3029
 57/200 [=======>......................] - ETA: 1s - loss: 13661.7845 - KL_divergence: 9.3046
 63/200 [========>.....................] - ETA: 1s - loss: 13685.5296 - KL_divergence: 9.2647
 69/200 [=========>....................] - ETA: 1s - loss: 13683.3783 - KL_divergence: 9.2887
 75/200 [==========>...................] - ETA: 1s - loss: 13677.6031 - KL_divergence: 9.2823
 81/200 [===========>..................] - ETA: 1s - loss: 13683.6835 - KL_divergence: 9.2649
 87/200 [============>.................] - ETA: 0s - loss: 13714.7920 - KL_divergence: 9.2273
 93/200 [============>.................] - ETA: 0s - loss: 13723.6433 - KL_divergence: 9.2330
 99/200 [=============>................] - ETA: 0s - loss: 13734.2163 - KL_divergence: 9.2318
105/200 [==============>...............] - ETA: 0s - loss: 13710.3641 - KL_divergence: 9.2351
111/200 [===============>..............] - ETA: 0s - loss: 13702.3028 - KL_divergence: 9.2319
117/200 [================>.............] - ETA: 0s - loss: 13693.6233 - KL_divergence: 9.2376
123/200 [=================>............] - ETA: 0s - loss: 13684.0769 - KL_divergence: 9.2521
129/200 [==================>...........] - ETA: 0s - loss: 13684.8269 - KL_divergence: 9.2612
135/200 [===================>..........] - ETA: 0s - loss: 13698.4253 - KL_divergence: 9.2500
140/200 [====================>.........] - ETA: 0s - loss: 13716.8920 - KL_divergence: 9.2480
146/200 [====================>.........] - ETA: 0s - loss: 13727.9444 - KL_divergence: 9.2433
152/200 [=====================>........] - ETA: 0s - loss: 13740.3015 - KL_divergence: 9.2486
158/200 [======================>.......] - ETA: 0s - loss: 13735.7250 - KL_divergence: 9.2544
164/200 [=======================>......] - ETA: 0s - loss: 13747.3415 - KL_divergence: 9.2440
170/200 [========================>.....] - ETA: 0s - loss: 13753.1445 - KL_divergence: 9.2456
176/200 [=========================>....] - ETA: 0s - loss: 13767.8410 - KL_divergence: 9.2410
182/200 [==========================>...] - ETA: 0s - loss: 13754.7008 - KL_divergence: 9.2485
188/200 [===========================>..] - ETA: 0s - loss: 13739.2427 - KL_divergence: 9.2537
194/200 [============================>.] - ETA: 0s - loss: 13745.1313 - KL_divergence: 9.2509
200/200 [==============================] - 2s 10ms/step - loss: 13741.9693 - KL_divergence: 9.2527 - val_loss: 13909.4721 - val_KL_divergence: 9.3221
Epoch 27/100

  1/200 [..............................] - ETA: 1s - loss: 14761.2178 - KL_divergence: 9.7858
  7/200 [>.............................] - ETA: 1s - loss: 14047.3753 - KL_divergence: 9.4176
 13/200 [>.............................] - ETA: 1s - loss: 13896.9908 - KL_divergence: 9.4469
 19/200 [=>............................] - ETA: 1s - loss: 13714.9532 - KL_divergence: 9.3320
 25/200 [==>...........................] - ETA: 1s - loss: 13668.1587 - KL_divergence: 9.3101
 31/200 [===>..........................] - ETA: 1s - loss: 13735.3916 - KL_divergence: 9.2693
 37/200 [====>.........................] - ETA: 1s - loss: 13735.6645 - KL_divergence: 9.2829
 43/200 [=====>........................] - ETA: 1s - loss: 13707.5041 - KL_divergence: 9.2981
 49/200 [======>.......................] - ETA: 1s - loss: 13777.8524 - KL_divergence: 9.2815
 55/200 [=======>......................] - ETA: 1s - loss: 13777.6873 - KL_divergence: 9.2811
 61/200 [========>.....................] - ETA: 1s - loss: 13792.4237 - KL_divergence: 9.2810
 67/200 [=========>....................] - ETA: 1s - loss: 13784.4376 - KL_divergence: 9.2735
 73/200 [=========>....................] - ETA: 1s - loss: 13748.1131 - KL_divergence: 9.2914
 79/200 [==========>...................] - ETA: 1s - loss: 13715.8485 - KL_divergence: 9.2881
 85/200 [===========>..................] - ETA: 1s - loss: 13711.9254 - KL_divergence: 9.2822
 91/200 [============>.................] - ETA: 0s - loss: 13709.1933 - KL_divergence: 9.2740
 97/200 [=============>................] - ETA: 0s - loss: 13741.2350 - KL_divergence: 9.2639
103/200 [==============>...............] - ETA: 0s - loss: 13748.9864 - KL_divergence: 9.2705
109/200 [===============>..............] - ETA: 0s - loss: 13758.7206 - KL_divergence: 9.2591
115/200 [================>.............] - ETA: 0s - loss: 13762.9483 - KL_divergence: 9.2565
121/200 [=================>............] - ETA: 0s - loss: 13775.5054 - KL_divergence: 9.2561
127/200 [==================>...........] - ETA: 0s - loss: 13780.6536 - KL_divergence: 9.2469
133/200 [==================>...........] - ETA: 0s - loss: 13780.6389 - KL_divergence: 9.2435
139/200 [===================>..........] - ETA: 0s - loss: 13749.2998 - KL_divergence: 9.2453
145/200 [====================>.........] - ETA: 0s - loss: 13754.0262 - KL_divergence: 9.2440
151/200 [=====================>........] - ETA: 0s - loss: 13757.3177 - KL_divergence: 9.2428
156/200 [======================>.......] - ETA: 0s - loss: 13762.0954 - KL_divergence: 9.2391
162/200 [=======================>......] - ETA: 0s - loss: 13758.3423 - KL_divergence: 9.2414
168/200 [========================>.....] - ETA: 0s - loss: 13759.5504 - KL_divergence: 9.2387
174/200 [=========================>....] - ETA: 0s - loss: 13760.8752 - KL_divergence: 9.2336
180/200 [==========================>...] - ETA: 0s - loss: 13762.3764 - KL_divergence: 9.2319
186/200 [==========================>...] - ETA: 0s - loss: 13753.4456 - KL_divergence: 9.2323
192/200 [===========================>..] - ETA: 0s - loss: 13745.6390 - KL_divergence: 9.2331
198/200 [============================>.] - ETA: 0s - loss: 13745.5140 - KL_divergence: 9.2347
200/200 [==============================] - 2s 10ms/step - loss: 13755.8148 - KL_divergence: 9.2330 - val_loss: 13798.1978 - val_KL_divergence: 8.9278
Epoch 28/100

  1/200 [..............................] - ETA: 1s - loss: 13585.4873 - KL_divergence: 8.3670
  7/200 [>.............................] - ETA: 1s - loss: 14456.0526 - KL_divergence: 9.0200
 13/200 [>.............................] - ETA: 1s - loss: 14238.1209 - KL_divergence: 9.0750
 19/200 [=>............................] - ETA: 1s - loss: 14180.1238 - KL_divergence: 9.0776
 25/200 [==>...........................] - ETA: 1s - loss: 13941.8109 - KL_divergence: 9.1741
 31/200 [===>..........................] - ETA: 1s - loss: 13846.3854 - KL_divergence: 9.1808
 37/200 [====>.........................] - ETA: 1s - loss: 13756.6059 - KL_divergence: 9.2079
 43/200 [=====>........................] - ETA: 1s - loss: 13770.4652 - KL_divergence: 9.2336
 49/200 [======>.......................] - ETA: 1s - loss: 13718.4975 - KL_divergence: 9.2315
 55/200 [=======>......................] - ETA: 1s - loss: 13740.5947 - KL_divergence: 9.2188
 61/200 [========>.....................] - ETA: 1s - loss: 13678.9990 - KL_divergence: 9.2193
 67/200 [=========>....................] - ETA: 1s - loss: 13686.6751 - KL_divergence: 9.2252
 73/200 [=========>....................] - ETA: 1s - loss: 13727.4467 - KL_divergence: 9.2262
 79/200 [==========>...................] - ETA: 1s - loss: 13710.4913 - KL_divergence: 9.2437
 84/200 [===========>..................] - ETA: 1s - loss: 13686.4747 - KL_divergence: 9.2498
 90/200 [============>.................] - ETA: 1s - loss: 13684.0152 - KL_divergence: 9.2726
 96/200 [=============>................] - ETA: 0s - loss: 13643.0269 - KL_divergence: 9.2795
102/200 [==============>...............] - ETA: 0s - loss: 13638.4923 - KL_divergence: 9.2828
108/200 [===============>..............] - ETA: 0s - loss: 13641.5763 - KL_divergence: 9.2935
114/200 [================>.............] - ETA: 0s - loss: 13636.1276 - KL_divergence: 9.3008
120/200 [=================>............] - ETA: 0s - loss: 13631.9111 - KL_divergence: 9.3097
126/200 [=================>............] - ETA: 0s - loss: 13619.2986 - KL_divergence: 9.3156
132/200 [==================>...........] - ETA: 0s - loss: 13592.7716 - KL_divergence: 9.3329
138/200 [===================>..........] - ETA: 0s - loss: 13587.3056 - KL_divergence: 9.3316
143/200 [====================>.........] - ETA: 0s - loss: 13586.3167 - KL_divergence: 9.3406
148/200 [=====================>........] - ETA: 0s - loss: 13599.2231 - KL_divergence: 9.3333
154/200 [======================>.......] - ETA: 0s - loss: 13603.2715 - KL_divergence: 9.3254
160/200 [=======================>......] - ETA: 0s - loss: 13611.5610 - KL_divergence: 9.3256
165/200 [=======================>......] - ETA: 0s - loss: 13606.8621 - KL_divergence: 9.3303
171/200 [========================>.....] - ETA: 0s - loss: 13605.2408 - KL_divergence: 9.3270
177/200 [=========================>....] - ETA: 0s - loss: 13621.1382 - KL_divergence: 9.3206
183/200 [==========================>...] - ETA: 0s - loss: 13602.2729 - KL_divergence: 9.3247
189/200 [===========================>..] - ETA: 0s - loss: 13601.9219 - KL_divergence: 9.3224
195/200 [============================>.] - ETA: 0s - loss: 13588.9817 - KL_divergence: 9.3217
200/200 [==============================] - 2s 10ms/step - loss: 13602.8051 - KL_divergence: 9.3100 - val_loss: 13757.3167 - val_KL_divergence: 9.0138
Epoch 29/100

  1/200 [..............................] - ETA: 1s - loss: 13705.6621 - KL_divergence: 9.1067
  7/200 [>.............................] - ETA: 1s - loss: 13375.7972 - KL_divergence: 9.2637
 13/200 [>.............................] - ETA: 1s - loss: 13277.4969 - KL_divergence: 9.3400
 19/200 [=>............................] - ETA: 1s - loss: 13536.2253 - KL_divergence: 9.2950
 25/200 [==>...........................] - ETA: 1s - loss: 13415.0977 - KL_divergence: 9.2698
 31/200 [===>..........................] - ETA: 1s - loss: 13507.1137 - KL_divergence: 9.2685
 37/200 [====>.........................] - ETA: 1s - loss: 13581.3132 - KL_divergence: 9.2148
 43/200 [=====>........................] - ETA: 1s - loss: 13617.0583 - KL_divergence: 9.2101
 49/200 [======>.......................] - ETA: 1s - loss: 13615.6289 - KL_divergence: 9.1857
 55/200 [=======>......................] - ETA: 1s - loss: 13657.4672 - KL_divergence: 9.1974
 61/200 [========>.....................] - ETA: 1s - loss: 13627.4082 - KL_divergence: 9.2053
 67/200 [=========>....................] - ETA: 1s - loss: 13627.6938 - KL_divergence: 9.2218
 73/200 [=========>....................] - ETA: 1s - loss: 13622.3252 - KL_divergence: 9.2384
 79/200 [==========>...................] - ETA: 1s - loss: 13609.0914 - KL_divergence: 9.2448
 85/200 [===========>..................] - ETA: 1s - loss: 13593.8840 - KL_divergence: 9.2515
 91/200 [============>.................] - ETA: 1s - loss: 13600.9395 - KL_divergence: 9.2393
 97/200 [=============>................] - ETA: 0s - loss: 13589.2956 - KL_divergence: 9.2353
103/200 [==============>...............] - ETA: 0s - loss: 13577.8823 - KL_divergence: 9.2514
109/200 [===============>..............] - ETA: 0s - loss: 13594.2068 - KL_divergence: 9.2532
115/200 [================>.............] - ETA: 0s - loss: 13586.8240 - KL_divergence: 9.2433
121/200 [=================>............] - ETA: 0s - loss: 13608.3663 - KL_divergence: 9.2305
127/200 [==================>...........] - ETA: 0s - loss: 13603.8177 - KL_divergence: 9.2239
133/200 [==================>...........] - ETA: 0s - loss: 13597.0515 - KL_divergence: 9.2258
139/200 [===================>..........] - ETA: 0s - loss: 13613.7072 - KL_divergence: 9.2230
145/200 [====================>.........] - ETA: 0s - loss: 13620.1967 - KL_divergence: 9.2177
151/200 [=====================>........] - ETA: 0s - loss: 13607.2555 - KL_divergence: 9.2232
157/200 [======================>.......] - ETA: 0s - loss: 13628.1063 - KL_divergence: 9.2280
164/200 [=======================>......] - ETA: 0s - loss: 13620.1390 - KL_divergence: 9.2275
170/200 [========================>.....] - ETA: 0s - loss: 13612.3469 - KL_divergence: 9.2304
176/200 [=========================>....] - ETA: 0s - loss: 13639.8455 - KL_divergence: 9.2264
182/200 [==========================>...] - ETA: 0s - loss: 13655.3317 - KL_divergence: 9.2198
188/200 [===========================>..] - ETA: 0s - loss: 13663.1624 - KL_divergence: 9.2234
194/200 [============================>.] - ETA: 0s - loss: 13655.3651 - KL_divergence: 9.2227
200/200 [==============================] - 2s 10ms/step - loss: 13650.5953 - KL_divergence: 9.2178 - val_loss: 13714.7516 - val_KL_divergence: 8.9268
Epoch 30/100

  1/200 [..............................] - ETA: 1s - loss: 14835.0352 - KL_divergence: 8.3186
  7/200 [>.............................] - ETA: 1s - loss: 14053.8500 - KL_divergence: 9.1109
 13/200 [>.............................] - ETA: 1s - loss: 13686.1324 - KL_divergence: 9.0755
 19/200 [=>............................] - ETA: 1s - loss: 13814.7432 - KL_divergence: 9.0766
 25/200 [==>...........................] - ETA: 1s - loss: 13727.2853 - KL_divergence: 9.0667
 31/200 [===>..........................] - ETA: 1s - loss: 13653.1454 - KL_divergence: 9.0846
 37/200 [====>.........................] - ETA: 1s - loss: 13621.3052 - KL_divergence: 9.1019
 43/200 [=====>........................] - ETA: 1s - loss: 13645.2488 - KL_divergence: 9.0784
 49/200 [======>.......................] - ETA: 1s - loss: 13586.7949 - KL_divergence: 9.1008
 55/200 [=======>......................] - ETA: 1s - loss: 13559.5625 - KL_divergence: 9.1253
 61/200 [========>.....................] - ETA: 1s - loss: 13563.3113 - KL_divergence: 9.1406
 67/200 [=========>....................] - ETA: 1s - loss: 13558.7414 - KL_divergence: 9.1541
 73/200 [=========>....................] - ETA: 1s - loss: 13602.6025 - KL_divergence: 9.1384
 79/200 [==========>...................] - ETA: 1s - loss: 13607.2475 - KL_divergence: 9.1307
 85/200 [===========>..................] - ETA: 1s - loss: 13578.4712 - KL_divergence: 9.1567
 91/200 [============>.................] - ETA: 0s - loss: 13578.5055 - KL_divergence: 9.1375
 97/200 [=============>................] - ETA: 0s - loss: 13554.9435 - KL_divergence: 9.1611
103/200 [==============>...............] - ETA: 0s - loss: 13557.9400 - KL_divergence: 9.1329
109/200 [===============>..............] - ETA: 0s - loss: 13559.0929 - KL_divergence: 9.1313
115/200 [================>.............] - ETA: 0s - loss: 13533.9527 - KL_divergence: 9.1335
121/200 [=================>............] - ETA: 0s - loss: 13535.0105 - KL_divergence: 9.1146
127/200 [==================>...........] - ETA: 0s - loss: 13546.1083 - KL_divergence: 9.1038
133/200 [==================>...........] - ETA: 0s - loss: 13538.6352 - KL_divergence: 9.1067
139/200 [===================>..........] - ETA: 0s - loss: 13535.5034 - KL_divergence: 9.1025
145/200 [====================>.........] - ETA: 0s - loss: 13529.8545 - KL_divergence: 9.0999
151/200 [=====================>........] - ETA: 0s - loss: 13509.4814 - KL_divergence: 9.0907
156/200 [======================>.......] - ETA: 0s - loss: 13526.8327 - KL_divergence: 9.0853
162/200 [=======================>......] - ETA: 0s - loss: 13519.1179 - KL_divergence: 9.0863
168/200 [========================>.....] - ETA: 0s - loss: 13529.3888 - KL_divergence: 9.0773
174/200 [=========================>....] - ETA: 0s - loss: 13521.6122 - KL_divergence: 9.0723
180/200 [==========================>...] - ETA: 0s - loss: 13526.9750 - KL_divergence: 9.0687
187/200 [===========================>..] - ETA: 0s - loss: 13517.8684 - KL_divergence: 9.0795
193/200 [===========================>..] - ETA: 0s - loss: 13514.1110 - KL_divergence: 9.0903
199/200 [============================>.] - ETA: 0s - loss: 13518.4908 - KL_divergence: 9.0926
200/200 [==============================] - 2s 10ms/step - loss: 13517.9999 - KL_divergence: 9.0910 - val_loss: 13787.8708 - val_KL_divergence: 9.1707
Epoch 31/100

  1/200 [..............................] - ETA: 1s - loss: 14738.7676 - KL_divergence: 8.6297
  8/200 [>.............................] - ETA: 1s - loss: 13420.9120 - KL_divergence: 9.1455
 15/200 [=>............................] - ETA: 1s - loss: 13579.6617 - KL_divergence: 9.0790
 21/200 [==>...........................] - ETA: 1s - loss: 13557.7720 - KL_divergence: 8.9959
 27/200 [===>..........................] - ETA: 1s - loss: 13604.2583 - KL_divergence: 8.9853
 34/200 [====>.........................] - ETA: 1s - loss: 13667.1560 - KL_divergence: 8.9728
 41/200 [=====>........................] - ETA: 1s - loss: 13621.5830 - KL_divergence: 8.9916
 47/200 [======>.......................] - ETA: 1s - loss: 13637.0224 - KL_divergence: 9.0023
 53/200 [======>.......................] - ETA: 1s - loss: 13594.5834 - KL_divergence: 9.0305
 59/200 [=======>......................] - ETA: 1s - loss: 13591.5180 - KL_divergence: 9.0259
 65/200 [========>.....................] - ETA: 1s - loss: 13609.1699 - KL_divergence: 9.0092
 71/200 [=========>....................] - ETA: 1s - loss: 13562.8161 - KL_divergence: 9.0197
 77/200 [==========>...................] - ETA: 1s - loss: 13571.5679 - KL_divergence: 9.0225
 83/200 [===========>..................] - ETA: 1s - loss: 13583.2139 - KL_divergence: 9.0218
 89/200 [============>.................] - ETA: 0s - loss: 13583.3861 - KL_divergence: 9.0270
 96/200 [=============>................] - ETA: 0s - loss: 13551.2447 - KL_divergence: 9.0331
102/200 [==============>...............] - ETA: 0s - loss: 13561.1529 - KL_divergence: 9.0313
108/200 [===============>..............] - ETA: 0s - loss: 13570.0741 - KL_divergence: 9.0240
114/200 [================>.............] - ETA: 0s - loss: 13527.6753 - KL_divergence: 9.0317
120/200 [=================>............] - ETA: 0s - loss: 13509.8538 - KL_divergence: 9.0324
126/200 [=================>............] - ETA: 0s - loss: 13507.5225 - KL_divergence: 9.0292
132/200 [==================>...........] - ETA: 0s - loss: 13502.5327 - KL_divergence: 9.0371
138/200 [===================>..........] - ETA: 0s - loss: 13466.3121 - KL_divergence: 9.0433
144/200 [====================>.........] - ETA: 0s - loss: 13441.2072 - KL_divergence: 9.0586
150/200 [=====================>........] - ETA: 0s - loss: 13445.2802 - KL_divergence: 9.0485
156/200 [======================>.......] - ETA: 0s - loss: 13433.1423 - KL_divergence: 9.0513
162/200 [=======================>......] - ETA: 0s - loss: 13412.6137 - KL_divergence: 9.0574
168/200 [========================>.....] - ETA: 0s - loss: 13415.5251 - KL_divergence: 9.0604
174/200 [=========================>....] - ETA: 0s - loss: 13423.1598 - KL_divergence: 9.0649
180/200 [==========================>...] - ETA: 0s - loss: 13421.7222 - KL_divergence: 9.0623
186/200 [==========================>...] - ETA: 0s - loss: 13445.3277 - KL_divergence: 9.0543
192/200 [===========================>..] - ETA: 0s - loss: 13457.5525 - KL_divergence: 9.0514
198/200 [============================>.] - ETA: 0s - loss: 13463.8576 - KL_divergence: 9.0537
200/200 [==============================] - 2s 10ms/step - loss: 13453.3018 - KL_divergence: 9.0563 - val_loss: 13788.5494 - val_KL_divergence: 9.1139
Epoch 32/100

  1/200 [..............................] - ETA: 1s - loss: 13931.0908 - KL_divergence: 9.3469
  7/200 [>.............................] - ETA: 1s - loss: 13482.9348 - KL_divergence: 9.0632
 13/200 [>.............................] - ETA: 1s - loss: 13377.5367 - KL_divergence: 9.1319
 19/200 [=>............................] - ETA: 1s - loss: 13389.6473 - KL_divergence: 9.1481
 25/200 [==>...........................] - ETA: 1s - loss: 13399.4201 - KL_divergence: 9.1167
 31/200 [===>..........................] - ETA: 1s - loss: 13459.6687 - KL_divergence: 9.0917
 37/200 [====>.........................] - ETA: 1s - loss: 13474.1809 - KL_divergence: 9.0667
 43/200 [=====>........................] - ETA: 1s - loss: 13523.7770 - KL_divergence: 9.0378
 49/200 [======>.......................] - ETA: 1s - loss: 13483.1383 - KL_divergence: 9.0256
 56/200 [=======>......................] - ETA: 1s - loss: 13427.1337 - KL_divergence: 9.0483
 62/200 [========>.....................] - ETA: 1s - loss: 13441.1768 - KL_divergence: 9.0328
 69/200 [=========>....................] - ETA: 1s - loss: 13436.4517 - KL_divergence: 9.0440
 75/200 [==========>...................] - ETA: 1s - loss: 13447.2179 - KL_divergence: 9.0396
 81/200 [===========>..................] - ETA: 1s - loss: 13414.2730 - KL_divergence: 9.0696
 87/200 [============>.................] - ETA: 0s - loss: 13409.0646 - KL_divergence: 9.0732
 93/200 [============>.................] - ETA: 0s - loss: 13407.9768 - KL_divergence: 9.0789
 99/200 [=============>................] - ETA: 0s - loss: 13391.6673 - KL_divergence: 9.0854
105/200 [==============>...............] - ETA: 0s - loss: 13409.6665 - KL_divergence: 9.0878
111/200 [===============>..............] - ETA: 0s - loss: 13415.1754 - KL_divergence: 9.0840
117/200 [================>.............] - ETA: 0s - loss: 13416.4667 - KL_divergence: 9.0795
123/200 [=================>............] - ETA: 0s - loss: 13425.9618 - KL_divergence: 9.0798
129/200 [==================>...........] - ETA: 0s - loss: 13432.2079 - KL_divergence: 9.0744
136/200 [===================>..........] - ETA: 0s - loss: 13420.1207 - KL_divergence: 9.0843
142/200 [====================>.........] - ETA: 0s - loss: 13430.1716 - KL_divergence: 9.0942
149/200 [=====================>........] - ETA: 0s - loss: 13458.2924 - KL_divergence: 9.0896
155/200 [======================>.......] - ETA: 0s - loss: 13430.2429 - KL_divergence: 9.1005
161/200 [=======================>......] - ETA: 0s - loss: 13418.7130 - KL_divergence: 9.1009
167/200 [========================>.....] - ETA: 0s - loss: 13417.6009 - KL_divergence: 9.0938
174/200 [=========================>....] - ETA: 0s - loss: 13420.6299 - KL_divergence: 9.0958
181/200 [==========================>...] - ETA: 0s - loss: 13411.8517 - KL_divergence: 9.0949
188/200 [===========================>..] - ETA: 0s - loss: 13396.4603 - KL_divergence: 9.0864
194/200 [============================>.] - ETA: 0s - loss: 13394.2613 - KL_divergence: 9.0839
200/200 [==============================] - 2s 10ms/step - loss: 13411.8963 - KL_divergence: 9.0731 - val_loss: 13637.1155 - val_KL_divergence: 9.1695
Epoch 33/100

  1/200 [..............................] - ETA: 1s - loss: 12966.5000 - KL_divergence: 9.6548
  7/200 [>.............................] - ETA: 1s - loss: 13584.6437 - KL_divergence: 9.0227
 13/200 [>.............................] - ETA: 1s - loss: 13661.0377 - KL_divergence: 8.9883
 19/200 [=>............................] - ETA: 1s - loss: 13593.7312 - KL_divergence: 8.9989
 26/200 [==>...........................] - ETA: 1s - loss: 13515.9425 - KL_divergence: 9.0022
 32/200 [===>..........................] - ETA: 1s - loss: 13409.8382 - KL_divergence: 9.0694
 38/200 [====>.........................] - ETA: 1s - loss: 13345.6310 - KL_divergence: 9.0869
 44/200 [=====>........................] - ETA: 1s - loss: 13391.2759 - KL_divergence: 9.0706
 50/200 [======>.......................] - ETA: 1s - loss: 13383.6676 - KL_divergence: 9.0940
 56/200 [=======>......................] - ETA: 1s - loss: 13388.2612 - KL_divergence: 9.1192
 63/200 [========>.....................] - ETA: 1s - loss: 13435.3002 - KL_divergence: 9.0867
 69/200 [=========>....................] - ETA: 1s - loss: 13402.3637 - KL_divergence: 9.0742
 75/200 [==========>...................] - ETA: 1s - loss: 13386.2500 - KL_divergence: 9.0654
 81/200 [===========>..................] - ETA: 1s - loss: 13390.7521 - KL_divergence: 9.0533
 87/200 [============>.................] - ETA: 0s - loss: 13394.5199 - KL_divergence: 9.0463
 93/200 [============>.................] - ETA: 0s - loss: 13417.0288 - KL_divergence: 9.0351
 99/200 [=============>................] - ETA: 0s - loss: 13402.7239 - KL_divergence: 9.0342
105/200 [==============>...............] - ETA: 0s - loss: 13424.8555 - KL_divergence: 9.0298
110/200 [===============>..............] - ETA: 0s - loss: 13412.3288 - KL_divergence: 9.0359
116/200 [================>.............] - ETA: 0s - loss: 13411.1193 - KL_divergence: 9.0469
122/200 [=================>............] - ETA: 0s - loss: 13420.1045 - KL_divergence: 9.0437
128/200 [==================>...........] - ETA: 0s - loss: 13406.5279 - KL_divergence: 9.0475
134/200 [===================>..........] - ETA: 0s - loss: 13413.5906 - KL_divergence: 9.0304
140/200 [====================>.........] - ETA: 0s - loss: 13411.9112 - KL_divergence: 9.0214
146/200 [====================>.........] - ETA: 0s - loss: 13409.9834 - KL_divergence: 9.0278
152/200 [=====================>........] - ETA: 0s - loss: 13422.6751 - KL_divergence: 9.0219
158/200 [======================>.......] - ETA: 0s - loss: 13433.3876 - KL_divergence: 9.0138
164/200 [=======================>......] - ETA: 0s - loss: 13439.4138 - KL_divergence: 9.0135
170/200 [========================>.....] - ETA: 0s - loss: 13451.9000 - KL_divergence: 9.0182
176/200 [=========================>....] - ETA: 0s - loss: 13458.7600 - KL_divergence: 9.0140
182/200 [==========================>...] - ETA: 0s - loss: 13467.2966 - KL_divergence: 9.0086
188/200 [===========================>..] - ETA: 0s - loss: 13484.5200 - KL_divergence: 9.0039
194/200 [============================>.] - ETA: 0s - loss: 13486.5070 - KL_divergence: 8.9981
200/200 [==============================] - 2s 10ms/step - loss: 13485.6653 - KL_divergence: 9.0023 - val_loss: 13500.6665 - val_KL_divergence: 8.6838
Epoch 34/100

  1/200 [..............................] - ETA: 1s - loss: 13338.4883 - KL_divergence: 8.6273
  7/200 [>.............................] - ETA: 1s - loss: 13161.8597 - KL_divergence: 9.1059
 13/200 [>.............................] - ETA: 1s - loss: 13020.4980 - KL_divergence: 9.2462
 19/200 [=>............................] - ETA: 1s - loss: 13130.4947 - KL_divergence: 9.1712
 26/200 [==>...........................] - ETA: 1s - loss: 13108.1533 - KL_divergence: 9.0962
 33/200 [===>..........................] - ETA: 1s - loss: 13114.3917 - KL_divergence: 9.1062
 39/200 [====>.........................] - ETA: 1s - loss: 13131.4348 - KL_divergence: 9.0868
 45/200 [=====>........................] - ETA: 1s - loss: 13154.6971 - KL_divergence: 9.0702
 51/200 [======>.......................] - ETA: 1s - loss: 13160.7961 - KL_divergence: 9.0572
 57/200 [=======>......................] - ETA: 1s - loss: 13169.7159 - KL_divergence: 9.0740
 63/200 [========>.....................] - ETA: 1s - loss: 13237.4608 - KL_divergence: 9.0253
 69/200 [=========>....................] - ETA: 1s - loss: 13251.0190 - KL_divergence: 9.0095
 75/200 [==========>...................] - ETA: 1s - loss: 13240.2450 - KL_divergence: 9.0328
 81/200 [===========>..................] - ETA: 1s - loss: 13281.9011 - KL_divergence: 9.0070
 87/200 [============>.................] - ETA: 0s - loss: 13288.9656 - KL_divergence: 9.0114
 93/200 [============>.................] - ETA: 0s - loss: 13302.8814 - KL_divergence: 8.9962
 99/200 [=============>................] - ETA: 0s - loss: 13316.8167 - KL_divergence: 8.9817
105/200 [==============>...............] - ETA: 0s - loss: 13359.1140 - KL_divergence: 8.9884
111/200 [===============>..............] - ETA: 0s - loss: 13364.2438 - KL_divergence: 8.9798
117/200 [================>.............] - ETA: 0s - loss: 13347.5269 - KL_divergence: 8.9867
123/200 [=================>............] - ETA: 0s - loss: 13381.2187 - KL_divergence: 8.9741
129/200 [==================>...........] - ETA: 0s - loss: 13363.8420 - KL_divergence: 8.9857
135/200 [===================>..........] - ETA: 0s - loss: 13394.4904 - KL_divergence: 8.9789
142/200 [====================>.........] - ETA: 0s - loss: 13375.3583 - KL_divergence: 8.9803
148/200 [=====================>........] - ETA: 0s - loss: 13364.1068 - KL_divergence: 8.9881
154/200 [======================>.......] - ETA: 0s - loss: 13389.0109 - KL_divergence: 8.9798
160/200 [=======================>......] - ETA: 0s - loss: 13384.8271 - KL_divergence: 8.9834
166/200 [=======================>......] - ETA: 0s - loss: 13412.0850 - KL_divergence: 8.9723
172/200 [========================>.....] - ETA: 0s - loss: 13410.7150 - KL_divergence: 8.9698
178/200 [=========================>....] - ETA: 0s - loss: 13406.7339 - KL_divergence: 8.9706
184/200 [==========================>...] - ETA: 0s - loss: 13402.9009 - KL_divergence: 8.9725
190/200 [===========================>..] - ETA: 0s - loss: 13395.0759 - KL_divergence: 8.9782
196/200 [============================>.] - ETA: 0s - loss: 13395.2517 - KL_divergence: 8.9691
200/200 [==============================] - 2s 10ms/step - loss: 13387.6910 - KL_divergence: 8.9702 - val_loss: 13478.5051 - val_KL_divergence: 8.9229
Epoch 35/100

  1/200 [..............................] - ETA: 1s - loss: 14465.1816 - KL_divergence: 8.4233
  8/200 [>.............................] - ETA: 1s - loss: 13700.5786 - KL_divergence: 8.9488
 15/200 [=>............................] - ETA: 1s - loss: 13641.0481 - KL_divergence: 8.9076
 22/200 [==>...........................] - ETA: 1s - loss: 13460.6624 - KL_divergence: 8.9490
 29/200 [===>..........................] - ETA: 1s - loss: 13275.9475 - KL_divergence: 9.0521
 35/200 [====>.........................] - ETA: 1s - loss: 13285.0836 - KL_divergence: 9.0216
 42/200 [=====>........................] - ETA: 1s - loss: 13281.5577 - KL_divergence: 8.9628
 48/200 [======>.......................] - ETA: 1s - loss: 13342.0981 - KL_divergence: 8.9550
 54/200 [=======>......................] - ETA: 1s - loss: 13272.3369 - KL_divergence: 8.9701
 60/200 [========>.....................] - ETA: 1s - loss: 13262.5054 - KL_divergence: 8.9756
 66/200 [========>.....................] - ETA: 1s - loss: 13290.5447 - KL_divergence: 8.9653
 72/200 [=========>....................] - ETA: 1s - loss: 13232.5182 - KL_divergence: 8.9701
 78/200 [==========>...................] - ETA: 1s - loss: 13220.3131 - KL_divergence: 8.9702
 84/200 [===========>..................] - ETA: 1s - loss: 13187.3824 - KL_divergence: 8.9959
 90/200 [============>.................] - ETA: 0s - loss: 13159.8388 - KL_divergence: 9.0163
 96/200 [=============>................] - ETA: 0s - loss: 13188.7380 - KL_divergence: 8.9996
103/200 [==============>...............] - ETA: 0s - loss: 13179.9527 - KL_divergence: 8.9963
109/200 [===============>..............] - ETA: 0s - loss: 13215.9559 - KL_divergence: 8.9800
115/200 [================>.............] - ETA: 0s - loss: 13225.3600 - KL_divergence: 8.9773
121/200 [=================>............] - ETA: 0s - loss: 13237.4691 - KL_divergence: 8.9642
127/200 [==================>...........] - ETA: 0s - loss: 13231.7728 - KL_divergence: 8.9757
134/200 [===================>..........] - ETA: 0s - loss: 13234.6183 - KL_divergence: 8.9730
141/200 [====================>.........] - ETA: 0s - loss: 13234.8449 - KL_divergence: 8.9670
147/200 [=====================>........] - ETA: 0s - loss: 13247.3162 - KL_divergence: 8.9596
154/200 [======================>.......] - ETA: 0s - loss: 13251.0511 - KL_divergence: 8.9528
160/200 [=======================>......] - ETA: 0s - loss: 13250.5265 - KL_divergence: 8.9488
166/200 [=======================>......] - ETA: 0s - loss: 13271.0588 - KL_divergence: 8.9352
172/200 [========================>.....] - ETA: 0s - loss: 13271.6058 - KL_divergence: 8.9383
178/200 [=========================>....] - ETA: 0s - loss: 13275.5206 - KL_divergence: 8.9307
184/200 [==========================>...] - ETA: 0s - loss: 13277.6625 - KL_divergence: 8.9247
190/200 [===========================>..] - ETA: 0s - loss: 13283.2127 - KL_divergence: 8.9245
196/200 [============================>.] - ETA: 0s - loss: 13281.9725 - KL_divergence: 8.9205
200/200 [==============================] - 2s 9ms/step - loss: 13283.8111 - KL_divergence: 8.9225 - val_loss: 13441.2058 - val_KL_divergence: 8.8973
Epoch 36/100

  1/200 [..............................] - ETA: 1s - loss: 11946.1777 - KL_divergence: 10.3803
  7/200 [>.............................] - ETA: 1s - loss: 13266.5769 - KL_divergence: 9.2116 
 13/200 [>.............................] - ETA: 1s - loss: 13049.5790 - KL_divergence: 9.1992
 19/200 [=>............................] - ETA: 1s - loss: 13170.8907 - KL_divergence: 9.0749
 25/200 [==>...........................] - ETA: 1s - loss: 13199.5559 - KL_divergence: 9.0378
 32/200 [===>..........................] - ETA: 1s - loss: 13235.4752 - KL_divergence: 9.0434
 38/200 [====>.........................] - ETA: 1s - loss: 13232.3683 - KL_divergence: 9.0363
 44/200 [=====>........................] - ETA: 1s - loss: 13216.1623 - KL_divergence: 9.0364
 51/200 [======>.......................] - ETA: 1s - loss: 13241.7317 - KL_divergence: 9.0197
 57/200 [=======>......................] - ETA: 1s - loss: 13259.5611 - KL_divergence: 9.0075
 63/200 [========>.....................] - ETA: 1s - loss: 13273.3119 - KL_divergence: 8.9900
 69/200 [=========>....................] - ETA: 1s - loss: 13252.0185 - KL_divergence: 8.9954
 75/200 [==========>...................] - ETA: 1s - loss: 13259.2539 - KL_divergence: 8.9909
 81/200 [===========>..................] - ETA: 1s - loss: 13267.0059 - KL_divergence: 9.0023
 87/200 [============>.................] - ETA: 0s - loss: 13239.6853 - KL_divergence: 8.9936
 93/200 [============>.................] - ETA: 0s - loss: 13226.9798 - KL_divergence: 8.9897
 99/200 [=============>................] - ETA: 0s - loss: 13210.5118 - KL_divergence: 8.9982
105/200 [==============>...............] - ETA: 0s - loss: 13233.3113 - KL_divergence: 8.9761
112/200 [===============>..............] - ETA: 0s - loss: 13229.7828 - KL_divergence: 8.9772
119/200 [================>.............] - ETA: 0s - loss: 13208.0501 - KL_divergence: 8.9811
125/200 [=================>............] - ETA: 0s - loss: 13214.6602 - KL_divergence: 8.9665
131/200 [==================>...........] - ETA: 0s - loss: 13210.4585 - KL_divergence: 8.9655
137/200 [===================>..........] - ETA: 0s - loss: 13208.9703 - KL_divergence: 8.9651
143/200 [====================>.........] - ETA: 0s - loss: 13202.9626 - KL_divergence: 8.9619
149/200 [=====================>........] - ETA: 0s - loss: 13199.4562 - KL_divergence: 8.9606
155/200 [======================>.......] - ETA: 0s - loss: 13231.0101 - KL_divergence: 8.9535
161/200 [=======================>......] - ETA: 0s - loss: 13232.0353 - KL_divergence: 8.9492
167/200 [========================>.....] - ETA: 0s - loss: 13259.8928 - KL_divergence: 8.9382
173/200 [========================>.....] - ETA: 0s - loss: 13270.4318 - KL_divergence: 8.9364
179/200 [=========================>....] - ETA: 0s - loss: 13279.8853 - KL_divergence: 8.9319
185/200 [==========================>...] - ETA: 0s - loss: 13280.0964 - KL_divergence: 8.9381
191/200 [===========================>..] - ETA: 0s - loss: 13289.7773 - KL_divergence: 8.9312
197/200 [============================>.] - ETA: 0s - loss: 13300.3389 - KL_divergence: 8.9277
200/200 [==============================] - 2s 10ms/step - loss: 13306.4363 - KL_divergence: 8.9231 - val_loss: 13819.4192 - val_KL_divergence: 9.1458
Epoch 37/100

  1/200 [..............................] - ETA: 1s - loss: 13467.1738 - KL_divergence: 8.8819
  7/200 [>.............................] - ETA: 1s - loss: 12910.4110 - KL_divergence: 9.1260
 13/200 [>.............................] - ETA: 1s - loss: 13120.2253 - KL_divergence: 9.0714
 20/200 [==>...........................] - ETA: 1s - loss: 13095.9283 - KL_divergence: 9.0445
 27/200 [===>..........................] - ETA: 1s - loss: 13012.7431 - KL_divergence: 8.9977
 33/200 [===>..........................] - ETA: 1s - loss: 12996.1719 - KL_divergence: 8.9433
 39/200 [====>.........................] - ETA: 1s - loss: 13097.7830 - KL_divergence: 8.8933
 45/200 [=====>........................] - ETA: 1s - loss: 13168.1490 - KL_divergence: 8.8913
 51/200 [======>.......................] - ETA: 1s - loss: 13212.3258 - KL_divergence: 8.8974
 57/200 [=======>......................] - ETA: 1s - loss: 13257.6147 - KL_divergence: 8.8869
 63/200 [========>.....................] - ETA: 1s - loss: 13267.1360 - KL_divergence: 8.8790
 69/200 [=========>....................] - ETA: 1s - loss: 13278.3912 - KL_divergence: 8.8843
 75/200 [==========>...................] - ETA: 1s - loss: 13316.9875 - KL_divergence: 8.8781
 81/200 [===========>..................] - ETA: 1s - loss: 13320.3482 - KL_divergence: 8.8706
 87/200 [============>.................] - ETA: 1s - loss: 13310.5987 - KL_divergence: 8.8693
 93/200 [============>.................] - ETA: 0s - loss: 13311.1513 - KL_divergence: 8.8725
 99/200 [=============>................] - ETA: 0s - loss: 13302.8791 - KL_divergence: 8.8845
105/200 [==============>...............] - ETA: 0s - loss: 13293.7514 - KL_divergence: 8.8802
111/200 [===============>..............] - ETA: 0s - loss: 13318.7139 - KL_divergence: 8.8842
117/200 [================>.............] - ETA: 0s - loss: 13275.1313 - KL_divergence: 8.8851
123/200 [=================>............] - ETA: 0s - loss: 13287.6949 - KL_divergence: 8.8826
129/200 [==================>...........] - ETA: 0s - loss: 13279.5012 - KL_divergence: 8.8754
135/200 [===================>..........] - ETA: 0s - loss: 13264.4145 - KL_divergence: 8.8773
141/200 [====================>.........] - ETA: 0s - loss: 13260.6092 - KL_divergence: 8.8883
147/200 [=====================>........] - ETA: 0s - loss: 13261.7720 - KL_divergence: 8.9021
153/200 [=====================>........] - ETA: 0s - loss: 13247.0912 - KL_divergence: 8.9051
159/200 [======================>.......] - ETA: 0s - loss: 13256.0226 - KL_divergence: 8.8983
165/200 [=======================>......] - ETA: 0s - loss: 13251.0234 - KL_divergence: 8.9050
171/200 [========================>.....] - ETA: 0s - loss: 13238.8675 - KL_divergence: 8.9094
177/200 [=========================>....] - ETA: 0s - loss: 13238.8928 - KL_divergence: 8.9115
183/200 [==========================>...] - ETA: 0s - loss: 13233.3806 - KL_divergence: 8.9159
189/200 [===========================>..] - ETA: 0s - loss: 13238.9021 - KL_divergence: 8.9122
195/200 [============================>.] - ETA: 0s - loss: 13245.2121 - KL_divergence: 8.9096
200/200 [==============================] - 2s 10ms/step - loss: 13242.0392 - KL_divergence: 8.9149 - val_loss: 13484.0603 - val_KL_divergence: 9.3453
Epoch 38/100

  1/200 [..............................] - ETA: 1s - loss: 13312.4502 - KL_divergence: 8.9950
  7/200 [>.............................] - ETA: 1s - loss: 12922.1752 - KL_divergence: 8.9503
 14/200 [=>............................] - ETA: 1s - loss: 13112.3329 - KL_divergence: 8.8374
 20/200 [==>...........................] - ETA: 1s - loss: 13291.5887 - KL_divergence: 8.8353
 26/200 [==>...........................] - ETA: 1s - loss: 13316.8670 - KL_divergence: 8.8915
 32/200 [===>..........................] - ETA: 1s - loss: 13188.7781 - KL_divergence: 8.9232
 38/200 [====>.........................] - ETA: 1s - loss: 13151.2351 - KL_divergence: 8.9300
 44/200 [=====>........................] - ETA: 1s - loss: 13172.2419 - KL_divergence: 8.8978
 50/200 [======>.......................] - ETA: 1s - loss: 13162.0514 - KL_divergence: 8.9101
 56/200 [=======>......................] - ETA: 1s - loss: 13197.8169 - KL_divergence: 8.9145
 62/200 [========>.....................] - ETA: 1s - loss: 13235.0901 - KL_divergence: 8.9054
 68/200 [=========>....................] - ETA: 1s - loss: 13271.6135 - KL_divergence: 8.8995
 75/200 [==========>...................] - ETA: 1s - loss: 13318.2582 - KL_divergence: 8.8740
 82/200 [===========>..................] - ETA: 1s - loss: 13306.1324 - KL_divergence: 8.8522
 89/200 [============>.................] - ETA: 0s - loss: 13302.8412 - KL_divergence: 8.8517
 95/200 [=============>................] - ETA: 0s - loss: 13257.7379 - KL_divergence: 8.8624
101/200 [==============>...............] - ETA: 0s - loss: 13275.4697 - KL_divergence: 8.8489
107/200 [===============>..............] - ETA: 0s - loss: 13267.8695 - KL_divergence: 8.8465
113/200 [===============>..............] - ETA: 0s - loss: 13289.2267 - KL_divergence: 8.8318
119/200 [================>.............] - ETA: 0s - loss: 13283.3113 - KL_divergence: 8.8292
125/200 [=================>............] - ETA: 0s - loss: 13288.7922 - KL_divergence: 8.8316
131/200 [==================>...........] - ETA: 0s - loss: 13269.9331 - KL_divergence: 8.8392
137/200 [===================>..........] - ETA: 0s - loss: 13240.7942 - KL_divergence: 8.8545
143/200 [====================>.........] - ETA: 0s - loss: 13267.4728 - KL_divergence: 8.8322
149/200 [=====================>........] - ETA: 0s - loss: 13255.2874 - KL_divergence: 8.8330
155/200 [======================>.......] - ETA: 0s - loss: 13259.5553 - KL_divergence: 8.8267
161/200 [=======================>......] - ETA: 0s - loss: 13257.9089 - KL_divergence: 8.8252
167/200 [========================>.....] - ETA: 0s - loss: 13256.2270 - KL_divergence: 8.8257
173/200 [========================>.....] - ETA: 0s - loss: 13267.0554 - KL_divergence: 8.8416
179/200 [=========================>....] - ETA: 0s - loss: 13280.6355 - KL_divergence: 8.8363
185/200 [==========================>...] - ETA: 0s - loss: 13283.4736 - KL_divergence: 8.8393
191/200 [===========================>..] - ETA: 0s - loss: 13270.8064 - KL_divergence: 8.8504
197/200 [============================>.] - ETA: 0s - loss: 13291.9326 - KL_divergence: 8.8385
200/200 [==============================] - 2s 10ms/step - loss: 13293.7690 - KL_divergence: 8.8359 - val_loss: 13464.2549 - val_KL_divergence: 8.9645
Epoch 39/100

  1/200 [..............................] - ETA: 1s - loss: 12356.1689 - KL_divergence: 9.4566
  7/200 [>.............................] - ETA: 1s - loss: 12882.5801 - KL_divergence: 9.1336
 13/200 [>.............................] - ETA: 1s - loss: 13007.4284 - KL_divergence: 8.9409
 19/200 [=>............................] - ETA: 1s - loss: 12913.6524 - KL_divergence: 9.0501
 26/200 [==>...........................] - ETA: 1s - loss: 12951.9378 - KL_divergence: 8.9959
 32/200 [===>..........................] - ETA: 1s - loss: 13001.7795 - KL_divergence: 8.9796
 38/200 [====>.........................] - ETA: 1s - loss: 13058.8062 - KL_divergence: 8.9327
 44/200 [=====>........................] - ETA: 1s - loss: 13072.7448 - KL_divergence: 8.9224
 50/200 [======>.......................] - ETA: 1s - loss: 13028.4475 - KL_divergence: 8.9285
 56/200 [=======>......................] - ETA: 1s - loss: 13033.8500 - KL_divergence: 8.9433
 63/200 [========>.....................] - ETA: 1s - loss: 13035.0957 - KL_divergence: 8.9490
 69/200 [=========>....................] - ETA: 1s - loss: 13038.1942 - KL_divergence: 8.9559
 76/200 [==========>...................] - ETA: 1s - loss: 13006.1410 - KL_divergence: 8.9506
 82/200 [===========>..................] - ETA: 1s - loss: 13006.3240 - KL_divergence: 8.9422
 88/200 [============>.................] - ETA: 0s - loss: 13027.7104 - KL_divergence: 8.9247
 94/200 [=============>................] - ETA: 0s - loss: 13044.2492 - KL_divergence: 8.9284
100/200 [==============>...............] - ETA: 0s - loss: 13075.1590 - KL_divergence: 8.9114
106/200 [==============>...............] - ETA: 0s - loss: 13076.7718 - KL_divergence: 8.9031
112/200 [===============>..............] - ETA: 0s - loss: 13061.2454 - KL_divergence: 8.9148
118/200 [================>.............] - ETA: 0s - loss: 13074.6108 - KL_divergence: 8.9072
124/200 [=================>............] - ETA: 0s - loss: 13084.7519 - KL_divergence: 8.8905
130/200 [==================>...........] - ETA: 0s - loss: 13098.5498 - KL_divergence: 8.8821
135/200 [===================>..........] - ETA: 0s - loss: 13093.2610 - KL_divergence: 8.8825
141/200 [====================>.........] - ETA: 0s - loss: 13115.7824 - KL_divergence: 8.8816
147/200 [=====================>........] - ETA: 0s - loss: 13127.3338 - KL_divergence: 8.8713
153/200 [=====================>........] - ETA: 0s - loss: 13125.9956 - KL_divergence: 8.8640
159/200 [======================>.......] - ETA: 0s - loss: 13134.1805 - KL_divergence: 8.8520
165/200 [=======================>......] - ETA: 0s - loss: 13119.0593 - KL_divergence: 8.8501
171/200 [========================>.....] - ETA: 0s - loss: 13109.2994 - KL_divergence: 8.8461
177/200 [=========================>....] - ETA: 0s - loss: 13118.2290 - KL_divergence: 8.8443
183/200 [==========================>...] - ETA: 0s - loss: 13121.3756 - KL_divergence: 8.8463
189/200 [===========================>..] - ETA: 0s - loss: 13126.4817 - KL_divergence: 8.8460
195/200 [============================>.] - ETA: 0s - loss: 13124.2797 - KL_divergence: 8.8570
200/200 [==============================] - 2s 10ms/step - loss: 13124.9918 - KL_divergence: 8.8633 - val_loss: 13397.4675 - val_KL_divergence: 8.9972
Epoch 40/100

  1/200 [..............................] - ETA: 1s - loss: 13115.6162 - KL_divergence: 9.3644
  7/200 [>.............................] - ETA: 1s - loss: 12962.7892 - KL_divergence: 9.2417
 13/200 [>.............................] - ETA: 1s - loss: 12929.1868 - KL_divergence: 9.1692
 19/200 [=>............................] - ETA: 1s - loss: 12872.8562 - KL_divergence: 9.1441
 25/200 [==>...........................] - ETA: 1s - loss: 12859.4214 - KL_divergence: 9.1651
 31/200 [===>..........................] - ETA: 1s - loss: 12925.0071 - KL_divergence: 9.0743
 37/200 [====>.........................] - ETA: 1s - loss: 12975.4566 - KL_divergence: 9.0423
 43/200 [=====>........................] - ETA: 1s - loss: 12997.5453 - KL_divergence: 8.9983
 49/200 [======>.......................] - ETA: 1s - loss: 13093.5057 - KL_divergence: 8.9436
 55/200 [=======>......................] - ETA: 1s - loss: 13063.2574 - KL_divergence: 8.9364
 61/200 [========>.....................] - ETA: 1s - loss: 13013.3179 - KL_divergence: 8.9492
 67/200 [=========>....................] - ETA: 1s - loss: 12999.3720 - KL_divergence: 8.9417
 73/200 [=========>....................] - ETA: 1s - loss: 12987.1194 - KL_divergence: 8.9436
 79/200 [==========>...................] - ETA: 1s - loss: 13002.2382 - KL_divergence: 8.9313
 85/200 [===========>..................] - ETA: 1s - loss: 13027.1876 - KL_divergence: 8.9131
 91/200 [============>.................] - ETA: 0s - loss: 13025.6723 - KL_divergence: 8.9140
 97/200 [=============>................] - ETA: 0s - loss: 13018.5977 - KL_divergence: 8.9182
103/200 [==============>...............] - ETA: 0s - loss: 13059.0867 - KL_divergence: 8.8992
109/200 [===============>..............] - ETA: 0s - loss: 13058.1667 - KL_divergence: 8.9089
115/200 [================>.............] - ETA: 0s - loss: 13097.2475 - KL_divergence: 8.8917
121/200 [=================>............] - ETA: 0s - loss: 13120.2749 - KL_divergence: 8.8836
127/200 [==================>...........] - ETA: 0s - loss: 13092.8080 - KL_divergence: 8.8871
133/200 [==================>...........] - ETA: 0s - loss: 13087.7226 - KL_divergence: 8.8755
139/200 [===================>..........] - ETA: 0s - loss: 13114.6639 - KL_divergence: 8.8715
146/200 [====================>.........] - ETA: 0s - loss: 13121.7905 - KL_divergence: 8.8743
152/200 [=====================>........] - ETA: 0s - loss: 13131.8904 - KL_divergence: 8.8607
158/200 [======================>.......] - ETA: 0s - loss: 13151.8140 - KL_divergence: 8.8480
164/200 [=======================>......] - ETA: 0s - loss: 13161.3019 - KL_divergence: 8.8391
170/200 [========================>.....] - ETA: 0s - loss: 13150.6965 - KL_divergence: 8.8373
176/200 [=========================>....] - ETA: 0s - loss: 13151.6278 - KL_divergence: 8.8333
182/200 [==========================>...] - ETA: 0s - loss: 13149.7652 - KL_divergence: 8.8369
188/200 [===========================>..] - ETA: 0s - loss: 13145.9565 - KL_divergence: 8.8327
193/200 [===========================>..] - ETA: 0s - loss: 13136.4216 - KL_divergence: 8.8316
199/200 [============================>.] - ETA: 0s - loss: 13141.5581 - KL_divergence: 8.8174
200/200 [==============================] - 2s 10ms/step - loss: 13136.7921 - KL_divergence: 8.8174 - val_loss: 13430.1653 - val_KL_divergence: 8.6243
Epoch 41/100

  1/200 [..............................] - ETA: 1s - loss: 11515.5996 - KL_divergence: 9.5694
  7/200 [>.............................] - ETA: 1s - loss: 12646.1960 - KL_divergence: 8.8982
 13/200 [>.............................] - ETA: 1s - loss: 12646.3690 - KL_divergence: 9.0130
 19/200 [=>............................] - ETA: 1s - loss: 12925.1170 - KL_divergence: 8.9210
 25/200 [==>...........................] - ETA: 1s - loss: 12997.8614 - KL_divergence: 8.8190
 31/200 [===>..........................] - ETA: 1s - loss: 13144.5048 - KL_divergence: 8.7614
 37/200 [====>.........................] - ETA: 1s - loss: 13189.5126 - KL_divergence: 8.7632
 43/200 [=====>........................] - ETA: 1s - loss: 13169.4355 - KL_divergence: 8.7463
 49/200 [======>.......................] - ETA: 1s - loss: 13139.1054 - KL_divergence: 8.7405
 55/200 [=======>......................] - ETA: 1s - loss: 13119.6599 - KL_divergence: 8.7480
 61/200 [========>.....................] - ETA: 1s - loss: 13057.4140 - KL_divergence: 8.7716
 67/200 [=========>....................] - ETA: 1s - loss: 13073.0924 - KL_divergence: 8.7639
 73/200 [=========>....................] - ETA: 1s - loss: 13094.7429 - KL_divergence: 8.7755
 79/200 [==========>...................] - ETA: 1s - loss: 13128.9711 - KL_divergence: 8.7664
 85/200 [===========>..................] - ETA: 1s - loss: 13121.2089 - KL_divergence: 8.7583
 91/200 [============>.................] - ETA: 1s - loss: 13146.3105 - KL_divergence: 8.7585
 97/200 [=============>................] - ETA: 0s - loss: 13155.1300 - KL_divergence: 8.7565
103/200 [==============>...............] - ETA: 0s - loss: 13188.5785 - KL_divergence: 8.7479
109/200 [===============>..............] - ETA: 0s - loss: 13187.3837 - KL_divergence: 8.7446
115/200 [================>.............] - ETA: 0s - loss: 13213.2947 - KL_divergence: 8.7406
121/200 [=================>............] - ETA: 0s - loss: 13183.4837 - KL_divergence: 8.7447
127/200 [==================>...........] - ETA: 0s - loss: 13156.7988 - KL_divergence: 8.7567
133/200 [==================>...........] - ETA: 0s - loss: 13163.2720 - KL_divergence: 8.7602
139/200 [===================>..........] - ETA: 0s - loss: 13176.3914 - KL_divergence: 8.7510
145/200 [====================>.........] - ETA: 0s - loss: 13168.7743 - KL_divergence: 8.7512
152/200 [=====================>........] - ETA: 0s - loss: 13168.6306 - KL_divergence: 8.7555
158/200 [======================>.......] - ETA: 0s - loss: 13162.6111 - KL_divergence: 8.7567
164/200 [=======================>......] - ETA: 0s - loss: 13139.4849 - KL_divergence: 8.7625
170/200 [========================>.....] - ETA: 0s - loss: 13146.1371 - KL_divergence: 8.7599
176/200 [=========================>....] - ETA: 0s - loss: 13124.4458 - KL_divergence: 8.7680
182/200 [==========================>...] - ETA: 0s - loss: 13120.3590 - KL_divergence: 8.7704
188/200 [===========================>..] - ETA: 0s - loss: 13109.3261 - KL_divergence: 8.7679
194/200 [============================>.] - ETA: 0s - loss: 13120.7242 - KL_divergence: 8.7617
200/200 [==============================] - 2s 10ms/step - loss: 13106.6941 - KL_divergence: 8.7674 - val_loss: 13286.9834 - val_KL_divergence: 8.6642
Epoch 42/100

  1/200 [..............................] - ETA: 1s - loss: 12831.7861 - KL_divergence: 9.0320
  7/200 [>.............................] - ETA: 1s - loss: 12790.1970 - KL_divergence: 8.8520
 13/200 [>.............................] - ETA: 1s - loss: 12813.7529 - KL_divergence: 8.8909
 19/200 [=>............................] - ETA: 1s - loss: 13023.6684 - KL_divergence: 8.7792
 25/200 [==>...........................] - ETA: 1s - loss: 12915.1776 - KL_divergence: 8.8095
 31/200 [===>..........................] - ETA: 1s - loss: 12983.0087 - KL_divergence: 8.8036
 37/200 [====>.........................] - ETA: 1s - loss: 12967.7237 - KL_divergence: 8.7799
 43/200 [=====>........................] - ETA: 1s - loss: 13046.6918 - KL_divergence: 8.7746
 49/200 [======>.......................] - ETA: 1s - loss: 13120.9565 - KL_divergence: 8.7586
 55/200 [=======>......................] - ETA: 1s - loss: 13152.7467 - KL_divergence: 8.7341
 61/200 [========>.....................] - ETA: 1s - loss: 13145.2125 - KL_divergence: 8.7415
 67/200 [=========>....................] - ETA: 1s - loss: 13172.5122 - KL_divergence: 8.7462
 73/200 [=========>....................] - ETA: 1s - loss: 13179.3135 - KL_divergence: 8.7306
 80/200 [===========>..................] - ETA: 1s - loss: 13194.7752 - KL_divergence: 8.7204
 86/200 [===========>..................] - ETA: 1s - loss: 13207.0160 - KL_divergence: 8.7087
 92/200 [============>.................] - ETA: 0s - loss: 13218.7940 - KL_divergence: 8.6978
 98/200 [=============>................] - ETA: 0s - loss: 13205.3330 - KL_divergence: 8.7081
104/200 [==============>...............] - ETA: 0s - loss: 13213.1897 - KL_divergence: 8.6821
110/200 [===============>..............] - ETA: 0s - loss: 13210.4119 - KL_divergence: 8.6789
116/200 [================>.............] - ETA: 0s - loss: 13217.5091 - KL_divergence: 8.6825
122/200 [=================>............] - ETA: 0s - loss: 13205.9777 - KL_divergence: 8.6838
128/200 [==================>...........] - ETA: 0s - loss: 13191.2336 - KL_divergence: 8.6743
134/200 [===================>..........] - ETA: 0s - loss: 13150.6903 - KL_divergence: 8.6943
140/200 [====================>.........] - ETA: 0s - loss: 13150.9140 - KL_divergence: 8.6960
146/200 [====================>.........] - ETA: 0s - loss: 13132.1960 - KL_divergence: 8.6964
152/200 [=====================>........] - ETA: 0s - loss: 13143.2981 - KL_divergence: 8.6976
158/200 [======================>.......] - ETA: 0s - loss: 13161.2692 - KL_divergence: 8.6920
164/200 [=======================>......] - ETA: 0s - loss: 13151.7058 - KL_divergence: 8.6932
170/200 [========================>.....] - ETA: 0s - loss: 13146.0761 - KL_divergence: 8.6960
176/200 [=========================>....] - ETA: 0s - loss: 13137.9312 - KL_divergence: 8.6957
182/200 [==========================>...] - ETA: 0s - loss: 13132.8879 - KL_divergence: 8.6896
188/200 [===========================>..] - ETA: 0s - loss: 13137.1761 - KL_divergence: 8.6899
194/200 [============================>.] - ETA: 0s - loss: 13139.1335 - KL_divergence: 8.6941
200/200 [==============================] - 2s 10ms/step - loss: 13137.8141 - KL_divergence: 8.6897 - val_loss: 13375.1254 - val_KL_divergence: 8.8680
Epoch 43/100

  1/200 [..............................] - ETA: 1s - loss: 12354.7715 - KL_divergence: 9.0632
  7/200 [>.............................] - ETA: 1s - loss: 12730.7264 - KL_divergence: 8.9580
 13/200 [>.............................] - ETA: 1s - loss: 12847.6621 - KL_divergence: 8.8333
 19/200 [=>............................] - ETA: 1s - loss: 12961.5306 - KL_divergence: 8.8158
 25/200 [==>...........................] - ETA: 1s - loss: 12823.0663 - KL_divergence: 8.8424
 31/200 [===>..........................] - ETA: 1s - loss: 12791.5162 - KL_divergence: 8.9290
 37/200 [====>.........................] - ETA: 1s - loss: 12778.3933 - KL_divergence: 8.9500
 43/200 [=====>........................] - ETA: 1s - loss: 12884.1549 - KL_divergence: 8.9514
 49/200 [======>.......................] - ETA: 1s - loss: 12925.7170 - KL_divergence: 8.9646
 55/200 [=======>......................] - ETA: 1s - loss: 12979.5462 - KL_divergence: 8.9248
 61/200 [========>.....................] - ETA: 1s - loss: 12995.8389 - KL_divergence: 8.9171
 67/200 [=========>....................] - ETA: 1s - loss: 13051.0941 - KL_divergence: 8.8704
 73/200 [=========>....................] - ETA: 1s - loss: 13047.7905 - KL_divergence: 8.8765
 79/200 [==========>...................] - ETA: 1s - loss: 13066.1724 - KL_divergence: 8.8757
 86/200 [===========>..................] - ETA: 1s - loss: 13051.6741 - KL_divergence: 8.8773
 92/200 [============>.................] - ETA: 0s - loss: 13077.7664 - KL_divergence: 8.8640
 98/200 [=============>................] - ETA: 0s - loss: 13073.7395 - KL_divergence: 8.8541
104/200 [==============>...............] - ETA: 0s - loss: 13086.5975 - KL_divergence: 8.8582
110/200 [===============>..............] - ETA: 0s - loss: 13059.7429 - KL_divergence: 8.8635
116/200 [================>.............] - ETA: 0s - loss: 13080.9318 - KL_divergence: 8.8640
122/200 [=================>............] - ETA: 0s - loss: 13095.2055 - KL_divergence: 8.8502
128/200 [==================>...........] - ETA: 0s - loss: 13097.6321 - KL_divergence: 8.8467
134/200 [===================>..........] - ETA: 0s - loss: 13098.4524 - KL_divergence: 8.8409
140/200 [====================>.........] - ETA: 0s - loss: 13122.7043 - KL_divergence: 8.8280
145/200 [====================>.........] - ETA: 0s - loss: 13121.2606 - KL_divergence: 8.8254
151/200 [=====================>........] - ETA: 0s - loss: 13126.2662 - KL_divergence: 8.8232
157/200 [======================>.......] - ETA: 0s - loss: 13122.1886 - KL_divergence: 8.8239
163/200 [=======================>......] - ETA: 0s - loss: 13101.5929 - KL_divergence: 8.8261
169/200 [========================>.....] - ETA: 0s - loss: 13092.9492 - KL_divergence: 8.8181
175/200 [=========================>....] - ETA: 0s - loss: 13094.5919 - KL_divergence: 8.8143
181/200 [==========================>...] - ETA: 0s - loss: 13073.8809 - KL_divergence: 8.8110
187/200 [===========================>..] - ETA: 0s - loss: 13081.1916 - KL_divergence: 8.8104
193/200 [===========================>..] - ETA: 0s - loss: 13064.0037 - KL_divergence: 8.8125
199/200 [============================>.] - ETA: 0s - loss: 13085.7652 - KL_divergence: 8.8080
200/200 [==============================] - 2s 10ms/step - loss: 13087.3840 - KL_divergence: 8.8089 - val_loss: 13565.2871 - val_KL_divergence: 8.8336
Epoch 44/100

  1/200 [..............................] - ETA: 1s - loss: 13223.5391 - KL_divergence: 8.6781
  7/200 [>.............................] - ETA: 1s - loss: 13834.7427 - KL_divergence: 8.6006
 13/200 [>.............................] - ETA: 1s - loss: 13286.8561 - KL_divergence: 8.7597
 19/200 [=>............................] - ETA: 1s - loss: 13031.6703 - KL_divergence: 8.8683
 25/200 [==>...........................] - ETA: 1s - loss: 13026.3074 - KL_divergence: 8.8853
 31/200 [===>..........................] - ETA: 1s - loss: 13026.5744 - KL_divergence: 8.8418
 37/200 [====>.........................] - ETA: 1s - loss: 13084.4689 - KL_divergence: 8.8032
 43/200 [=====>........................] - ETA: 1s - loss: 13063.8015 - KL_divergence: 8.7987
 49/200 [======>.......................] - ETA: 1s - loss: 13041.3725 - KL_divergence: 8.7976
 55/200 [=======>......................] - ETA: 1s - loss: 13043.9486 - KL_divergence: 8.7855
 61/200 [========>.....................] - ETA: 1s - loss: 13031.9103 - KL_divergence: 8.7837
 67/200 [=========>....................] - ETA: 1s - loss: 13084.1702 - KL_divergence: 8.7625
 73/200 [=========>....................] - ETA: 1s - loss: 13065.2285 - KL_divergence: 8.7410
 79/200 [==========>...................] - ETA: 1s - loss: 13072.5167 - KL_divergence: 8.7340
 85/200 [===========>..................] - ETA: 1s - loss: 13059.2597 - KL_divergence: 8.7252
 91/200 [============>.................] - ETA: 1s - loss: 13055.9340 - KL_divergence: 8.7347
 97/200 [=============>................] - ETA: 0s - loss: 13057.5469 - KL_divergence: 8.7275
103/200 [==============>...............] - ETA: 0s - loss: 13076.7333 - KL_divergence: 8.7038
109/200 [===============>..............] - ETA: 0s - loss: 13082.2866 - KL_divergence: 8.7045
115/200 [================>.............] - ETA: 0s - loss: 13045.2091 - KL_divergence: 8.7105
121/200 [=================>............] - ETA: 0s - loss: 13058.9740 - KL_divergence: 8.7143
127/200 [==================>...........] - ETA: 0s - loss: 13038.2963 - KL_divergence: 8.7143
133/200 [==================>...........] - ETA: 0s - loss: 13034.7504 - KL_divergence: 8.7054
139/200 [===================>..........] - ETA: 0s - loss: 13052.1110 - KL_divergence: 8.6966
145/200 [====================>.........] - ETA: 0s - loss: 13050.9344 - KL_divergence: 8.6938
151/200 [=====================>........] - ETA: 0s - loss: 13042.9133 - KL_divergence: 8.6858
157/200 [======================>.......] - ETA: 0s - loss: 13046.0850 - KL_divergence: 8.6754
163/200 [=======================>......] - ETA: 0s - loss: 13062.0243 - KL_divergence: 8.6711
169/200 [========================>.....] - ETA: 0s - loss: 13062.7596 - KL_divergence: 8.6616
175/200 [=========================>....] - ETA: 0s - loss: 13062.0576 - KL_divergence: 8.6638
181/200 [==========================>...] - ETA: 0s - loss: 13058.2434 - KL_divergence: 8.6595
187/200 [===========================>..] - ETA: 0s - loss: 13062.5499 - KL_divergence: 8.6599
193/200 [===========================>..] - ETA: 0s - loss: 13049.5350 - KL_divergence: 8.6677
199/200 [============================>.] - ETA: 0s - loss: 13044.2551 - KL_divergence: 8.6727
200/200 [==============================] - 2s 10ms/step - loss: 13043.6614 - KL_divergence: 8.6731 - val_loss: 13365.8747 - val_KL_divergence: 8.7820
Epoch 45/100

  1/200 [..............................] - ETA: 1s - loss: 13924.9199 - KL_divergence: 8.6825
  7/200 [>.............................] - ETA: 1s - loss: 13048.1077 - KL_divergence: 8.7138
 13/200 [>.............................] - ETA: 1s - loss: 13012.1009 - KL_divergence: 8.6698
 19/200 [=>............................] - ETA: 1s - loss: 13065.9609 - KL_divergence: 8.6468
 26/200 [==>...........................] - ETA: 1s - loss: 12923.8933 - KL_divergence: 8.6941
 32/200 [===>..........................] - ETA: 1s - loss: 12937.2989 - KL_divergence: 8.6461
 38/200 [====>.........................] - ETA: 1s - loss: 12905.5200 - KL_divergence: 8.6540
 44/200 [=====>........................] - ETA: 1s - loss: 12874.1513 - KL_divergence: 8.6653
 50/200 [======>.......................] - ETA: 1s - loss: 12865.9907 - KL_divergence: 8.6481
 56/200 [=======>......................] - ETA: 1s - loss: 12819.7165 - KL_divergence: 8.6643
 62/200 [========>.....................] - ETA: 1s - loss: 12864.3911 - KL_divergence: 8.6750
 68/200 [=========>....................] - ETA: 1s - loss: 12906.4687 - KL_divergence: 8.6636
 74/200 [==========>...................] - ETA: 1s - loss: 12918.7751 - KL_divergence: 8.6448
 80/200 [===========>..................] - ETA: 1s - loss: 12878.8716 - KL_divergence: 8.6644
 86/200 [===========>..................] - ETA: 1s - loss: 12883.2992 - KL_divergence: 8.6462
 92/200 [============>.................] - ETA: 0s - loss: 12891.5533 - KL_divergence: 8.6374
 98/200 [=============>................] - ETA: 0s - loss: 12915.1959 - KL_divergence: 8.6338
104/200 [==============>...............] - ETA: 0s - loss: 12911.2819 - KL_divergence: 8.6312
110/200 [===============>..............] - ETA: 0s - loss: 12937.0680 - KL_divergence: 8.6198
116/200 [================>.............] - ETA: 0s - loss: 12954.3161 - KL_divergence: 8.6119
122/200 [=================>............] - ETA: 0s - loss: 12976.9493 - KL_divergence: 8.6017
128/200 [==================>...........] - ETA: 0s - loss: 12972.0951 - KL_divergence: 8.5981
134/200 [===================>..........] - ETA: 0s - loss: 12989.4606 - KL_divergence: 8.6014
140/200 [====================>.........] - ETA: 0s - loss: 12999.6485 - KL_divergence: 8.6023
146/200 [====================>.........] - ETA: 0s - loss: 12984.7562 - KL_divergence: 8.6033
152/200 [=====================>........] - ETA: 0s - loss: 12984.4927 - KL_divergence: 8.6133
158/200 [======================>.......] - ETA: 0s - loss: 12988.1052 - KL_divergence: 8.6288
164/200 [=======================>......] - ETA: 0s - loss: 12989.9837 - KL_divergence: 8.6299
170/200 [========================>.....] - ETA: 0s - loss: 12989.4827 - KL_divergence: 8.6263
176/200 [=========================>....] - ETA: 0s - loss: 12982.7771 - KL_divergence: 8.6254
182/200 [==========================>...] - ETA: 0s - loss: 12966.7509 - KL_divergence: 8.6294
188/200 [===========================>..] - ETA: 0s - loss: 12962.9095 - KL_divergence: 8.6326
194/200 [============================>.] - ETA: 0s - loss: 12956.2189 - KL_divergence: 8.6331
200/200 [==============================] - 2s 10ms/step - loss: 12968.6466 - KL_divergence: 8.6256 - val_loss: 13244.1929 - val_KL_divergence: 8.7163
Epoch 46/100

  1/200 [..............................] - ETA: 1s - loss: 12144.6650 - KL_divergence: 9.4329
  7/200 [>.............................] - ETA: 1s - loss: 12415.7443 - KL_divergence: 8.8525
 13/200 [>.............................] - ETA: 1s - loss: 12655.8894 - KL_divergence: 8.7976
 19/200 [=>............................] - ETA: 1s - loss: 12710.0487 - KL_divergence: 8.8345
 25/200 [==>...........................] - ETA: 1s - loss: 12760.5296 - KL_divergence: 8.7932
 31/200 [===>..........................] - ETA: 1s - loss: 12682.5627 - KL_divergence: 8.7997
 37/200 [====>.........................] - ETA: 1s - loss: 12741.4546 - KL_divergence: 8.7272
 43/200 [=====>........................] - ETA: 1s - loss: 12738.2536 - KL_divergence: 8.7176
 49/200 [======>.......................] - ETA: 1s - loss: 12833.5159 - KL_divergence: 8.6874
 55/200 [=======>......................] - ETA: 1s - loss: 12833.0355 - KL_divergence: 8.6729
 61/200 [========>.....................] - ETA: 1s - loss: 12852.0113 - KL_divergence: 8.6603
 67/200 [=========>....................] - ETA: 1s - loss: 12893.5905 - KL_divergence: 8.6484
 73/200 [=========>....................] - ETA: 1s - loss: 12896.7975 - KL_divergence: 8.6576
 79/200 [==========>...................] - ETA: 1s - loss: 12865.9259 - KL_divergence: 8.6552
 85/200 [===========>..................] - ETA: 1s - loss: 12877.3231 - KL_divergence: 8.6463
 91/200 [============>.................] - ETA: 0s - loss: 12917.2249 - KL_divergence: 8.6359
 97/200 [=============>................] - ETA: 0s - loss: 12938.4836 - KL_divergence: 8.6190
103/200 [==============>...............] - ETA: 0s - loss: 12898.2834 - KL_divergence: 8.6328
109/200 [===============>..............] - ETA: 0s - loss: 12880.0726 - KL_divergence: 8.6212
115/200 [================>.............] - ETA: 0s - loss: 12884.3029 - KL_divergence: 8.6179
121/200 [=================>............] - ETA: 0s - loss: 12874.6836 - KL_divergence: 8.6166
127/200 [==================>...........] - ETA: 0s - loss: 12864.1766 - KL_divergence: 8.6162
133/200 [==================>...........] - ETA: 0s - loss: 12893.6630 - KL_divergence: 8.5984
139/200 [===================>..........] - ETA: 0s - loss: 12891.0795 - KL_divergence: 8.6097
145/200 [====================>.........] - ETA: 0s - loss: 12897.9836 - KL_divergence: 8.6088
151/200 [=====================>........] - ETA: 0s - loss: 12919.5177 - KL_divergence: 8.6069
157/200 [======================>.......] - ETA: 0s - loss: 12942.1494 - KL_divergence: 8.6049
164/200 [=======================>......] - ETA: 0s - loss: 12937.0651 - KL_divergence: 8.6091
171/200 [========================>.....] - ETA: 0s - loss: 12957.2461 - KL_divergence: 8.6015
177/200 [=========================>....] - ETA: 0s - loss: 12969.7174 - KL_divergence: 8.6049
183/200 [==========================>...] - ETA: 0s - loss: 12957.5470 - KL_divergence: 8.6051
189/200 [===========================>..] - ETA: 0s - loss: 12969.1666 - KL_divergence: 8.6050
195/200 [============================>.] - ETA: 0s - loss: 12966.8779 - KL_divergence: 8.6036
200/200 [==============================] - 2s 10ms/step - loss: 12966.5559 - KL_divergence: 8.6027 - val_loss: 13190.0460 - val_KL_divergence: 8.6621
Epoch 47/100

  1/200 [..............................] - ETA: 1s - loss: 13503.3721 - KL_divergence: 8.1747
  7/200 [>.............................] - ETA: 1s - loss: 12934.3590 - KL_divergence: 8.5950
 13/200 [>.............................] - ETA: 1s - loss: 12943.1813 - KL_divergence: 8.5674
 19/200 [=>............................] - ETA: 1s - loss: 13029.2129 - KL_divergence: 8.5267
 25/200 [==>...........................] - ETA: 1s - loss: 13046.9372 - KL_divergence: 8.5851
 31/200 [===>..........................] - ETA: 1s - loss: 13108.5582 - KL_divergence: 8.5761
 37/200 [====>.........................] - ETA: 1s - loss: 13070.5825 - KL_divergence: 8.5964
 43/200 [=====>........................] - ETA: 1s - loss: 13070.9133 - KL_divergence: 8.5963
 49/200 [======>.......................] - ETA: 1s - loss: 13067.5459 - KL_divergence: 8.5766
 55/200 [=======>......................] - ETA: 1s - loss: 12972.9574 - KL_divergence: 8.6077
 61/200 [========>.....................] - ETA: 1s - loss: 12992.3653 - KL_divergence: 8.5850
 67/200 [=========>....................] - ETA: 1s - loss: 12969.8957 - KL_divergence: 8.5850
 73/200 [=========>....................] - ETA: 1s - loss: 12969.8506 - KL_divergence: 8.5805
 79/200 [==========>...................] - ETA: 1s - loss: 12964.9304 - KL_divergence: 8.5627
 85/200 [===========>..................] - ETA: 1s - loss: 12986.8960 - KL_divergence: 8.5573
 91/200 [============>.................] - ETA: 1s - loss: 12998.7299 - KL_divergence: 8.5397
 97/200 [=============>................] - ETA: 0s - loss: 12953.4863 - KL_divergence: 8.5503
103/200 [==============>...............] - ETA: 0s - loss: 12970.4530 - KL_divergence: 8.5306
109/200 [===============>..............] - ETA: 0s - loss: 12962.2427 - KL_divergence: 8.5263
115/200 [================>.............] - ETA: 0s - loss: 12976.6369 - KL_divergence: 8.5241
121/200 [=================>............] - ETA: 0s - loss: 12967.6990 - KL_divergence: 8.5126
128/200 [==================>...........] - ETA: 0s - loss: 12962.0453 - KL_divergence: 8.5134
134/200 [===================>..........] - ETA: 0s - loss: 12953.5322 - KL_divergence: 8.5228
140/200 [====================>.........] - ETA: 0s - loss: 12967.3904 - KL_divergence: 8.5067
146/200 [====================>.........] - ETA: 0s - loss: 12977.5925 - KL_divergence: 8.5072
152/200 [=====================>........] - ETA: 0s - loss: 12939.0009 - KL_divergence: 8.5209
158/200 [======================>.......] - ETA: 0s - loss: 12948.6126 - KL_divergence: 8.5140
164/200 [=======================>......] - ETA: 0s - loss: 12940.7232 - KL_divergence: 8.5125
170/200 [========================>.....] - ETA: 0s - loss: 12930.3127 - KL_divergence: 8.5190
176/200 [=========================>....] - ETA: 0s - loss: 12945.8126 - KL_divergence: 8.5163
182/200 [==========================>...] - ETA: 0s - loss: 12948.2390 - KL_divergence: 8.5160
188/200 [===========================>..] - ETA: 0s - loss: 12953.8362 - KL_divergence: 8.5214
194/200 [============================>.] - ETA: 0s - loss: 12957.2782 - KL_divergence: 8.5114
200/200 [==============================] - 2s 10ms/step - loss: 12958.7715 - KL_divergence: 8.5084 - val_loss: 13285.7906 - val_KL_divergence: 8.1044
Epoch 48/100

  1/200 [..............................] - ETA: 1s - loss: 12376.7939 - KL_divergence: 7.7622
  7/200 [>.............................] - ETA: 1s - loss: 12476.7295 - KL_divergence: 8.6087
 13/200 [>.............................] - ETA: 1s - loss: 12706.3178 - KL_divergence: 8.5021
 19/200 [=>............................] - ETA: 1s - loss: 12835.5596 - KL_divergence: 8.5158
 25/200 [==>...........................] - ETA: 1s - loss: 12696.5033 - KL_divergence: 8.4896
 31/200 [===>..........................] - ETA: 1s - loss: 12778.6131 - KL_divergence: 8.4728
 37/200 [====>.........................] - ETA: 1s - loss: 12736.8277 - KL_divergence: 8.4890
 43/200 [=====>........................] - ETA: 1s - loss: 12791.4037 - KL_divergence: 8.5106
 49/200 [======>.......................] - ETA: 1s - loss: 12816.7208 - KL_divergence: 8.5006
 55/200 [=======>......................] - ETA: 1s - loss: 12810.0479 - KL_divergence: 8.5039
 61/200 [========>.....................] - ETA: 1s - loss: 12815.1041 - KL_divergence: 8.5199
 67/200 [=========>....................] - ETA: 1s - loss: 12833.5496 - KL_divergence: 8.5145
 73/200 [=========>....................] - ETA: 1s - loss: 12812.2296 - KL_divergence: 8.5372
 79/200 [==========>...................] - ETA: 1s - loss: 12800.3123 - KL_divergence: 8.5373
 85/200 [===========>..................] - ETA: 1s - loss: 12795.3580 - KL_divergence: 8.5614
 91/200 [============>.................] - ETA: 0s - loss: 12809.8927 - KL_divergence: 8.5621
 97/200 [=============>................] - ETA: 0s - loss: 12832.1736 - KL_divergence: 8.5653
103/200 [==============>...............] - ETA: 0s - loss: 12854.6615 - KL_divergence: 8.5654
109/200 [===============>..............] - ETA: 0s - loss: 12852.8670 - KL_divergence: 8.5771
115/200 [================>.............] - ETA: 0s - loss: 12872.7056 - KL_divergence: 8.5638
121/200 [=================>............] - ETA: 0s - loss: 12884.8451 - KL_divergence: 8.5514
127/200 [==================>...........] - ETA: 0s - loss: 12881.2199 - KL_divergence: 8.5481
133/200 [==================>...........] - ETA: 0s - loss: 12862.8848 - KL_divergence: 8.5571
139/200 [===================>..........] - ETA: 0s - loss: 12884.1289 - KL_divergence: 8.5475
145/200 [====================>.........] - ETA: 0s - loss: 12889.5736 - KL_divergence: 8.5436
151/200 [=====================>........] - ETA: 0s - loss: 12890.5882 - KL_divergence: 8.5410
157/200 [======================>.......] - ETA: 0s - loss: 12916.3265 - KL_divergence: 8.5344
163/200 [=======================>......] - ETA: 0s - loss: 12917.3396 - KL_divergence: 8.5342
169/200 [========================>.....] - ETA: 0s - loss: 12915.9360 - KL_divergence: 8.5263
175/200 [=========================>....] - ETA: 0s - loss: 12910.0903 - KL_divergence: 8.5284
181/200 [==========================>...] - ETA: 0s - loss: 12929.9697 - KL_divergence: 8.5175
187/200 [===========================>..] - ETA: 0s - loss: 12932.6985 - KL_divergence: 8.5194
193/200 [===========================>..] - ETA: 0s - loss: 12918.0917 - KL_divergence: 8.5251
199/200 [============================>.] - ETA: 0s - loss: 12924.9582 - KL_divergence: 8.5249
200/200 [==============================] - 2s 10ms/step - loss: 12931.3151 - KL_divergence: 8.5235 - val_loss: 13180.7905 - val_KL_divergence: 8.3428
Epoch 49/100

  1/200 [..............................] - ETA: 1s - loss: 13097.1885 - KL_divergence: 7.9287
  7/200 [>.............................] - ETA: 1s - loss: 13143.9806 - KL_divergence: 8.4221
 13/200 [>.............................] - ETA: 1s - loss: 12990.7556 - KL_divergence: 8.3859
 19/200 [=>............................] - ETA: 1s - loss: 12940.3998 - KL_divergence: 8.4040
 25/200 [==>...........................] - ETA: 1s - loss: 12966.6708 - KL_divergence: 8.4342
 31/200 [===>..........................] - ETA: 1s - loss: 13006.0477 - KL_divergence: 8.3931
 37/200 [====>.........................] - ETA: 1s - loss: 12987.0679 - KL_divergence: 8.4382
 43/200 [=====>........................] - ETA: 1s - loss: 12971.1243 - KL_divergence: 8.4646
 50/200 [======>.......................] - ETA: 1s - loss: 12925.1725 - KL_divergence: 8.4763
 57/200 [=======>......................] - ETA: 1s - loss: 12926.4724 - KL_divergence: 8.4946
 63/200 [========>.....................] - ETA: 1s - loss: 12912.9544 - KL_divergence: 8.4949
 69/200 [=========>....................] - ETA: 1s - loss: 12887.2232 - KL_divergence: 8.5012
 75/200 [==========>...................] - ETA: 1s - loss: 12885.1629 - KL_divergence: 8.5097
 81/200 [===========>..................] - ETA: 1s - loss: 12870.9704 - KL_divergence: 8.4978
 87/200 [============>.................] - ETA: 0s - loss: 12868.7697 - KL_divergence: 8.4821
 93/200 [============>.................] - ETA: 0s - loss: 12873.6305 - KL_divergence: 8.4710
 99/200 [=============>................] - ETA: 0s - loss: 12859.6956 - KL_divergence: 8.4713
105/200 [==============>...............] - ETA: 0s - loss: 12830.7091 - KL_divergence: 8.4698
111/200 [===============>..............] - ETA: 0s - loss: 12858.6103 - KL_divergence: 8.4745
117/200 [================>.............] - ETA: 0s - loss: 12851.5896 - KL_divergence: 8.4718
123/200 [=================>............] - ETA: 0s - loss: 12840.8762 - KL_divergence: 8.4675
129/200 [==================>...........] - ETA: 0s - loss: 12835.7587 - KL_divergence: 8.4680
135/200 [===================>..........] - ETA: 0s - loss: 12835.1376 - KL_divergence: 8.4730
141/200 [====================>.........] - ETA: 0s - loss: 12832.7966 - KL_divergence: 8.4782
147/200 [=====================>........] - ETA: 0s - loss: 12862.9518 - KL_divergence: 8.4538
153/200 [=====================>........] - ETA: 0s - loss: 12868.9009 - KL_divergence: 8.4499
159/200 [======================>.......] - ETA: 0s - loss: 12877.3571 - KL_divergence: 8.4415
165/200 [=======================>......] - ETA: 0s - loss: 12877.2996 - KL_divergence: 8.4410
171/200 [========================>.....] - ETA: 0s - loss: 12893.9927 - KL_divergence: 8.4302
177/200 [=========================>....] - ETA: 0s - loss: 12893.5349 - KL_divergence: 8.4336
183/200 [==========================>...] - ETA: 0s - loss: 12891.1358 - KL_divergence: 8.4266
189/200 [===========================>..] - ETA: 0s - loss: 12903.8375 - KL_divergence: 8.4242
195/200 [============================>.] - ETA: 0s - loss: 12893.0606 - KL_divergence: 8.4255
200/200 [==============================] - 2s 10ms/step - loss: 12890.1483 - KL_divergence: 8.4256 - val_loss: 13257.3523 - val_KL_divergence: 8.2768
Epoch 50/100

  1/200 [..............................] - ETA: 1s - loss: 12181.5078 - KL_divergence: 9.0856
  7/200 [>.............................] - ETA: 1s - loss: 12799.2589 - KL_divergence: 8.4800
 13/200 [>.............................] - ETA: 1s - loss: 12925.6600 - KL_divergence: 8.4379
 20/200 [==>...........................] - ETA: 1s - loss: 12879.7309 - KL_divergence: 8.4883
 26/200 [==>...........................] - ETA: 1s - loss: 12812.3868 - KL_divergence: 8.5238
 32/200 [===>..........................] - ETA: 1s - loss: 12825.7769 - KL_divergence: 8.5067
 38/200 [====>.........................] - ETA: 1s - loss: 12779.5483 - KL_divergence: 8.4997
 45/200 [=====>........................] - ETA: 1s - loss: 12806.2759 - KL_divergence: 8.4676
 52/200 [======>.......................] - ETA: 1s - loss: 12827.9791 - KL_divergence: 8.4710
 58/200 [=======>......................] - ETA: 1s - loss: 12858.2105 - KL_divergence: 8.4578
 64/200 [========>.....................] - ETA: 1s - loss: 12870.8648 - KL_divergence: 8.4469
 70/200 [=========>....................] - ETA: 1s - loss: 12869.2562 - KL_divergence: 8.4716
 76/200 [==========>...................] - ETA: 1s - loss: 12876.8296 - KL_divergence: 8.4591
 82/200 [===========>..................] - ETA: 1s - loss: 12859.7008 - KL_divergence: 8.4764
 88/200 [============>.................] - ETA: 0s - loss: 12880.7746 - KL_divergence: 8.4770
 94/200 [=============>................] - ETA: 0s - loss: 12875.2174 - KL_divergence: 8.4755
100/200 [==============>...............] - ETA: 0s - loss: 12836.2221 - KL_divergence: 8.4764
107/200 [===============>..............] - ETA: 0s - loss: 12846.6078 - KL_divergence: 8.4632
113/200 [===============>..............] - ETA: 0s - loss: 12857.9120 - KL_divergence: 8.4618
119/200 [================>.............] - ETA: 0s - loss: 12867.7507 - KL_divergence: 8.4581
125/200 [=================>............] - ETA: 0s - loss: 12863.9963 - KL_divergence: 8.4620
131/200 [==================>...........] - ETA: 0s - loss: 12867.2567 - KL_divergence: 8.4673
137/200 [===================>..........] - ETA: 0s - loss: 12869.2982 - KL_divergence: 8.4721
143/200 [====================>.........] - ETA: 0s - loss: 12899.2887 - KL_divergence: 8.4637
149/200 [=====================>........] - ETA: 0s - loss: 12913.6786 - KL_divergence: 8.4572
155/200 [======================>.......] - ETA: 0s - loss: 12928.4321 - KL_divergence: 8.4470
161/200 [=======================>......] - ETA: 0s - loss: 12921.0988 - KL_divergence: 8.4424
167/200 [========================>.....] - ETA: 0s - loss: 12921.0100 - KL_divergence: 8.4384
173/200 [========================>.....] - ETA: 0s - loss: 12921.4431 - KL_divergence: 8.4328
179/200 [=========================>....] - ETA: 0s - loss: 12917.4548 - KL_divergence: 8.4397
185/200 [==========================>...] - ETA: 0s - loss: 12913.0781 - KL_divergence: 8.4348
191/200 [===========================>..] - ETA: 0s - loss: 12905.4355 - KL_divergence: 8.4402
197/200 [============================>.] - ETA: 0s - loss: 12900.0068 - KL_divergence: 8.4425
200/200 [==============================] - 2s 10ms/step - loss: 12911.0499 - KL_divergence: 8.4398 - val_loss: 13148.0449 - val_KL_divergence: 8.3282
Epoch 51/100

  1/200 [..............................] - ETA: 1s - loss: 11860.7715 - KL_divergence: 8.2371
  7/200 [>.............................] - ETA: 1s - loss: 12634.9937 - KL_divergence: 8.3563
 14/200 [=>............................] - ETA: 1s - loss: 12754.4038 - KL_divergence: 8.4920
 20/200 [==>...........................] - ETA: 1s - loss: 12742.3503 - KL_divergence: 8.5238
 26/200 [==>...........................] - ETA: 1s - loss: 12736.0852 - KL_divergence: 8.4795
 32/200 [===>..........................] - ETA: 1s - loss: 12874.9358 - KL_divergence: 8.4174
 38/200 [====>.........................] - ETA: 1s - loss: 12839.2701 - KL_divergence: 8.4278
 44/200 [=====>........................] - ETA: 1s - loss: 12833.8974 - KL_divergence: 8.4050
 50/200 [======>.......................] - ETA: 1s - loss: 12769.5096 - KL_divergence: 8.4374
 56/200 [=======>......................] - ETA: 1s - loss: 12781.6545 - KL_divergence: 8.4438
 62/200 [========>.....................] - ETA: 1s - loss: 12805.0651 - KL_divergence: 8.4271
 68/200 [=========>....................] - ETA: 1s - loss: 12766.8920 - KL_divergence: 8.4501
 74/200 [==========>...................] - ETA: 1s - loss: 12750.6330 - KL_divergence: 8.4575
 80/200 [===========>..................] - ETA: 1s - loss: 12753.8911 - KL_divergence: 8.4534
 86/200 [===========>..................] - ETA: 1s - loss: 12790.9043 - KL_divergence: 8.4742
 92/200 [============>.................] - ETA: 0s - loss: 12785.5228 - KL_divergence: 8.4701
 98/200 [=============>................] - ETA: 0s - loss: 12803.1698 - KL_divergence: 8.4593
104/200 [==============>...............] - ETA: 0s - loss: 12802.7473 - KL_divergence: 8.4591
111/200 [===============>..............] - ETA: 0s - loss: 12830.2845 - KL_divergence: 8.4532
118/200 [================>.............] - ETA: 0s - loss: 12807.6153 - KL_divergence: 8.4490
124/200 [=================>............] - ETA: 0s - loss: 12809.1432 - KL_divergence: 8.4492
130/200 [==================>...........] - ETA: 0s - loss: 12783.0267 - KL_divergence: 8.4626
136/200 [===================>..........] - ETA: 0s - loss: 12794.6877 - KL_divergence: 8.4607
142/200 [====================>.........] - ETA: 0s - loss: 12767.8155 - KL_divergence: 8.4728
148/200 [=====================>........] - ETA: 0s - loss: 12769.3386 - KL_divergence: 8.4748
154/200 [======================>.......] - ETA: 0s - loss: 12788.2255 - KL_divergence: 8.4630
160/200 [=======================>......] - ETA: 0s - loss: 12789.0389 - KL_divergence: 8.4543
166/200 [=======================>......] - ETA: 0s - loss: 12810.8909 - KL_divergence: 8.4485
172/200 [========================>.....] - ETA: 0s - loss: 12829.7951 - KL_divergence: 8.4441
178/200 [=========================>....] - ETA: 0s - loss: 12829.1759 - KL_divergence: 8.4382
184/200 [==========================>...] - ETA: 0s - loss: 12838.3259 - KL_divergence: 8.4362
190/200 [===========================>..] - ETA: 0s - loss: 12825.2311 - KL_divergence: 8.4389
196/200 [============================>.] - ETA: 0s - loss: 12825.3088 - KL_divergence: 8.4329
200/200 [==============================] - 2s 10ms/step - loss: 12825.0662 - KL_divergence: 8.4327 - val_loss: 13104.2507 - val_KL_divergence: 7.9614
Epoch 52/100

  1/200 [..............................] - ETA: 1s - loss: 12541.0625 - KL_divergence: 8.0093
  7/200 [>.............................] - ETA: 1s - loss: 12567.6876 - KL_divergence: 8.5354
 13/200 [>.............................] - ETA: 1s - loss: 12721.3623 - KL_divergence: 8.5049
 19/200 [=>............................] - ETA: 1s - loss: 12764.2688 - KL_divergence: 8.4938
 25/200 [==>...........................] - ETA: 1s - loss: 12838.4873 - KL_divergence: 8.4657
 31/200 [===>..........................] - ETA: 1s - loss: 12878.8231 - KL_divergence: 8.4698
 37/200 [====>.........................] - ETA: 1s - loss: 12907.0493 - KL_divergence: 8.4607
 43/200 [=====>........................] - ETA: 1s - loss: 12877.1755 - KL_divergence: 8.4904
 49/200 [======>.......................] - ETA: 1s - loss: 12818.5235 - KL_divergence: 8.5045
 55/200 [=======>......................] - ETA: 1s - loss: 12846.0972 - KL_divergence: 8.4817
 61/200 [========>.....................] - ETA: 1s - loss: 12817.6465 - KL_divergence: 8.4779
 67/200 [=========>....................] - ETA: 1s - loss: 12855.4142 - KL_divergence: 8.4383
 73/200 [=========>....................] - ETA: 1s - loss: 12860.3522 - KL_divergence: 8.4312
 79/200 [==========>...................] - ETA: 1s - loss: 12883.0222 - KL_divergence: 8.4293
 85/200 [===========>..................] - ETA: 1s - loss: 12873.0933 - KL_divergence: 8.4333
 91/200 [============>.................] - ETA: 0s - loss: 12851.1311 - KL_divergence: 8.4294
 97/200 [=============>................] - ETA: 0s - loss: 12845.2503 - KL_divergence: 8.4259
103/200 [==============>...............] - ETA: 0s - loss: 12853.9756 - KL_divergence: 8.4277
109/200 [===============>..............] - ETA: 0s - loss: 12823.7614 - KL_divergence: 8.4365
115/200 [================>.............] - ETA: 0s - loss: 12825.5841 - KL_divergence: 8.4415
121/200 [=================>............] - ETA: 0s - loss: 12830.1680 - KL_divergence: 8.4537
127/200 [==================>...........] - ETA: 0s - loss: 12843.7045 - KL_divergence: 8.4472
133/200 [==================>...........] - ETA: 0s - loss: 12848.2660 - KL_divergence: 8.4447
139/200 [===================>..........] - ETA: 0s - loss: 12857.4782 - KL_divergence: 8.4505
145/200 [====================>.........] - ETA: 0s - loss: 12862.3793 - KL_divergence: 8.4571
151/200 [=====================>........] - ETA: 0s - loss: 12864.3020 - KL_divergence: 8.4630
157/200 [======================>.......] - ETA: 0s - loss: 12858.5372 - KL_divergence: 8.4645
163/200 [=======================>......] - ETA: 0s - loss: 12846.3622 - KL_divergence: 8.4639
169/200 [========================>.....] - ETA: 0s - loss: 12852.2171 - KL_divergence: 8.4640
175/200 [=========================>....] - ETA: 0s - loss: 12853.7855 - KL_divergence: 8.4609
181/200 [==========================>...] - ETA: 0s - loss: 12841.0340 - KL_divergence: 8.4569
187/200 [===========================>..] - ETA: 0s - loss: 12861.9468 - KL_divergence: 8.4549
193/200 [===========================>..] - ETA: 0s - loss: 12846.1201 - KL_divergence: 8.4633
199/200 [============================>.] - ETA: 0s - loss: 12845.7406 - KL_divergence: 8.4517
200/200 [==============================] - 2s 10ms/step - loss: 12845.2837 - KL_divergence: 8.4525 - val_loss: 13149.6449 - val_KL_divergence: 8.2889
Epoch 53/100

  1/200 [..............................] - ETA: 1s - loss: 11818.9375 - KL_divergence: 8.2172
  7/200 [>.............................] - ETA: 1s - loss: 12346.8905 - KL_divergence: 8.4730
 13/200 [>.............................] - ETA: 1s - loss: 12527.4791 - KL_divergence: 8.3544
 19/200 [=>............................] - ETA: 1s - loss: 12820.3119 - KL_divergence: 8.3251
 25/200 [==>...........................] - ETA: 1s - loss: 12900.4025 - KL_divergence: 8.3240
 31/200 [===>..........................] - ETA: 1s - loss: 12877.1996 - KL_divergence: 8.3575
 37/200 [====>.........................] - ETA: 1s - loss: 12880.6697 - KL_divergence: 8.3391
 43/200 [=====>........................] - ETA: 1s - loss: 12855.3907 - KL_divergence: 8.3810
 49/200 [======>.......................] - ETA: 1s - loss: 12872.9109 - KL_divergence: 8.3811
 55/200 [=======>......................] - ETA: 1s - loss: 12844.4527 - KL_divergence: 8.3691
 61/200 [========>.....................] - ETA: 1s - loss: 12823.2742 - KL_divergence: 8.3562
 67/200 [=========>....................] - ETA: 1s - loss: 12853.5916 - KL_divergence: 8.3502
 73/200 [=========>....................] - ETA: 1s - loss: 12798.7994 - KL_divergence: 8.3753
 79/200 [==========>...................] - ETA: 1s - loss: 12773.2523 - KL_divergence: 8.4030
 85/200 [===========>..................] - ETA: 1s - loss: 12761.0128 - KL_divergence: 8.4075
 91/200 [============>.................] - ETA: 0s - loss: 12768.8762 - KL_divergence: 8.4151
 97/200 [=============>................] - ETA: 0s - loss: 12760.7338 - KL_divergence: 8.4282
103/200 [==============>...............] - ETA: 0s - loss: 12747.6651 - KL_divergence: 8.4214
109/200 [===============>..............] - ETA: 0s - loss: 12747.0767 - KL_divergence: 8.4213
115/200 [================>.............] - ETA: 0s - loss: 12780.2579 - KL_divergence: 8.4079
121/200 [=================>............] - ETA: 0s - loss: 12795.7900 - KL_divergence: 8.4101
127/200 [==================>...........] - ETA: 0s - loss: 12790.2186 - KL_divergence: 8.4249
133/200 [==================>...........] - ETA: 0s - loss: 12773.1203 - KL_divergence: 8.4228
139/200 [===================>..........] - ETA: 0s - loss: 12774.3763 - KL_divergence: 8.4372
145/200 [====================>.........] - ETA: 0s - loss: 12793.3952 - KL_divergence: 8.4206
151/200 [=====================>........] - ETA: 0s - loss: 12789.6431 - KL_divergence: 8.4209
157/200 [======================>.......] - ETA: 0s - loss: 12817.7930 - KL_divergence: 8.4038
163/200 [=======================>......] - ETA: 0s - loss: 12809.4973 - KL_divergence: 8.3992
169/200 [========================>.....] - ETA: 0s - loss: 12802.3138 - KL_divergence: 8.4013
175/200 [=========================>....] - ETA: 0s - loss: 12809.4437 - KL_divergence: 8.4011
181/200 [==========================>...] - ETA: 0s - loss: 12816.4215 - KL_divergence: 8.4000
187/200 [===========================>..] - ETA: 0s - loss: 12833.2845 - KL_divergence: 8.3947
193/200 [===========================>..] - ETA: 0s - loss: 12830.2237 - KL_divergence: 8.3908
199/200 [============================>.] - ETA: 0s - loss: 12833.9866 - KL_divergence: 8.3882
200/200 [==============================] - 2s 10ms/step - loss: 12840.1720 - KL_divergence: 8.3882 - val_loss: 13048.1438 - val_KL_divergence: 8.3879
Epoch 54/100

  1/200 [..............................] - ETA: 1s - loss: 12322.3525 - KL_divergence: 8.4113
  7/200 [>.............................] - ETA: 1s - loss: 13053.3076 - KL_divergence: 8.2751
 13/200 [>.............................] - ETA: 1s - loss: 12964.4573 - KL_divergence: 8.2820
 19/200 [=>............................] - ETA: 1s - loss: 12795.8452 - KL_divergence: 8.3077
 25/200 [==>...........................] - ETA: 1s - loss: 12848.0722 - KL_divergence: 8.3402
 31/200 [===>..........................] - ETA: 1s - loss: 12807.5855 - KL_divergence: 8.3325
 37/200 [====>.........................] - ETA: 1s - loss: 12812.4237 - KL_divergence: 8.3361
 43/200 [=====>........................] - ETA: 1s - loss: 12767.6691 - KL_divergence: 8.3544
 50/200 [======>.......................] - ETA: 1s - loss: 12734.1640 - KL_divergence: 8.3777
 56/200 [=======>......................] - ETA: 1s - loss: 12787.2699 - KL_divergence: 8.3574
 62/200 [========>.....................] - ETA: 1s - loss: 12802.2016 - KL_divergence: 8.3456
 68/200 [=========>....................] - ETA: 1s - loss: 12739.9005 - KL_divergence: 8.3758
 74/200 [==========>...................] - ETA: 1s - loss: 12770.4678 - KL_divergence: 8.3681
 80/200 [===========>..................] - ETA: 1s - loss: 12765.7635 - KL_divergence: 8.3626
 86/200 [===========>..................] - ETA: 1s - loss: 12748.6130 - KL_divergence: 8.3683
 92/200 [============>.................] - ETA: 0s - loss: 12694.3989 - KL_divergence: 8.3839
 98/200 [=============>................] - ETA: 0s - loss: 12671.3163 - KL_divergence: 8.4086
104/200 [==============>...............] - ETA: 0s - loss: 12663.1088 - KL_divergence: 8.4271
110/200 [===============>..............] - ETA: 0s - loss: 12661.3662 - KL_divergence: 8.4377
116/200 [================>.............] - ETA: 0s - loss: 12676.4293 - KL_divergence: 8.4379
122/200 [=================>............] - ETA: 0s - loss: 12686.6399 - KL_divergence: 8.4349
128/200 [==================>...........] - ETA: 0s - loss: 12699.8255 - KL_divergence: 8.4239
134/200 [===================>..........] - ETA: 0s - loss: 12714.4286 - KL_divergence: 8.4052
141/200 [====================>.........] - ETA: 0s - loss: 12714.4232 - KL_divergence: 8.4042
147/200 [=====================>........] - ETA: 0s - loss: 12744.1326 - KL_divergence: 8.3973
154/200 [======================>.......] - ETA: 0s - loss: 12760.1892 - KL_divergence: 8.3833
160/200 [=======================>......] - ETA: 0s - loss: 12755.3319 - KL_divergence: 8.3747
166/200 [=======================>......] - ETA: 0s - loss: 12738.0433 - KL_divergence: 8.3722
172/200 [========================>.....] - ETA: 0s - loss: 12720.0138 - KL_divergence: 8.3773
178/200 [=========================>....] - ETA: 0s - loss: 12725.2626 - KL_divergence: 8.3672
184/200 [==========================>...] - ETA: 0s - loss: 12739.4104 - KL_divergence: 8.3603
190/200 [===========================>..] - ETA: 0s - loss: 12742.0171 - KL_divergence: 8.3562
196/200 [============================>.] - ETA: 0s - loss: 12733.4558 - KL_divergence: 8.3614
200/200 [==============================] - 2s 10ms/step - loss: 12726.0483 - KL_divergence: 8.3611 - val_loss: 13264.0412 - val_KL_divergence: 7.5325
Epoch 55/100

  1/200 [..............................] - ETA: 1s - loss: 11202.5859 - KL_divergence: 7.8669
  7/200 [>.............................] - ETA: 1s - loss: 12249.1003 - KL_divergence: 8.4916
 13/200 [>.............................] - ETA: 1s - loss: 12657.2087 - KL_divergence: 8.3079
 19/200 [=>............................] - ETA: 1s - loss: 12398.7132 - KL_divergence: 8.3893
 25/200 [==>...........................] - ETA: 1s - loss: 12496.2716 - KL_divergence: 8.4089
 31/200 [===>..........................] - ETA: 1s - loss: 12601.5520 - KL_divergence: 8.3514
 37/200 [====>.........................] - ETA: 1s - loss: 12589.8909 - KL_divergence: 8.3811
 43/200 [=====>........................] - ETA: 1s - loss: 12612.0878 - KL_divergence: 8.4003
 49/200 [======>.......................] - ETA: 1s - loss: 12641.9776 - KL_divergence: 8.3869
 55/200 [=======>......................] - ETA: 1s - loss: 12566.5312 - KL_divergence: 8.3920
 61/200 [========>.....................] - ETA: 1s - loss: 12565.9279 - KL_divergence: 8.3703
 67/200 [=========>....................] - ETA: 1s - loss: 12614.3927 - KL_divergence: 8.3696
 73/200 [=========>....................] - ETA: 1s - loss: 12612.1028 - KL_divergence: 8.3430
 80/200 [===========>..................] - ETA: 1s - loss: 12635.6895 - KL_divergence: 8.3283
 87/200 [============>.................] - ETA: 1s - loss: 12650.3109 - KL_divergence: 8.3254
 94/200 [=============>................] - ETA: 0s - loss: 12596.2762 - KL_divergence: 8.3480
100/200 [==============>...............] - ETA: 0s - loss: 12625.9971 - KL_divergence: 8.3360
107/200 [===============>..............] - ETA: 0s - loss: 12668.5093 - KL_divergence: 8.3245
113/200 [===============>..............] - ETA: 0s - loss: 12646.8610 - KL_divergence: 8.3449
119/200 [================>.............] - ETA: 0s - loss: 12628.7171 - KL_divergence: 8.3502
126/200 [=================>............] - ETA: 0s - loss: 12637.1180 - KL_divergence: 8.3459
133/200 [==================>...........] - ETA: 0s - loss: 12632.3193 - KL_divergence: 8.3379
140/200 [====================>.........] - ETA: 0s - loss: 12636.3801 - KL_divergence: 8.3390
147/200 [=====================>........] - ETA: 0s - loss: 12627.2665 - KL_divergence: 8.3437
153/200 [=====================>........] - ETA: 0s - loss: 12647.3370 - KL_divergence: 8.3329
159/200 [======================>.......] - ETA: 0s - loss: 12650.1602 - KL_divergence: 8.3309
165/200 [=======================>......] - ETA: 0s - loss: 12658.9619 - KL_divergence: 8.3201
171/200 [========================>.....] - ETA: 0s - loss: 12674.2780 - KL_divergence: 8.3113
177/200 [=========================>....] - ETA: 0s - loss: 12675.4357 - KL_divergence: 8.3109
183/200 [==========================>...] - ETA: 0s - loss: 12685.6051 - KL_divergence: 8.3111
189/200 [===========================>..] - ETA: 0s - loss: 12699.1608 - KL_divergence: 8.3058
195/200 [============================>.] - ETA: 0s - loss: 12712.9451 - KL_divergence: 8.3028
200/200 [==============================] - 2s 10ms/step - loss: 12719.6910 - KL_divergence: 8.3011 - val_loss: 13074.8678 - val_KL_divergence: 8.1355
Epoch 56/100

  1/200 [..............................] - ETA: 1s - loss: 12603.8486 - KL_divergence: 8.6957
  7/200 [>.............................] - ETA: 1s - loss: 12410.0063 - KL_divergence: 8.6640
 13/200 [>.............................] - ETA: 1s - loss: 12683.1938 - KL_divergence: 8.4364
 19/200 [=>............................] - ETA: 1s - loss: 12713.4106 - KL_divergence: 8.4080
 25/200 [==>...........................] - ETA: 1s - loss: 12782.3739 - KL_divergence: 8.3811
 31/200 [===>..........................] - ETA: 1s - loss: 12710.6961 - KL_divergence: 8.3777
 37/200 [====>.........................] - ETA: 1s - loss: 12692.1838 - KL_divergence: 8.3724
 43/200 [=====>........................] - ETA: 1s - loss: 12667.8086 - KL_divergence: 8.3625
 49/200 [======>.......................] - ETA: 1s - loss: 12650.5672 - KL_divergence: 8.3728
 55/200 [=======>......................] - ETA: 1s - loss: 12679.2672 - KL_divergence: 8.3688
 61/200 [========>.....................] - ETA: 1s - loss: 12661.9068 - KL_divergence: 8.3746
 67/200 [=========>....................] - ETA: 1s - loss: 12675.9354 - KL_divergence: 8.3636
 73/200 [=========>....................] - ETA: 1s - loss: 12721.6091 - KL_divergence: 8.3628
 79/200 [==========>...................] - ETA: 1s - loss: 12714.0100 - KL_divergence: 8.3467
 85/200 [===========>..................] - ETA: 1s - loss: 12734.2031 - KL_divergence: 8.3484
 91/200 [============>.................] - ETA: 1s - loss: 12709.8487 - KL_divergence: 8.3519
 98/200 [=============>................] - ETA: 0s - loss: 12741.0630 - KL_divergence: 8.3320
104/200 [==============>...............] - ETA: 0s - loss: 12731.5623 - KL_divergence: 8.3317
110/200 [===============>..............] - ETA: 0s - loss: 12758.5137 - KL_divergence: 8.3187
116/200 [================>.............] - ETA: 0s - loss: 12766.5698 - KL_divergence: 8.3190
122/200 [=================>............] - ETA: 0s - loss: 12786.5507 - KL_divergence: 8.3033
128/200 [==================>...........] - ETA: 0s - loss: 12768.7129 - KL_divergence: 8.3086
134/200 [===================>..........] - ETA: 0s - loss: 12756.5575 - KL_divergence: 8.3039
140/200 [====================>.........] - ETA: 0s - loss: 12753.6629 - KL_divergence: 8.3013
146/200 [====================>.........] - ETA: 0s - loss: 12763.1944 - KL_divergence: 8.2913
152/200 [=====================>........] - ETA: 0s - loss: 12765.7169 - KL_divergence: 8.2905
158/200 [======================>.......] - ETA: 0s - loss: 12772.8010 - KL_divergence: 8.2871
164/200 [=======================>......] - ETA: 0s - loss: 12754.3474 - KL_divergence: 8.2901
171/200 [========================>.....] - ETA: 0s - loss: 12746.6732 - KL_divergence: 8.2943
177/200 [=========================>....] - ETA: 0s - loss: 12750.5481 - KL_divergence: 8.2902
183/200 [==========================>...] - ETA: 0s - loss: 12760.2475 - KL_divergence: 8.2820
190/200 [===========================>..] - ETA: 0s - loss: 12763.6009 - KL_divergence: 8.2822
196/200 [============================>.] - ETA: 0s - loss: 12781.2510 - KL_divergence: 8.2702
200/200 [==============================] - 2s 10ms/step - loss: 12772.6062 - KL_divergence: 8.2752 - val_loss: 13128.7740 - val_KL_divergence: 8.4310
Epoch 57/100

  1/200 [..............................] - ETA: 1s - loss: 14346.5938 - KL_divergence: 8.2324
  7/200 [>.............................] - ETA: 1s - loss: 12831.3136 - KL_divergence: 8.3421
 13/200 [>.............................] - ETA: 1s - loss: 13002.8976 - KL_divergence: 8.2415
 19/200 [=>............................] - ETA: 1s - loss: 13086.4092 - KL_divergence: 8.2105
 25/200 [==>...........................] - ETA: 1s - loss: 12970.5230 - KL_divergence: 8.2580
 31/200 [===>..........................] - ETA: 1s - loss: 12951.3418 - KL_divergence: 8.2485
 37/200 [====>.........................] - ETA: 1s - loss: 12927.9932 - KL_divergence: 8.2733
 43/200 [=====>........................] - ETA: 1s - loss: 12893.7519 - KL_divergence: 8.3171
 49/200 [======>.......................] - ETA: 1s - loss: 12850.2288 - KL_divergence: 8.3248
 55/200 [=======>......................] - ETA: 1s - loss: 12853.8259 - KL_divergence: 8.3265
 61/200 [========>.....................] - ETA: 1s - loss: 12853.8670 - KL_divergence: 8.3335
 67/200 [=========>....................] - ETA: 1s - loss: 12830.3384 - KL_divergence: 8.3084
 73/200 [=========>....................] - ETA: 1s - loss: 12807.6288 - KL_divergence: 8.3246
 79/200 [==========>...................] - ETA: 1s - loss: 12772.7052 - KL_divergence: 8.3284
 85/200 [===========>..................] - ETA: 1s - loss: 12752.3607 - KL_divergence: 8.3255
 91/200 [============>.................] - ETA: 1s - loss: 12728.1108 - KL_divergence: 8.3302
 97/200 [=============>................] - ETA: 0s - loss: 12684.5737 - KL_divergence: 8.3448
103/200 [==============>...............] - ETA: 0s - loss: 12714.9270 - KL_divergence: 8.3443
109/200 [===============>..............] - ETA: 0s - loss: 12705.1406 - KL_divergence: 8.3384
115/200 [================>.............] - ETA: 0s - loss: 12713.5643 - KL_divergence: 8.3369
121/200 [=================>............] - ETA: 0s - loss: 12687.9324 - KL_divergence: 8.3402
127/200 [==================>...........] - ETA: 0s - loss: 12666.1025 - KL_divergence: 8.3393
133/200 [==================>...........] - ETA: 0s - loss: 12664.1921 - KL_divergence: 8.3490
139/200 [===================>..........] - ETA: 0s - loss: 12668.8835 - KL_divergence: 8.3471
145/200 [====================>.........] - ETA: 0s - loss: 12662.3645 - KL_divergence: 8.3484
150/200 [=====================>........] - ETA: 0s - loss: 12660.9160 - KL_divergence: 8.3429
156/200 [======================>.......] - ETA: 0s - loss: 12685.6964 - KL_divergence: 8.3316
162/200 [=======================>......] - ETA: 0s - loss: 12697.4676 - KL_divergence: 8.3214
168/200 [========================>.....] - ETA: 0s - loss: 12712.3479 - KL_divergence: 8.3070
174/200 [=========================>....] - ETA: 0s - loss: 12703.2919 - KL_divergence: 8.3085
180/200 [==========================>...] - ETA: 0s - loss: 12705.2892 - KL_divergence: 8.3037
186/200 [==========================>...] - ETA: 0s - loss: 12715.7992 - KL_divergence: 8.2980
192/200 [===========================>..] - ETA: 0s - loss: 12715.5069 - KL_divergence: 8.2978
198/200 [============================>.] - ETA: 0s - loss: 12717.1951 - KL_divergence: 8.2956
200/200 [==============================] - 2s 10ms/step - loss: 12727.6359 - KL_divergence: 8.2909 - val_loss: 13289.4909 - val_KL_divergence: 7.8422
Epoch 58/100

  1/200 [..............................] - ETA: 1s - loss: 11436.8223 - KL_divergence: 8.0475
  7/200 [>.............................] - ETA: 1s - loss: 12245.9350 - KL_divergence: 8.3640
 13/200 [>.............................] - ETA: 1s - loss: 12238.1813 - KL_divergence: 8.3865
 19/200 [=>............................] - ETA: 1s - loss: 12255.5310 - KL_divergence: 8.3807
 25/200 [==>...........................] - ETA: 1s - loss: 12302.3280 - KL_divergence: 8.3812
 31/200 [===>..........................] - ETA: 1s - loss: 12430.5054 - KL_divergence: 8.3738
 37/200 [====>.........................] - ETA: 1s - loss: 12448.2844 - KL_divergence: 8.3907
 43/200 [=====>........................] - ETA: 1s - loss: 12476.6193 - KL_divergence: 8.3842
 49/200 [======>.......................] - ETA: 1s - loss: 12458.7271 - KL_divergence: 8.3894
 55/200 [=======>......................] - ETA: 1s - loss: 12442.2751 - KL_divergence: 8.4206
 62/200 [========>.....................] - ETA: 1s - loss: 12499.8153 - KL_divergence: 8.4017
 68/200 [=========>....................] - ETA: 1s - loss: 12531.5489 - KL_divergence: 8.4092
 74/200 [==========>...................] - ETA: 1s - loss: 12557.0861 - KL_divergence: 8.3772
 80/200 [===========>..................] - ETA: 1s - loss: 12602.7899 - KL_divergence: 8.3712
 86/200 [===========>..................] - ETA: 1s - loss: 12606.8918 - KL_divergence: 8.3613
 92/200 [============>.................] - ETA: 0s - loss: 12636.4006 - KL_divergence: 8.3450
 98/200 [=============>................] - ETA: 0s - loss: 12626.9895 - KL_divergence: 8.3472
104/200 [==============>...............] - ETA: 0s - loss: 12620.5187 - KL_divergence: 8.3403
110/200 [===============>..............] - ETA: 0s - loss: 12636.0183 - KL_divergence: 8.3314
116/200 [================>.............] - ETA: 0s - loss: 12653.6851 - KL_divergence: 8.3320
122/200 [=================>............] - ETA: 0s - loss: 12651.5651 - KL_divergence: 8.3377
128/200 [==================>...........] - ETA: 0s - loss: 12654.0962 - KL_divergence: 8.3254
134/200 [===================>..........] - ETA: 0s - loss: 12665.9130 - KL_divergence: 8.3283
140/200 [====================>.........] - ETA: 0s - loss: 12658.5930 - KL_divergence: 8.3210
146/200 [====================>.........] - ETA: 0s - loss: 12663.2350 - KL_divergence: 8.3183
152/200 [=====================>........] - ETA: 0s - loss: 12659.7597 - KL_divergence: 8.3196
158/200 [======================>.......] - ETA: 0s - loss: 12662.2628 - KL_divergence: 8.3133
164/200 [=======================>......] - ETA: 0s - loss: 12681.1969 - KL_divergence: 8.3097
170/200 [========================>.....] - ETA: 0s - loss: 12665.2388 - KL_divergence: 8.3115
176/200 [=========================>....] - ETA: 0s - loss: 12653.3107 - KL_divergence: 8.3153
182/200 [==========================>...] - ETA: 0s - loss: 12654.3861 - KL_divergence: 8.3203
188/200 [===========================>..] - ETA: 0s - loss: 12640.3614 - KL_divergence: 8.3191
194/200 [============================>.] - ETA: 0s - loss: 12652.5837 - KL_divergence: 8.3183
200/200 [==============================] - 2s 10ms/step - loss: 12665.7306 - KL_divergence: 8.3161 - val_loss: 13129.3771 - val_KL_divergence: 7.8396
Epoch 59/100

  1/200 [..............................] - ETA: 1s - loss: 12638.0322 - KL_divergence: 7.7998
  7/200 [>.............................] - ETA: 1s - loss: 12455.5505 - KL_divergence: 8.2002
 13/200 [>.............................] - ETA: 1s - loss: 12483.6753 - KL_divergence: 8.2990
 19/200 [=>............................] - ETA: 1s - loss: 12540.2643 - KL_divergence: 8.2785
 25/200 [==>...........................] - ETA: 1s - loss: 12504.8774 - KL_divergence: 8.2695
 31/200 [===>..........................] - ETA: 1s - loss: 12620.3942 - KL_divergence: 8.2006
 37/200 [====>.........................] - ETA: 1s - loss: 12662.2790 - KL_divergence: 8.1983
 43/200 [=====>........................] - ETA: 1s - loss: 12645.0155 - KL_divergence: 8.2137
 49/200 [======>.......................] - ETA: 1s - loss: 12661.7510 - KL_divergence: 8.1868
 56/200 [=======>......................] - ETA: 1s - loss: 12692.9928 - KL_divergence: 8.1683
 62/200 [========>.....................] - ETA: 1s - loss: 12749.3902 - KL_divergence: 8.1680
 68/200 [=========>....................] - ETA: 1s - loss: 12749.5744 - KL_divergence: 8.1773
 74/200 [==========>...................] - ETA: 1s - loss: 12760.0485 - KL_divergence: 8.1812
 80/200 [===========>..................] - ETA: 1s - loss: 12786.0161 - KL_divergence: 8.1762
 86/200 [===========>..................] - ETA: 1s - loss: 12783.4235 - KL_divergence: 8.1901
 92/200 [============>.................] - ETA: 0s - loss: 12773.6919 - KL_divergence: 8.2089
 98/200 [=============>................] - ETA: 0s - loss: 12785.3865 - KL_divergence: 8.2211
104/200 [==============>...............] - ETA: 0s - loss: 12786.3416 - KL_divergence: 8.2355
109/200 [===============>..............] - ETA: 0s - loss: 12770.3300 - KL_divergence: 8.2290
115/200 [================>.............] - ETA: 0s - loss: 12750.8995 - KL_divergence: 8.2369
121/200 [=================>............] - ETA: 0s - loss: 12773.1954 - KL_divergence: 8.2242
127/200 [==================>...........] - ETA: 0s - loss: 12759.9988 - KL_divergence: 8.2336
132/200 [==================>...........] - ETA: 0s - loss: 12738.5554 - KL_divergence: 8.2313
138/200 [===================>..........] - ETA: 0s - loss: 12740.7174 - KL_divergence: 8.2294
144/200 [====================>.........] - ETA: 0s - loss: 12738.0942 - KL_divergence: 8.2294
150/200 [=====================>........] - ETA: 0s - loss: 12740.1372 - KL_divergence: 8.2241
156/200 [======================>.......] - ETA: 0s - loss: 12730.2838 - KL_divergence: 8.2200
162/200 [=======================>......] - ETA: 0s - loss: 12712.0453 - KL_divergence: 8.2374
168/200 [========================>.....] - ETA: 0s - loss: 12720.1592 - KL_divergence: 8.2376
174/200 [=========================>....] - ETA: 0s - loss: 12709.0359 - KL_divergence: 8.2352
180/200 [==========================>...] - ETA: 0s - loss: 12719.2096 - KL_divergence: 8.2259
186/200 [==========================>...] - ETA: 0s - loss: 12704.7455 - KL_divergence: 8.2304
192/200 [===========================>..] - ETA: 0s - loss: 12700.8275 - KL_divergence: 8.2273
198/200 [============================>.] - ETA: 0s - loss: 12696.4700 - KL_divergence: 8.2272
200/200 [==============================] - 2s 10ms/step - loss: 12688.0842 - KL_divergence: 8.2256 - val_loss: 12978.7630 - val_KL_divergence: 7.9690
Epoch 60/100

  1/200 [..............................] - ETA: 1s - loss: 12160.5127 - KL_divergence: 8.1982
  8/200 [>.............................] - ETA: 1s - loss: 12149.8881 - KL_divergence: 8.1600
 14/200 [=>............................] - ETA: 1s - loss: 12284.4565 - KL_divergence: 8.1904
 20/200 [==>...........................] - ETA: 1s - loss: 12330.2296 - KL_divergence: 8.1796
 26/200 [==>...........................] - ETA: 1s - loss: 12365.1173 - KL_divergence: 8.1740
 32/200 [===>..........................] - ETA: 1s - loss: 12557.5399 - KL_divergence: 8.1450
 37/200 [====>.........................] - ETA: 1s - loss: 12606.1542 - KL_divergence: 8.1206
 43/200 [=====>........................] - ETA: 1s - loss: 12565.0266 - KL_divergence: 8.1374
 49/200 [======>.......................] - ETA: 1s - loss: 12594.5811 - KL_divergence: 8.1300
 55/200 [=======>......................] - ETA: 1s - loss: 12618.7318 - KL_divergence: 8.1265
 61/200 [========>.....................] - ETA: 1s - loss: 12632.3202 - KL_divergence: 8.1028
 67/200 [=========>....................] - ETA: 1s - loss: 12603.4714 - KL_divergence: 8.1238
 73/200 [=========>....................] - ETA: 1s - loss: 12631.4573 - KL_divergence: 8.1136
 79/200 [==========>...................] - ETA: 1s - loss: 12645.1990 - KL_divergence: 8.1106
 85/200 [===========>..................] - ETA: 1s - loss: 12678.7108 - KL_divergence: 8.1028
 91/200 [============>.................] - ETA: 0s - loss: 12689.8259 - KL_divergence: 8.1065
 97/200 [=============>................] - ETA: 0s - loss: 12680.7636 - KL_divergence: 8.1062
103/200 [==============>...............] - ETA: 0s - loss: 12644.7859 - KL_divergence: 8.1169
109/200 [===============>..............] - ETA: 0s - loss: 12667.4121 - KL_divergence: 8.1175
115/200 [================>.............] - ETA: 0s - loss: 12655.9999 - KL_divergence: 8.1114
121/200 [=================>............] - ETA: 0s - loss: 12663.4700 - KL_divergence: 8.1106
127/200 [==================>...........] - ETA: 0s - loss: 12632.2923 - KL_divergence: 8.1316
133/200 [==================>...........] - ETA: 0s - loss: 12646.6334 - KL_divergence: 8.1195
139/200 [===================>..........] - ETA: 0s - loss: 12634.7052 - KL_divergence: 8.1268
145/200 [====================>.........] - ETA: 0s - loss: 12663.7285 - KL_divergence: 8.1238
151/200 [=====================>........] - ETA: 0s - loss: 12652.1817 - KL_divergence: 8.1264
157/200 [======================>.......] - ETA: 0s - loss: 12651.9491 - KL_divergence: 8.1312
163/200 [=======================>......] - ETA: 0s - loss: 12658.0467 - KL_divergence: 8.1303
169/200 [========================>.....] - ETA: 0s - loss: 12653.4864 - KL_divergence: 8.1378
176/200 [=========================>....] - ETA: 0s - loss: 12640.2556 - KL_divergence: 8.1422
182/200 [==========================>...] - ETA: 0s - loss: 12648.6796 - KL_divergence: 8.1442
188/200 [===========================>..] - ETA: 0s - loss: 12662.0594 - KL_divergence: 8.1370
194/200 [============================>.] - ETA: 0s - loss: 12677.4652 - KL_divergence: 8.1313
200/200 [==============================] - 2s 10ms/step - loss: 12667.5516 - KL_divergence: 8.1383 - val_loss: 13057.1610 - val_KL_divergence: 8.2634
Epoch 61/100

  1/200 [..............................] - ETA: 1s - loss: 12385.2490 - KL_divergence: 8.2741
  7/200 [>.............................] - ETA: 1s - loss: 12388.9577 - KL_divergence: 8.3418
 13/200 [>.............................] - ETA: 1s - loss: 12550.4098 - KL_divergence: 8.2024
 19/200 [=>............................] - ETA: 1s - loss: 12640.6042 - KL_divergence: 8.1120
 25/200 [==>...........................] - ETA: 1s - loss: 12630.6582 - KL_divergence: 8.0895
 31/200 [===>..........................] - ETA: 1s - loss: 12673.6506 - KL_divergence: 8.0786
 37/200 [====>.........................] - ETA: 1s - loss: 12755.8192 - KL_divergence: 8.1056
 43/200 [=====>........................] - ETA: 1s - loss: 12746.3204 - KL_divergence: 8.1118
 49/200 [======>.......................] - ETA: 1s - loss: 12779.1059 - KL_divergence: 8.1325
 55/200 [=======>......................] - ETA: 1s - loss: 12777.9012 - KL_divergence: 8.1375
 61/200 [========>.....................] - ETA: 1s - loss: 12774.3794 - KL_divergence: 8.1458
 67/200 [=========>....................] - ETA: 1s - loss: 12812.4378 - KL_divergence: 8.1490
 73/200 [=========>....................] - ETA: 1s - loss: 12831.1623 - KL_divergence: 8.1490
 79/200 [==========>...................] - ETA: 1s - loss: 12844.8624 - KL_divergence: 8.1600
 85/200 [===========>..................] - ETA: 1s - loss: 12819.6741 - KL_divergence: 8.1714
 91/200 [============>.................] - ETA: 0s - loss: 12824.2721 - KL_divergence: 8.1750
 97/200 [=============>................] - ETA: 0s - loss: 12828.8916 - KL_divergence: 8.1734
103/200 [==============>...............] - ETA: 0s - loss: 12799.3649 - KL_divergence: 8.1864
109/200 [===============>..............] - ETA: 0s - loss: 12766.0692 - KL_divergence: 8.1930
115/200 [================>.............] - ETA: 0s - loss: 12790.7425 - KL_divergence: 8.1768
121/200 [=================>............] - ETA: 0s - loss: 12788.3590 - KL_divergence: 8.1832
127/200 [==================>...........] - ETA: 0s - loss: 12809.2714 - KL_divergence: 8.1866
133/200 [==================>...........] - ETA: 0s - loss: 12779.0714 - KL_divergence: 8.2020
139/200 [===================>..........] - ETA: 0s - loss: 12773.2240 - KL_divergence: 8.1991
145/200 [====================>.........] - ETA: 0s - loss: 12753.4286 - KL_divergence: 8.2066
151/200 [=====================>........] - ETA: 0s - loss: 12778.2700 - KL_divergence: 8.1975
157/200 [======================>.......] - ETA: 0s - loss: 12770.2793 - KL_divergence: 8.1998
163/200 [=======================>......] - ETA: 0s - loss: 12752.4566 - KL_divergence: 8.2050
169/200 [========================>.....] - ETA: 0s - loss: 12714.1252 - KL_divergence: 8.2149
175/200 [=========================>....] - ETA: 0s - loss: 12723.1885 - KL_divergence: 8.2078
181/200 [==========================>...] - ETA: 0s - loss: 12728.6987 - KL_divergence: 8.1986
187/200 [===========================>..] - ETA: 0s - loss: 12723.5109 - KL_divergence: 8.1992
193/200 [===========================>..] - ETA: 0s - loss: 12705.0522 - KL_divergence: 8.2027
199/200 [============================>.] - ETA: 0s - loss: 12704.9188 - KL_divergence: 8.2052
200/200 [==============================] - 2s 10ms/step - loss: 12706.1710 - KL_divergence: 8.2041 - val_loss: 12935.6506 - val_KL_divergence: 7.8952
Epoch 62/100

  1/200 [..............................] - ETA: 1s - loss: 11633.6035 - KL_divergence: 8.4043
  7/200 [>.............................] - ETA: 1s - loss: 12697.5974 - KL_divergence: 7.9636
 13/200 [>.............................] - ETA: 1s - loss: 12446.2146 - KL_divergence: 8.2826
 19/200 [=>............................] - ETA: 1s - loss: 12557.5879 - KL_divergence: 8.2001
 25/200 [==>...........................] - ETA: 1s - loss: 12645.7388 - KL_divergence: 8.1536
 31/200 [===>..........................] - ETA: 1s - loss: 12700.1995 - KL_divergence: 8.1209
 37/200 [====>.........................] - ETA: 1s - loss: 12695.9389 - KL_divergence: 8.1242
 43/200 [=====>........................] - ETA: 1s - loss: 12622.0018 - KL_divergence: 8.1524
 49/200 [======>.......................] - ETA: 1s - loss: 12625.1110 - KL_divergence: 8.1657
 55/200 [=======>......................] - ETA: 1s - loss: 12626.8284 - KL_divergence: 8.1662
 61/200 [========>.....................] - ETA: 1s - loss: 12603.4111 - KL_divergence: 8.1638
 67/200 [=========>....................] - ETA: 1s - loss: 12566.3810 - KL_divergence: 8.1700
 73/200 [=========>....................] - ETA: 1s - loss: 12565.2987 - KL_divergence: 8.1967
 79/200 [==========>...................] - ETA: 1s - loss: 12591.8428 - KL_divergence: 8.1863
 85/200 [===========>..................] - ETA: 1s - loss: 12584.7035 - KL_divergence: 8.1886
 91/200 [============>.................] - ETA: 1s - loss: 12599.5383 - KL_divergence: 8.1810
 97/200 [=============>................] - ETA: 0s - loss: 12620.3969 - KL_divergence: 8.1838
103/200 [==============>...............] - ETA: 0s - loss: 12596.1631 - KL_divergence: 8.2027
109/200 [===============>..............] - ETA: 0s - loss: 12574.9143 - KL_divergence: 8.2033
115/200 [================>.............] - ETA: 0s - loss: 12588.5432 - KL_divergence: 8.1994
121/200 [=================>............] - ETA: 0s - loss: 12597.0683 - KL_divergence: 8.1918
127/200 [==================>...........] - ETA: 0s - loss: 12583.2304 - KL_divergence: 8.1854
133/200 [==================>...........] - ETA: 0s - loss: 12570.7324 - KL_divergence: 8.1907
139/200 [===================>..........] - ETA: 0s - loss: 12562.1358 - KL_divergence: 8.1970
145/200 [====================>.........] - ETA: 0s - loss: 12550.1703 - KL_divergence: 8.1969
151/200 [=====================>........] - ETA: 0s - loss: 12542.7414 - KL_divergence: 8.2041
157/200 [======================>.......] - ETA: 0s - loss: 12552.0347 - KL_divergence: 8.1986
163/200 [=======================>......] - ETA: 0s - loss: 12574.3857 - KL_divergence: 8.1952
169/200 [========================>.....] - ETA: 0s - loss: 12575.1395 - KL_divergence: 8.1910
175/200 [=========================>....] - ETA: 0s - loss: 12571.1276 - KL_divergence: 8.1897
181/200 [==========================>...] - ETA: 0s - loss: 12560.2000 - KL_divergence: 8.1947
187/200 [===========================>..] - ETA: 0s - loss: 12566.2551 - KL_divergence: 8.1905
193/200 [===========================>..] - ETA: 0s - loss: 12553.5570 - KL_divergence: 8.1917
199/200 [============================>.] - ETA: 0s - loss: 12548.7445 - KL_divergence: 8.1991
200/200 [==============================] - 2s 10ms/step - loss: 12559.7984 - KL_divergence: 8.1956 - val_loss: 13025.6883 - val_KL_divergence: 8.4303
Epoch 63/100

  1/200 [..............................] - ETA: 1s - loss: 12615.6846 - KL_divergence: 8.6308
  7/200 [>.............................] - ETA: 1s - loss: 12253.1593 - KL_divergence: 8.3850
 13/200 [>.............................] - ETA: 1s - loss: 12742.4879 - KL_divergence: 8.2053
 19/200 [=>............................] - ETA: 1s - loss: 12813.1720 - KL_divergence: 8.2396
 25/200 [==>...........................] - ETA: 1s - loss: 12834.6207 - KL_divergence: 8.1730
 31/200 [===>..........................] - ETA: 1s - loss: 12809.6765 - KL_divergence: 8.1459
 37/200 [====>.........................] - ETA: 1s - loss: 12701.7685 - KL_divergence: 8.1483
 43/200 [=====>........................] - ETA: 1s - loss: 12680.6019 - KL_divergence: 8.1551
 49/200 [======>.......................] - ETA: 1s - loss: 12586.7888 - KL_divergence: 8.1723
 55/200 [=======>......................] - ETA: 1s - loss: 12558.1752 - KL_divergence: 8.1657
 61/200 [========>.....................] - ETA: 1s - loss: 12548.5600 - KL_divergence: 8.1499
 67/200 [=========>....................] - ETA: 1s - loss: 12548.1327 - KL_divergence: 8.1300
 73/200 [=========>....................] - ETA: 1s - loss: 12558.0008 - KL_divergence: 8.1156
 79/200 [==========>...................] - ETA: 1s - loss: 12545.9856 - KL_divergence: 8.1143
 85/200 [===========>..................] - ETA: 1s - loss: 12565.6563 - KL_divergence: 8.1007
 91/200 [============>.................] - ETA: 0s - loss: 12544.7504 - KL_divergence: 8.0992
 97/200 [=============>................] - ETA: 0s - loss: 12549.8777 - KL_divergence: 8.0955
103/200 [==============>...............] - ETA: 0s - loss: 12558.2692 - KL_divergence: 8.0910
109/200 [===============>..............] - ETA: 0s - loss: 12541.2236 - KL_divergence: 8.0967
115/200 [================>.............] - ETA: 0s - loss: 12537.6350 - KL_divergence: 8.0998
121/200 [=================>............] - ETA: 0s - loss: 12558.8848 - KL_divergence: 8.0910
127/200 [==================>...........] - ETA: 0s - loss: 12565.2875 - KL_divergence: 8.0841
133/200 [==================>...........] - ETA: 0s - loss: 12539.8162 - KL_divergence: 8.0853
139/200 [===================>..........] - ETA: 0s - loss: 12542.1659 - KL_divergence: 8.0808
145/200 [====================>.........] - ETA: 0s - loss: 12535.5424 - KL_divergence: 8.0831
151/200 [=====================>........] - ETA: 0s - loss: 12539.4471 - KL_divergence: 8.0861
157/200 [======================>.......] - ETA: 0s - loss: 12544.1705 - KL_divergence: 8.0816
163/200 [=======================>......] - ETA: 0s - loss: 12548.8779 - KL_divergence: 8.0807
169/200 [========================>.....] - ETA: 0s - loss: 12577.1861 - KL_divergence: 8.0756
175/200 [=========================>....] - ETA: 0s - loss: 12565.2076 - KL_divergence: 8.0773
181/200 [==========================>...] - ETA: 0s - loss: 12565.3639 - KL_divergence: 8.0758
187/200 [===========================>..] - ETA: 0s - loss: 12557.9266 - KL_divergence: 8.0684
193/200 [===========================>..] - ETA: 0s - loss: 12555.1933 - KL_divergence: 8.0746
199/200 [============================>.] - ETA: 0s - loss: 12567.7246 - KL_divergence: 8.0778
200/200 [==============================] - 2s 10ms/step - loss: 12575.8500 - KL_divergence: 8.0764 - val_loss: 12955.9283 - val_KL_divergence: 7.8965
Epoch 64/100

  1/200 [..............................] - ETA: 1s - loss: 13133.8760 - KL_divergence: 7.8100
  7/200 [>.............................] - ETA: 1s - loss: 12715.3112 - KL_divergence: 8.0344
 13/200 [>.............................] - ETA: 1s - loss: 12662.9921 - KL_divergence: 8.0983
 19/200 [=>............................] - ETA: 1s - loss: 12692.6677 - KL_divergence: 8.1186
 25/200 [==>...........................] - ETA: 1s - loss: 12559.7474 - KL_divergence: 8.1160
 31/200 [===>..........................] - ETA: 1s - loss: 12519.9168 - KL_divergence: 8.0956
 36/200 [====>.........................] - ETA: 1s - loss: 12509.9849 - KL_divergence: 8.1058
 42/200 [=====>........................] - ETA: 1s - loss: 12450.1906 - KL_divergence: 8.1449
 48/200 [======>.......................] - ETA: 1s - loss: 12488.3585 - KL_divergence: 8.1428
 53/200 [======>.......................] - ETA: 1s - loss: 12503.4066 - KL_divergence: 8.1258
 59/200 [=======>......................] - ETA: 1s - loss: 12569.2082 - KL_divergence: 8.1305
 65/200 [========>.....................] - ETA: 1s - loss: 12555.8101 - KL_divergence: 8.1273
 71/200 [=========>....................] - ETA: 1s - loss: 12498.1625 - KL_divergence: 8.1422
 77/200 [==========>...................] - ETA: 1s - loss: 12520.3598 - KL_divergence: 8.1381
 83/200 [===========>..................] - ETA: 1s - loss: 12535.7554 - KL_divergence: 8.1298
 89/200 [============>.................] - ETA: 1s - loss: 12548.3696 - KL_divergence: 8.1299
 95/200 [=============>................] - ETA: 0s - loss: 12538.1344 - KL_divergence: 8.1345
101/200 [==============>...............] - ETA: 0s - loss: 12555.7983 - KL_divergence: 8.1252
106/200 [==============>...............] - ETA: 0s - loss: 12551.0814 - KL_divergence: 8.1191
112/200 [===============>..............] - ETA: 0s - loss: 12525.2818 - KL_divergence: 8.1213
118/200 [================>.............] - ETA: 0s - loss: 12519.3694 - KL_divergence: 8.1204
124/200 [=================>............] - ETA: 0s - loss: 12531.8621 - KL_divergence: 8.1221
130/200 [==================>...........] - ETA: 0s - loss: 12528.9818 - KL_divergence: 8.1278
137/200 [===================>..........] - ETA: 0s - loss: 12525.7255 - KL_divergence: 8.1328
144/200 [====================>.........] - ETA: 0s - loss: 12542.9100 - KL_divergence: 8.1374
150/200 [=====================>........] - ETA: 0s - loss: 12524.7153 - KL_divergence: 8.1426
156/200 [======================>.......] - ETA: 0s - loss: 12513.3949 - KL_divergence: 8.1597
162/200 [=======================>......] - ETA: 0s - loss: 12523.7362 - KL_divergence: 8.1610
168/200 [========================>.....] - ETA: 0s - loss: 12542.0689 - KL_divergence: 8.1542
174/200 [=========================>....] - ETA: 0s - loss: 12528.7965 - KL_divergence: 8.1539
180/200 [==========================>...] - ETA: 0s - loss: 12529.5594 - KL_divergence: 8.1416
186/200 [==========================>...] - ETA: 0s - loss: 12542.0365 - KL_divergence: 8.1317
192/200 [===========================>..] - ETA: 0s - loss: 12540.6613 - KL_divergence: 8.1245
198/200 [============================>.] - ETA: 0s - loss: 12552.2250 - KL_divergence: 8.1231
200/200 [==============================] - 2s 10ms/step - loss: 12547.8802 - KL_divergence: 8.1263 - val_loss: 12943.0656 - val_KL_divergence: 7.8410
Epoch 65/100

  1/200 [..............................] - ETA: 1s - loss: 11402.2002 - KL_divergence: 8.2332
  7/200 [>.............................] - ETA: 1s - loss: 12208.0770 - KL_divergence: 8.1175
 13/200 [>.............................] - ETA: 1s - loss: 12359.2527 - KL_divergence: 8.1931
 19/200 [=>............................] - ETA: 1s - loss: 12299.7255 - KL_divergence: 8.1406
 25/200 [==>...........................] - ETA: 1s - loss: 12378.1502 - KL_divergence: 8.0532
 31/200 [===>..........................] - ETA: 1s - loss: 12301.2587 - KL_divergence: 8.1133
 36/200 [====>.........................] - ETA: 1s - loss: 12371.8797 - KL_divergence: 8.0771
 42/200 [=====>........................] - ETA: 1s - loss: 12453.9784 - KL_divergence: 8.0897
 48/200 [======>.......................] - ETA: 1s - loss: 12492.5166 - KL_divergence: 8.0829
 54/200 [=======>......................] - ETA: 1s - loss: 12440.9105 - KL_divergence: 8.0929
 60/200 [========>.....................] - ETA: 1s - loss: 12403.4450 - KL_divergence: 8.1023
 66/200 [========>.....................] - ETA: 1s - loss: 12444.2142 - KL_divergence: 8.0871
 72/200 [=========>....................] - ETA: 1s - loss: 12485.3424 - KL_divergence: 8.0903
 78/200 [==========>...................] - ETA: 1s - loss: 12475.3622 - KL_divergence: 8.1017
 84/200 [===========>..................] - ETA: 1s - loss: 12496.5655 - KL_divergence: 8.0970
 90/200 [============>.................] - ETA: 1s - loss: 12533.9952 - KL_divergence: 8.0869
 96/200 [=============>................] - ETA: 0s - loss: 12528.7943 - KL_divergence: 8.0819
102/200 [==============>...............] - ETA: 0s - loss: 12535.3789 - KL_divergence: 8.0931
108/200 [===============>..............] - ETA: 0s - loss: 12552.3800 - KL_divergence: 8.0837
114/200 [================>.............] - ETA: 0s - loss: 12537.5806 - KL_divergence: 8.0828
120/200 [=================>............] - ETA: 0s - loss: 12566.9818 - KL_divergence: 8.0704
126/200 [=================>............] - ETA: 0s - loss: 12574.3504 - KL_divergence: 8.0630
132/200 [==================>...........] - ETA: 0s - loss: 12574.2701 - KL_divergence: 8.0660
138/200 [===================>..........] - ETA: 0s - loss: 12576.6629 - KL_divergence: 8.0676
144/200 [====================>.........] - ETA: 0s - loss: 12564.2526 - KL_divergence: 8.0630
150/200 [=====================>........] - ETA: 0s - loss: 12573.6046 - KL_divergence: 8.0585
156/200 [======================>.......] - ETA: 0s - loss: 12582.8364 - KL_divergence: 8.0526
162/200 [=======================>......] - ETA: 0s - loss: 12556.4884 - KL_divergence: 8.0606
168/200 [========================>.....] - ETA: 0s - loss: 12550.1420 - KL_divergence: 8.0631
174/200 [=========================>....] - ETA: 0s - loss: 12543.0162 - KL_divergence: 8.0660
181/200 [==========================>...] - ETA: 0s - loss: 12556.4385 - KL_divergence: 8.0623
187/200 [===========================>..] - ETA: 0s - loss: 12572.7622 - KL_divergence: 8.0544
193/200 [===========================>..] - ETA: 0s - loss: 12564.0601 - KL_divergence: 8.0550
199/200 [============================>.] - ETA: 0s - loss: 12582.7806 - KL_divergence: 8.0502
200/200 [==============================] - 2s 10ms/step - loss: 12583.7379 - KL_divergence: 8.0469 - val_loss: 12939.5144 - val_KL_divergence: 8.3694
Epoch 66/100

  1/200 [..............................] - ETA: 1s - loss: 12858.4873 - KL_divergence: 8.1136
  7/200 [>.............................] - ETA: 1s - loss: 12369.8387 - KL_divergence: 8.0694
 14/200 [=>............................] - ETA: 1s - loss: 12575.6016 - KL_divergence: 8.0750
 20/200 [==>...........................] - ETA: 1s - loss: 12580.6619 - KL_divergence: 8.0840
 26/200 [==>...........................] - ETA: 1s - loss: 12555.8982 - KL_divergence: 8.0609
 32/200 [===>..........................] - ETA: 1s - loss: 12507.8390 - KL_divergence: 8.0496
 38/200 [====>.........................] - ETA: 1s - loss: 12554.7540 - KL_divergence: 8.0775
 44/200 [=====>........................] - ETA: 1s - loss: 12557.8274 - KL_divergence: 8.0624
 50/200 [======>.......................] - ETA: 1s - loss: 12562.0941 - KL_divergence: 8.0565
 56/200 [=======>......................] - ETA: 1s - loss: 12582.7836 - KL_divergence: 8.0351
 62/200 [========>.....................] - ETA: 1s - loss: 12553.2804 - KL_divergence: 8.0432
 68/200 [=========>....................] - ETA: 1s - loss: 12579.4938 - KL_divergence: 8.0553
 74/200 [==========>...................] - ETA: 1s - loss: 12595.9217 - KL_divergence: 8.0359
 80/200 [===========>..................] - ETA: 1s - loss: 12638.2164 - KL_divergence: 8.0253
 86/200 [===========>..................] - ETA: 1s - loss: 12616.1597 - KL_divergence: 8.0387
 92/200 [============>.................] - ETA: 0s - loss: 12601.3742 - KL_divergence: 8.0343
 98/200 [=============>................] - ETA: 0s - loss: 12632.4373 - KL_divergence: 8.0206
103/200 [==============>...............] - ETA: 0s - loss: 12626.8276 - KL_divergence: 8.0244
109/200 [===============>..............] - ETA: 0s - loss: 12603.2287 - KL_divergence: 8.0319
115/200 [================>.............] - ETA: 0s - loss: 12575.9515 - KL_divergence: 8.0410
120/200 [=================>............] - ETA: 0s - loss: 12576.4885 - KL_divergence: 8.0325
126/200 [=================>............] - ETA: 0s - loss: 12564.4370 - KL_divergence: 8.0320
132/200 [==================>...........] - ETA: 0s - loss: 12561.4588 - KL_divergence: 8.0307
138/200 [===================>..........] - ETA: 0s - loss: 12544.9783 - KL_divergence: 8.0362
144/200 [====================>.........] - ETA: 0s - loss: 12536.9566 - KL_divergence: 8.0378
150/200 [=====================>........] - ETA: 0s - loss: 12543.1596 - KL_divergence: 8.0475
156/200 [======================>.......] - ETA: 0s - loss: 12549.5393 - KL_divergence: 8.0473
162/200 [=======================>......] - ETA: 0s - loss: 12548.9623 - KL_divergence: 8.0545
168/200 [========================>.....] - ETA: 0s - loss: 12544.1739 - KL_divergence: 8.0522
174/200 [=========================>....] - ETA: 0s - loss: 12548.9646 - KL_divergence: 8.0605
180/200 [==========================>...] - ETA: 0s - loss: 12550.3519 - KL_divergence: 8.0595
186/200 [==========================>...] - ETA: 0s - loss: 12531.5470 - KL_divergence: 8.0687
192/200 [===========================>..] - ETA: 0s - loss: 12535.9292 - KL_divergence: 8.0669
198/200 [============================>.] - ETA: 0s - loss: 12542.9785 - KL_divergence: 8.0614
200/200 [==============================] - 2s 10ms/step - loss: 12545.5351 - KL_divergence: 8.0634 - val_loss: 13011.8045 - val_KL_divergence: 7.7588
Epoch 67/100

  1/200 [..............................] - ETA: 1s - loss: 12203.8223 - KL_divergence: 8.0461
  7/200 [>.............................] - ETA: 1s - loss: 12630.2257 - KL_divergence: 8.1835
 13/200 [>.............................] - ETA: 1s - loss: 12436.7964 - KL_divergence: 8.1337
 19/200 [=>............................] - ETA: 1s - loss: 12342.6139 - KL_divergence: 8.1313
 25/200 [==>...........................] - ETA: 1s - loss: 12265.2552 - KL_divergence: 8.1635
 31/200 [===>..........................] - ETA: 1s - loss: 12274.6646 - KL_divergence: 8.1308
 37/200 [====>.........................] - ETA: 1s - loss: 12334.8729 - KL_divergence: 8.1369
 43/200 [=====>........................] - ETA: 1s - loss: 12360.3618 - KL_divergence: 8.1132
 49/200 [======>.......................] - ETA: 1s - loss: 12374.4896 - KL_divergence: 8.1147
 55/200 [=======>......................] - ETA: 1s - loss: 12346.4656 - KL_divergence: 8.1119
 61/200 [========>.....................] - ETA: 1s - loss: 12342.8098 - KL_divergence: 8.1280
 67/200 [=========>....................] - ETA: 1s - loss: 12374.5368 - KL_divergence: 8.1075
 73/200 [=========>....................] - ETA: 1s - loss: 12386.7267 - KL_divergence: 8.1331
 79/200 [==========>...................] - ETA: 1s - loss: 12403.0677 - KL_divergence: 8.1277
 85/200 [===========>..................] - ETA: 1s - loss: 12411.5657 - KL_divergence: 8.1285
 91/200 [============>.................] - ETA: 0s - loss: 12412.5134 - KL_divergence: 8.1369
 97/200 [=============>................] - ETA: 0s - loss: 12392.3170 - KL_divergence: 8.1508
103/200 [==============>...............] - ETA: 0s - loss: 12409.8810 - KL_divergence: 8.1453
109/200 [===============>..............] - ETA: 0s - loss: 12425.8318 - KL_divergence: 8.1406
115/200 [================>.............] - ETA: 0s - loss: 12418.9674 - KL_divergence: 8.1461
121/200 [=================>............] - ETA: 0s - loss: 12428.8105 - KL_divergence: 8.1483
127/200 [==================>...........] - ETA: 0s - loss: 12445.3491 - KL_divergence: 8.1523
133/200 [==================>...........] - ETA: 0s - loss: 12438.4784 - KL_divergence: 8.1605
139/200 [===================>..........] - ETA: 0s - loss: 12437.2643 - KL_divergence: 8.1617
145/200 [====================>.........] - ETA: 0s - loss: 12444.3506 - KL_divergence: 8.1541
151/200 [=====================>........] - ETA: 0s - loss: 12441.5198 - KL_divergence: 8.1478
157/200 [======================>.......] - ETA: 0s - loss: 12453.8629 - KL_divergence: 8.1420
163/200 [=======================>......] - ETA: 0s - loss: 12482.2318 - KL_divergence: 8.1351
169/200 [========================>.....] - ETA: 0s - loss: 12494.8342 - KL_divergence: 8.1320
175/200 [=========================>....] - ETA: 0s - loss: 12515.8992 - KL_divergence: 8.1272
181/200 [==========================>...] - ETA: 0s - loss: 12520.1488 - KL_divergence: 8.1211
187/200 [===========================>..] - ETA: 0s - loss: 12512.7457 - KL_divergence: 8.1212
193/200 [===========================>..] - ETA: 0s - loss: 12505.3507 - KL_divergence: 8.1243
199/200 [============================>.] - ETA: 0s - loss: 12511.6933 - KL_divergence: 8.1225
200/200 [==============================] - 2s 10ms/step - loss: 12506.8312 - KL_divergence: 8.1223 - val_loss: 12880.0634 - val_KL_divergence: 7.7992
Epoch 68/100

  1/200 [..............................] - ETA: 1s - loss: 13200.5234 - KL_divergence: 7.3723
  7/200 [>.............................] - ETA: 1s - loss: 12513.2193 - KL_divergence: 7.9752
 13/200 [>.............................] - ETA: 1s - loss: 12627.3107 - KL_divergence: 8.0569
 19/200 [=>............................] - ETA: 1s - loss: 12553.2278 - KL_divergence: 8.0390
 25/200 [==>...........................] - ETA: 1s - loss: 12587.9399 - KL_divergence: 8.0374
 31/200 [===>..........................] - ETA: 1s - loss: 12661.6329 - KL_divergence: 8.0336
 37/200 [====>.........................] - ETA: 1s - loss: 12653.0812 - KL_divergence: 8.0703
 43/200 [=====>........................] - ETA: 1s - loss: 12674.2830 - KL_divergence: 8.0842
 49/200 [======>.......................] - ETA: 1s - loss: 12659.2329 - KL_divergence: 8.0594
 55/200 [=======>......................] - ETA: 1s - loss: 12598.5247 - KL_divergence: 8.0538
 61/200 [========>.....................] - ETA: 1s - loss: 12607.7135 - KL_divergence: 8.0269
 67/200 [=========>....................] - ETA: 1s - loss: 12587.7767 - KL_divergence: 8.0127
 73/200 [=========>....................] - ETA: 1s - loss: 12550.4157 - KL_divergence: 8.0054
 79/200 [==========>...................] - ETA: 1s - loss: 12528.2639 - KL_divergence: 8.0166
 85/200 [===========>..................] - ETA: 1s - loss: 12488.4163 - KL_divergence: 8.0184
 91/200 [============>.................] - ETA: 0s - loss: 12489.1703 - KL_divergence: 8.0295
 97/200 [=============>................] - ETA: 0s - loss: 12526.2659 - KL_divergence: 8.0305
103/200 [==============>...............] - ETA: 0s - loss: 12533.1721 - KL_divergence: 8.0309
109/200 [===============>..............] - ETA: 0s - loss: 12546.0568 - KL_divergence: 8.0240
115/200 [================>.............] - ETA: 0s - loss: 12550.6103 - KL_divergence: 8.0283
121/200 [=================>............] - ETA: 0s - loss: 12549.7942 - KL_divergence: 8.0189
127/200 [==================>...........] - ETA: 0s - loss: 12553.9016 - KL_divergence: 8.0180
133/200 [==================>...........] - ETA: 0s - loss: 12557.7449 - KL_divergence: 8.0148
139/200 [===================>..........] - ETA: 0s - loss: 12581.7146 - KL_divergence: 8.0038
145/200 [====================>.........] - ETA: 0s - loss: 12591.1728 - KL_divergence: 7.9992
152/200 [=====================>........] - ETA: 0s - loss: 12593.5315 - KL_divergence: 7.9944
158/200 [======================>.......] - ETA: 0s - loss: 12583.8154 - KL_divergence: 7.9973
164/200 [=======================>......] - ETA: 0s - loss: 12566.2502 - KL_divergence: 7.9923
171/200 [========================>.....] - ETA: 0s - loss: 12561.1364 - KL_divergence: 7.9905
177/200 [=========================>....] - ETA: 0s - loss: 12561.1412 - KL_divergence: 7.9913
183/200 [==========================>...] - ETA: 0s - loss: 12537.0139 - KL_divergence: 7.9961
189/200 [===========================>..] - ETA: 0s - loss: 12531.1087 - KL_divergence: 7.9946
195/200 [============================>.] - ETA: 0s - loss: 12541.9349 - KL_divergence: 7.9965
200/200 [==============================] - 2s 10ms/step - loss: 12541.8517 - KL_divergence: 7.9933 - val_loss: 12908.1764 - val_KL_divergence: 8.0878
Epoch 69/100

  1/200 [..............................] - ETA: 1s - loss: 12148.8174 - KL_divergence: 8.3752
  7/200 [>.............................] - ETA: 1s - loss: 12122.9142 - KL_divergence: 8.0844
 13/200 [>.............................] - ETA: 1s - loss: 12242.1230 - KL_divergence: 8.1385
 19/200 [=>............................] - ETA: 1s - loss: 12280.9769 - KL_divergence: 8.1580
 25/200 [==>...........................] - ETA: 1s - loss: 12381.5449 - KL_divergence: 8.1498
 31/200 [===>..........................] - ETA: 1s - loss: 12410.1968 - KL_divergence: 8.1118
 37/200 [====>.........................] - ETA: 1s - loss: 12393.2999 - KL_divergence: 8.1087
 43/200 [=====>........................] - ETA: 1s - loss: 12342.5809 - KL_divergence: 8.0848
 49/200 [======>.......................] - ETA: 1s - loss: 12363.0778 - KL_divergence: 8.0731
 55/200 [=======>......................] - ETA: 1s - loss: 12376.0993 - KL_divergence: 8.0764
 61/200 [========>.....................] - ETA: 1s - loss: 12397.7581 - KL_divergence: 8.0686
 67/200 [=========>....................] - ETA: 1s - loss: 12433.7885 - KL_divergence: 8.0489
 73/200 [=========>....................] - ETA: 1s - loss: 12396.3720 - KL_divergence: 8.0554
 79/200 [==========>...................] - ETA: 1s - loss: 12477.4625 - KL_divergence: 8.0504
 85/200 [===========>..................] - ETA: 1s - loss: 12447.9612 - KL_divergence: 8.0553
 91/200 [============>.................] - ETA: 0s - loss: 12470.7442 - KL_divergence: 8.0554
 97/200 [=============>................] - ETA: 0s - loss: 12448.2731 - KL_divergence: 8.0686
103/200 [==============>...............] - ETA: 0s - loss: 12430.2619 - KL_divergence: 8.0768
109/200 [===============>..............] - ETA: 0s - loss: 12399.8053 - KL_divergence: 8.0913
116/200 [================>.............] - ETA: 0s - loss: 12375.3162 - KL_divergence: 8.1006
122/200 [=================>............] - ETA: 0s - loss: 12391.7697 - KL_divergence: 8.0913
128/200 [==================>...........] - ETA: 0s - loss: 12424.6601 - KL_divergence: 8.0907
134/200 [===================>..........] - ETA: 0s - loss: 12432.3476 - KL_divergence: 8.0918
140/200 [====================>.........] - ETA: 0s - loss: 12420.4342 - KL_divergence: 8.0992
146/200 [====================>.........] - ETA: 0s - loss: 12430.0542 - KL_divergence: 8.1008
152/200 [=====================>........] - ETA: 0s - loss: 12443.3235 - KL_divergence: 8.1038
158/200 [======================>.......] - ETA: 0s - loss: 12448.6630 - KL_divergence: 8.1046
164/200 [=======================>......] - ETA: 0s - loss: 12463.5798 - KL_divergence: 8.1003
170/200 [========================>.....] - ETA: 0s - loss: 12463.2143 - KL_divergence: 8.0913
176/200 [=========================>....] - ETA: 0s - loss: 12468.2527 - KL_divergence: 8.0907
182/200 [==========================>...] - ETA: 0s - loss: 12467.4866 - KL_divergence: 8.0929
188/200 [===========================>..] - ETA: 0s - loss: 12477.3548 - KL_divergence: 8.0884
194/200 [============================>.] - ETA: 0s - loss: 12459.1404 - KL_divergence: 8.0899
200/200 [==============================] - 2s 10ms/step - loss: 12443.3294 - KL_divergence: 8.0948 - val_loss: 12889.8481 - val_KL_divergence: 7.9097
Epoch 70/100

  1/200 [..............................] - ETA: 1s - loss: 12042.5439 - KL_divergence: 7.7303
  8/200 [>.............................] - ETA: 1s - loss: 12380.3824 - KL_divergence: 8.2241
 15/200 [=>............................] - ETA: 1s - loss: 12501.3617 - KL_divergence: 8.0453
 21/200 [==>...........................] - ETA: 1s - loss: 12377.3824 - KL_divergence: 8.0858
 27/200 [===>..........................] - ETA: 1s - loss: 12330.0478 - KL_divergence: 8.0882
 33/200 [===>..........................] - ETA: 1s - loss: 12346.3149 - KL_divergence: 8.0938
 39/200 [====>.........................] - ETA: 1s - loss: 12413.7722 - KL_divergence: 8.0749
 45/200 [=====>........................] - ETA: 1s - loss: 12363.8557 - KL_divergence: 8.1038
 51/200 [======>.......................] - ETA: 1s - loss: 12457.1689 - KL_divergence: 8.0693
 57/200 [=======>......................] - ETA: 1s - loss: 12429.9760 - KL_divergence: 8.0977
 62/200 [========>.....................] - ETA: 1s - loss: 12410.7763 - KL_divergence: 8.1214
 68/200 [=========>....................] - ETA: 1s - loss: 12405.7266 - KL_divergence: 8.1287
 74/200 [==========>...................] - ETA: 1s - loss: 12397.4930 - KL_divergence: 8.1185
 80/200 [===========>..................] - ETA: 1s - loss: 12405.5345 - KL_divergence: 8.1150
 87/200 [============>.................] - ETA: 0s - loss: 12351.9398 - KL_divergence: 8.1203
 94/200 [=============>................] - ETA: 0s - loss: 12341.8447 - KL_divergence: 8.1187
100/200 [==============>...............] - ETA: 0s - loss: 12371.3729 - KL_divergence: 8.1020
106/200 [==============>...............] - ETA: 0s - loss: 12372.2870 - KL_divergence: 8.0931
112/200 [===============>..............] - ETA: 0s - loss: 12376.0383 - KL_divergence: 8.0873
118/200 [================>.............] - ETA: 0s - loss: 12377.5539 - KL_divergence: 8.0741
124/200 [=================>............] - ETA: 0s - loss: 12372.0188 - KL_divergence: 8.0722
130/200 [==================>...........] - ETA: 0s - loss: 12357.3963 - KL_divergence: 8.0717
136/200 [===================>..........] - ETA: 0s - loss: 12337.5729 - KL_divergence: 8.0766
142/200 [====================>.........] - ETA: 0s - loss: 12335.3607 - KL_divergence: 8.0761
148/200 [=====================>........] - ETA: 0s - loss: 12343.3167 - KL_divergence: 8.0822
154/200 [======================>.......] - ETA: 0s - loss: 12346.3378 - KL_divergence: 8.0844
160/200 [=======================>......] - ETA: 0s - loss: 12340.2460 - KL_divergence: 8.0758
166/200 [=======================>......] - ETA: 0s - loss: 12348.4356 - KL_divergence: 8.0742
172/200 [========================>.....] - ETA: 0s - loss: 12350.0416 - KL_divergence: 8.0806
178/200 [=========================>....] - ETA: 0s - loss: 12351.5032 - KL_divergence: 8.0844
184/200 [==========================>...] - ETA: 0s - loss: 12342.2447 - KL_divergence: 8.0991
190/200 [===========================>..] - ETA: 0s - loss: 12348.7794 - KL_divergence: 8.1015
196/200 [============================>.] - ETA: 0s - loss: 12353.7045 - KL_divergence: 8.0984
200/200 [==============================] - 2s 10ms/step - loss: 12350.7405 - KL_divergence: 8.1013 - val_loss: 12818.6195 - val_KL_divergence: 7.9930
Epoch 71/100

  1/200 [..............................] - ETA: 1s - loss: 11929.5059 - KL_divergence: 7.9239
  7/200 [>.............................] - ETA: 1s - loss: 12353.4381 - KL_divergence: 8.1197
 13/200 [>.............................] - ETA: 1s - loss: 12447.6735 - KL_divergence: 8.0330
 19/200 [=>............................] - ETA: 1s - loss: 12366.0388 - KL_divergence: 8.0485
 25/200 [==>...........................] - ETA: 1s - loss: 12470.6928 - KL_divergence: 8.0552
 31/200 [===>..........................] - ETA: 1s - loss: 12506.2013 - KL_divergence: 8.0408
 37/200 [====>.........................] - ETA: 1s - loss: 12467.3190 - KL_divergence: 8.0394
 43/200 [=====>........................] - ETA: 1s - loss: 12469.4047 - KL_divergence: 8.0587
 49/200 [======>.......................] - ETA: 1s - loss: 12504.0823 - KL_divergence: 8.0562
 55/200 [=======>......................] - ETA: 1s - loss: 12546.9617 - KL_divergence: 8.0458
 61/200 [========>.....................] - ETA: 1s - loss: 12572.0226 - KL_divergence: 8.0556
 67/200 [=========>....................] - ETA: 1s - loss: 12554.6905 - KL_divergence: 8.0633
 73/200 [=========>....................] - ETA: 1s - loss: 12514.3628 - KL_divergence: 8.0742
 79/200 [==========>...................] - ETA: 1s - loss: 12531.5710 - KL_divergence: 8.0726
 85/200 [===========>..................] - ETA: 1s - loss: 12531.0634 - KL_divergence: 8.0661
 91/200 [============>.................] - ETA: 1s - loss: 12534.3437 - KL_divergence: 8.0591
 97/200 [=============>................] - ETA: 0s - loss: 12547.6570 - KL_divergence: 8.0609
103/200 [==============>...............] - ETA: 0s - loss: 12511.9585 - KL_divergence: 8.0601
109/200 [===============>..............] - ETA: 0s - loss: 12533.0691 - KL_divergence: 8.0589
116/200 [================>.............] - ETA: 0s - loss: 12510.7729 - KL_divergence: 8.0657
123/200 [=================>............] - ETA: 0s - loss: 12510.0142 - KL_divergence: 8.0631
130/200 [==================>...........] - ETA: 0s - loss: 12507.6830 - KL_divergence: 8.0664
136/200 [===================>..........] - ETA: 0s - loss: 12483.9835 - KL_divergence: 8.0750
143/200 [====================>.........] - ETA: 0s - loss: 12506.3012 - KL_divergence: 8.0684
150/200 [=====================>........] - ETA: 0s - loss: 12494.4244 - KL_divergence: 8.0799
156/200 [======================>.......] - ETA: 0s - loss: 12502.4579 - KL_divergence: 8.0785
162/200 [=======================>......] - ETA: 0s - loss: 12504.4429 - KL_divergence: 8.0765
169/200 [========================>.....] - ETA: 0s - loss: 12520.7491 - KL_divergence: 8.0696
175/200 [=========================>....] - ETA: 0s - loss: 12510.0478 - KL_divergence: 8.0758
181/200 [==========================>...] - ETA: 0s - loss: 12513.3008 - KL_divergence: 8.0743
186/200 [==========================>...] - ETA: 0s - loss: 12525.0744 - KL_divergence: 8.0744
192/200 [===========================>..] - ETA: 0s - loss: 12541.2608 - KL_divergence: 8.0652
198/200 [============================>.] - ETA: 0s - loss: 12524.3967 - KL_divergence: 8.0693
200/200 [==============================] - 2s 10ms/step - loss: 12530.7418 - KL_divergence: 8.0690 - val_loss: 13032.6295 - val_KL_divergence: 8.1497
Epoch 72/100

  1/200 [..............................] - ETA: 1s - loss: 13746.7412 - KL_divergence: 7.9199
  7/200 [>.............................] - ETA: 1s - loss: 13041.2648 - KL_divergence: 8.0385
 13/200 [>.............................] - ETA: 1s - loss: 12550.5328 - KL_divergence: 8.1081
 19/200 [=>............................] - ETA: 1s - loss: 12409.6410 - KL_divergence: 8.1174
 25/200 [==>...........................] - ETA: 1s - loss: 12397.0480 - KL_divergence: 8.0714
 31/200 [===>..........................] - ETA: 1s - loss: 12422.6185 - KL_divergence: 8.0537
 37/200 [====>.........................] - ETA: 1s - loss: 12385.0325 - KL_divergence: 8.0193
 43/200 [=====>........................] - ETA: 1s - loss: 12395.0433 - KL_divergence: 8.0091
 49/200 [======>.......................] - ETA: 1s - loss: 12373.2809 - KL_divergence: 8.0167
 55/200 [=======>......................] - ETA: 1s - loss: 12372.1735 - KL_divergence: 8.0093
 61/200 [========>.....................] - ETA: 1s - loss: 12382.1896 - KL_divergence: 8.0136
 67/200 [=========>....................] - ETA: 1s - loss: 12334.2865 - KL_divergence: 8.0353
 73/200 [=========>....................] - ETA: 1s - loss: 12336.5832 - KL_divergence: 8.0391
 79/200 [==========>...................] - ETA: 1s - loss: 12369.9944 - KL_divergence: 8.0519
 85/200 [===========>..................] - ETA: 1s - loss: 12380.1907 - KL_divergence: 8.0564
 92/200 [============>.................] - ETA: 0s - loss: 12363.0375 - KL_divergence: 8.0667
 98/200 [=============>................] - ETA: 0s - loss: 12404.8975 - KL_divergence: 8.0667
104/200 [==============>...............] - ETA: 0s - loss: 12430.0326 - KL_divergence: 8.0710
110/200 [===============>..............] - ETA: 0s - loss: 12429.5803 - KL_divergence: 8.0758
116/200 [================>.............] - ETA: 0s - loss: 12407.0954 - KL_divergence: 8.0723
122/200 [=================>............] - ETA: 0s - loss: 12410.7891 - KL_divergence: 8.0645
128/200 [==================>...........] - ETA: 0s - loss: 12421.7311 - KL_divergence: 8.0635
135/200 [===================>..........] - ETA: 0s - loss: 12428.7353 - KL_divergence: 8.0574
141/200 [====================>.........] - ETA: 0s - loss: 12446.9191 - KL_divergence: 8.0520
147/200 [=====================>........] - ETA: 0s - loss: 12450.5345 - KL_divergence: 8.0536
153/200 [=====================>........] - ETA: 0s - loss: 12450.3860 - KL_divergence: 8.0479
159/200 [======================>.......] - ETA: 0s - loss: 12471.3012 - KL_divergence: 8.0428
165/200 [=======================>......] - ETA: 0s - loss: 12494.4329 - KL_divergence: 8.0308
171/200 [========================>.....] - ETA: 0s - loss: 12491.3515 - KL_divergence: 8.0293
177/200 [=========================>....] - ETA: 0s - loss: 12505.4564 - KL_divergence: 8.0262
183/200 [==========================>...] - ETA: 0s - loss: 12492.7787 - KL_divergence: 8.0312
190/200 [===========================>..] - ETA: 0s - loss: 12471.9516 - KL_divergence: 8.0426
196/200 [============================>.] - ETA: 0s - loss: 12461.9470 - KL_divergence: 8.0514
200/200 [==============================] - 2s 9ms/step - loss: 12471.2175 - KL_divergence: 8.0487 - val_loss: 12832.1155 - val_KL_divergence: 8.0416
Epoch 73/100

  1/200 [..............................] - ETA: 1s - loss: 12917.4229 - KL_divergence: 8.0251
  7/200 [>.............................] - ETA: 1s - loss: 12208.5628 - KL_divergence: 8.0660
 14/200 [=>............................] - ETA: 1s - loss: 12314.6929 - KL_divergence: 8.0588
 20/200 [==>...........................] - ETA: 1s - loss: 12483.0084 - KL_divergence: 8.0700
 27/200 [===>..........................] - ETA: 1s - loss: 12496.7799 - KL_divergence: 8.0946
 33/200 [===>..........................] - ETA: 1s - loss: 12409.2650 - KL_divergence: 8.1145
 39/200 [====>.........................] - ETA: 1s - loss: 12391.9713 - KL_divergence: 8.1182
 45/200 [=====>........................] - ETA: 1s - loss: 12379.2650 - KL_divergence: 8.0912
 51/200 [======>.......................] - ETA: 1s - loss: 12398.9812 - KL_divergence: 8.0826
 57/200 [=======>......................] - ETA: 1s - loss: 12325.2545 - KL_divergence: 8.0795
 63/200 [========>.....................] - ETA: 1s - loss: 12311.7249 - KL_divergence: 8.0829
 69/200 [=========>....................] - ETA: 1s - loss: 12296.0949 - KL_divergence: 8.0942
 75/200 [==========>...................] - ETA: 1s - loss: 12246.6508 - KL_divergence: 8.1026
 81/200 [===========>..................] - ETA: 1s - loss: 12284.3519 - KL_divergence: 8.1171
 87/200 [============>.................] - ETA: 0s - loss: 12293.8659 - KL_divergence: 8.1107
 93/200 [============>.................] - ETA: 0s - loss: 12306.0712 - KL_divergence: 8.1088
 99/200 [=============>................] - ETA: 0s - loss: 12295.0977 - KL_divergence: 8.1140
105/200 [==============>...............] - ETA: 0s - loss: 12301.0647 - KL_divergence: 8.1166
111/200 [===============>..............] - ETA: 0s - loss: 12275.7566 - KL_divergence: 8.1269
117/200 [================>.............] - ETA: 0s - loss: 12283.3273 - KL_divergence: 8.1260
123/200 [=================>............] - ETA: 0s - loss: 12282.8449 - KL_divergence: 8.1297
129/200 [==================>...........] - ETA: 0s - loss: 12305.0705 - KL_divergence: 8.1226
135/200 [===================>..........] - ETA: 0s - loss: 12297.8130 - KL_divergence: 8.1336
141/200 [====================>.........] - ETA: 0s - loss: 12324.3346 - KL_divergence: 8.1286
147/200 [=====================>........] - ETA: 0s - loss: 12336.4754 - KL_divergence: 8.1267
154/200 [======================>.......] - ETA: 0s - loss: 12358.2911 - KL_divergence: 8.1174
160/200 [=======================>......] - ETA: 0s - loss: 12356.3665 - KL_divergence: 8.1129
166/200 [=======================>......] - ETA: 0s - loss: 12343.9672 - KL_divergence: 8.1128
172/200 [========================>.....] - ETA: 0s - loss: 12356.4985 - KL_divergence: 8.1079
178/200 [=========================>....] - ETA: 0s - loss: 12354.0601 - KL_divergence: 8.1068
183/200 [==========================>...] - ETA: 0s - loss: 12354.9647 - KL_divergence: 8.1013
189/200 [===========================>..] - ETA: 0s - loss: 12365.9217 - KL_divergence: 8.0923
195/200 [============================>.] - ETA: 0s - loss: 12368.6792 - KL_divergence: 8.0885
200/200 [==============================] - 2s 10ms/step - loss: 12358.9090 - KL_divergence: 8.0906 - val_loss: 12951.0096 - val_KL_divergence: 7.9219
Epoch 74/100

  1/200 [..............................] - ETA: 1s - loss: 12758.3750 - KL_divergence: 8.1031
  7/200 [>.............................] - ETA: 1s - loss: 12395.3320 - KL_divergence: 8.1624
 13/200 [>.............................] - ETA: 1s - loss: 12348.4286 - KL_divergence: 8.1201
 19/200 [=>............................] - ETA: 1s - loss: 12258.2648 - KL_divergence: 8.1429
 25/200 [==>...........................] - ETA: 1s - loss: 12200.3065 - KL_divergence: 8.1400
 31/200 [===>..........................] - ETA: 1s - loss: 12229.4093 - KL_divergence: 8.1376
 38/200 [====>.........................] - ETA: 1s - loss: 12233.0749 - KL_divergence: 8.1421
 44/200 [=====>........................] - ETA: 1s - loss: 12244.7490 - KL_divergence: 8.1418
 50/200 [======>.......................] - ETA: 1s - loss: 12236.3201 - KL_divergence: 8.1314
 56/200 [=======>......................] - ETA: 1s - loss: 12243.2237 - KL_divergence: 8.1072
 62/200 [========>.....................] - ETA: 1s - loss: 12283.1416 - KL_divergence: 8.0947
 68/200 [=========>....................] - ETA: 1s - loss: 12251.1673 - KL_divergence: 8.0840
 75/200 [==========>...................] - ETA: 1s - loss: 12288.0516 - KL_divergence: 8.0629
 82/200 [===========>..................] - ETA: 1s - loss: 12265.3459 - KL_divergence: 8.0573
 88/200 [============>.................] - ETA: 0s - loss: 12273.3562 - KL_divergence: 8.0666
 94/200 [=============>................] - ETA: 0s - loss: 12304.8733 - KL_divergence: 8.0609
101/200 [==============>...............] - ETA: 0s - loss: 12357.2158 - KL_divergence: 8.0503
107/200 [===============>..............] - ETA: 0s - loss: 12362.4318 - KL_divergence: 8.0517
113/200 [===============>..............] - ETA: 0s - loss: 12355.2862 - KL_divergence: 8.0532
119/200 [================>.............] - ETA: 0s - loss: 12378.0381 - KL_divergence: 8.0401
125/200 [=================>............] - ETA: 0s - loss: 12372.1047 - KL_divergence: 8.0403
131/200 [==================>...........] - ETA: 0s - loss: 12381.6715 - KL_divergence: 8.0352
137/200 [===================>..........] - ETA: 0s - loss: 12383.3425 - KL_divergence: 8.0236
143/200 [====================>.........] - ETA: 0s - loss: 12381.0047 - KL_divergence: 8.0196
149/200 [=====================>........] - ETA: 0s - loss: 12374.7869 - KL_divergence: 8.0232
155/200 [======================>.......] - ETA: 0s - loss: 12387.8134 - KL_divergence: 8.0162
161/200 [=======================>......] - ETA: 0s - loss: 12381.0957 - KL_divergence: 8.0191
167/200 [========================>.....] - ETA: 0s - loss: 12387.0200 - KL_divergence: 8.0259
173/200 [========================>.....] - ETA: 0s - loss: 12402.4574 - KL_divergence: 8.0266
179/200 [=========================>....] - ETA: 0s - loss: 12406.0228 - KL_divergence: 8.0234
185/200 [==========================>...] - ETA: 0s - loss: 12386.5336 - KL_divergence: 8.0277
191/200 [===========================>..] - ETA: 0s - loss: 12387.5276 - KL_divergence: 8.0234
197/200 [============================>.] - ETA: 0s - loss: 12386.8038 - KL_divergence: 8.0309
200/200 [==============================] - 2s 10ms/step - loss: 12378.3716 - KL_divergence: 8.0336 - val_loss: 13013.5459 - val_KL_divergence: 8.2084
Epoch 75/100

  1/200 [..............................] - ETA: 1s - loss: 12734.1016 - KL_divergence: 8.0988
  7/200 [>.............................] - ETA: 1s - loss: 12411.8997 - KL_divergence: 8.0348
 12/200 [>.............................] - ETA: 1s - loss: 12597.7234 - KL_divergence: 7.9307
 18/200 [=>............................] - ETA: 1s - loss: 12538.4820 - KL_divergence: 7.9556
 24/200 [==>...........................] - ETA: 1s - loss: 12499.9309 - KL_divergence: 8.0298
 30/200 [===>..........................] - ETA: 1s - loss: 12472.8520 - KL_divergence: 8.0929
 35/200 [====>.........................] - ETA: 1s - loss: 12458.0475 - KL_divergence: 8.0733
 41/200 [=====>........................] - ETA: 1s - loss: 12492.4821 - KL_divergence: 8.0251
 47/200 [======>.......................] - ETA: 1s - loss: 12484.2038 - KL_divergence: 8.0313
 53/200 [======>.......................] - ETA: 1s - loss: 12453.3910 - KL_divergence: 8.0347
 59/200 [=======>......................] - ETA: 1s - loss: 12444.1233 - KL_divergence: 8.0106
 65/200 [========>.....................] - ETA: 1s - loss: 12435.6503 - KL_divergence: 8.0146
 71/200 [=========>....................] - ETA: 1s - loss: 12448.7672 - KL_divergence: 8.0246
 77/200 [==========>...................] - ETA: 1s - loss: 12434.2276 - KL_divergence: 8.0266
 83/200 [===========>..................] - ETA: 1s - loss: 12436.4723 - KL_divergence: 8.0165
 89/200 [============>.................] - ETA: 1s - loss: 12454.9070 - KL_divergence: 8.0020
 95/200 [=============>................] - ETA: 0s - loss: 12433.7898 - KL_divergence: 8.0047
101/200 [==============>...............] - ETA: 0s - loss: 12477.4655 - KL_divergence: 7.9984
107/200 [===============>..............] - ETA: 0s - loss: 12446.8574 - KL_divergence: 8.0021
113/200 [===============>..............] - ETA: 0s - loss: 12447.8663 - KL_divergence: 7.9925
119/200 [================>.............] - ETA: 0s - loss: 12463.9700 - KL_divergence: 7.9968
125/200 [=================>............] - ETA: 0s - loss: 12469.7621 - KL_divergence: 7.9947
131/200 [==================>...........] - ETA: 0s - loss: 12502.4616 - KL_divergence: 7.9773
137/200 [===================>..........] - ETA: 0s - loss: 12504.2804 - KL_divergence: 7.9792
143/200 [====================>.........] - ETA: 0s - loss: 12537.9682 - KL_divergence: 7.9753
149/200 [=====================>........] - ETA: 0s - loss: 12529.4417 - KL_divergence: 7.9746
155/200 [======================>.......] - ETA: 0s - loss: 12519.9171 - KL_divergence: 7.9695
161/200 [=======================>......] - ETA: 0s - loss: 12517.5263 - KL_divergence: 7.9663
167/200 [========================>.....] - ETA: 0s - loss: 12488.1049 - KL_divergence: 7.9807
173/200 [========================>.....] - ETA: 0s - loss: 12479.7548 - KL_divergence: 7.9905
179/200 [=========================>....] - ETA: 0s - loss: 12486.4882 - KL_divergence: 7.9919
185/200 [==========================>...] - ETA: 0s - loss: 12487.5374 - KL_divergence: 7.9876
191/200 [===========================>..] - ETA: 0s - loss: 12473.7371 - KL_divergence: 7.9886
197/200 [============================>.] - ETA: 0s - loss: 12469.0381 - KL_divergence: 7.9854
200/200 [==============================] - 2s 10ms/step - loss: 12463.5034 - KL_divergence: 7.9886 - val_loss: 12751.4068 - val_KL_divergence: 7.5114
Epoch 76/100

  1/200 [..............................] - ETA: 1s - loss: 11122.1348 - KL_divergence: 8.1620
  7/200 [>.............................] - ETA: 1s - loss: 11967.3521 - KL_divergence: 8.0809
 13/200 [>.............................] - ETA: 1s - loss: 12393.8063 - KL_divergence: 8.0118
 19/200 [=>............................] - ETA: 1s - loss: 12456.9162 - KL_divergence: 7.9681
 24/200 [==>...........................] - ETA: 1s - loss: 12377.1236 - KL_divergence: 7.9386
 30/200 [===>..........................] - ETA: 1s - loss: 12440.4212 - KL_divergence: 7.9321
 36/200 [====>.........................] - ETA: 1s - loss: 12429.0506 - KL_divergence: 7.9169
 42/200 [=====>........................] - ETA: 1s - loss: 12468.0730 - KL_divergence: 7.9382
 48/200 [======>.......................] - ETA: 1s - loss: 12484.3373 - KL_divergence: 7.9372
 54/200 [=======>......................] - ETA: 1s - loss: 12490.8532 - KL_divergence: 7.9212
 60/200 [========>.....................] - ETA: 1s - loss: 12519.5981 - KL_divergence: 7.9117
 66/200 [========>.....................] - ETA: 1s - loss: 12467.7723 - KL_divergence: 7.9162
 72/200 [=========>....................] - ETA: 1s - loss: 12537.7279 - KL_divergence: 7.8979
 78/200 [==========>...................] - ETA: 1s - loss: 12494.1807 - KL_divergence: 7.9046
 84/200 [===========>..................] - ETA: 1s - loss: 12492.7161 - KL_divergence: 7.8997
 91/200 [============>.................] - ETA: 1s - loss: 12519.4937 - KL_divergence: 7.8951
 98/200 [=============>................] - ETA: 0s - loss: 12504.4437 - KL_divergence: 7.9109
105/200 [==============>...............] - ETA: 0s - loss: 12460.2549 - KL_divergence: 7.9309
111/200 [===============>..............] - ETA: 0s - loss: 12422.5372 - KL_divergence: 7.9452
117/200 [================>.............] - ETA: 0s - loss: 12419.3254 - KL_divergence: 7.9408
123/200 [=================>............] - ETA: 0s - loss: 12396.7628 - KL_divergence: 7.9511
129/200 [==================>...........] - ETA: 0s - loss: 12398.0780 - KL_divergence: 7.9605
135/200 [===================>..........] - ETA: 0s - loss: 12370.7482 - KL_divergence: 7.9708
141/200 [====================>.........] - ETA: 0s - loss: 12362.8959 - KL_divergence: 7.9759
147/200 [=====================>........] - ETA: 0s - loss: 12351.7794 - KL_divergence: 7.9747
153/200 [=====================>........] - ETA: 0s - loss: 12351.0294 - KL_divergence: 7.9791
159/200 [======================>.......] - ETA: 0s - loss: 12379.5701 - KL_divergence: 7.9733
165/200 [=======================>......] - ETA: 0s - loss: 12363.2977 - KL_divergence: 7.9780
171/200 [========================>.....] - ETA: 0s - loss: 12373.8931 - KL_divergence: 7.9718
177/200 [=========================>....] - ETA: 0s - loss: 12365.4401 - KL_divergence: 7.9787
182/200 [==========================>...] - ETA: 0s - loss: 12354.5028 - KL_divergence: 7.9856
188/200 [===========================>..] - ETA: 0s - loss: 12354.3443 - KL_divergence: 7.9752
194/200 [============================>.] - ETA: 0s - loss: 12366.8740 - KL_divergence: 7.9718
200/200 [==============================] - 2s 10ms/step - loss: 12354.5359 - KL_divergence: 7.9745 - val_loss: 12777.4063 - val_KL_divergence: 7.7424
Epoch 77/100

  1/200 [..............................] - ETA: 1s - loss: 12574.6953 - KL_divergence: 7.7790
  7/200 [>.............................] - ETA: 1s - loss: 12358.8104 - KL_divergence: 8.0344
 13/200 [>.............................] - ETA: 1s - loss: 12365.3613 - KL_divergence: 8.0206
 19/200 [=>............................] - ETA: 1s - loss: 12279.0060 - KL_divergence: 8.0163
 25/200 [==>...........................] - ETA: 1s - loss: 12317.3818 - KL_divergence: 8.0429
 31/200 [===>..........................] - ETA: 1s - loss: 12284.8790 - KL_divergence: 8.0350
 37/200 [====>.........................] - ETA: 1s - loss: 12254.9432 - KL_divergence: 8.0466
 43/200 [=====>........................] - ETA: 1s - loss: 12216.8638 - KL_divergence: 8.0514
 49/200 [======>.......................] - ETA: 1s - loss: 12255.6991 - KL_divergence: 8.0317
 55/200 [=======>......................] - ETA: 1s - loss: 12266.0012 - KL_divergence: 8.0110
 61/200 [========>.....................] - ETA: 1s - loss: 12289.2361 - KL_divergence: 7.9818
 68/200 [=========>....................] - ETA: 1s - loss: 12276.7386 - KL_divergence: 7.9993
 74/200 [==========>...................] - ETA: 1s - loss: 12254.9810 - KL_divergence: 8.0109
 80/200 [===========>..................] - ETA: 1s - loss: 12246.4637 - KL_divergence: 8.0086
 86/200 [===========>..................] - ETA: 1s - loss: 12290.0714 - KL_divergence: 8.0130
 92/200 [============>.................] - ETA: 0s - loss: 12283.1845 - KL_divergence: 8.0126
 98/200 [=============>................] - ETA: 0s - loss: 12282.1332 - KL_divergence: 8.0076
104/200 [==============>...............] - ETA: 0s - loss: 12315.4569 - KL_divergence: 8.0022
110/200 [===============>..............] - ETA: 0s - loss: 12324.9459 - KL_divergence: 8.0014
116/200 [================>.............] - ETA: 0s - loss: 12301.2425 - KL_divergence: 8.0099
122/200 [=================>............] - ETA: 0s - loss: 12288.1323 - KL_divergence: 8.0150
128/200 [==================>...........] - ETA: 0s - loss: 12277.6646 - KL_divergence: 8.0181
134/200 [===================>..........] - ETA: 0s - loss: 12292.6185 - KL_divergence: 8.0112
140/200 [====================>.........] - ETA: 0s - loss: 12295.0478 - KL_divergence: 8.0098
146/200 [====================>.........] - ETA: 0s - loss: 12297.1492 - KL_divergence: 8.0175
153/200 [=====================>........] - ETA: 0s - loss: 12321.2405 - KL_divergence: 8.0097
160/200 [=======================>......] - ETA: 0s - loss: 12318.7988 - KL_divergence: 8.0089
167/200 [========================>.....] - ETA: 0s - loss: 12325.6692 - KL_divergence: 7.9970
173/200 [========================>.....] - ETA: 0s - loss: 12335.0915 - KL_divergence: 7.9924
180/200 [==========================>...] - ETA: 0s - loss: 12328.3382 - KL_divergence: 7.9846
187/200 [===========================>..] - ETA: 0s - loss: 12334.6861 - KL_divergence: 7.9795
193/200 [===========================>..] - ETA: 0s - loss: 12338.5289 - KL_divergence: 7.9748
199/200 [============================>.] - ETA: 0s - loss: 12350.9263 - KL_divergence: 7.9686
200/200 [==============================] - 2s 10ms/step - loss: 12346.5655 - KL_divergence: 7.9684 - val_loss: 12770.2223 - val_KL_divergence: 7.9321
Epoch 78/100

  1/200 [..............................] - ETA: 1s - loss: 13237.0967 - KL_divergence: 7.2065
  7/200 [>.............................] - ETA: 1s - loss: 12844.8556 - KL_divergence: 7.7288
 13/200 [>.............................] - ETA: 1s - loss: 12698.6560 - KL_divergence: 7.7877
 19/200 [=>............................] - ETA: 1s - loss: 12747.1239 - KL_divergence: 7.7971
 25/200 [==>...........................] - ETA: 1s - loss: 12666.7566 - KL_divergence: 7.8604
 31/200 [===>..........................] - ETA: 1s - loss: 12522.7536 - KL_divergence: 7.8986
 37/200 [====>.........................] - ETA: 1s - loss: 12524.2146 - KL_divergence: 7.8918
 43/200 [=====>........................] - ETA: 1s - loss: 12500.5431 - KL_divergence: 7.9280
 49/200 [======>.......................] - ETA: 1s - loss: 12481.6074 - KL_divergence: 7.9473
 55/200 [=======>......................] - ETA: 1s - loss: 12508.4509 - KL_divergence: 7.9395
 61/200 [========>.....................] - ETA: 1s - loss: 12488.5961 - KL_divergence: 7.9338
 67/200 [=========>....................] - ETA: 1s - loss: 12464.6554 - KL_divergence: 7.9343
 73/200 [=========>....................] - ETA: 1s - loss: 12452.3137 - KL_divergence: 7.9306
 79/200 [==========>...................] - ETA: 1s - loss: 12428.0285 - KL_divergence: 7.9365
 85/200 [===========>..................] - ETA: 1s - loss: 12364.3316 - KL_divergence: 7.9671
 91/200 [============>.................] - ETA: 0s - loss: 12364.5779 - KL_divergence: 7.9663
 97/200 [=============>................] - ETA: 0s - loss: 12353.5329 - KL_divergence: 7.9724
103/200 [==============>...............] - ETA: 0s - loss: 12319.0816 - KL_divergence: 7.9845
109/200 [===============>..............] - ETA: 0s - loss: 12336.1709 - KL_divergence: 7.9798
115/200 [================>.............] - ETA: 0s - loss: 12339.3762 - KL_divergence: 7.9699
121/200 [=================>............] - ETA: 0s - loss: 12367.3602 - KL_divergence: 7.9666
128/200 [==================>...........] - ETA: 0s - loss: 12345.9640 - KL_divergence: 7.9652
134/200 [===================>..........] - ETA: 0s - loss: 12364.5979 - KL_divergence: 7.9600
140/200 [====================>.........] - ETA: 0s - loss: 12356.9720 - KL_divergence: 7.9518
146/200 [====================>.........] - ETA: 0s - loss: 12352.4689 - KL_divergence: 7.9482
152/200 [=====================>........] - ETA: 0s - loss: 12365.0593 - KL_divergence: 7.9388
158/200 [======================>.......] - ETA: 0s - loss: 12377.2835 - KL_divergence: 7.9363
164/200 [=======================>......] - ETA: 0s - loss: 12376.1320 - KL_divergence: 7.9310
170/200 [========================>.....] - ETA: 0s - loss: 12363.9477 - KL_divergence: 7.9337
176/200 [=========================>....] - ETA: 0s - loss: 12358.9146 - KL_divergence: 7.9354
182/200 [==========================>...] - ETA: 0s - loss: 12366.4231 - KL_divergence: 7.9399
188/200 [===========================>..] - ETA: 0s - loss: 12359.3829 - KL_divergence: 7.9451
194/200 [============================>.] - ETA: 0s - loss: 12338.1297 - KL_divergence: 7.9482
200/200 [==============================] - 2s 10ms/step - loss: 12358.0652 - KL_divergence: 7.9454 - val_loss: 12953.0200 - val_KL_divergence: 8.3198
Epoch 79/100

  1/200 [..............................] - ETA: 1s - loss: 13977.4658 - KL_divergence: 8.3030
  7/200 [>.............................] - ETA: 1s - loss: 12246.4914 - KL_divergence: 8.0831
 13/200 [>.............................] - ETA: 1s - loss: 12297.4023 - KL_divergence: 8.0741
 19/200 [=>............................] - ETA: 1s - loss: 12339.1215 - KL_divergence: 8.0062
 25/200 [==>...........................] - ETA: 1s - loss: 12368.9203 - KL_divergence: 7.9814
 31/200 [===>..........................] - ETA: 1s - loss: 12392.2805 - KL_divergence: 8.0063
 37/200 [====>.........................] - ETA: 1s - loss: 12440.0725 - KL_divergence: 7.9861
 43/200 [=====>........................] - ETA: 1s - loss: 12403.9066 - KL_divergence: 7.9879
 49/200 [======>.......................] - ETA: 1s - loss: 12422.6508 - KL_divergence: 7.9721
 55/200 [=======>......................] - ETA: 1s - loss: 12453.9876 - KL_divergence: 7.9443
 60/200 [========>.....................] - ETA: 1s - loss: 12421.6860 - KL_divergence: 7.9531
 66/200 [========>.....................] - ETA: 1s - loss: 12414.8449 - KL_divergence: 7.9641
 72/200 [=========>....................] - ETA: 1s - loss: 12419.8928 - KL_divergence: 7.9734
 78/200 [==========>...................] - ETA: 1s - loss: 12407.1637 - KL_divergence: 7.9777
 84/200 [===========>..................] - ETA: 1s - loss: 12391.7392 - KL_divergence: 7.9870
 90/200 [============>.................] - ETA: 1s - loss: 12392.9536 - KL_divergence: 7.9938
 96/200 [=============>................] - ETA: 0s - loss: 12372.3766 - KL_divergence: 7.9927
102/200 [==============>...............] - ETA: 0s - loss: 12346.8265 - KL_divergence: 7.9927
108/200 [===============>..............] - ETA: 0s - loss: 12342.7216 - KL_divergence: 7.9915
114/200 [================>.............] - ETA: 0s - loss: 12327.4920 - KL_divergence: 7.9908
120/200 [=================>............] - ETA: 0s - loss: 12307.7448 - KL_divergence: 7.9958
126/200 [=================>............] - ETA: 0s - loss: 12295.3700 - KL_divergence: 7.9938
132/200 [==================>...........] - ETA: 0s - loss: 12301.2513 - KL_divergence: 7.9886
138/200 [===================>..........] - ETA: 0s - loss: 12316.1027 - KL_divergence: 7.9878
144/200 [====================>.........] - ETA: 0s - loss: 12309.8934 - KL_divergence: 7.9847
150/200 [=====================>........] - ETA: 0s - loss: 12312.1471 - KL_divergence: 7.9916
156/200 [======================>.......] - ETA: 0s - loss: 12317.2694 - KL_divergence: 7.9943
163/200 [=======================>......] - ETA: 0s - loss: 12320.8909 - KL_divergence: 7.9976
169/200 [========================>.....] - ETA: 0s - loss: 12314.7878 - KL_divergence: 8.0025
175/200 [=========================>....] - ETA: 0s - loss: 12300.8695 - KL_divergence: 8.0062
181/200 [==========================>...] - ETA: 0s - loss: 12297.1208 - KL_divergence: 8.0064
188/200 [===========================>..] - ETA: 0s - loss: 12295.6465 - KL_divergence: 8.0085
194/200 [============================>.] - ETA: 0s - loss: 12284.4573 - KL_divergence: 8.0067
200/200 [==============================] - 2s 10ms/step - loss: 12278.2676 - KL_divergence: 8.0077 - val_loss: 12790.1564 - val_KL_divergence: 7.6801
Epoch 80/100

  1/200 [..............................] - ETA: 1s - loss: 11717.1221 - KL_divergence: 7.7078
  7/200 [>.............................] - ETA: 1s - loss: 12227.9508 - KL_divergence: 8.0159
 13/200 [>.............................] - ETA: 1s - loss: 12318.0730 - KL_divergence: 7.9084
 18/200 [=>............................] - ETA: 1s - loss: 12170.0394 - KL_divergence: 7.9989
 24/200 [==>...........................] - ETA: 1s - loss: 12177.5411 - KL_divergence: 8.0023
 30/200 [===>..........................] - ETA: 1s - loss: 12214.1013 - KL_divergence: 7.9840
 36/200 [====>.........................] - ETA: 1s - loss: 12288.4181 - KL_divergence: 7.9843
 42/200 [=====>........................] - ETA: 1s - loss: 12270.3840 - KL_divergence: 7.9760
 48/200 [======>.......................] - ETA: 1s - loss: 12251.3070 - KL_divergence: 7.9815
 54/200 [=======>......................] - ETA: 1s - loss: 12256.2171 - KL_divergence: 7.9733
 60/200 [========>.....................] - ETA: 1s - loss: 12273.0486 - KL_divergence: 7.9817
 66/200 [========>.....................] - ETA: 1s - loss: 12275.9958 - KL_divergence: 7.9738
 72/200 [=========>....................] - ETA: 1s - loss: 12279.9197 - KL_divergence: 7.9765
 78/200 [==========>...................] - ETA: 1s - loss: 12225.9722 - KL_divergence: 7.9695
 84/200 [===========>..................] - ETA: 1s - loss: 12247.3177 - KL_divergence: 7.9435
 90/200 [============>.................] - ETA: 1s - loss: 12231.4289 - KL_divergence: 7.9358
 96/200 [=============>................] - ETA: 0s - loss: 12264.0171 - KL_divergence: 7.9277
102/200 [==============>...............] - ETA: 0s - loss: 12240.9584 - KL_divergence: 7.9354
108/200 [===============>..............] - ETA: 0s - loss: 12220.8877 - KL_divergence: 7.9370
114/200 [================>.............] - ETA: 0s - loss: 12244.3090 - KL_divergence: 7.9273
120/200 [=================>............] - ETA: 0s - loss: 12273.2521 - KL_divergence: 7.9204
126/200 [=================>............] - ETA: 0s - loss: 12293.7277 - KL_divergence: 7.9119
132/200 [==================>...........] - ETA: 0s - loss: 12273.0608 - KL_divergence: 7.9182
138/200 [===================>..........] - ETA: 0s - loss: 12291.5083 - KL_divergence: 7.9169
144/200 [====================>.........] - ETA: 0s - loss: 12291.5146 - KL_divergence: 7.9115
150/200 [=====================>........] - ETA: 0s - loss: 12285.4552 - KL_divergence: 7.9178
156/200 [======================>.......] - ETA: 0s - loss: 12281.5031 - KL_divergence: 7.9175
162/200 [=======================>......] - ETA: 0s - loss: 12267.7697 - KL_divergence: 7.9234
168/200 [========================>.....] - ETA: 0s - loss: 12268.3919 - KL_divergence: 7.9284
174/200 [=========================>....] - ETA: 0s - loss: 12266.9520 - KL_divergence: 7.9347
179/200 [=========================>....] - ETA: 0s - loss: 12273.4107 - KL_divergence: 7.9302
185/200 [==========================>...] - ETA: 0s - loss: 12282.5532 - KL_divergence: 7.9246
191/200 [===========================>..] - ETA: 0s - loss: 12284.5772 - KL_divergence: 7.9252
197/200 [============================>.] - ETA: 0s - loss: 12277.9437 - KL_divergence: 7.9274
200/200 [==============================] - 2s 10ms/step - loss: 12276.3850 - KL_divergence: 7.9239 - val_loss: 12815.3761 - val_KL_divergence: 8.1260
Epoch 81/100

  1/200 [..............................] - ETA: 1s - loss: 13116.0898 - KL_divergence: 8.1585
  7/200 [>.............................] - ETA: 1s - loss: 12382.1406 - KL_divergence: 7.8933
 13/200 [>.............................] - ETA: 1s - loss: 12242.2984 - KL_divergence: 7.9189
 19/200 [=>............................] - ETA: 1s - loss: 12384.0722 - KL_divergence: 7.9230
 25/200 [==>...........................] - ETA: 1s - loss: 12404.8525 - KL_divergence: 7.8996
 31/200 [===>..........................] - ETA: 1s - loss: 12291.7634 - KL_divergence: 7.9248
 37/200 [====>.........................] - ETA: 1s - loss: 12279.5190 - KL_divergence: 7.9569
 43/200 [=====>........................] - ETA: 1s - loss: 12328.4739 - KL_divergence: 7.9540
 49/200 [======>.......................] - ETA: 1s - loss: 12312.9936 - KL_divergence: 7.9283
 55/200 [=======>......................] - ETA: 1s - loss: 12384.2124 - KL_divergence: 7.9278
 61/200 [========>.....................] - ETA: 1s - loss: 12372.2878 - KL_divergence: 7.9083
 67/200 [=========>....................] - ETA: 1s - loss: 12346.1075 - KL_divergence: 7.9083
 73/200 [=========>....................] - ETA: 1s - loss: 12344.3038 - KL_divergence: 7.9083
 79/200 [==========>...................] - ETA: 1s - loss: 12329.9508 - KL_divergence: 7.9102
 85/200 [===========>..................] - ETA: 1s - loss: 12347.4339 - KL_divergence: 7.9037
 91/200 [============>.................] - ETA: 0s - loss: 12357.6134 - KL_divergence: 7.8986
 97/200 [=============>................] - ETA: 0s - loss: 12337.4874 - KL_divergence: 7.9024
103/200 [==============>...............] - ETA: 0s - loss: 12369.0064 - KL_divergence: 7.9029
109/200 [===============>..............] - ETA: 0s - loss: 12361.5599 - KL_divergence: 7.9006
115/200 [================>.............] - ETA: 0s - loss: 12368.2043 - KL_divergence: 7.8962
121/200 [=================>............] - ETA: 0s - loss: 12367.0395 - KL_divergence: 7.8997
127/200 [==================>...........] - ETA: 0s - loss: 12379.5419 - KL_divergence: 7.8955
133/200 [==================>...........] - ETA: 0s - loss: 12378.9391 - KL_divergence: 7.8974
139/200 [===================>..........] - ETA: 0s - loss: 12398.6161 - KL_divergence: 7.8926
145/200 [====================>.........] - ETA: 0s - loss: 12395.7040 - KL_divergence: 7.8936
151/200 [=====================>........] - ETA: 0s - loss: 12388.8983 - KL_divergence: 7.8992
157/200 [======================>.......] - ETA: 0s - loss: 12393.3052 - KL_divergence: 7.8936
163/200 [=======================>......] - ETA: 0s - loss: 12390.1428 - KL_divergence: 7.8944
169/200 [========================>.....] - ETA: 0s - loss: 12379.7976 - KL_divergence: 7.9029
175/200 [=========================>....] - ETA: 0s - loss: 12386.0475 - KL_divergence: 7.9002
181/200 [==========================>...] - ETA: 0s - loss: 12376.2541 - KL_divergence: 7.8984
187/200 [===========================>..] - ETA: 0s - loss: 12370.5371 - KL_divergence: 7.9061
193/200 [===========================>..] - ETA: 0s - loss: 12364.5267 - KL_divergence: 7.9040
199/200 [============================>.] - ETA: 0s - loss: 12359.4775 - KL_divergence: 7.9089
200/200 [==============================] - 2s 10ms/step - loss: 12365.5967 - KL_divergence: 7.9101 - val_loss: 12769.7847 - val_KL_divergence: 7.5235
Epoch 82/100

  1/200 [..............................] - ETA: 1s - loss: 13192.9961 - KL_divergence: 7.4277
  7/200 [>.............................] - ETA: 1s - loss: 12483.0089 - KL_divergence: 7.8200
 13/200 [>.............................] - ETA: 1s - loss: 12385.4589 - KL_divergence: 7.7924
 19/200 [=>............................] - ETA: 1s - loss: 12304.5149 - KL_divergence: 7.8332
 26/200 [==>...........................] - ETA: 1s - loss: 12366.5925 - KL_divergence: 7.8600
 33/200 [===>..........................] - ETA: 1s - loss: 12394.8949 - KL_divergence: 7.8867
 39/200 [====>.........................] - ETA: 1s - loss: 12341.3926 - KL_divergence: 7.9136
 45/200 [=====>........................] - ETA: 1s - loss: 12317.2827 - KL_divergence: 7.9462
 51/200 [======>.......................] - ETA: 1s - loss: 12262.1476 - KL_divergence: 7.9413
 57/200 [=======>......................] - ETA: 1s - loss: 12249.0330 - KL_divergence: 7.9460
 63/200 [========>.....................] - ETA: 1s - loss: 12259.0911 - KL_divergence: 7.9367
 69/200 [=========>....................] - ETA: 1s - loss: 12275.3301 - KL_divergence: 7.9361
 75/200 [==========>...................] - ETA: 1s - loss: 12304.3889 - KL_divergence: 7.9373
 81/200 [===========>..................] - ETA: 1s - loss: 12288.0697 - KL_divergence: 7.9275
 87/200 [============>.................] - ETA: 0s - loss: 12287.0260 - KL_divergence: 7.9163
 93/200 [============>.................] - ETA: 0s - loss: 12303.6474 - KL_divergence: 7.9060
 99/200 [=============>................] - ETA: 0s - loss: 12300.2217 - KL_divergence: 7.9156
105/200 [==============>...............] - ETA: 0s - loss: 12294.8076 - KL_divergence: 7.9060
111/200 [===============>..............] - ETA: 0s - loss: 12279.3822 - KL_divergence: 7.9078
117/200 [================>.............] - ETA: 0s - loss: 12254.3145 - KL_divergence: 7.9089
123/200 [=================>............] - ETA: 0s - loss: 12239.6967 - KL_divergence: 7.9140
129/200 [==================>...........] - ETA: 0s - loss: 12216.7310 - KL_divergence: 7.9191
135/200 [===================>..........] - ETA: 0s - loss: 12201.0437 - KL_divergence: 7.9226
141/200 [====================>.........] - ETA: 0s - loss: 12185.8007 - KL_divergence: 7.9264
147/200 [=====================>........] - ETA: 0s - loss: 12168.4946 - KL_divergence: 7.9386
153/200 [=====================>........] - ETA: 0s - loss: 12184.5699 - KL_divergence: 7.9416
159/200 [======================>.......] - ETA: 0s - loss: 12190.0970 - KL_divergence: 7.9386
165/200 [=======================>......] - ETA: 0s - loss: 12178.6833 - KL_divergence: 7.9420
171/200 [========================>.....] - ETA: 0s - loss: 12199.8721 - KL_divergence: 7.9335
177/200 [=========================>....] - ETA: 0s - loss: 12202.0436 - KL_divergence: 7.9343
183/200 [==========================>...] - ETA: 0s - loss: 12214.5434 - KL_divergence: 7.9294
189/200 [===========================>..] - ETA: 0s - loss: 12227.1750 - KL_divergence: 7.9347
195/200 [============================>.] - ETA: 0s - loss: 12247.8931 - KL_divergence: 7.9307
200/200 [==============================] - 2s 10ms/step - loss: 12243.9205 - KL_divergence: 7.9374 - val_loss: 12789.1742 - val_KL_divergence: 7.6569
Epoch 83/100

  1/200 [..............................] - ETA: 1s - loss: 11432.5303 - KL_divergence: 7.7289
  7/200 [>.............................] - ETA: 1s - loss: 12035.9912 - KL_divergence: 8.0374
 13/200 [>.............................] - ETA: 1s - loss: 11805.9072 - KL_divergence: 8.0486
 19/200 [=>............................] - ETA: 1s - loss: 12000.2897 - KL_divergence: 8.0504
 25/200 [==>...........................] - ETA: 1s - loss: 12149.0316 - KL_divergence: 8.0028
 31/200 [===>..........................] - ETA: 1s - loss: 12125.5118 - KL_divergence: 8.0323
 37/200 [====>.........................] - ETA: 1s - loss: 12162.5686 - KL_divergence: 8.0305
 43/200 [=====>........................] - ETA: 1s - loss: 12156.9777 - KL_divergence: 8.0421
 49/200 [======>.......................] - ETA: 1s - loss: 12134.4434 - KL_divergence: 8.0414
 55/200 [=======>......................] - ETA: 1s - loss: 12130.5258 - KL_divergence: 8.0388
 61/200 [========>.....................] - ETA: 1s - loss: 12113.9846 - KL_divergence: 8.0309
 67/200 [=========>....................] - ETA: 1s - loss: 12119.7099 - KL_divergence: 8.0215
 73/200 [=========>....................] - ETA: 1s - loss: 12114.2422 - KL_divergence: 8.0084
 79/200 [==========>...................] - ETA: 1s - loss: 12151.0820 - KL_divergence: 7.9874
 85/200 [===========>..................] - ETA: 1s - loss: 12118.8345 - KL_divergence: 8.0094
 91/200 [============>.................] - ETA: 0s - loss: 12126.0176 - KL_divergence: 8.0210
 97/200 [=============>................] - ETA: 0s - loss: 12155.4948 - KL_divergence: 8.0069
103/200 [==============>...............] - ETA: 0s - loss: 12166.2863 - KL_divergence: 8.0015
109/200 [===============>..............] - ETA: 0s - loss: 12183.8277 - KL_divergence: 7.9949
115/200 [================>.............] - ETA: 0s - loss: 12200.9499 - KL_divergence: 7.9820
121/200 [=================>............] - ETA: 0s - loss: 12196.9895 - KL_divergence: 7.9824
127/200 [==================>...........] - ETA: 0s - loss: 12242.9691 - KL_divergence: 7.9700
133/200 [==================>...........] - ETA: 0s - loss: 12231.0607 - KL_divergence: 7.9663
139/200 [===================>..........] - ETA: 0s - loss: 12232.0156 - KL_divergence: 7.9579
146/200 [====================>.........] - ETA: 0s - loss: 12260.9591 - KL_divergence: 7.9557
152/200 [=====================>........] - ETA: 0s - loss: 12264.7819 - KL_divergence: 7.9551
158/200 [======================>.......] - ETA: 0s - loss: 12267.0286 - KL_divergence: 7.9489
164/200 [=======================>......] - ETA: 0s - loss: 12261.6626 - KL_divergence: 7.9441
170/200 [========================>.....] - ETA: 0s - loss: 12286.3010 - KL_divergence: 7.9377
176/200 [=========================>....] - ETA: 0s - loss: 12283.9905 - KL_divergence: 7.9430
182/200 [==========================>...] - ETA: 0s - loss: 12284.7118 - KL_divergence: 7.9453
188/200 [===========================>..] - ETA: 0s - loss: 12281.5394 - KL_divergence: 7.9454
194/200 [============================>.] - ETA: 0s - loss: 12293.6723 - KL_divergence: 7.9362
200/200 [==============================] - 2s 10ms/step - loss: 12294.6163 - KL_divergence: 7.9253 - val_loss: 12744.9556 - val_KL_divergence: 7.9098
Epoch 84/100

  1/200 [..............................] - ETA: 1s - loss: 12189.8701 - KL_divergence: 8.1877
  7/200 [>.............................] - ETA: 1s - loss: 12118.3856 - KL_divergence: 8.0206
 13/200 [>.............................] - ETA: 1s - loss: 11979.3672 - KL_divergence: 7.9376
 19/200 [=>............................] - ETA: 1s - loss: 12137.2359 - KL_divergence: 7.8662
 24/200 [==>...........................] - ETA: 1s - loss: 12068.4483 - KL_divergence: 7.8650
 30/200 [===>..........................] - ETA: 1s - loss: 12149.5473 - KL_divergence: 7.8531
 36/200 [====>.........................] - ETA: 1s - loss: 12236.1927 - KL_divergence: 7.8306
 42/200 [=====>........................] - ETA: 1s - loss: 12206.7660 - KL_divergence: 7.8693
 48/200 [======>.......................] - ETA: 1s - loss: 12287.5022 - KL_divergence: 7.8725
 54/200 [=======>......................] - ETA: 1s - loss: 12299.2716 - KL_divergence: 7.8851
 60/200 [========>.....................] - ETA: 1s - loss: 12307.2461 - KL_divergence: 7.9086
 66/200 [========>.....................] - ETA: 1s - loss: 12303.9215 - KL_divergence: 7.9124
 72/200 [=========>....................] - ETA: 1s - loss: 12337.3292 - KL_divergence: 7.9123
 78/200 [==========>...................] - ETA: 1s - loss: 12351.3903 - KL_divergence: 7.9236
 84/200 [===========>..................] - ETA: 1s - loss: 12321.9439 - KL_divergence: 7.9291
 90/200 [============>.................] - ETA: 1s - loss: 12306.9948 - KL_divergence: 7.9252
 96/200 [=============>................] - ETA: 0s - loss: 12312.5993 - KL_divergence: 7.9232
102/200 [==============>...............] - ETA: 0s - loss: 12314.8983 - KL_divergence: 7.9246
108/200 [===============>..............] - ETA: 0s - loss: 12287.2405 - KL_divergence: 7.9384
114/200 [================>.............] - ETA: 0s - loss: 12270.0559 - KL_divergence: 7.9474
120/200 [=================>............] - ETA: 0s - loss: 12270.0923 - KL_divergence: 7.9485
126/200 [=================>............] - ETA: 0s - loss: 12263.3038 - KL_divergence: 7.9423
132/200 [==================>...........] - ETA: 0s - loss: 12272.8463 - KL_divergence: 7.9438
138/200 [===================>..........] - ETA: 0s - loss: 12301.4073 - KL_divergence: 7.9386
144/200 [====================>.........] - ETA: 0s - loss: 12301.5124 - KL_divergence: 7.9378
150/200 [=====================>........] - ETA: 0s - loss: 12290.2858 - KL_divergence: 7.9491
157/200 [======================>.......] - ETA: 0s - loss: 12295.5570 - KL_divergence: 7.9423
164/200 [=======================>......] - ETA: 0s - loss: 12284.9340 - KL_divergence: 7.9408
171/200 [========================>.....] - ETA: 0s - loss: 12288.7075 - KL_divergence: 7.9463
177/200 [=========================>....] - ETA: 0s - loss: 12290.3636 - KL_divergence: 7.9463
183/200 [==========================>...] - ETA: 0s - loss: 12272.3775 - KL_divergence: 7.9455
189/200 [===========================>..] - ETA: 0s - loss: 12266.6953 - KL_divergence: 7.9399
195/200 [============================>.] - ETA: 0s - loss: 12252.1077 - KL_divergence: 7.9405
200/200 [==============================] - 2s 10ms/step - loss: 12245.9441 - KL_divergence: 7.9455 - val_loss: 12725.9011 - val_KL_divergence: 8.2207
Epoch 85/100

  1/200 [..............................] - ETA: 1s - loss: 11434.0049 - KL_divergence: 8.8133
  7/200 [>.............................] - ETA: 1s - loss: 12342.9897 - KL_divergence: 7.8675
 13/200 [>.............................] - ETA: 1s - loss: 12311.8062 - KL_divergence: 7.8908
 18/200 [=>............................] - ETA: 1s - loss: 12360.0780 - KL_divergence: 7.9047
 24/200 [==>...........................] - ETA: 1s - loss: 12344.0768 - KL_divergence: 7.9284
 30/200 [===>..........................] - ETA: 1s - loss: 12246.3332 - KL_divergence: 7.9590
 36/200 [====>.........................] - ETA: 1s - loss: 12174.7260 - KL_divergence: 7.9908
 42/200 [=====>........................] - ETA: 1s - loss: 12243.8417 - KL_divergence: 7.9711
 48/200 [======>.......................] - ETA: 1s - loss: 12188.4470 - KL_divergence: 7.9616
 54/200 [=======>......................] - ETA: 1s - loss: 12181.5101 - KL_divergence: 7.9679
 60/200 [========>.....................] - ETA: 1s - loss: 12222.4308 - KL_divergence: 7.9510
 66/200 [========>.....................] - ETA: 1s - loss: 12231.6728 - KL_divergence: 7.9692
 72/200 [=========>....................] - ETA: 1s - loss: 12263.0881 - KL_divergence: 7.9578
 78/200 [==========>...................] - ETA: 1s - loss: 12264.9592 - KL_divergence: 7.9569
 84/200 [===========>..................] - ETA: 1s - loss: 12300.2000 - KL_divergence: 7.9463
 90/200 [============>.................] - ETA: 0s - loss: 12296.7849 - KL_divergence: 7.9444
 96/200 [=============>................] - ETA: 0s - loss: 12292.2281 - KL_divergence: 7.9503
102/200 [==============>...............] - ETA: 0s - loss: 12296.3085 - KL_divergence: 7.9531
108/200 [===============>..............] - ETA: 0s - loss: 12303.3633 - KL_divergence: 7.9569
114/200 [================>.............] - ETA: 0s - loss: 12313.6009 - KL_divergence: 7.9442
120/200 [=================>............] - ETA: 0s - loss: 12309.4128 - KL_divergence: 7.9437
126/200 [=================>............] - ETA: 0s - loss: 12279.6261 - KL_divergence: 7.9564
132/200 [==================>...........] - ETA: 0s - loss: 12283.4195 - KL_divergence: 7.9604
138/200 [===================>..........] - ETA: 0s - loss: 12257.7475 - KL_divergence: 7.9684
144/200 [====================>.........] - ETA: 0s - loss: 12248.5832 - KL_divergence: 7.9717
150/200 [=====================>........] - ETA: 0s - loss: 12240.4318 - KL_divergence: 7.9715
156/200 [======================>.......] - ETA: 0s - loss: 12222.6950 - KL_divergence: 7.9764
162/200 [=======================>......] - ETA: 0s - loss: 12219.9367 - KL_divergence: 7.9688
168/200 [========================>.....] - ETA: 0s - loss: 12209.3571 - KL_divergence: 7.9674
174/200 [=========================>....] - ETA: 0s - loss: 12208.0261 - KL_divergence: 7.9722
180/200 [==========================>...] - ETA: 0s - loss: 12211.6744 - KL_divergence: 7.9658
186/200 [==========================>...] - ETA: 0s - loss: 12217.7693 - KL_divergence: 7.9641
192/200 [===========================>..] - ETA: 0s - loss: 12195.0467 - KL_divergence: 7.9677
198/200 [============================>.] - ETA: 0s - loss: 12212.6385 - KL_divergence: 7.9689
200/200 [==============================] - 2s 10ms/step - loss: 12213.9524 - KL_divergence: 7.9659 - val_loss: 12784.2944 - val_KL_divergence: 7.7090
Epoch 86/100

  1/200 [..............................] - ETA: 1s - loss: 13806.0117 - KL_divergence: 7.3537
  7/200 [>.............................] - ETA: 1s - loss: 12615.9683 - KL_divergence: 7.6837
 13/200 [>.............................] - ETA: 1s - loss: 12610.7998 - KL_divergence: 7.7654
 19/200 [=>............................] - ETA: 1s - loss: 12505.5683 - KL_divergence: 7.8201
 25/200 [==>...........................] - ETA: 1s - loss: 12450.7273 - KL_divergence: 7.9019
 31/200 [===>..........................] - ETA: 1s - loss: 12413.9059 - KL_divergence: 7.8903
 37/200 [====>.........................] - ETA: 1s - loss: 12404.2049 - KL_divergence: 7.9320
 43/200 [=====>........................] - ETA: 1s - loss: 12416.4429 - KL_divergence: 7.9651
 49/200 [======>.......................] - ETA: 1s - loss: 12360.6823 - KL_divergence: 7.9622
 55/200 [=======>......................] - ETA: 1s - loss: 12316.7093 - KL_divergence: 7.9712
 61/200 [========>.....................] - ETA: 1s - loss: 12321.7809 - KL_divergence: 7.9541
 67/200 [=========>....................] - ETA: 1s - loss: 12306.4335 - KL_divergence: 7.9619
 73/200 [=========>....................] - ETA: 1s - loss: 12273.4758 - KL_divergence: 7.9650
 79/200 [==========>...................] - ETA: 1s - loss: 12249.0486 - KL_divergence: 7.9775
 85/200 [===========>..................] - ETA: 1s - loss: 12261.8060 - KL_divergence: 7.9734
 91/200 [============>.................] - ETA: 0s - loss: 12240.7064 - KL_divergence: 7.9693
 97/200 [=============>................] - ETA: 0s - loss: 12272.7513 - KL_divergence: 7.9695
103/200 [==============>...............] - ETA: 0s - loss: 12257.3216 - KL_divergence: 7.9668
109/200 [===============>..............] - ETA: 0s - loss: 12226.4055 - KL_divergence: 7.9721
115/200 [================>.............] - ETA: 0s - loss: 12203.4130 - KL_divergence: 7.9847
121/200 [=================>............] - ETA: 0s - loss: 12224.7140 - KL_divergence: 7.9808
126/200 [=================>............] - ETA: 0s - loss: 12203.1658 - KL_divergence: 7.9871
132/200 [==================>...........] - ETA: 0s - loss: 12229.0652 - KL_divergence: 7.9768
138/200 [===================>..........] - ETA: 0s - loss: 12241.0853 - KL_divergence: 7.9821
144/200 [====================>.........] - ETA: 0s - loss: 12224.6230 - KL_divergence: 7.9830
150/200 [=====================>........] - ETA: 0s - loss: 12223.3625 - KL_divergence: 7.9817
156/200 [======================>.......] - ETA: 0s - loss: 12228.1874 - KL_divergence: 7.9845
162/200 [=======================>......] - ETA: 0s - loss: 12229.1291 - KL_divergence: 7.9887
168/200 [========================>.....] - ETA: 0s - loss: 12238.6107 - KL_divergence: 7.9846
174/200 [=========================>....] - ETA: 0s - loss: 12240.1145 - KL_divergence: 7.9862
180/200 [==========================>...] - ETA: 0s - loss: 12231.3336 - KL_divergence: 7.9829
186/200 [==========================>...] - ETA: 0s - loss: 12247.1655 - KL_divergence: 7.9782
192/200 [===========================>..] - ETA: 0s - loss: 12244.6744 - KL_divergence: 7.9805
198/200 [============================>.] - ETA: 0s - loss: 12251.2533 - KL_divergence: 7.9765
200/200 [==============================] - 2s 10ms/step - loss: 12247.3248 - KL_divergence: 7.9770 - val_loss: 12824.1108 - val_KL_divergence: 8.0256
Epoch 87/100

  1/200 [..............................] - ETA: 1s - loss: 11705.8154 - KL_divergence: 8.2401
  7/200 [>.............................] - ETA: 1s - loss: 12360.0492 - KL_divergence: 7.9887
 13/200 [>.............................] - ETA: 1s - loss: 12006.4112 - KL_divergence: 8.0311
 19/200 [=>............................] - ETA: 1s - loss: 12065.7479 - KL_divergence: 7.9879
 25/200 [==>...........................] - ETA: 1s - loss: 12060.7465 - KL_divergence: 7.9949
 31/200 [===>..........................] - ETA: 1s - loss: 12132.5224 - KL_divergence: 7.9980
 37/200 [====>.........................] - ETA: 1s - loss: 12137.2594 - KL_divergence: 8.0248
 43/200 [=====>........................] - ETA: 1s - loss: 12116.8348 - KL_divergence: 8.0149
 49/200 [======>.......................] - ETA: 1s - loss: 12182.8620 - KL_divergence: 7.9950
 55/200 [=======>......................] - ETA: 1s - loss: 12161.6153 - KL_divergence: 8.0069
 61/200 [========>.....................] - ETA: 1s - loss: 12219.0155 - KL_divergence: 8.0057
 67/200 [=========>....................] - ETA: 1s - loss: 12224.0803 - KL_divergence: 7.9995
 73/200 [=========>....................] - ETA: 1s - loss: 12216.3779 - KL_divergence: 7.9796
 79/200 [==========>...................] - ETA: 1s - loss: 12203.2240 - KL_divergence: 7.9857
 85/200 [===========>..................] - ETA: 1s - loss: 12166.2206 - KL_divergence: 7.9827
 91/200 [============>.................] - ETA: 0s - loss: 12147.1960 - KL_divergence: 7.9881
 97/200 [=============>................] - ETA: 0s - loss: 12135.3071 - KL_divergence: 7.9963
103/200 [==============>...............] - ETA: 0s - loss: 12136.9838 - KL_divergence: 7.9927
109/200 [===============>..............] - ETA: 0s - loss: 12144.5703 - KL_divergence: 7.9857
114/200 [================>.............] - ETA: 0s - loss: 12161.2800 - KL_divergence: 7.9841
119/200 [================>.............] - ETA: 0s - loss: 12167.7371 - KL_divergence: 7.9867
125/200 [=================>............] - ETA: 0s - loss: 12169.5240 - KL_divergence: 7.9861
131/200 [==================>...........] - ETA: 0s - loss: 12147.1408 - KL_divergence: 7.9902
137/200 [===================>..........] - ETA: 0s - loss: 12153.4317 - KL_divergence: 7.9857
143/200 [====================>.........] - ETA: 0s - loss: 12144.7469 - KL_divergence: 7.9924
149/200 [=====================>........] - ETA: 0s - loss: 12131.9476 - KL_divergence: 7.9993
155/200 [======================>.......] - ETA: 0s - loss: 12150.9202 - KL_divergence: 7.9957
161/200 [=======================>......] - ETA: 0s - loss: 12159.9087 - KL_divergence: 7.9999
167/200 [========================>.....] - ETA: 0s - loss: 12173.3508 - KL_divergence: 7.9952
173/200 [========================>.....] - ETA: 0s - loss: 12183.1487 - KL_divergence: 7.9864
179/200 [=========================>....] - ETA: 0s - loss: 12183.6390 - KL_divergence: 7.9879
185/200 [==========================>...] - ETA: 0s - loss: 12183.2647 - KL_divergence: 7.9882
191/200 [===========================>..] - ETA: 0s - loss: 12173.1049 - KL_divergence: 7.9945
197/200 [============================>.] - ETA: 0s - loss: 12185.4617 - KL_divergence: 7.9872
200/200 [==============================] - 2s 10ms/step - loss: 12195.9198 - KL_divergence: 7.9832 - val_loss: 12758.6337 - val_KL_divergence: 7.6493
Epoch 88/100

  1/200 [..............................] - ETA: 1s - loss: 12722.9717 - KL_divergence: 7.8909
  7/200 [>.............................] - ETA: 1s - loss: 12407.3631 - KL_divergence: 7.7966
 13/200 [>.............................] - ETA: 1s - loss: 12253.3072 - KL_divergence: 7.9056
 19/200 [=>............................] - ETA: 1s - loss: 12234.2719 - KL_divergence: 7.9146
 25/200 [==>...........................] - ETA: 1s - loss: 12262.2932 - KL_divergence: 7.9223
 31/200 [===>..........................] - ETA: 1s - loss: 12261.8453 - KL_divergence: 7.9306
 37/200 [====>.........................] - ETA: 1s - loss: 12215.6028 - KL_divergence: 7.9201
 43/200 [=====>........................] - ETA: 1s - loss: 12144.9831 - KL_divergence: 7.9021
 49/200 [======>.......................] - ETA: 1s - loss: 12135.1287 - KL_divergence: 7.9351
 55/200 [=======>......................] - ETA: 1s - loss: 12131.1475 - KL_divergence: 7.9439
 61/200 [========>.....................] - ETA: 1s - loss: 12103.5360 - KL_divergence: 7.9502
 67/200 [=========>....................] - ETA: 1s - loss: 12090.6888 - KL_divergence: 7.9534
 73/200 [=========>....................] - ETA: 1s - loss: 12048.8658 - KL_divergence: 7.9725
 79/200 [==========>...................] - ETA: 1s - loss: 12108.5492 - KL_divergence: 7.9634
 85/200 [===========>..................] - ETA: 1s - loss: 12081.5547 - KL_divergence: 7.9658
 91/200 [============>.................] - ETA: 0s - loss: 12104.2134 - KL_divergence: 7.9589
 97/200 [=============>................] - ETA: 0s - loss: 12117.2192 - KL_divergence: 7.9535
103/200 [==============>...............] - ETA: 0s - loss: 12131.0174 - KL_divergence: 7.9492
109/200 [===============>..............] - ETA: 0s - loss: 12175.8211 - KL_divergence: 7.9370
116/200 [================>.............] - ETA: 0s - loss: 12178.6099 - KL_divergence: 7.9372
122/200 [=================>............] - ETA: 0s - loss: 12156.7711 - KL_divergence: 7.9372
128/200 [==================>...........] - ETA: 0s - loss: 12152.0668 - KL_divergence: 7.9468
134/200 [===================>..........] - ETA: 0s - loss: 12154.8971 - KL_divergence: 7.9498
140/200 [====================>.........] - ETA: 0s - loss: 12149.1283 - KL_divergence: 7.9524
146/200 [====================>.........] - ETA: 0s - loss: 12138.5021 - KL_divergence: 7.9518
152/200 [=====================>........] - ETA: 0s - loss: 12147.8010 - KL_divergence: 7.9494
158/200 [======================>.......] - ETA: 0s - loss: 12147.8942 - KL_divergence: 7.9535
164/200 [=======================>......] - ETA: 0s - loss: 12139.9836 - KL_divergence: 7.9568
171/200 [========================>.....] - ETA: 0s - loss: 12154.6282 - KL_divergence: 7.9574
177/200 [=========================>....] - ETA: 0s - loss: 12164.2326 - KL_divergence: 7.9554
183/200 [==========================>...] - ETA: 0s - loss: 12169.6941 - KL_divergence: 7.9580
189/200 [===========================>..] - ETA: 0s - loss: 12151.4814 - KL_divergence: 7.9635
195/200 [============================>.] - ETA: 0s - loss: 12146.7963 - KL_divergence: 7.9688
200/200 [==============================] - 2s 10ms/step - loss: 12145.7585 - KL_divergence: 7.9695 - val_loss: 12822.7899 - val_KL_divergence: 7.5784
Epoch 89/100

  1/200 [..............................] - ETA: 1s - loss: 12532.6973 - KL_divergence: 7.9054
  7/200 [>.............................] - ETA: 1s - loss: 12497.5400 - KL_divergence: 7.8286
 13/200 [>.............................] - ETA: 1s - loss: 12261.3033 - KL_divergence: 7.9128
 19/200 [=>............................] - ETA: 1s - loss: 12171.6930 - KL_divergence: 7.9394
 25/200 [==>...........................] - ETA: 1s - loss: 12206.9759 - KL_divergence: 7.9395
 31/200 [===>..........................] - ETA: 1s - loss: 12182.9227 - KL_divergence: 7.8913
 37/200 [====>.........................] - ETA: 1s - loss: 12105.7328 - KL_divergence: 7.8806
 43/200 [=====>........................] - ETA: 1s - loss: 12109.2427 - KL_divergence: 7.8943
 49/200 [======>.......................] - ETA: 1s - loss: 12173.0283 - KL_divergence: 7.8564
 55/200 [=======>......................] - ETA: 1s - loss: 12236.0901 - KL_divergence: 7.8566
 61/200 [========>.....................] - ETA: 1s - loss: 12223.9597 - KL_divergence: 7.8756
 67/200 [=========>....................] - ETA: 1s - loss: 12234.4051 - KL_divergence: 7.8680
 73/200 [=========>....................] - ETA: 1s - loss: 12193.5791 - KL_divergence: 7.8825
 79/200 [==========>...................] - ETA: 1s - loss: 12223.4622 - KL_divergence: 7.8757
 85/200 [===========>..................] - ETA: 1s - loss: 12175.5742 - KL_divergence: 7.8919
 91/200 [============>.................] - ETA: 0s - loss: 12156.5453 - KL_divergence: 7.9008
 97/200 [=============>................] - ETA: 0s - loss: 12113.8648 - KL_divergence: 7.9084
103/200 [==============>...............] - ETA: 0s - loss: 12114.1559 - KL_divergence: 7.9112
109/200 [===============>..............] - ETA: 0s - loss: 12125.5043 - KL_divergence: 7.9168
115/200 [================>.............] - ETA: 0s - loss: 12125.5930 - KL_divergence: 7.9282
121/200 [=================>............] - ETA: 0s - loss: 12131.3708 - KL_divergence: 7.9247
127/200 [==================>...........] - ETA: 0s - loss: 12117.0234 - KL_divergence: 7.9263
133/200 [==================>...........] - ETA: 0s - loss: 12108.5705 - KL_divergence: 7.9335
139/200 [===================>..........] - ETA: 0s - loss: 12131.1702 - KL_divergence: 7.9288
145/200 [====================>.........] - ETA: 0s - loss: 12138.3105 - KL_divergence: 7.9303
150/200 [=====================>........] - ETA: 0s - loss: 12110.7565 - KL_divergence: 7.9418
156/200 [======================>.......] - ETA: 0s - loss: 12129.5195 - KL_divergence: 7.9337
162/200 [=======================>......] - ETA: 0s - loss: 12141.7022 - KL_divergence: 7.9339
168/200 [========================>.....] - ETA: 0s - loss: 12149.1945 - KL_divergence: 7.9288
174/200 [=========================>....] - ETA: 0s - loss: 12147.9363 - KL_divergence: 7.9361
180/200 [==========================>...] - ETA: 0s - loss: 12144.7777 - KL_divergence: 7.9366
186/200 [==========================>...] - ETA: 0s - loss: 12153.9544 - KL_divergence: 7.9343
192/200 [===========================>..] - ETA: 0s - loss: 12152.3416 - KL_divergence: 7.9342
198/200 [============================>.] - ETA: 0s - loss: 12164.8790 - KL_divergence: 7.9303
200/200 [==============================] - 2s 10ms/step - loss: 12162.8847 - KL_divergence: 7.9308 - val_loss: 12669.3448 - val_KL_divergence: 7.5827
Epoch 90/100

  1/200 [..............................] - ETA: 1s - loss: 11867.3564 - KL_divergence: 7.6011
  7/200 [>.............................] - ETA: 1s - loss: 12251.4540 - KL_divergence: 7.8841
 13/200 [>.............................] - ETA: 1s - loss: 12088.6599 - KL_divergence: 7.8457
 19/200 [=>............................] - ETA: 1s - loss: 12064.0286 - KL_divergence: 7.8677
 25/200 [==>...........................] - ETA: 1s - loss: 12177.7112 - KL_divergence: 7.9039
 31/200 [===>..........................] - ETA: 1s - loss: 12129.7780 - KL_divergence: 7.9331
 37/200 [====>.........................] - ETA: 1s - loss: 12084.9005 - KL_divergence: 7.9599
 43/200 [=====>........................] - ETA: 1s - loss: 12111.8243 - KL_divergence: 7.9638
 49/200 [======>.......................] - ETA: 1s - loss: 12122.6478 - KL_divergence: 7.9590
 55/200 [=======>......................] - ETA: 1s - loss: 12155.4342 - KL_divergence: 7.9535
 61/200 [========>.....................] - ETA: 1s - loss: 12133.3997 - KL_divergence: 7.9550
 67/200 [=========>....................] - ETA: 1s - loss: 12141.9441 - KL_divergence: 7.9582
 73/200 [=========>....................] - ETA: 1s - loss: 12154.6644 - KL_divergence: 7.9493
 79/200 [==========>...................] - ETA: 1s - loss: 12167.7641 - KL_divergence: 7.9543
 85/200 [===========>..................] - ETA: 1s - loss: 12176.6919 - KL_divergence: 7.9578
 91/200 [============>.................] - ETA: 1s - loss: 12161.2830 - KL_divergence: 7.9587
 97/200 [=============>................] - ETA: 0s - loss: 12190.8022 - KL_divergence: 7.9558
103/200 [==============>...............] - ETA: 0s - loss: 12176.4695 - KL_divergence: 7.9690
109/200 [===============>..............] - ETA: 0s - loss: 12186.7748 - KL_divergence: 7.9669
115/200 [================>.............] - ETA: 0s - loss: 12202.1415 - KL_divergence: 7.9667
121/200 [=================>............] - ETA: 0s - loss: 12206.6072 - KL_divergence: 7.9660
127/200 [==================>...........] - ETA: 0s - loss: 12214.2740 - KL_divergence: 7.9672
133/200 [==================>...........] - ETA: 0s - loss: 12227.1179 - KL_divergence: 7.9621
139/200 [===================>..........] - ETA: 0s - loss: 12223.6408 - KL_divergence: 7.9590
145/200 [====================>.........] - ETA: 0s - loss: 12234.8240 - KL_divergence: 7.9548
151/200 [=====================>........] - ETA: 0s - loss: 12243.0440 - KL_divergence: 7.9496
157/200 [======================>.......] - ETA: 0s - loss: 12253.4551 - KL_divergence: 7.9471
163/200 [=======================>......] - ETA: 0s - loss: 12268.4696 - KL_divergence: 7.9409
169/200 [========================>.....] - ETA: 0s - loss: 12246.4931 - KL_divergence: 7.9484
175/200 [=========================>....] - ETA: 0s - loss: 12245.3703 - KL_divergence: 7.9466
181/200 [==========================>...] - ETA: 0s - loss: 12245.5204 - KL_divergence: 7.9457
187/200 [===========================>..] - ETA: 0s - loss: 12241.0098 - KL_divergence: 7.9413
193/200 [===========================>..] - ETA: 0s - loss: 12231.2240 - KL_divergence: 7.9493
199/200 [============================>.] - ETA: 0s - loss: 12217.5245 - KL_divergence: 7.9552
200/200 [==============================] - 2s 10ms/step - loss: 12215.9747 - KL_divergence: 7.9543 - val_loss: 12754.7185 - val_KL_divergence: 7.7069
Epoch 91/100

  1/200 [..............................] - ETA: 1s - loss: 11884.3516 - KL_divergence: 7.6211
  7/200 [>.............................] - ETA: 1s - loss: 12282.9572 - KL_divergence: 7.8093
 13/200 [>.............................] - ETA: 1s - loss: 12232.2903 - KL_divergence: 7.8169
 19/200 [=>............................] - ETA: 1s - loss: 12287.6323 - KL_divergence: 7.8966
 25/200 [==>...........................] - ETA: 1s - loss: 12293.0959 - KL_divergence: 7.8712
 31/200 [===>..........................] - ETA: 1s - loss: 12256.1406 - KL_divergence: 7.9200
 37/200 [====>.........................] - ETA: 1s - loss: 12298.5092 - KL_divergence: 7.9263
 43/200 [=====>........................] - ETA: 1s - loss: 12286.7738 - KL_divergence: 7.9211
 49/200 [======>.......................] - ETA: 1s - loss: 12299.5323 - KL_divergence: 7.9064
 55/200 [=======>......................] - ETA: 1s - loss: 12294.2955 - KL_divergence: 7.9051
 61/200 [========>.....................] - ETA: 1s - loss: 12262.9409 - KL_divergence: 7.9197
 67/200 [=========>....................] - ETA: 1s - loss: 12220.8651 - KL_divergence: 7.9325
 73/200 [=========>....................] - ETA: 1s - loss: 12202.7774 - KL_divergence: 7.9381
 79/200 [==========>...................] - ETA: 1s - loss: 12233.3085 - KL_divergence: 7.9395
 85/200 [===========>..................] - ETA: 1s - loss: 12231.3832 - KL_divergence: 7.9319
 91/200 [============>.................] - ETA: 0s - loss: 12213.5784 - KL_divergence: 7.9272
 97/200 [=============>................] - ETA: 0s - loss: 12179.7899 - KL_divergence: 7.9340
103/200 [==============>...............] - ETA: 0s - loss: 12187.8100 - KL_divergence: 7.9378
110/200 [===============>..............] - ETA: 0s - loss: 12203.7785 - KL_divergence: 7.9520
116/200 [================>.............] - ETA: 0s - loss: 12199.5089 - KL_divergence: 7.9505
122/200 [=================>............] - ETA: 0s - loss: 12217.5852 - KL_divergence: 7.9513
128/200 [==================>...........] - ETA: 0s - loss: 12201.2383 - KL_divergence: 7.9607
135/200 [===================>..........] - ETA: 0s - loss: 12212.0117 - KL_divergence: 7.9758
141/200 [====================>.........] - ETA: 0s - loss: 12218.0423 - KL_divergence: 7.9725
147/200 [=====================>........] - ETA: 0s - loss: 12242.1762 - KL_divergence: 7.9637
153/200 [=====================>........] - ETA: 0s - loss: 12229.8182 - KL_divergence: 7.9668
159/200 [======================>.......] - ETA: 0s - loss: 12213.5840 - KL_divergence: 7.9643
165/200 [=======================>......] - ETA: 0s - loss: 12202.6646 - KL_divergence: 7.9677
171/200 [========================>.....] - ETA: 0s - loss: 12206.9684 - KL_divergence: 7.9694
177/200 [=========================>....] - ETA: 0s - loss: 12207.7986 - KL_divergence: 7.9718
183/200 [==========================>...] - ETA: 0s - loss: 12190.5768 - KL_divergence: 7.9723
189/200 [===========================>..] - ETA: 0s - loss: 12176.9342 - KL_divergence: 7.9787
195/200 [============================>.] - ETA: 0s - loss: 12171.3862 - KL_divergence: 7.9800
200/200 [==============================] - 2s 10ms/step - loss: 12162.7253 - KL_divergence: 7.9823 - val_loss: 12696.4322 - val_KL_divergence: 7.7619
Epoch 92/100

  1/200 [..............................] - ETA: 1s - loss: 13511.5527 - KL_divergence: 7.3480
  7/200 [>.............................] - ETA: 1s - loss: 12550.7418 - KL_divergence: 7.8786
 13/200 [>.............................] - ETA: 1s - loss: 12153.5462 - KL_divergence: 7.9780
 19/200 [=>............................] - ETA: 1s - loss: 12116.3948 - KL_divergence: 8.0095
 25/200 [==>...........................] - ETA: 1s - loss: 12076.3481 - KL_divergence: 8.0034
 31/200 [===>..........................] - ETA: 1s - loss: 12107.7765 - KL_divergence: 7.9621
 37/200 [====>.........................] - ETA: 1s - loss: 12192.7736 - KL_divergence: 7.9562
 43/200 [=====>........................] - ETA: 1s - loss: 12213.5275 - KL_divergence: 7.9370
 49/200 [======>.......................] - ETA: 1s - loss: 12204.9213 - KL_divergence: 7.9177
 55/200 [=======>......................] - ETA: 1s - loss: 12182.2750 - KL_divergence: 7.9219
 61/200 [========>.....................] - ETA: 1s - loss: 12184.6651 - KL_divergence: 7.9259
 67/200 [=========>....................] - ETA: 1s - loss: 12235.4138 - KL_divergence: 7.9138
 73/200 [=========>....................] - ETA: 1s - loss: 12236.3378 - KL_divergence: 7.9185
 79/200 [==========>...................] - ETA: 1s - loss: 12246.9174 - KL_divergence: 7.9041
 85/200 [===========>..................] - ETA: 0s - loss: 12212.3862 - KL_divergence: 7.9171
 91/200 [============>.................] - ETA: 0s - loss: 12217.7451 - KL_divergence: 7.9061
 97/200 [=============>................] - ETA: 0s - loss: 12202.2569 - KL_divergence: 7.9013
103/200 [==============>...............] - ETA: 0s - loss: 12210.4855 - KL_divergence: 7.8945
109/200 [===============>..............] - ETA: 0s - loss: 12222.9700 - KL_divergence: 7.8877
115/200 [================>.............] - ETA: 0s - loss: 12218.6809 - KL_divergence: 7.8783
121/200 [=================>............] - ETA: 0s - loss: 12187.6144 - KL_divergence: 7.8742
127/200 [==================>...........] - ETA: 0s - loss: 12185.8346 - KL_divergence: 7.8768
133/200 [==================>...........] - ETA: 0s - loss: 12204.8903 - KL_divergence: 7.8675
139/200 [===================>..........] - ETA: 0s - loss: 12198.2788 - KL_divergence: 7.8672
145/200 [====================>.........] - ETA: 0s - loss: 12191.3848 - KL_divergence: 7.8639
151/200 [=====================>........] - ETA: 0s - loss: 12188.2775 - KL_divergence: 7.8634
157/200 [======================>.......] - ETA: 0s - loss: 12186.4765 - KL_divergence: 7.8622
163/200 [=======================>......] - ETA: 0s - loss: 12195.7398 - KL_divergence: 7.8630
169/200 [========================>.....] - ETA: 0s - loss: 12202.4031 - KL_divergence: 7.8632
175/200 [=========================>....] - ETA: 0s - loss: 12201.3711 - KL_divergence: 7.8609
181/200 [==========================>...] - ETA: 0s - loss: 12187.9725 - KL_divergence: 7.8636
187/200 [===========================>..] - ETA: 0s - loss: 12204.3739 - KL_divergence: 7.8614
193/200 [===========================>..] - ETA: 0s - loss: 12217.2776 - KL_divergence: 7.8646
199/200 [============================>.] - ETA: 0s - loss: 12212.7239 - KL_divergence: 7.8701
200/200 [==============================] - 2s 10ms/step - loss: 12211.8236 - KL_divergence: 7.8693 - val_loss: 12763.9823 - val_KL_divergence: 7.9711
Epoch 93/100

  1/200 [..............................] - ETA: 1s - loss: 12680.0771 - KL_divergence: 8.0076
  7/200 [>.............................] - ETA: 1s - loss: 11681.8574 - KL_divergence: 7.9984
 13/200 [>.............................] - ETA: 1s - loss: 11638.4479 - KL_divergence: 7.9639
 19/200 [=>............................] - ETA: 1s - loss: 11627.3827 - KL_divergence: 7.9796
 25/200 [==>...........................] - ETA: 1s - loss: 11663.3352 - KL_divergence: 7.9876
 31/200 [===>..........................] - ETA: 1s - loss: 11781.5679 - KL_divergence: 7.9772
 37/200 [====>.........................] - ETA: 1s - loss: 11835.9695 - KL_divergence: 7.9571
 44/200 [=====>........................] - ETA: 1s - loss: 11798.4597 - KL_divergence: 7.9394
 51/200 [======>.......................] - ETA: 1s - loss: 11866.3345 - KL_divergence: 7.9156
 57/200 [=======>......................] - ETA: 1s - loss: 11932.2767 - KL_divergence: 7.9022
 63/200 [========>.....................] - ETA: 1s - loss: 11959.1601 - KL_divergence: 7.8873
 69/200 [=========>....................] - ETA: 1s - loss: 11950.1913 - KL_divergence: 7.8867
 75/200 [==========>...................] - ETA: 1s - loss: 11955.7685 - KL_divergence: 7.8911
 81/200 [===========>..................] - ETA: 1s - loss: 11953.1364 - KL_divergence: 7.9032
 87/200 [============>.................] - ETA: 1s - loss: 11954.8210 - KL_divergence: 7.9085
 93/200 [============>.................] - ETA: 0s - loss: 11962.1962 - KL_divergence: 7.9035
 99/200 [=============>................] - ETA: 0s - loss: 11971.7159 - KL_divergence: 7.9017
105/200 [==============>...............] - ETA: 0s - loss: 11990.3182 - KL_divergence: 7.8935
110/200 [===============>..............] - ETA: 0s - loss: 11984.2111 - KL_divergence: 7.9080
116/200 [================>.............] - ETA: 0s - loss: 11981.7474 - KL_divergence: 7.9057
122/200 [=================>............] - ETA: 0s - loss: 11990.7481 - KL_divergence: 7.9011
128/200 [==================>...........] - ETA: 0s - loss: 12007.1543 - KL_divergence: 7.9028
134/200 [===================>..........] - ETA: 0s - loss: 11999.1223 - KL_divergence: 7.9065
140/200 [====================>.........] - ETA: 0s - loss: 12012.1210 - KL_divergence: 7.9004
146/200 [====================>.........] - ETA: 0s - loss: 12019.9289 - KL_divergence: 7.8963
152/200 [=====================>........] - ETA: 0s - loss: 12042.8265 - KL_divergence: 7.8885
158/200 [======================>.......] - ETA: 0s - loss: 12033.9877 - KL_divergence: 7.8858
164/200 [=======================>......] - ETA: 0s - loss: 12036.2367 - KL_divergence: 7.8819
170/200 [========================>.....] - ETA: 0s - loss: 12025.7421 - KL_divergence: 7.8932
176/200 [=========================>....] - ETA: 0s - loss: 12029.0168 - KL_divergence: 7.8948
182/200 [==========================>...] - ETA: 0s - loss: 12035.1433 - KL_divergence: 7.8939
188/200 [===========================>..] - ETA: 0s - loss: 12033.7165 - KL_divergence: 7.9072
194/200 [============================>.] - ETA: 0s - loss: 12016.5258 - KL_divergence: 7.9087
200/200 [==============================] - 2s 10ms/step - loss: 12034.3654 - KL_divergence: 7.9024 - val_loss: 12810.8600 - val_KL_divergence: 7.9934
Epoch 94/100

  1/200 [..............................] - ETA: 1s - loss: 11280.4336 - KL_divergence: 8.7500
  7/200 [>.............................] - ETA: 1s - loss: 12000.8492 - KL_divergence: 8.1062
 13/200 [>.............................] - ETA: 1s - loss: 12004.2577 - KL_divergence: 8.0086
 19/200 [=>............................] - ETA: 1s - loss: 12091.5096 - KL_divergence: 7.9936
 25/200 [==>...........................] - ETA: 1s - loss: 12017.2346 - KL_divergence: 7.9487
 31/200 [===>..........................] - ETA: 1s - loss: 12038.3128 - KL_divergence: 7.9191
 37/200 [====>.........................] - ETA: 1s - loss: 12032.1941 - KL_divergence: 7.9253
 43/200 [=====>........................] - ETA: 1s - loss: 12021.2483 - KL_divergence: 7.9331
 49/200 [======>.......................] - ETA: 1s - loss: 11978.0926 - KL_divergence: 7.9330
 55/200 [=======>......................] - ETA: 1s - loss: 11949.4327 - KL_divergence: 7.9404
 61/200 [========>.....................] - ETA: 1s - loss: 11964.2566 - KL_divergence: 7.9531
 67/200 [=========>....................] - ETA: 1s - loss: 11974.0439 - KL_divergence: 7.9392
 73/200 [=========>....................] - ETA: 1s - loss: 12014.2975 - KL_divergence: 7.9344
 79/200 [==========>...................] - ETA: 1s - loss: 12041.0247 - KL_divergence: 7.9239
 86/200 [===========>..................] - ETA: 0s - loss: 12068.8738 - KL_divergence: 7.9080
 92/200 [============>.................] - ETA: 0s - loss: 12058.3405 - KL_divergence: 7.9244
 98/200 [=============>................] - ETA: 0s - loss: 12082.1022 - KL_divergence: 7.9178
104/200 [==============>...............] - ETA: 0s - loss: 12091.5020 - KL_divergence: 7.9084
110/200 [===============>..............] - ETA: 0s - loss: 12103.7462 - KL_divergence: 7.8943
117/200 [================>.............] - ETA: 0s - loss: 12108.4806 - KL_divergence: 7.8936
123/200 [=================>............] - ETA: 0s - loss: 12081.4123 - KL_divergence: 7.9147
129/200 [==================>...........] - ETA: 0s - loss: 12074.8444 - KL_divergence: 7.9087
136/200 [===================>..........] - ETA: 0s - loss: 12064.5089 - KL_divergence: 7.9125
142/200 [====================>.........] - ETA: 0s - loss: 12097.6655 - KL_divergence: 7.9074
148/200 [=====================>........] - ETA: 0s - loss: 12102.5627 - KL_divergence: 7.9115
154/200 [======================>.......] - ETA: 0s - loss: 12086.7098 - KL_divergence: 7.9165
160/200 [=======================>......] - ETA: 0s - loss: 12082.6570 - KL_divergence: 7.9176
166/200 [=======================>......] - ETA: 0s - loss: 12073.1724 - KL_divergence: 7.9211
172/200 [========================>.....] - ETA: 0s - loss: 12054.1139 - KL_divergence: 7.9231
178/200 [=========================>....] - ETA: 0s - loss: 12065.9227 - KL_divergence: 7.9173
184/200 [==========================>...] - ETA: 0s - loss: 12090.0232 - KL_divergence: 7.9090
190/200 [===========================>..] - ETA: 0s - loss: 12094.0202 - KL_divergence: 7.9091
196/200 [============================>.] - ETA: 0s - loss: 12101.2740 - KL_divergence: 7.9088
200/200 [==============================] - 2s 10ms/step - loss: 12096.9103 - KL_divergence: 7.9098 - val_loss: 12775.8467 - val_KL_divergence: 7.9578
Epoch 95/100

  1/200 [..............................] - ETA: 1s - loss: 10615.1328 - KL_divergence: 8.3970
  6/200 [..............................] - ETA: 1s - loss: 11804.5573 - KL_divergence: 7.9457
 12/200 [>.............................] - ETA: 1s - loss: 12169.5285 - KL_divergence: 7.8936
 18/200 [=>............................] - ETA: 1s - loss: 12333.8895 - KL_divergence: 7.8192
 24/200 [==>...........................] - ETA: 1s - loss: 12259.8696 - KL_divergence: 7.8494
 30/200 [===>..........................] - ETA: 1s - loss: 12281.3666 - KL_divergence: 7.8499
 36/200 [====>.........................] - ETA: 1s - loss: 12295.1546 - KL_divergence: 7.8510
 42/200 [=====>........................] - ETA: 1s - loss: 12288.6991 - KL_divergence: 7.8845
 48/200 [======>.......................] - ETA: 1s - loss: 12268.2405 - KL_divergence: 7.8856
 54/200 [=======>......................] - ETA: 1s - loss: 12315.7067 - KL_divergence: 7.8809
 60/200 [========>.....................] - ETA: 1s - loss: 12313.5483 - KL_divergence: 7.8815
 66/200 [========>.....................] - ETA: 1s - loss: 12312.7304 - KL_divergence: 7.9062
 72/200 [=========>....................] - ETA: 1s - loss: 12330.2830 - KL_divergence: 7.8961
 78/200 [==========>...................] - ETA: 1s - loss: 12342.3196 - KL_divergence: 7.8882
 84/200 [===========>..................] - ETA: 1s - loss: 12326.2196 - KL_divergence: 7.8769
 90/200 [============>.................] - ETA: 1s - loss: 12320.7479 - KL_divergence: 7.8880
 96/200 [=============>................] - ETA: 0s - loss: 12256.3349 - KL_divergence: 7.9044
102/200 [==============>...............] - ETA: 0s - loss: 12219.5038 - KL_divergence: 7.9143
108/200 [===============>..............] - ETA: 0s - loss: 12240.5016 - KL_divergence: 7.9053
114/200 [================>.............] - ETA: 0s - loss: 12242.5323 - KL_divergence: 7.9009
120/200 [=================>............] - ETA: 0s - loss: 12220.5647 - KL_divergence: 7.9097
127/200 [==================>...........] - ETA: 0s - loss: 12217.1527 - KL_divergence: 7.9069
134/200 [===================>..........] - ETA: 0s - loss: 12212.3941 - KL_divergence: 7.9017
140/200 [====================>.........] - ETA: 0s - loss: 12198.8475 - KL_divergence: 7.8992
146/200 [====================>.........] - ETA: 0s - loss: 12220.8782 - KL_divergence: 7.8913
152/200 [=====================>........] - ETA: 0s - loss: 12215.3665 - KL_divergence: 7.8877
158/200 [======================>.......] - ETA: 0s - loss: 12204.1799 - KL_divergence: 7.8888
164/200 [=======================>......] - ETA: 0s - loss: 12206.3187 - KL_divergence: 7.8907
170/200 [========================>.....] - ETA: 0s - loss: 12187.8027 - KL_divergence: 7.8932
176/200 [=========================>....] - ETA: 0s - loss: 12185.8210 - KL_divergence: 7.8865
182/200 [==========================>...] - ETA: 0s - loss: 12182.7729 - KL_divergence: 7.8864
188/200 [===========================>..] - ETA: 0s - loss: 12193.0236 - KL_divergence: 7.8841
194/200 [============================>.] - ETA: 0s - loss: 12181.5496 - KL_divergence: 7.8849
200/200 [==============================] - 2s 10ms/step - loss: 12173.4140 - KL_divergence: 7.8828 - val_loss: 12748.8708 - val_KL_divergence: 8.0223
Epoch 96/100

  1/200 [..............................] - ETA: 1s - loss: 12921.2236 - KL_divergence: 8.4220
  7/200 [>.............................] - ETA: 1s - loss: 12285.6550 - KL_divergence: 7.9431
 13/200 [>.............................] - ETA: 1s - loss: 11996.3848 - KL_divergence: 7.8807
 19/200 [=>............................] - ETA: 1s - loss: 12112.5708 - KL_divergence: 7.8811
 25/200 [==>...........................] - ETA: 1s - loss: 12078.2211 - KL_divergence: 7.8760
 31/200 [===>..........................] - ETA: 1s - loss: 12089.7136 - KL_divergence: 7.8613
 37/200 [====>.........................] - ETA: 1s - loss: 12062.1237 - KL_divergence: 7.8707
 42/200 [=====>........................] - ETA: 1s - loss: 12054.5476 - KL_divergence: 7.8634
 47/200 [======>.......................] - ETA: 1s - loss: 12039.6475 - KL_divergence: 7.8844
 53/200 [======>.......................] - ETA: 1s - loss: 12061.2109 - KL_divergence: 7.8869
 59/200 [=======>......................] - ETA: 1s - loss: 12056.4530 - KL_divergence: 7.8870
 65/200 [========>.....................] - ETA: 1s - loss: 12064.1305 - KL_divergence: 7.8592
 71/200 [=========>....................] - ETA: 1s - loss: 12010.6784 - KL_divergence: 7.8701
 77/200 [==========>...................] - ETA: 1s - loss: 12016.2764 - KL_divergence: 7.8587
 83/200 [===========>..................] - ETA: 1s - loss: 12045.2514 - KL_divergence: 7.8438
 89/200 [============>.................] - ETA: 0s - loss: 12043.9195 - KL_divergence: 7.8384
 95/200 [=============>................] - ETA: 0s - loss: 12021.3761 - KL_divergence: 7.8388
101/200 [==============>...............] - ETA: 0s - loss: 12047.8747 - KL_divergence: 7.8374
107/200 [===============>..............] - ETA: 0s - loss: 12056.9938 - KL_divergence: 7.8353
113/200 [===============>..............] - ETA: 0s - loss: 12018.0458 - KL_divergence: 7.8588
119/200 [================>.............] - ETA: 0s - loss: 11995.5367 - KL_divergence: 7.8626
125/200 [=================>............] - ETA: 0s - loss: 11990.4711 - KL_divergence: 7.8622
131/200 [==================>...........] - ETA: 0s - loss: 12004.7676 - KL_divergence: 7.8641
137/200 [===================>..........] - ETA: 0s - loss: 12023.2782 - KL_divergence: 7.8620
143/200 [====================>.........] - ETA: 0s - loss: 12022.3297 - KL_divergence: 7.8585
149/200 [=====================>........] - ETA: 0s - loss: 12020.5448 - KL_divergence: 7.8599
155/200 [======================>.......] - ETA: 0s - loss: 12026.9127 - KL_divergence: 7.8558
161/200 [=======================>......] - ETA: 0s - loss: 12021.4262 - KL_divergence: 7.8636
167/200 [========================>.....] - ETA: 0s - loss: 12002.9641 - KL_divergence: 7.8606
173/200 [========================>.....] - ETA: 0s - loss: 12007.3129 - KL_divergence: 7.8566
179/200 [=========================>....] - ETA: 0s - loss: 12012.6659 - KL_divergence: 7.8502
185/200 [==========================>...] - ETA: 0s - loss: 12004.4065 - KL_divergence: 7.8511
191/200 [===========================>..] - ETA: 0s - loss: 12006.0011 - KL_divergence: 7.8553
197/200 [============================>.] - ETA: 0s - loss: 12015.5716 - KL_divergence: 7.8554
200/200 [==============================] - 2s 10ms/step - loss: 12015.8449 - KL_divergence: 7.8521 - val_loss: 12713.3043 - val_KL_divergence: 7.8836
Epoch 97/100

  1/200 [..............................] - ETA: 1s - loss: 11725.6533 - KL_divergence: 7.6108
  7/200 [>.............................] - ETA: 1s - loss: 11966.0050 - KL_divergence: 7.8145
 13/200 [>.............................] - ETA: 1s - loss: 11868.3299 - KL_divergence: 7.8788
 19/200 [=>............................] - ETA: 1s - loss: 11907.3289 - KL_divergence: 7.9110
 25/200 [==>...........................] - ETA: 1s - loss: 11980.0495 - KL_divergence: 7.8931
 32/200 [===>..........................] - ETA: 1s - loss: 11893.7435 - KL_divergence: 7.9107
 38/200 [====>.........................] - ETA: 1s - loss: 11901.9459 - KL_divergence: 7.9325
 44/200 [=====>........................] - ETA: 1s - loss: 11969.5176 - KL_divergence: 7.9431
 50/200 [======>.......................] - ETA: 1s - loss: 11957.6564 - KL_divergence: 7.9544
 56/200 [=======>......................] - ETA: 1s - loss: 12005.5458 - KL_divergence: 7.9427
 62/200 [========>.....................] - ETA: 1s - loss: 11975.5941 - KL_divergence: 7.9308
 68/200 [=========>....................] - ETA: 1s - loss: 11994.7193 - KL_divergence: 7.9115
 74/200 [==========>...................] - ETA: 1s - loss: 11988.7626 - KL_divergence: 7.9135
 80/200 [===========>..................] - ETA: 1s - loss: 12009.1101 - KL_divergence: 7.9117
 86/200 [===========>..................] - ETA: 1s - loss: 11988.2730 - KL_divergence: 7.9166
 92/200 [============>.................] - ETA: 0s - loss: 12001.5761 - KL_divergence: 7.9060
 97/200 [=============>................] - ETA: 0s - loss: 12001.0552 - KL_divergence: 7.9051
103/200 [==============>...............] - ETA: 0s - loss: 11969.0033 - KL_divergence: 7.9202
109/200 [===============>..............] - ETA: 0s - loss: 11986.3776 - KL_divergence: 7.9172
115/200 [================>.............] - ETA: 0s - loss: 11980.6479 - KL_divergence: 7.9109
121/200 [=================>............] - ETA: 0s - loss: 11986.2044 - KL_divergence: 7.9058
127/200 [==================>...........] - ETA: 0s - loss: 12010.5994 - KL_divergence: 7.8962
133/200 [==================>...........] - ETA: 0s - loss: 12018.7239 - KL_divergence: 7.8947
139/200 [===================>..........] - ETA: 0s - loss: 12021.8249 - KL_divergence: 7.8872
145/200 [====================>.........] - ETA: 0s - loss: 12022.2609 - KL_divergence: 7.8865
151/200 [=====================>........] - ETA: 0s - loss: 12018.2388 - KL_divergence: 7.8901
157/200 [======================>.......] - ETA: 0s - loss: 12019.6019 - KL_divergence: 7.8856
163/200 [=======================>......] - ETA: 0s - loss: 12030.5164 - KL_divergence: 7.8863
169/200 [========================>.....] - ETA: 0s - loss: 12032.9484 - KL_divergence: 7.8840
175/200 [=========================>....] - ETA: 0s - loss: 12036.7444 - KL_divergence: 7.8805
181/200 [==========================>...] - ETA: 0s - loss: 12039.2498 - KL_divergence: 7.8831
187/200 [===========================>..] - ETA: 0s - loss: 12052.6290 - KL_divergence: 7.8822
193/200 [===========================>..] - ETA: 0s - loss: 12046.2567 - KL_divergence: 7.8871
199/200 [============================>.] - ETA: 0s - loss: 12059.0509 - KL_divergence: 7.8836
200/200 [==============================] - 2s 10ms/step - loss: 12064.4113 - KL_divergence: 7.8818 - val_loss: 12612.3133 - val_KL_divergence: 7.8387
Epoch 98/100

  1/200 [..............................] - ETA: 1s - loss: 11903.7637 - KL_divergence: 8.1696
  7/200 [>.............................] - ETA: 1s - loss: 12293.0935 - KL_divergence: 7.9914
 13/200 [>.............................] - ETA: 1s - loss: 11916.0349 - KL_divergence: 7.9951
 19/200 [=>............................] - ETA: 1s - loss: 11873.1473 - KL_divergence: 7.9635
 25/200 [==>...........................] - ETA: 1s - loss: 11889.3588 - KL_divergence: 7.9849
 31/200 [===>..........................] - ETA: 1s - loss: 11887.1064 - KL_divergence: 7.9522
 37/200 [====>.........................] - ETA: 1s - loss: 11856.5040 - KL_divergence: 7.9559
 43/200 [=====>........................] - ETA: 1s - loss: 11928.0297 - KL_divergence: 7.9577
 49/200 [======>.......................] - ETA: 1s - loss: 11975.2468 - KL_divergence: 7.9282
 55/200 [=======>......................] - ETA: 1s - loss: 12020.4759 - KL_divergence: 7.9365
 61/200 [========>.....................] - ETA: 1s - loss: 12026.5826 - KL_divergence: 7.9339
 67/200 [=========>....................] - ETA: 1s - loss: 12043.2851 - KL_divergence: 7.9349
 73/200 [=========>....................] - ETA: 1s - loss: 12044.1878 - KL_divergence: 7.9350
 79/200 [==========>...................] - ETA: 1s - loss: 12026.7557 - KL_divergence: 7.9372
 85/200 [===========>..................] - ETA: 1s - loss: 12043.8927 - KL_divergence: 7.9329
 91/200 [============>.................] - ETA: 0s - loss: 12011.4501 - KL_divergence: 7.9321
 97/200 [=============>................] - ETA: 0s - loss: 12004.0930 - KL_divergence: 7.9358
103/200 [==============>...............] - ETA: 0s - loss: 12014.3175 - KL_divergence: 7.9447
109/200 [===============>..............] - ETA: 0s - loss: 12024.2585 - KL_divergence: 7.9397
115/200 [================>.............] - ETA: 0s - loss: 12005.4562 - KL_divergence: 7.9432
121/200 [=================>............] - ETA: 0s - loss: 12013.6911 - KL_divergence: 7.9407
127/200 [==================>...........] - ETA: 0s - loss: 12014.8785 - KL_divergence: 7.9480
133/200 [==================>...........] - ETA: 0s - loss: 12006.2237 - KL_divergence: 7.9554
139/200 [===================>..........] - ETA: 0s - loss: 11996.1010 - KL_divergence: 7.9573
145/200 [====================>.........] - ETA: 0s - loss: 12002.6968 - KL_divergence: 7.9542
151/200 [=====================>........] - ETA: 0s - loss: 12014.9784 - KL_divergence: 7.9478
157/200 [======================>.......] - ETA: 0s - loss: 12027.2173 - KL_divergence: 7.9473
163/200 [=======================>......] - ETA: 0s - loss: 12018.1527 - KL_divergence: 7.9446
169/200 [========================>.....] - ETA: 0s - loss: 12016.5218 - KL_divergence: 7.9416
175/200 [=========================>....] - ETA: 0s - loss: 12020.3774 - KL_divergence: 7.9422
181/200 [==========================>...] - ETA: 0s - loss: 12017.9457 - KL_divergence: 7.9368
187/200 [===========================>..] - ETA: 0s - loss: 12012.3533 - KL_divergence: 7.9356
193/200 [===========================>..] - ETA: 0s - loss: 12021.3313 - KL_divergence: 7.9340
199/200 [============================>.] - ETA: 0s - loss: 12017.1617 - KL_divergence: 7.9309
200/200 [==============================] - 2s 10ms/step - loss: 12020.5623 - KL_divergence: 7.9295 - val_loss: 12621.1612 - val_KL_divergence: 7.6779
Epoch 99/100

  1/200 [..............................] - ETA: 1s - loss: 12365.0498 - KL_divergence: 7.5185
  7/200 [>.............................] - ETA: 1s - loss: 11832.9696 - KL_divergence: 8.0821
 13/200 [>.............................] - ETA: 1s - loss: 11922.4404 - KL_divergence: 8.0342
 19/200 [=>............................] - ETA: 1s - loss: 11863.0523 - KL_divergence: 8.0099
 25/200 [==>...........................] - ETA: 1s - loss: 12054.0998 - KL_divergence: 7.9625
 31/200 [===>..........................] - ETA: 1s - loss: 12111.5955 - KL_divergence: 7.9383
 37/200 [====>.........................] - ETA: 1s - loss: 12162.3648 - KL_divergence: 7.9144
 43/200 [=====>........................] - ETA: 1s - loss: 12146.7970 - KL_divergence: 7.9255
 49/200 [======>.......................] - ETA: 1s - loss: 12109.5629 - KL_divergence: 7.9112
 55/200 [=======>......................] - ETA: 1s - loss: 12064.7047 - KL_divergence: 7.9024
 61/200 [========>.....................] - ETA: 1s - loss: 12046.7944 - KL_divergence: 7.8954
 67/200 [=========>....................] - ETA: 1s - loss: 12051.5675 - KL_divergence: 7.8684
 73/200 [=========>....................] - ETA: 1s - loss: 12022.7197 - KL_divergence: 7.8622
 79/200 [==========>...................] - ETA: 1s - loss: 12031.4764 - KL_divergence: 7.8553
 85/200 [===========>..................] - ETA: 1s - loss: 12062.0463 - KL_divergence: 7.8582
 91/200 [============>.................] - ETA: 1s - loss: 12057.4464 - KL_divergence: 7.8714
 97/200 [=============>................] - ETA: 0s - loss: 12095.9984 - KL_divergence: 7.8619
103/200 [==============>...............] - ETA: 0s - loss: 12103.5290 - KL_divergence: 7.8613
109/200 [===============>..............] - ETA: 0s - loss: 12128.3000 - KL_divergence: 7.8546
115/200 [================>.............] - ETA: 0s - loss: 12118.4252 - KL_divergence: 7.8478
121/200 [=================>............] - ETA: 0s - loss: 12109.4429 - KL_divergence: 7.8498
127/200 [==================>...........] - ETA: 0s - loss: 12090.5758 - KL_divergence: 7.8572
134/200 [===================>..........] - ETA: 0s - loss: 12059.1481 - KL_divergence: 7.8684
140/200 [====================>.........] - ETA: 0s - loss: 12081.3137 - KL_divergence: 7.8621
146/200 [====================>.........] - ETA: 0s - loss: 12099.8996 - KL_divergence: 7.8637
153/200 [=====================>........] - ETA: 0s - loss: 12099.6079 - KL_divergence: 7.8671
159/200 [======================>.......] - ETA: 0s - loss: 12099.5407 - KL_divergence: 7.8696
165/200 [=======================>......] - ETA: 0s - loss: 12082.4286 - KL_divergence: 7.8716
171/200 [========================>.....] - ETA: 0s - loss: 12081.1277 - KL_divergence: 7.8743
177/200 [=========================>....] - ETA: 0s - loss: 12077.4460 - KL_divergence: 7.8802
183/200 [==========================>...] - ETA: 0s - loss: 12069.3847 - KL_divergence: 7.8767
189/200 [===========================>..] - ETA: 0s - loss: 12087.2339 - KL_divergence: 7.8677
195/200 [============================>.] - ETA: 0s - loss: 12089.8496 - KL_divergence: 7.8602
200/200 [==============================] - 2s 10ms/step - loss: 12092.8036 - KL_divergence: 7.8553 - val_loss: 12725.0621 - val_KL_divergence: 7.9556
Epoch 100/100

  1/200 [..............................] - ETA: 1s - loss: 11802.2305 - KL_divergence: 8.2336
  7/200 [>.............................] - ETA: 1s - loss: 12547.3898 - KL_divergence: 7.7060
 13/200 [>.............................] - ETA: 1s - loss: 12321.8305 - KL_divergence: 7.8064
 19/200 [=>............................] - ETA: 1s - loss: 12183.7198 - KL_divergence: 7.8595
 25/200 [==>...........................] - ETA: 1s - loss: 12145.7441 - KL_divergence: 7.8744
 31/200 [===>..........................] - ETA: 1s - loss: 12154.7003 - KL_divergence: 7.8522
 37/200 [====>.........................] - ETA: 1s - loss: 12082.4011 - KL_divergence: 7.8535
 43/200 [=====>........................] - ETA: 1s - loss: 12060.6685 - KL_divergence: 7.8481
 49/200 [======>.......................] - ETA: 1s - loss: 12083.5425 - KL_divergence: 7.8259
 55/200 [=======>......................] - ETA: 1s - loss: 12074.3772 - KL_divergence: 7.8506
 61/200 [========>.....................] - ETA: 1s - loss: 12004.2409 - KL_divergence: 7.8887
 67/200 [=========>....................] - ETA: 1s - loss: 11975.3716 - KL_divergence: 7.8880
 73/200 [=========>....................] - ETA: 1s - loss: 11986.3454 - KL_divergence: 7.8828
 79/200 [==========>...................] - ETA: 1s - loss: 11984.1545 - KL_divergence: 7.8966
 85/200 [===========>..................] - ETA: 1s - loss: 11955.7886 - KL_divergence: 7.9087
 91/200 [============>.................] - ETA: 0s - loss: 11939.5582 - KL_divergence: 7.9160
 97/200 [=============>................] - ETA: 0s - loss: 11970.9802 - KL_divergence: 7.9051
103/200 [==============>...............] - ETA: 0s - loss: 11960.7047 - KL_divergence: 7.9184
109/200 [===============>..............] - ETA: 0s - loss: 11931.5537 - KL_divergence: 7.9226
115/200 [================>.............] - ETA: 0s - loss: 11969.2544 - KL_divergence: 7.9128
121/200 [=================>............] - ETA: 0s - loss: 11964.4205 - KL_divergence: 7.9121
127/200 [==================>...........] - ETA: 0s - loss: 11958.1167 - KL_divergence: 7.9151
133/200 [==================>...........] - ETA: 0s - loss: 11950.9971 - KL_divergence: 7.9144
139/200 [===================>..........] - ETA: 0s - loss: 11974.6459 - KL_divergence: 7.9112
145/200 [====================>.........] - ETA: 0s - loss: 11980.6292 - KL_divergence: 7.9087
151/200 [=====================>........] - ETA: 0s - loss: 11992.9568 - KL_divergence: 7.9017
157/200 [======================>.......] - ETA: 0s - loss: 11994.3850 - KL_divergence: 7.9024
164/200 [=======================>......] - ETA: 0s - loss: 12006.7962 - KL_divergence: 7.8922
170/200 [========================>.....] - ETA: 0s - loss: 12030.0741 - KL_divergence: 7.8900
176/200 [=========================>....] - ETA: 0s - loss: 12031.3649 - KL_divergence: 7.8878
182/200 [==========================>...] - ETA: 0s - loss: 12033.2496 - KL_divergence: 7.8821
189/200 [===========================>..] - ETA: 0s - loss: 12024.0300 - KL_divergence: 7.8810
195/200 [============================>.] - ETA: 0s - loss: 12009.6845 - KL_divergence: 7.8829
200/200 [==============================] - 2s 10ms/step - loss: 12009.0479 - KL_divergence: 7.8804 - val_loss: 12720.5285 - val_KL_divergence: 8.0132
Saving the trained inference, generator and latent models...	
 1/50 [..............................] - ETA: 3s
16/50 [========>.....................] - ETA: 0s
22/50 [============>.................] - ETA: 0s
29/50 [================>.............] - ETA: 0s
38/50 [=====================>........] - ETA: 0s
48/50 [===========================>..] - ETA: 0s
50/50 [==============================] - 0s 7ms/step
