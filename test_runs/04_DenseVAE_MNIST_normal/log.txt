Using TensorFlow backend.
WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/qbeer666/.local/share/virtualenvs/wigner-csnl-textures-nHVgIMTt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

2019-10-30 16:30:07.690377: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-30 16:30:07.695571: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 16:30:07.826291: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5fef520 executing computations on platform CUDA. Devices:
2019-10-30 16:30:07.826330: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2019-10-30 16:30:07.828415: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599260000 Hz
2019-10-30 16:30:07.828956: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6061520 executing computations on platform Host. Devices:
2019-10-30 16:30:07.828985: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 16:30:07.829926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
2019-10-30 16:30:07.830244: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 16:30:07.831653: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 16:30:07.832848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 16:30:07.833142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 16:30:07.834520: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 16:30:07.835530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 16:30:07.838727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 16:30:07.840519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 16:30:07.840579: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 16:30:07.841865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 16:30:07.841892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 16:30:07.841903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 16:30:07.843221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7191 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-10-30 16:30:08.960098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
Training size : 60000 	 Test size : 10000
Shapes :  (60000, 28, 28, 1) 	 (10000, 28, 28, 1)
Label shaped :  (60000,) 	 (10000,)
Train set : 
Mean: 0.131, Standard Deviation: 0.308
Min: 0.000, Max: 1.000
Test set : 
Mean: 0.133, Standard Deviation: 0.310
Min: 0.000, Max: 1.000
Train SHAPE :  (60000, 28, 28, 1)
MEAN :  {0: 0.17339933, 1: 0.07599865, 2: 0.14897515, 3: 0.14153005, 4: 0.12136563, 5: 0.12874936, 6: 0.13730176, 7: 0.11452767, 8: 0.15015592, 9: 0.12258992}
STD :  {0: 0.34771788, 1: 0.24428155, 2: 0.32592347, 3: 0.31791866, 4: 0.29748434, 5: 0.30358848, 6: 0.31489742, 7: 0.29169568, 8: 0.32525992, 9: 0.29863754}
Test SHAPE :  (10000, 28, 28, 1)
MEAN :  {0: 0.1318914, 1: 0.1331554, 2: 0.13190052, 3: 0.13167885, 4: 0.13254727, 5: 0.13240181, 6: 0.13207603, 7: 0.13214922, 8: 0.13352935, 9: 0.13374092}
STD :  {0: 0.30971634, 1: 0.31134936, 2: 0.30982253, 3: 0.30960315, 4: 0.31059068, 5: 0.3102617, 6: 0.31024668, 7: 0.3097429, 8: 0.3115874, 9: 0.3117678}
Training size : 60000 	 Test size : 10000
Shapes :  (60000, 28, 28, 1) 	 (10000, 28, 28, 1)
Label shaped :  (60000,) 	 (10000,)
Train set : 
Mean: 0.131, Standard Deviation: 0.308
Min: 0.000, Max: 1.000
Test set : 
Mean: 0.133, Standard Deviation: 0.310
Min: 0.000, Max: 1.000
Train set : 
Mean: 0.131, Standard Deviation: 0.308
Min: 0.000, Max: 1.000
Train SHAPE :  (60000, 28, 28, 1)
Test SHAPE :  (10000, 28, 28, 1)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (100, 784)           0                                            
__________________________________________________________________________________________________
dense_encoder (Model)           multiple             1788416     input_1[0][0]                    
__________________________________________________________________________________________________
mean (Dense)                    (100, 2)             514         dense_encoder[1][0]              
__________________________________________________________________________________________________
log_sigma (Dense)               (100, 2)             514         dense_encoder[1][0]              
__________________________________________________________________________________________________
sampling_z (Lambda)             (100, 2)             0           mean[0][0]                       
                                                                 log_sigma[0][0]                  
__________________________________________________________________________________________________
dense_decoder (Model)           multiple             5544720     sampling_z[0][0]                 
==================================================================================================
Total params: 7,334,164
Trainable params: 7,334,164
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100

  1/200 [..............................] - ETA: 4:53 - loss: 4462438400.0000 - KL_divergence: 0.0140
  7/200 [>.............................] - ETA: 42s - loss: 3732636891.4286 - KL_divergence: 0.9284 
 13/200 [>.............................] - ETA: 22s - loss: 3231029444.9231 - KL_divergence: 1.6577
 19/200 [=>............................] - ETA: 15s - loss: 3045004746.1053 - KL_divergence: 2.1341
 25/200 [==>...........................] - ETA: 11s - loss: 2939227863.0400 - KL_divergence: 2.4786
 31/200 [===>..........................] - ETA: 9s - loss: 2870547348.6452 - KL_divergence: 2.7313 
 37/200 [====>.........................] - ETA: 7s - loss: 2814545670.9189 - KL_divergence: 2.9320
 43/200 [=====>........................] - ETA: 6s - loss: 2771869029.2093 - KL_divergence: 3.0947
 49/200 [======>.......................] - ETA: 5s - loss: 2743870751.3469 - KL_divergence: 3.2405
 55/200 [=======>......................] - ETA: 5s - loss: 2724122135.2727 - KL_divergence: 3.3770
 61/200 [========>.....................] - ETA: 4s - loss: 2707429044.4590 - KL_divergence: 3.4994
 67/200 [=========>....................] - ETA: 4s - loss: 2691795945.0746 - KL_divergence: 3.6093
 72/200 [=========>....................] - ETA: 3s - loss: 2681133127.1111 - KL_divergence: 3.6938
 78/200 [==========>...................] - ETA: 3s - loss: 2672429420.3077 - KL_divergence: 3.7732
 84/200 [===========>..................] - ETA: 3s - loss: 2661476199.6190 - KL_divergence: 3.8411
 90/200 [============>.................] - ETA: 2s - loss: 2650469612.0889 - KL_divergence: 3.9007
 96/200 [=============>................] - ETA: 2s - loss: 2644418946.6667 - KL_divergence: 3.9654
102/200 [==============>...............] - ETA: 2s - loss: 2637382696.1569 - KL_divergence: 4.0186
108/200 [===============>..............] - ETA: 2s - loss: 2631853421.0370 - KL_divergence: 4.0753
114/200 [================>.............] - ETA: 1s - loss: 2623590741.3333 - KL_divergence: 4.1157
120/200 [=================>............] - ETA: 1s - loss: 2617658826.6667 - KL_divergence: 4.1602
126/200 [=================>............] - ETA: 1s - loss: 2613277913.3968 - KL_divergence: 4.2087
132/200 [==================>...........] - ETA: 1s - loss: 2608998334.0606 - KL_divergence: 4.2615
139/200 [===================>..........] - ETA: 1s - loss: 2600513454.9640 - KL_divergence: 4.3286
145/200 [====================>.........] - ETA: 1s - loss: 2591800494.7862 - KL_divergence: 4.3841
151/200 [=====================>........] - ETA: 0s - loss: 2583695366.7815 - KL_divergence: 4.4570
158/200 [======================>.......] - ETA: 0s - loss: 2572782950.0759 - KL_divergence: 4.5448
164/200 [=======================>......] - ETA: 0s - loss: 2563820381.6585 - KL_divergence: 4.6221
170/200 [========================>.....] - ETA: 0s - loss: 2555053536.3765 - KL_divergence: 4.7097
176/200 [=========================>....] - ETA: 0s - loss: 2546646379.6364 - KL_divergence: 4.7906
183/200 [==========================>...] - ETA: 0s - loss: 2535268599.6066 - KL_divergence: 4.8698
190/200 [===========================>..] - ETA: 0s - loss: 2525135987.8737 - KL_divergence: 4.9605
196/200 [============================>.] - ETA: 0s - loss: 2515411889.6327 - KL_divergence: 5.0284
200/200 [==============================] - 4s 18ms/step - loss: 2509712608.6400 - KL_divergence: 5.0774 - val_loss: 2182550224.6400 - val_KL_divergence: 8.5457
Epoch 2/100

  1/200 [..............................] - ETA: 1s - loss: 2250372096.0000 - KL_divergence: 8.7451
  7/200 [>.............................] - ETA: 1s - loss: 2201036233.1429 - KL_divergence: 7.8845
 13/200 [>.............................] - ETA: 1s - loss: 2188673575.3846 - KL_divergence: 7.7932
 20/200 [==>...........................] - ETA: 1s - loss: 2187648166.4000 - KL_divergence: 7.7836
 26/200 [==>...........................] - ETA: 1s - loss: 2187686582.1538 - KL_divergence: 7.7509
 32/200 [===>..........................] - ETA: 1s - loss: 2183848736.0000 - KL_divergence: 7.7539
 38/200 [====>.........................] - ETA: 1s - loss: 2185400576.0000 - KL_divergence: 7.7330
 45/200 [=====>........................] - ETA: 1s - loss: 2177134355.9111 - KL_divergence: 7.6872
 52/200 [======>.......................] - ETA: 1s - loss: 2174317070.7692 - KL_divergence: 7.7177
 59/200 [=======>......................] - ETA: 1s - loss: 2175673472.0000 - KL_divergence: 7.7378
 65/200 [========>.....................] - ETA: 1s - loss: 2172699541.6615 - KL_divergence: 7.7372
 71/200 [=========>....................] - ETA: 1s - loss: 2170525831.2113 - KL_divergence: 7.7393
 77/200 [==========>...................] - ETA: 1s - loss: 2165948271.3766 - KL_divergence: 7.7251
 83/200 [===========>..................] - ETA: 1s - loss: 2165726373.0120 - KL_divergence: 7.7230
 89/200 [============>.................] - ETA: 0s - loss: 2162513569.0787 - KL_divergence: 7.7166
 95/200 [=============>................] - ETA: 0s - loss: 2158991938.0211 - KL_divergence: 7.7310
101/200 [==============>...............] - ETA: 0s - loss: 2155821343.6832 - KL_divergence: 7.7408
107/200 [===============>..............] - ETA: 0s - loss: 2155515540.3364 - KL_divergence: 7.7503
113/200 [===============>..............] - ETA: 0s - loss: 2153352003.9646 - KL_divergence: 7.7575
119/200 [================>.............] - ETA: 0s - loss: 2149882511.0588 - KL_divergence: 7.7556
125/200 [=================>............] - ETA: 0s - loss: 2149590640.6400 - KL_divergence: 7.7601
131/200 [==================>...........] - ETA: 0s - loss: 2144817624.9160 - KL_divergence: 7.7603
137/200 [===================>..........] - ETA: 0s - loss: 2142374325.2555 - KL_divergence: 7.7651
143/200 [====================>.........] - ETA: 0s - loss: 2138331259.5245 - KL_divergence: 7.7598
149/200 [=====================>........] - ETA: 0s - loss: 2136709611.3826 - KL_divergence: 7.7659
155/200 [======================>.......] - ETA: 0s - loss: 2134075915.5613 - KL_divergence: 7.7637
161/200 [=======================>......] - ETA: 0s - loss: 2132558136.4472 - KL_divergence: 7.7614
167/200 [========================>.....] - ETA: 0s - loss: 2130451692.0719 - KL_divergence: 7.7564
173/200 [========================>.....] - ETA: 0s - loss: 2127468103.7688 - KL_divergence: 7.7522
179/200 [=========================>....] - ETA: 0s - loss: 2126439127.2402 - KL_divergence: 7.7432
185/200 [==========================>...] - ETA: 0s - loss: 2123898574.8757 - KL_divergence: 7.7386
191/200 [===========================>..] - ETA: 0s - loss: 2122071589.5288 - KL_divergence: 7.7361
197/200 [============================>.] - ETA: 0s - loss: 2119888661.4416 - KL_divergence: 7.7350
200/200 [==============================] - 2s 10ms/step - loss: 2119819880.9600 - KL_divergence: 7.7312 - val_loss: 2051203093.7600 - val_KL_divergence: 8.1488
Epoch 3/100

  1/200 [..............................] - ETA: 1s - loss: 1991334656.0000 - KL_divergence: 7.3131
  8/200 [>.............................] - ETA: 1s - loss: 2051866272.0000 - KL_divergence: 7.6179
 14/200 [=>............................] - ETA: 1s - loss: 2045114596.5714 - KL_divergence: 7.5702
 20/200 [==>...........................] - ETA: 1s - loss: 2016366073.6000 - KL_divergence: 7.5566
 26/200 [==>...........................] - ETA: 1s - loss: 2034457156.9231 - KL_divergence: 7.5392
 32/200 [===>..........................] - ETA: 1s - loss: 2031146000.0000 - KL_divergence: 7.4934
 38/200 [====>.........................] - ETA: 1s - loss: 2035221652.2105 - KL_divergence: 7.5022
 44/200 [=====>........................] - ETA: 1s - loss: 2028896992.0000 - KL_divergence: 7.4971
 50/200 [======>.......................] - ETA: 1s - loss: 2029163719.6800 - KL_divergence: 7.5070
 56/200 [=======>......................] - ETA: 1s - loss: 2029626402.2857 - KL_divergence: 7.5118
 62/200 [========>.....................] - ETA: 1s - loss: 2032043377.5484 - KL_divergence: 7.5284
 68/200 [=========>....................] - ETA: 1s - loss: 2033049662.1176 - KL_divergence: 7.5326
 74/200 [==========>...................] - ETA: 1s - loss: 2036479854.7027 - KL_divergence: 7.5246
 80/200 [===========>..................] - ETA: 1s - loss: 2031610259.2000 - KL_divergence: 7.5286
 86/200 [===========>..................] - ETA: 0s - loss: 2036597768.9302 - KL_divergence: 7.5361
 92/200 [============>.................] - ETA: 0s - loss: 2035559979.1304 - KL_divergence: 7.5348
 98/200 [=============>................] - ETA: 0s - loss: 2033913761.9592 - KL_divergence: 7.5343
104/200 [==============>...............] - ETA: 0s - loss: 2032171468.3077 - KL_divergence: 7.5201
110/200 [===============>..............] - ETA: 0s - loss: 2030253645.9636 - KL_divergence: 7.5155
116/200 [================>.............] - ETA: 0s - loss: 2030031309.2414 - KL_divergence: 7.5148
122/200 [=================>............] - ETA: 0s - loss: 2028095182.6885 - KL_divergence: 7.5063
128/200 [==================>...........] - ETA: 0s - loss: 2026243038.0000 - KL_divergence: 7.5094
134/200 [===================>..........] - ETA: 0s - loss: 2025943102.0896 - KL_divergence: 7.5084
140/200 [====================>.........] - ETA: 0s - loss: 2020756128.9143 - KL_divergence: 7.4917
146/200 [====================>.........] - ETA: 0s - loss: 2018999074.1918 - KL_divergence: 7.4887
152/200 [=====================>........] - ETA: 0s - loss: 2016062780.6316 - KL_divergence: 7.4867
158/200 [======================>.......] - ETA: 0s - loss: 2014906206.7848 - KL_divergence: 7.4769
164/200 [=======================>......] - ETA: 0s - loss: 2012903538.7317 - KL_divergence: 7.4719
170/200 [========================>.....] - ETA: 0s - loss: 2012065746.0706 - KL_divergence: 7.4686
176/200 [=========================>....] - ETA: 0s - loss: 2010802682.9091 - KL_divergence: 7.4700
182/200 [==========================>...] - ETA: 0s - loss: 2008818140.8352 - KL_divergence: 7.4607
188/200 [===========================>..] - ETA: 0s - loss: 2007390655.3191 - KL_divergence: 7.4478
192/200 [===========================>..] - ETA: 0s - loss: 2006113219.3333 - KL_divergence: 7.4394
197/200 [============================>.] - ETA: 0s - loss: 2004980946.5178 - KL_divergence: 7.4349
200/200 [==============================] - 2s 10ms/step - loss: 2005530196.4800 - KL_divergence: 7.4353 - val_loss: 1959670105.6000 - val_KL_divergence: 6.7780
Epoch 4/100

  1/200 [..............................] - ETA: 1s - loss: 2013135232.0000 - KL_divergence: 6.4804
  7/200 [>.............................] - ETA: 1s - loss: 1978095104.0000 - KL_divergence: 7.0946
 14/200 [=>............................] - ETA: 1s - loss: 1973345179.4286 - KL_divergence: 7.0726
 20/200 [==>...........................] - ETA: 1s - loss: 1966674176.0000 - KL_divergence: 7.0688
 25/200 [==>...........................] - ETA: 1s - loss: 1968910914.5600 - KL_divergence: 7.0938
 31/200 [===>..........................] - ETA: 1s - loss: 1956632774.1935 - KL_divergence: 7.0734
 37/200 [====>.........................] - ETA: 1s - loss: 1958710600.6486 - KL_divergence: 7.1082
 43/200 [=====>........................] - ETA: 1s - loss: 1962484676.4651 - KL_divergence: 7.1154
 49/200 [======>.......................] - ETA: 1s - loss: 1954401026.6122 - KL_divergence: 7.1238
 55/200 [=======>......................] - ETA: 1s - loss: 1949759308.8000 - KL_divergence: 7.1312
 61/200 [========>.....................] - ETA: 1s - loss: 1952454020.1967 - KL_divergence: 7.1645
 67/200 [=========>....................] - ETA: 1s - loss: 1952206523.2239 - KL_divergence: 7.1676
 73/200 [=========>....................] - ETA: 1s - loss: 1952338638.9041 - KL_divergence: 7.1772
 79/200 [==========>...................] - ETA: 1s - loss: 1951770246.4810 - KL_divergence: 7.1833
 85/200 [===========>..................] - ETA: 1s - loss: 1949002812.2353 - KL_divergence: 7.1828
 91/200 [============>.................] - ETA: 0s - loss: 1948056974.0659 - KL_divergence: 7.1838
 97/200 [=============>................] - ETA: 0s - loss: 1943948836.9485 - KL_divergence: 7.2010
103/200 [==============>...............] - ETA: 0s - loss: 1944159910.5243 - KL_divergence: 7.2002
109/200 [===============>..............] - ETA: 0s - loss: 1944044071.9266 - KL_divergence: 7.2047
115/200 [================>.............] - ETA: 0s - loss: 1942219932.9391 - KL_divergence: 7.2032
121/200 [=================>............] - ETA: 0s - loss: 1939211011.1736 - KL_divergence: 7.2063
127/200 [==================>...........] - ETA: 0s - loss: 1938405838.6142 - KL_divergence: 7.2071
133/200 [==================>...........] - ETA: 0s - loss: 1939697216.4812 - KL_divergence: 7.2083
139/200 [===================>..........] - ETA: 0s - loss: 1937285138.4173 - KL_divergence: 7.2064
145/200 [====================>.........] - ETA: 0s - loss: 1935138164.5241 - KL_divergence: 7.2088
151/200 [=====================>........] - ETA: 0s - loss: 1932431417.6424 - KL_divergence: 7.2101
157/200 [======================>.......] - ETA: 0s - loss: 1932574338.4459 - KL_divergence: 7.2092
163/200 [=======================>......] - ETA: 0s - loss: 1930236555.7791 - KL_divergence: 7.2008
169/200 [========================>.....] - ETA: 0s - loss: 1930186616.4260 - KL_divergence: 7.1978
175/200 [=========================>....] - ETA: 0s - loss: 1930801287.3143 - KL_divergence: 7.1923
181/200 [==========================>...] - ETA: 0s - loss: 1930774654.5856 - KL_divergence: 7.1990
187/200 [===========================>..] - ETA: 0s - loss: 1930880163.5936 - KL_divergence: 7.2032
193/200 [===========================>..] - ETA: 0s - loss: 1929742280.2902 - KL_divergence: 7.2047
199/200 [============================>.] - ETA: 0s - loss: 1929720751.5980 - KL_divergence: 7.2022
200/200 [==============================] - 2s 10ms/step - loss: 1929447918.7200 - KL_divergence: 7.2024 - val_loss: 1862217404.1600 - val_KL_divergence: 7.3657
Epoch 5/100

  1/200 [..............................] - ETA: 1s - loss: 1824045184.0000 - KL_divergence: 6.8049
  7/200 [>.............................] - ETA: 1s - loss: 1911576941.7143 - KL_divergence: 7.0724
 13/200 [>.............................] - ETA: 1s - loss: 1905249102.7692 - KL_divergence: 7.2075
 19/200 [=>............................] - ETA: 1s - loss: 1898036224.0000 - KL_divergence: 7.1665
 25/200 [==>...........................] - ETA: 1s - loss: 1885549399.0400 - KL_divergence: 7.1334
 31/200 [===>..........................] - ETA: 1s - loss: 1886984646.1935 - KL_divergence: 7.1096
 37/200 [====>.........................] - ETA: 1s - loss: 1885983318.4865 - KL_divergence: 7.1087
 43/200 [=====>........................] - ETA: 1s - loss: 1888352812.6512 - KL_divergence: 7.0815
 50/200 [======>.......................] - ETA: 1s - loss: 1883356945.9200 - KL_divergence: 7.0740
 56/200 [=======>......................] - ETA: 1s - loss: 1887207613.7143 - KL_divergence: 7.0662
 62/200 [========>.....................] - ETA: 1s - loss: 1888455388.9032 - KL_divergence: 7.0773
 69/200 [=========>....................] - ETA: 1s - loss: 1887662501.1014 - KL_divergence: 7.0793
 75/200 [==========>...................] - ETA: 1s - loss: 1884465621.3333 - KL_divergence: 7.1224
 81/200 [===========>..................] - ETA: 1s - loss: 1884285454.2222 - KL_divergence: 7.1354
 87/200 [============>.................] - ETA: 1s - loss: 1884463885.2414 - KL_divergence: 7.1236
 93/200 [============>.................] - ETA: 0s - loss: 1884456632.4301 - KL_divergence: 7.1201
 99/200 [=============>................] - ETA: 0s - loss: 1885791171.2323 - KL_divergence: 7.1365
105/200 [==============>...............] - ETA: 0s - loss: 1886356559.2381 - KL_divergence: 7.1497
111/200 [===============>..............] - ETA: 0s - loss: 1885736433.0090 - KL_divergence: 7.1627
117/200 [================>.............] - ETA: 0s - loss: 1888071851.7607 - KL_divergence: 7.1590
123/200 [=================>............] - ETA: 0s - loss: 1887477405.1382 - KL_divergence: 7.1520
129/200 [==================>...........] - ETA: 0s - loss: 1887919088.1240 - KL_divergence: 7.1498
135/200 [===================>..........] - ETA: 0s - loss: 1886743407.8815 - KL_divergence: 7.1517
141/200 [====================>.........] - ETA: 0s - loss: 1887477927.0355 - KL_divergence: 7.1517
147/200 [=====================>........] - ETA: 0s - loss: 1886176494.5850 - KL_divergence: 7.1459
153/200 [=====================>........] - ETA: 0s - loss: 1885449957.2288 - KL_divergence: 7.1395
159/200 [======================>.......] - ETA: 0s - loss: 1885555065.5597 - KL_divergence: 7.1403
165/200 [=======================>......] - ETA: 0s - loss: 1884064972.8000 - KL_divergence: 7.1384
171/200 [========================>.....] - ETA: 0s - loss: 1883061523.4620 - KL_divergence: 7.1377
177/200 [=========================>....] - ETA: 0s - loss: 1882322533.9661 - KL_divergence: 7.1382
183/200 [==========================>...] - ETA: 0s - loss: 1880635128.3060 - KL_divergence: 7.1378
189/200 [===========================>..] - ETA: 0s - loss: 1879384281.3968 - KL_divergence: 7.1400
195/200 [============================>.] - ETA: 0s - loss: 1878364319.5077 - KL_divergence: 7.1468
200/200 [==============================] - 2s 10ms/step - loss: 1877037363.2000 - KL_divergence: 7.1423 - val_loss: 1824782890.2400 - val_KL_divergence: 7.8369
Epoch 6/100

  1/200 [..............................] - ETA: 1s - loss: 1813373312.0000 - KL_divergence: 7.6719
  8/200 [>.............................] - ETA: 1s - loss: 1890799952.0000 - KL_divergence: 7.2219
 15/200 [=>............................] - ETA: 1s - loss: 1900828953.6000 - KL_divergence: 7.2529
 22/200 [==>...........................] - ETA: 1s - loss: 1882979042.9091 - KL_divergence: 7.2354
 28/200 [===>..........................] - ETA: 1s - loss: 1867213481.1429 - KL_divergence: 7.2351
 34/200 [====>.........................] - ETA: 1s - loss: 1852135796.7059 - KL_divergence: 7.2196
 40/200 [=====>........................] - ETA: 1s - loss: 1853869174.4000 - KL_divergence: 7.2393
 46/200 [=====>........................] - ETA: 1s - loss: 1852114640.6957 - KL_divergence: 7.2255
 52/200 [======>.......................] - ETA: 1s - loss: 1854993543.3846 - KL_divergence: 7.2390
 58/200 [=======>......................] - ETA: 1s - loss: 1856392476.6897 - KL_divergence: 7.2662
 64/200 [========>.....................] - ETA: 1s - loss: 1856326418.0000 - KL_divergence: 7.2720
 70/200 [=========>....................] - ETA: 1s - loss: 1850977356.8000 - KL_divergence: 7.2736
 76/200 [==========>...................] - ETA: 1s - loss: 1849259553.6842 - KL_divergence: 7.2673
 82/200 [===========>..................] - ETA: 1s - loss: 1847368496.3902 - KL_divergence: 7.2480
 88/200 [============>.................] - ETA: 1s - loss: 1846883579.6364 - KL_divergence: 7.2590
 94/200 [=============>................] - ETA: 0s - loss: 1848704012.2553 - KL_divergence: 7.2433
100/200 [==============>...............] - ETA: 0s - loss: 1846796458.2400 - KL_divergence: 7.2242
105/200 [==============>...............] - ETA: 0s - loss: 1846644516.5714 - KL_divergence: 7.2245
111/200 [===============>..............] - ETA: 0s - loss: 1844725424.4324 - KL_divergence: 7.2211
117/200 [================>.............] - ETA: 0s - loss: 1847860348.7179 - KL_divergence: 7.2271
123/200 [=================>............] - ETA: 0s - loss: 1845570788.9431 - KL_divergence: 7.2196
129/200 [==================>...........] - ETA: 0s - loss: 1844210812.0310 - KL_divergence: 7.2226
135/200 [===================>..........] - ETA: 0s - loss: 1841647129.6000 - KL_divergence: 7.2203
141/200 [====================>.........] - ETA: 0s - loss: 1842409150.6383 - KL_divergence: 7.2225
147/200 [=====================>........] - ETA: 0s - loss: 1842008062.2585 - KL_divergence: 7.2181
153/200 [=====================>........] - ETA: 0s - loss: 1842851892.7059 - KL_divergence: 7.2251
159/200 [======================>.......] - ETA: 0s - loss: 1839693893.2327 - KL_divergence: 7.2187
165/200 [=======================>......] - ETA: 0s - loss: 1841865688.4364 - KL_divergence: 7.2298
172/200 [========================>.....] - ETA: 0s - loss: 1838535910.6977 - KL_divergence: 7.2286
179/200 [=========================>....] - ETA: 0s - loss: 1838634658.3240 - KL_divergence: 7.2250
185/200 [==========================>...] - ETA: 0s - loss: 1838559608.3892 - KL_divergence: 7.2232
191/200 [===========================>..] - ETA: 0s - loss: 1837360931.5183 - KL_divergence: 7.2284
197/200 [============================>.] - ETA: 0s - loss: 1838020461.1574 - KL_divergence: 7.2325
200/200 [==============================] - 2s 10ms/step - loss: 1836987260.8000 - KL_divergence: 7.2349 - val_loss: 1775049425.9200 - val_KL_divergence: 7.4198
Epoch 7/100

  1/200 [..............................] - ETA: 1s - loss: 1689042304.0000 - KL_divergence: 7.6057
  8/200 [>.............................] - ETA: 1s - loss: 1750776944.0000 - KL_divergence: 7.3572
 15/200 [=>............................] - ETA: 1s - loss: 1779627306.6667 - KL_divergence: 7.4759
 21/200 [==>...........................] - ETA: 1s - loss: 1781662768.7619 - KL_divergence: 7.4791
 28/200 [===>..........................] - ETA: 1s - loss: 1794652667.4286 - KL_divergence: 7.4369
 34/200 [====>.........................] - ETA: 1s - loss: 1804050262.5882 - KL_divergence: 7.4394
 40/200 [=====>........................] - ETA: 1s - loss: 1813674115.2000 - KL_divergence: 7.4592
 46/200 [=====>........................] - ETA: 1s - loss: 1810982032.6957 - KL_divergence: 7.4485
 52/200 [======>.......................] - ETA: 1s - loss: 1807488263.3846 - KL_divergence: 7.4465
 58/200 [=======>......................] - ETA: 1s - loss: 1809385213.7931 - KL_divergence: 7.4463
 64/200 [========>.....................] - ETA: 1s - loss: 1808883690.0000 - KL_divergence: 7.4260
 70/200 [=========>....................] - ETA: 1s - loss: 1809803404.8000 - KL_divergence: 7.4306
 76/200 [==========>...................] - ETA: 1s - loss: 1809402708.2105 - KL_divergence: 7.3901
 82/200 [===========>..................] - ETA: 1s - loss: 1810808733.6585 - KL_divergence: 7.3685
 88/200 [============>.................] - ETA: 0s - loss: 1807401405.0909 - KL_divergence: 7.3596
 94/200 [=============>................] - ETA: 0s - loss: 1807075186.3830 - KL_divergence: 7.3505
100/200 [==============>...............] - ETA: 0s - loss: 1804677050.8800 - KL_divergence: 7.3425
106/200 [==============>...............] - ETA: 0s - loss: 1807520342.9434 - KL_divergence: 7.3436
113/200 [===============>..............] - ETA: 0s - loss: 1806905609.0619 - KL_divergence: 7.3275
119/200 [================>.............] - ETA: 0s - loss: 1805437064.6050 - KL_divergence: 7.3228
125/200 [=================>............] - ETA: 0s - loss: 1802112172.0320 - KL_divergence: 7.3319
131/200 [==================>...........] - ETA: 0s - loss: 1801920909.6794 - KL_divergence: 7.3252
137/200 [===================>..........] - ETA: 0s - loss: 1800053130.2774 - KL_divergence: 7.3126
143/200 [====================>.........] - ETA: 0s - loss: 1802356681.3986 - KL_divergence: 7.3234
149/200 [=====================>........] - ETA: 0s - loss: 1800730727.9463 - KL_divergence: 7.3247
155/200 [======================>.......] - ETA: 0s - loss: 1799951323.6645 - KL_divergence: 7.3343
161/200 [=======================>......] - ETA: 0s - loss: 1800272217.0435 - KL_divergence: 7.3368
167/200 [========================>.....] - ETA: 0s - loss: 1798797220.0240 - KL_divergence: 7.3334
173/200 [========================>.....] - ETA: 0s - loss: 1799314261.8266 - KL_divergence: 7.3492
179/200 [=========================>....] - ETA: 0s - loss: 1798430396.7821 - KL_divergence: 7.3487
185/200 [==========================>...] - ETA: 0s - loss: 1798699123.5459 - KL_divergence: 7.3538
191/200 [===========================>..] - ETA: 0s - loss: 1798722274.5131 - KL_divergence: 7.3565
197/200 [============================>.] - ETA: 0s - loss: 1797045927.6345 - KL_divergence: 7.3572
200/200 [==============================] - 2s 10ms/step - loss: 1796489763.8400 - KL_divergence: 7.3548 - val_loss: 1752006214.4000 - val_KL_divergence: 7.6861
Epoch 8/100

  1/200 [..............................] - ETA: 1s - loss: 1843889792.0000 - KL_divergence: 7.3635
  8/200 [>.............................] - ETA: 1s - loss: 1766972800.0000 - KL_divergence: 7.1543
 14/200 [=>............................] - ETA: 1s - loss: 1781698002.2857 - KL_divergence: 7.3796
 20/200 [==>...........................] - ETA: 1s - loss: 1793379059.2000 - KL_divergence: 7.3940
 26/200 [==>...........................] - ETA: 1s - loss: 1788811377.2308 - KL_divergence: 7.4387
 32/200 [===>..........................] - ETA: 1s - loss: 1794505492.0000 - KL_divergence: 7.4258
 38/200 [====>.........................] - ETA: 1s - loss: 1793525541.0526 - KL_divergence: 7.4635
 44/200 [=====>........................] - ETA: 1s - loss: 1793925620.3636 - KL_divergence: 7.4517
 50/200 [======>.......................] - ETA: 1s - loss: 1787171888.6400 - KL_divergence: 7.4384
 56/200 [=======>......................] - ETA: 1s - loss: 1788482333.7143 - KL_divergence: 7.4358
 62/200 [========>.....................] - ETA: 1s - loss: 1784715848.2581 - KL_divergence: 7.4392
 68/200 [=========>....................] - ETA: 1s - loss: 1787097611.2941 - KL_divergence: 7.4646
 75/200 [==========>...................] - ETA: 1s - loss: 1783530654.7200 - KL_divergence: 7.4534
 81/200 [===========>..................] - ETA: 1s - loss: 1784947871.6049 - KL_divergence: 7.4548
 87/200 [============>.................] - ETA: 1s - loss: 1787405966.7126 - KL_divergence: 7.4712
 93/200 [============>.................] - ETA: 0s - loss: 1786438004.9892 - KL_divergence: 7.4702
 99/200 [=============>................] - ETA: 0s - loss: 1784489265.1313 - KL_divergence: 7.4619
105/200 [==============>...............] - ETA: 0s - loss: 1783740765.8667 - KL_divergence: 7.4628
112/200 [===============>..............] - ETA: 0s - loss: 1784585576.0000 - KL_divergence: 7.4633
119/200 [================>.............] - ETA: 0s - loss: 1784505808.6723 - KL_divergence: 7.4416
126/200 [=================>............] - ETA: 0s - loss: 1783542740.3175 - KL_divergence: 7.4437
132/200 [==================>...........] - ETA: 0s - loss: 1780019789.5758 - KL_divergence: 7.4440
138/200 [===================>..........] - ETA: 0s - loss: 1779691616.4638 - KL_divergence: 7.4497
144/200 [====================>.........] - ETA: 0s - loss: 1778613006.2222 - KL_divergence: 7.4483
150/200 [=====================>........] - ETA: 0s - loss: 1778836612.2667 - KL_divergence: 7.4509
157/200 [======================>.......] - ETA: 0s - loss: 1778244571.3121 - KL_divergence: 7.4421
163/200 [=======================>......] - ETA: 0s - loss: 1778675637.3988 - KL_divergence: 7.4443
169/200 [========================>.....] - ETA: 0s - loss: 1777528273.7988 - KL_divergence: 7.4437
175/200 [=========================>....] - ETA: 0s - loss: 1778478853.8514 - KL_divergence: 7.4537
182/200 [==========================>...] - ETA: 0s - loss: 1777500435.6923 - KL_divergence: 7.4615
188/200 [===========================>..] - ETA: 0s - loss: 1777772787.7447 - KL_divergence: 7.4688
195/200 [============================>.] - ETA: 0s - loss: 1779362944.0000 - KL_divergence: 7.4739
200/200 [==============================] - 2s 10ms/step - loss: 1777312599.6800 - KL_divergence: 7.4768 - val_loss: 1717423934.7200 - val_KL_divergence: 7.8841
Epoch 9/100

  1/200 [..............................] - ETA: 1s - loss: 1870474112.0000 - KL_divergence: 7.5749
  7/200 [>.............................] - ETA: 1s - loss: 1728467328.0000 - KL_divergence: 7.5497
 13/200 [>.............................] - ETA: 1s - loss: 1740974395.0769 - KL_divergence: 7.5590
 19/200 [=>............................] - ETA: 1s - loss: 1741868887.5789 - KL_divergence: 7.6254
 25/200 [==>...........................] - ETA: 1s - loss: 1744230543.3600 - KL_divergence: 7.6287
 31/200 [===>..........................] - ETA: 1s - loss: 1729128914.5806 - KL_divergence: 7.6243
 37/200 [====>.........................] - ETA: 1s - loss: 1737091632.4324 - KL_divergence: 7.6810
 43/200 [=====>........................] - ETA: 1s - loss: 1744112952.5581 - KL_divergence: 7.6695
 49/200 [======>.......................] - ETA: 1s - loss: 1741723253.5510 - KL_divergence: 7.6504
 56/200 [=======>......................] - ETA: 1s - loss: 1744257072.0000 - KL_divergence: 7.6541
 63/200 [========>.....................] - ETA: 1s - loss: 1740108576.5079 - KL_divergence: 7.6616
 69/200 [=========>....................] - ETA: 1s - loss: 1737895188.4058 - KL_divergence: 7.6499
 75/200 [==========>...................] - ETA: 1s - loss: 1735756951.8933 - KL_divergence: 7.6555
 81/200 [===========>..................] - ETA: 1s - loss: 1735161310.8148 - KL_divergence: 7.6601
 87/200 [============>.................] - ETA: 0s - loss: 1733621786.4828 - KL_divergence: 7.6677
 93/200 [============>.................] - ETA: 0s - loss: 1733335646.9677 - KL_divergence: 7.6733
 99/200 [=============>................] - ETA: 0s - loss: 1731627553.6162 - KL_divergence: 7.6742
105/200 [==============>...............] - ETA: 0s - loss: 1733975901.8667 - KL_divergence: 7.6845
111/200 [===============>..............] - ETA: 0s - loss: 1735745582.1261 - KL_divergence: 7.6855
117/200 [================>.............] - ETA: 0s - loss: 1733928227.0085 - KL_divergence: 7.7049
123/200 [=================>............] - ETA: 0s - loss: 1731971644.3577 - KL_divergence: 7.7182
129/200 [==================>...........] - ETA: 0s - loss: 1731602358.5736 - KL_divergence: 7.7200
135/200 [===================>..........] - ETA: 0s - loss: 1730420567.2296 - KL_divergence: 7.7200
141/200 [====================>.........] - ETA: 0s - loss: 1730166554.3262 - KL_divergence: 7.7270
147/200 [=====================>........] - ETA: 0s - loss: 1729997628.9524 - KL_divergence: 7.7371
153/200 [=====================>........] - ETA: 0s - loss: 1729258422.3791 - KL_divergence: 7.7498
159/200 [======================>.......] - ETA: 0s - loss: 1728570980.6289 - KL_divergence: 7.7486
165/200 [=======================>......] - ETA: 0s - loss: 1728405707.2485 - KL_divergence: 7.7618
171/200 [========================>.....] - ETA: 0s - loss: 1729315354.1988 - KL_divergence: 7.7703
178/200 [=========================>....] - ETA: 0s - loss: 1726810769.2584 - KL_divergence: 7.7689
184/200 [==========================>...] - ETA: 0s - loss: 1726960008.3478 - KL_divergence: 7.7773
191/200 [===========================>..] - ETA: 0s - loss: 1726371280.4188 - KL_divergence: 7.7875
197/200 [============================>.] - ETA: 0s - loss: 1725141523.4924 - KL_divergence: 7.7944
200/200 [==============================] - 2s 10ms/step - loss: 1724588240.6400 - KL_divergence: 7.8020 - val_loss: 1711908698.8800 - val_KL_divergence: 8.0010
Epoch 10/100

  1/200 [..............................] - ETA: 1s - loss: 1665156992.0000 - KL_divergence: 8.0519
  8/200 [>.............................] - ETA: 1s - loss: 1707836176.0000 - KL_divergence: 7.9214
 15/200 [=>............................] - ETA: 1s - loss: 1725747387.7333 - KL_divergence: 8.0633
 22/200 [==>...........................] - ETA: 1s - loss: 1731774580.3636 - KL_divergence: 8.0915
 28/200 [===>..........................] - ETA: 1s - loss: 1721207433.1429 - KL_divergence: 8.1327
 35/200 [====>.........................] - ETA: 1s - loss: 1731432685.7143 - KL_divergence: 8.1059
 42/200 [=====>........................] - ETA: 1s - loss: 1728314218.6667 - KL_divergence: 8.0851
 49/200 [======>.......................] - ETA: 1s - loss: 1726032859.4286 - KL_divergence: 8.0778
 56/200 [=======>......................] - ETA: 1s - loss: 1723213531.4286 - KL_divergence: 8.0647
 63/200 [========>.....................] - ETA: 1s - loss: 1718662788.0635 - KL_divergence: 8.0598
 69/200 [=========>....................] - ETA: 1s - loss: 1712884646.9565 - KL_divergence: 8.0610
 75/200 [==========>...................] - ETA: 1s - loss: 1709204768.4267 - KL_divergence: 8.0623
 81/200 [===========>..................] - ETA: 0s - loss: 1703807404.2469 - KL_divergence: 8.0564
 87/200 [============>.................] - ETA: 0s - loss: 1703992618.6667 - KL_divergence: 8.0503
 93/200 [============>.................] - ETA: 0s - loss: 1704615618.0645 - KL_divergence: 8.0427
 99/200 [=============>................] - ETA: 0s - loss: 1704193931.6364 - KL_divergence: 8.0423
105/200 [==============>...............] - ETA: 0s - loss: 1703315260.9524 - KL_divergence: 8.0541
111/200 [===============>..............] - ETA: 0s - loss: 1697110170.5225 - KL_divergence: 8.0589
117/200 [================>.............] - ETA: 0s - loss: 1698828771.5556 - KL_divergence: 8.0760
123/200 [=================>............] - ETA: 0s - loss: 1697763358.1789 - KL_divergence: 8.0968
129/200 [==================>...........] - ETA: 0s - loss: 1696865713.6124 - KL_divergence: 8.1083
135/200 [===================>..........] - ETA: 0s - loss: 1698104735.2889 - KL_divergence: 8.1088
141/200 [====================>.........] - ETA: 0s - loss: 1697179564.4823 - KL_divergence: 8.1154
147/200 [=====================>........] - ETA: 0s - loss: 1699276007.6190 - KL_divergence: 8.1169
153/200 [=====================>........] - ETA: 0s - loss: 1698961710.8497 - KL_divergence: 8.1246
159/200 [======================>.......] - ETA: 0s - loss: 1697246178.2138 - KL_divergence: 8.1311
165/200 [=======================>......] - ETA: 0s - loss: 1697880108.2182 - KL_divergence: 8.1405
171/200 [========================>.....] - ETA: 0s - loss: 1696230411.2281 - KL_divergence: 8.1526
177/200 [=========================>....] - ETA: 0s - loss: 1698841943.5028 - KL_divergence: 8.1590
183/200 [==========================>...] - ETA: 0s - loss: 1698827782.2951 - KL_divergence: 8.1541
189/200 [===========================>..] - ETA: 0s - loss: 1698721671.4497 - KL_divergence: 8.1503
195/200 [============================>.] - ETA: 0s - loss: 1698597862.4000 - KL_divergence: 8.1540
200/200 [==============================] - 2s 10ms/step - loss: 1698775660.1600 - KL_divergence: 8.1526 - val_loss: 1689904780.8000 - val_KL_divergence: 8.7146
Epoch 11/100

  1/200 [..............................] - ETA: 1s - loss: 1677843200.0000 - KL_divergence: 8.2127
  7/200 [>.............................] - ETA: 1s - loss: 1705326610.2857 - KL_divergence: 8.3730
 13/200 [>.............................] - ETA: 1s - loss: 1691391980.3077 - KL_divergence: 8.4087
 20/200 [==>...........................] - ETA: 1s - loss: 1695276262.4000 - KL_divergence: 8.4349
 26/200 [==>...........................] - ETA: 1s - loss: 1701473757.5385 - KL_divergence: 8.3649
 32/200 [===>..........................] - ETA: 1s - loss: 1714006112.0000 - KL_divergence: 8.3797
 38/200 [====>.........................] - ETA: 1s - loss: 1703940638.3158 - KL_divergence: 8.3405
 44/200 [=====>........................] - ETA: 1s - loss: 1697320826.1818 - KL_divergence: 8.3452
 50/200 [======>.......................] - ETA: 1s - loss: 1698970718.7200 - KL_divergence: 8.3695
 56/200 [=======>......................] - ETA: 1s - loss: 1697178093.7143 - KL_divergence: 8.3923
 62/200 [========>.....................] - ETA: 1s - loss: 1698092733.9355 - KL_divergence: 8.4021
 68/200 [=========>....................] - ETA: 1s - loss: 1698874215.5294 - KL_divergence: 8.3853
 74/200 [==========>...................] - ETA: 1s - loss: 1698462901.6216 - KL_divergence: 8.3900
 80/200 [===========>..................] - ETA: 1s - loss: 1691847808.0000 - KL_divergence: 8.4059
 86/200 [===========>..................] - ETA: 1s - loss: 1686201534.5116 - KL_divergence: 8.4138
 92/200 [============>.................] - ETA: 0s - loss: 1682752187.8261 - KL_divergence: 8.4260
 98/200 [=============>................] - ETA: 0s - loss: 1680839730.9388 - KL_divergence: 8.4303
104/200 [==============>...............] - ETA: 0s - loss: 1685273364.9231 - KL_divergence: 8.4367
110/200 [===============>..............] - ETA: 0s - loss: 1681484507.9273 - KL_divergence: 8.4350
116/200 [================>.............] - ETA: 0s - loss: 1679523859.8621 - KL_divergence: 8.4429
122/200 [=================>............] - ETA: 0s - loss: 1677023396.7213 - KL_divergence: 8.4519
128/200 [==================>...........] - ETA: 0s - loss: 1676917452.0000 - KL_divergence: 8.4485
134/200 [===================>..........] - ETA: 0s - loss: 1673533562.2687 - KL_divergence: 8.4496
140/200 [====================>.........] - ETA: 0s - loss: 1674397778.2857 - KL_divergence: 8.4474
146/200 [====================>.........] - ETA: 0s - loss: 1674104220.0548 - KL_divergence: 8.4564
152/200 [=====================>........] - ETA: 0s - loss: 1674422943.1579 - KL_divergence: 8.4560
158/200 [======================>.......] - ETA: 0s - loss: 1674579916.9620 - KL_divergence: 8.4615
164/200 [=======================>......] - ETA: 0s - loss: 1673496392.5854 - KL_divergence: 8.4637
170/200 [========================>.....] - ETA: 0s - loss: 1673502139.4824 - KL_divergence: 8.4649
176/200 [=========================>....] - ETA: 0s - loss: 1674406055.2727 - KL_divergence: 8.4636
182/200 [==========================>...] - ETA: 0s - loss: 1676185168.1758 - KL_divergence: 8.4756
188/200 [===========================>..] - ETA: 0s - loss: 1676461774.2979 - KL_divergence: 8.4803
194/200 [============================>.] - ETA: 0s - loss: 1675912269.1959 - KL_divergence: 8.4730
200/200 [==============================] - 2s 10ms/step - loss: 1675425619.2000 - KL_divergence: 8.4718 - val_loss: 1642133568.0000 - val_KL_divergence: 8.8004
Epoch 12/100

  1/200 [..............................] - ETA: 1s - loss: 1671431424.0000 - KL_divergence: 8.3109
  7/200 [>.............................] - ETA: 1s - loss: 1676607250.2857 - KL_divergence: 8.6573
 13/200 [>.............................] - ETA: 1s - loss: 1671034436.9231 - KL_divergence: 8.7136
 19/200 [=>............................] - ETA: 1s - loss: 1667318447.1579 - KL_divergence: 8.7125
 25/200 [==>...........................] - ETA: 1s - loss: 1670047549.4400 - KL_divergence: 8.7379
 31/200 [===>..........................] - ETA: 1s - loss: 1671930116.1290 - KL_divergence: 8.7993
 37/200 [====>.........................] - ETA: 1s - loss: 1675691308.9730 - KL_divergence: 8.7913
 43/200 [=====>........................] - ETA: 1s - loss: 1671485490.6047 - KL_divergence: 8.8299
 49/200 [======>.......................] - ETA: 1s - loss: 1667864711.8367 - KL_divergence: 8.7978
 55/200 [=======>......................] - ETA: 1s - loss: 1665466349.3818 - KL_divergence: 8.7901
 61/200 [========>.....................] - ETA: 1s - loss: 1662539939.6721 - KL_divergence: 8.7854
 67/200 [=========>....................] - ETA: 1s - loss: 1661319150.8060 - KL_divergence: 8.7924
 73/200 [=========>....................] - ETA: 1s - loss: 1653852950.7945 - KL_divergence: 8.7885
 79/200 [==========>...................] - ETA: 1s - loss: 1649054543.3924 - KL_divergence: 8.8081
 85/200 [===========>..................] - ETA: 1s - loss: 1651404720.1882 - KL_divergence: 8.8100
 91/200 [============>.................] - ETA: 0s - loss: 1650946890.5495 - KL_divergence: 8.8202
 97/200 [=============>................] - ETA: 0s - loss: 1652792264.5773 - KL_divergence: 8.8231
103/200 [==============>...............] - ETA: 0s - loss: 1651574460.8932 - KL_divergence: 8.8314
109/200 [===============>..............] - ETA: 0s - loss: 1650025742.0917 - KL_divergence: 8.8253
115/200 [================>.............] - ETA: 0s - loss: 1651154106.9913 - KL_divergence: 8.8387
121/200 [=================>............] - ETA: 0s - loss: 1652556901.5537 - KL_divergence: 8.8411
127/200 [==================>...........] - ETA: 0s - loss: 1650387892.4094 - KL_divergence: 8.8465
133/200 [==================>...........] - ETA: 0s - loss: 1652715069.5940 - KL_divergence: 8.8366
139/200 [===================>..........] - ETA: 0s - loss: 1652483196.3165 - KL_divergence: 8.8265
145/200 [====================>.........] - ETA: 0s - loss: 1652155383.1724 - KL_divergence: 8.8121
151/200 [=====================>........] - ETA: 0s - loss: 1651723530.1722 - KL_divergence: 8.8133
157/200 [======================>.......] - ETA: 0s - loss: 1650781426.9554 - KL_divergence: 8.8039
163/200 [=======================>......] - ETA: 0s - loss: 1649333111.3620 - KL_divergence: 8.7873
169/200 [========================>.....] - ETA: 0s - loss: 1647886900.2604 - KL_divergence: 8.7912
175/200 [=========================>....] - ETA: 0s - loss: 1648406520.6857 - KL_divergence: 8.8011
182/200 [==========================>...] - ETA: 0s - loss: 1650727604.7473 - KL_divergence: 8.8059
189/200 [===========================>..] - ETA: 0s - loss: 1651099156.3175 - KL_divergence: 8.8112
195/200 [============================>.] - ETA: 0s - loss: 1651712426.6667 - KL_divergence: 8.8079
200/200 [==============================] - 2s 10ms/step - loss: 1651245916.8000 - KL_divergence: 8.8147 - val_loss: 1625926356.4800 - val_KL_divergence: 8.8811
Epoch 13/100

  1/200 [..............................] - ETA: 1s - loss: 1601413120.0000 - KL_divergence: 8.7334
  7/200 [>.............................] - ETA: 1s - loss: 1615941888.0000 - KL_divergence: 8.8414
 13/200 [>.............................] - ETA: 1s - loss: 1618829902.7692 - KL_divergence: 8.7214
 19/200 [=>............................] - ETA: 1s - loss: 1627003897.2632 - KL_divergence: 8.8315
 25/200 [==>...........................] - ETA: 1s - loss: 1645550156.8000 - KL_divergence: 8.9230
 32/200 [===>..........................] - ETA: 1s - loss: 1633280624.0000 - KL_divergence: 8.8654
 39/200 [====>.........................] - ETA: 1s - loss: 1635395764.5128 - KL_divergence: 8.8417
 45/200 [=====>........................] - ETA: 1s - loss: 1639691619.5556 - KL_divergence: 8.8066
 51/200 [======>.......................] - ETA: 1s - loss: 1640487009.8824 - KL_divergence: 8.8144
 57/200 [=======>......................] - ETA: 1s - loss: 1635442818.2456 - KL_divergence: 8.8245
 63/200 [========>.....................] - ETA: 1s - loss: 1633148930.0317 - KL_divergence: 8.8063
 69/200 [=========>....................] - ETA: 1s - loss: 1631077867.5942 - KL_divergence: 8.8117
 75/200 [==========>...................] - ETA: 1s - loss: 1629782056.9600 - KL_divergence: 8.7840
 81/200 [===========>..................] - ETA: 1s - loss: 1631240661.3333 - KL_divergence: 8.7966
 87/200 [============>.................] - ETA: 0s - loss: 1627989158.2529 - KL_divergence: 8.7930
 93/200 [============>.................] - ETA: 0s - loss: 1626848679.9140 - KL_divergence: 8.7980
100/200 [==============>...............] - ETA: 0s - loss: 1628192725.7600 - KL_divergence: 8.7906
106/200 [==============>...............] - ETA: 0s - loss: 1629527110.0377 - KL_divergence: 8.7977
112/200 [===============>..............] - ETA: 0s - loss: 1627553412.5714 - KL_divergence: 8.7923
118/200 [================>.............] - ETA: 0s - loss: 1626922963.5254 - KL_divergence: 8.7914
124/200 [=================>............] - ETA: 0s - loss: 1624881153.0323 - KL_divergence: 8.7905
130/200 [==================>...........] - ETA: 0s - loss: 1623069838.7692 - KL_divergence: 8.7902
136/200 [===================>..........] - ETA: 0s - loss: 1624020153.4118 - KL_divergence: 8.8067
142/200 [====================>.........] - ETA: 0s - loss: 1626317727.5493 - KL_divergence: 8.8074
148/200 [=====================>........] - ETA: 0s - loss: 1626844284.5405 - KL_divergence: 8.8125
154/200 [======================>.......] - ETA: 0s - loss: 1626774854.6494 - KL_divergence: 8.8155
160/200 [=======================>......] - ETA: 0s - loss: 1627372725.6000 - KL_divergence: 8.8098
166/200 [=======================>......] - ETA: 0s - loss: 1625960493.4940 - KL_divergence: 8.8142
172/200 [========================>.....] - ETA: 0s - loss: 1626934162.6047 - KL_divergence: 8.8174
178/200 [=========================>....] - ETA: 0s - loss: 1626999696.5393 - KL_divergence: 8.8100
184/200 [==========================>...] - ETA: 0s - loss: 1626722631.6522 - KL_divergence: 8.8155
190/200 [===========================>..] - ETA: 0s - loss: 1625757072.8421 - KL_divergence: 8.8149
197/200 [============================>.] - ETA: 0s - loss: 1627356401.0558 - KL_divergence: 8.8247
200/200 [==============================] - 2s 10ms/step - loss: 1626723145.6000 - KL_divergence: 8.8236 - val_loss: 1610106270.7200 - val_KL_divergence: 9.1133
Epoch 14/100

  1/200 [..............................] - ETA: 1s - loss: 1636394880.0000 - KL_divergence: 9.7068
  8/200 [>.............................] - ETA: 1s - loss: 1614549584.0000 - KL_divergence: 8.9748
 14/200 [=>............................] - ETA: 1s - loss: 1619408347.4286 - KL_divergence: 8.8298
 21/200 [==>...........................] - ETA: 1s - loss: 1631736124.9524 - KL_divergence: 8.8471
 27/200 [===>..........................] - ETA: 1s - loss: 1620835375.4074 - KL_divergence: 8.8150
 33/200 [===>..........................] - ETA: 1s - loss: 1622821488.4848 - KL_divergence: 8.8795
 40/200 [=====>........................] - ETA: 1s - loss: 1614427824.0000 - KL_divergence: 8.9364
 46/200 [=====>........................] - ETA: 1s - loss: 1619202982.9565 - KL_divergence: 8.9884
 52/200 [======>.......................] - ETA: 1s - loss: 1625753159.3846 - KL_divergence: 9.0208
 58/200 [=======>......................] - ETA: 1s - loss: 1629181616.5517 - KL_divergence: 9.0531
 64/200 [========>.....................] - ETA: 1s - loss: 1627159336.0000 - KL_divergence: 9.0126
 70/200 [=========>....................] - ETA: 1s - loss: 1626358379.8857 - KL_divergence: 9.0074
 76/200 [==========>...................] - ETA: 1s - loss: 1625548826.9474 - KL_divergence: 9.0331
 82/200 [===========>..................] - ETA: 1s - loss: 1627855278.8293 - KL_divergence: 9.0705
 88/200 [============>.................] - ETA: 0s - loss: 1629000538.1818 - KL_divergence: 9.0838
 94/200 [=============>................] - ETA: 0s - loss: 1629216682.2128 - KL_divergence: 9.1040
100/200 [==============>...............] - ETA: 0s - loss: 1633314069.7600 - KL_divergence: 9.1143
106/200 [==============>...............] - ETA: 0s - loss: 1629313990.0377 - KL_divergence: 9.1107
112/200 [===============>..............] - ETA: 0s - loss: 1629634777.1429 - KL_divergence: 9.1218
118/200 [================>.............] - ETA: 0s - loss: 1628304628.0678 - KL_divergence: 9.1228
124/200 [=================>............] - ETA: 0s - loss: 1627874295.7419 - KL_divergence: 9.1252
130/200 [==================>...........] - ETA: 0s - loss: 1625385728.9846 - KL_divergence: 9.1229
136/200 [===================>..........] - ETA: 0s - loss: 1626035185.8824 - KL_divergence: 9.1225
142/200 [====================>.........] - ETA: 0s - loss: 1625549991.6620 - KL_divergence: 9.1270
148/200 [=====================>........] - ETA: 0s - loss: 1626107570.1622 - KL_divergence: 9.1208
154/200 [======================>.......] - ETA: 0s - loss: 1627525676.0519 - KL_divergence: 9.1160
160/200 [=======================>......] - ETA: 0s - loss: 1626172184.8000 - KL_divergence: 9.1062
166/200 [=======================>......] - ETA: 0s - loss: 1624814578.1205 - KL_divergence: 9.1035
172/200 [========================>.....] - ETA: 0s - loss: 1624436215.0698 - KL_divergence: 9.1125
178/200 [=========================>....] - ETA: 0s - loss: 1623856965.0337 - KL_divergence: 9.1142
184/200 [==========================>...] - ETA: 0s - loss: 1624411609.0435 - KL_divergence: 9.1136
190/200 [===========================>..] - ETA: 0s - loss: 1624070090.7789 - KL_divergence: 9.1113
196/200 [============================>.] - ETA: 0s - loss: 1623599595.7551 - KL_divergence: 9.1142
200/200 [==============================] - 2s 10ms/step - loss: 1624523399.0400 - KL_divergence: 9.1190 - val_loss: 1592853953.2800 - val_KL_divergence: 9.2573
Epoch 15/100

  1/200 [..............................] - ETA: 1s - loss: 1549946368.0000 - KL_divergence: 8.9933
  8/200 [>.............................] - ETA: 1s - loss: 1602211760.0000 - KL_divergence: 9.2134
 14/200 [=>............................] - ETA: 1s - loss: 1612586285.7143 - KL_divergence: 9.1934
 20/200 [==>...........................] - ETA: 1s - loss: 1596779539.2000 - KL_divergence: 9.1184
 26/200 [==>...........................] - ETA: 1s - loss: 1601791970.4615 - KL_divergence: 9.0985
 33/200 [===>..........................] - ETA: 1s - loss: 1595834387.3939 - KL_divergence: 9.1425
 39/200 [====>.........................] - ETA: 1s - loss: 1596892658.8718 - KL_divergence: 9.1190
 45/200 [=====>........................] - ETA: 1s - loss: 1596497638.4000 - KL_divergence: 9.1201
 51/200 [======>.......................] - ETA: 1s - loss: 1593944676.3922 - KL_divergence: 9.1158
 57/200 [=======>......................] - ETA: 1s - loss: 1597439674.3860 - KL_divergence: 9.1090
 63/200 [========>.....................] - ETA: 1s - loss: 1597005003.1746 - KL_divergence: 9.1196
 69/200 [=========>....................] - ETA: 1s - loss: 1603754564.6377 - KL_divergence: 9.1138
 75/200 [==========>...................] - ETA: 1s - loss: 1605107607.8933 - KL_divergence: 9.0934
 81/200 [===========>..................] - ETA: 1s - loss: 1607266234.4691 - KL_divergence: 9.0829
 87/200 [============>.................] - ETA: 0s - loss: 1602561001.9310 - KL_divergence: 9.0825
 93/200 [============>.................] - ETA: 0s - loss: 1602480356.4731 - KL_divergence: 9.0787
 99/200 [=============>................] - ETA: 0s - loss: 1602568704.0000 - KL_divergence: 9.0727
105/200 [==============>...............] - ETA: 0s - loss: 1599344240.1524 - KL_divergence: 9.0712
111/200 [===============>..............] - ETA: 0s - loss: 1600586278.0541 - KL_divergence: 9.0768
117/200 [================>.............] - ETA: 0s - loss: 1603510618.8034 - KL_divergence: 9.0799
123/200 [=================>............] - ETA: 0s - loss: 1603419206.7642 - KL_divergence: 9.1116
129/200 [==================>...........] - ETA: 0s - loss: 1602133509.9535 - KL_divergence: 9.1269
135/200 [===================>..........] - ETA: 0s - loss: 1601665011.6741 - KL_divergence: 9.1379
141/200 [====================>.........] - ETA: 0s - loss: 1600959694.9787 - KL_divergence: 9.1527
147/200 [=====================>........] - ETA: 0s - loss: 1602763693.2789 - KL_divergence: 9.1555
153/200 [=====================>........] - ETA: 0s - loss: 1604164081.7778 - KL_divergence: 9.1728
159/200 [======================>.......] - ETA: 0s - loss: 1605360039.4465 - KL_divergence: 9.1794
165/200 [=======================>......] - ETA: 0s - loss: 1604971189.5273 - KL_divergence: 9.1873
171/200 [========================>.....] - ETA: 0s - loss: 1603865157.6140 - KL_divergence: 9.1960
177/200 [=========================>....] - ETA: 0s - loss: 1604102825.9435 - KL_divergence: 9.2042
183/200 [==========================>...] - ETA: 0s - loss: 1603175383.4317 - KL_divergence: 9.2055
189/200 [===========================>..] - ETA: 0s - loss: 1603544799.4921 - KL_divergence: 9.2089
195/200 [============================>.] - ETA: 0s - loss: 1603944925.8667 - KL_divergence: 9.2213
200/200 [==============================] - 2s 10ms/step - loss: 1604470598.4000 - KL_divergence: 9.2174 - val_loss: 1593328405.7600 - val_KL_divergence: 9.1800
Epoch 16/100

  1/200 [..............................] - ETA: 1s - loss: 1503282432.0000 - KL_divergence: 9.1005
  7/200 [>.............................] - ETA: 1s - loss: 1552887204.5714 - KL_divergence: 9.3636
 13/200 [>.............................] - ETA: 1s - loss: 1559027830.1538 - KL_divergence: 9.4378
 20/200 [==>...........................] - ETA: 1s - loss: 1583846054.4000 - KL_divergence: 9.3212
 27/200 [===>..........................] - ETA: 1s - loss: 1584047834.0741 - KL_divergence: 9.3237
 33/200 [===>..........................] - ETA: 1s - loss: 1578022698.6667 - KL_divergence: 9.3095
 39/200 [====>.........................] - ETA: 1s - loss: 1579491813.7436 - KL_divergence: 9.3552
 45/200 [=====>........................] - ETA: 1s - loss: 1581806609.0667 - KL_divergence: 9.2993
 51/200 [======>.......................] - ETA: 1s - loss: 1578199544.4706 - KL_divergence: 9.2841
 57/200 [=======>......................] - ETA: 1s - loss: 1577877495.0175 - KL_divergence: 9.2645
 63/200 [========>.....................] - ETA: 1s - loss: 1582357355.6825 - KL_divergence: 9.2622
 69/200 [=========>....................] - ETA: 1s - loss: 1582421071.7681 - KL_divergence: 9.2923
 75/200 [==========>...................] - ETA: 1s - loss: 1580318163.6267 - KL_divergence: 9.2826
 81/200 [===========>..................] - ETA: 1s - loss: 1580244151.3086 - KL_divergence: 9.2854
 87/200 [============>.................] - ETA: 0s - loss: 1583125053.7931 - KL_divergence: 9.2694
 93/200 [============>.................] - ETA: 0s - loss: 1584775276.7312 - KL_divergence: 9.2738
100/200 [==============>...............] - ETA: 0s - loss: 1585198502.4000 - KL_divergence: 9.2934
106/200 [==============>...............] - ETA: 0s - loss: 1583995830.3396 - KL_divergence: 9.2781
112/200 [===============>..............] - ETA: 0s - loss: 1584269398.8571 - KL_divergence: 9.2600
118/200 [================>.............] - ETA: 0s - loss: 1585547708.7458 - KL_divergence: 9.2730
124/200 [=================>............] - ETA: 0s - loss: 1588068874.3226 - KL_divergence: 9.2959
131/200 [==================>...........] - ETA: 0s - loss: 1588698322.0763 - KL_divergence: 9.3123
137/200 [===================>..........] - ETA: 0s - loss: 1588282090.5109 - KL_divergence: 9.3231
143/200 [====================>.........] - ETA: 0s - loss: 1589101985.1189 - KL_divergence: 9.3271
149/200 [=====================>........] - ETA: 0s - loss: 1590650303.5705 - KL_divergence: 9.3454
155/200 [======================>.......] - ETA: 0s - loss: 1589958674.9935 - KL_divergence: 9.3504
161/200 [=======================>......] - ETA: 0s - loss: 1591341670.5590 - KL_divergence: 9.3641
168/200 [========================>.....] - ETA: 0s - loss: 1591691660.1905 - KL_divergence: 9.3669
174/200 [=========================>....] - ETA: 0s - loss: 1593494925.2414 - KL_divergence: 9.3626
180/200 [==========================>...] - ETA: 0s - loss: 1595694255.6444 - KL_divergence: 9.3621
187/200 [===========================>..] - ETA: 0s - loss: 1597492874.2674 - KL_divergence: 9.3605
193/200 [===========================>..] - ETA: 0s - loss: 1599546700.2694 - KL_divergence: 9.3731
199/200 [============================>.] - ETA: 0s - loss: 1597585154.5729 - KL_divergence: 9.3646
200/200 [==============================] - 2s 10ms/step - loss: 1597199167.3600 - KL_divergence: 9.3643 - val_loss: 1582328371.2000 - val_KL_divergence: 9.4403
Epoch 17/100

  1/200 [..............................] - ETA: 1s - loss: 1618758016.0000 - KL_divergence: 9.6519
  7/200 [>.............................] - ETA: 1s - loss: 1601630939.4286 - KL_divergence: 9.4339
 13/200 [>.............................] - ETA: 1s - loss: 1569431266.4615 - KL_divergence: 9.3395
 19/200 [=>............................] - ETA: 1s - loss: 1583240468.2105 - KL_divergence: 9.3754
 25/200 [==>...........................] - ETA: 1s - loss: 1590004085.7600 - KL_divergence: 9.3379
 31/200 [===>..........................] - ETA: 1s - loss: 1586346504.2581 - KL_divergence: 9.3200
 37/200 [====>.........................] - ETA: 1s - loss: 1591262156.1081 - KL_divergence: 9.3545
 43/200 [=====>........................] - ETA: 1s - loss: 1584176532.8372 - KL_divergence: 9.3765
 49/200 [======>.......................] - ETA: 1s - loss: 1596017138.9388 - KL_divergence: 9.3653
 55/200 [=======>......................] - ETA: 1s - loss: 1585926732.8000 - KL_divergence: 9.3379
 61/200 [========>.....................] - ETA: 1s - loss: 1587630644.4590 - KL_divergence: 9.3570
 67/200 [=========>....................] - ETA: 1s - loss: 1584351577.7910 - KL_divergence: 9.3797
 73/200 [=========>....................] - ETA: 1s - loss: 1584512897.7534 - KL_divergence: 9.4205
 79/200 [==========>...................] - ETA: 1s - loss: 1581192750.9873 - KL_divergence: 9.4323
 85/200 [===========>..................] - ETA: 1s - loss: 1577216751.4353 - KL_divergence: 9.4324
 91/200 [============>.................] - ETA: 0s - loss: 1576295990.8571 - KL_divergence: 9.4592
 98/200 [=============>................] - ETA: 0s - loss: 1573819749.8776 - KL_divergence: 9.4866
105/200 [==============>...............] - ETA: 0s - loss: 1572722778.2095 - KL_divergence: 9.4853
112/200 [===============>..............] - ETA: 0s - loss: 1572954452.5714 - KL_divergence: 9.4989
119/200 [================>.............] - ETA: 0s - loss: 1575985605.9160 - KL_divergence: 9.5091
125/200 [=================>............] - ETA: 0s - loss: 1575844013.0560 - KL_divergence: 9.5201
131/200 [==================>...........] - ETA: 0s - loss: 1573765362.3206 - KL_divergence: 9.5113
137/200 [===================>..........] - ETA: 0s - loss: 1572908062.8321 - KL_divergence: 9.5095
144/200 [====================>.........] - ETA: 0s - loss: 1571696873.7778 - KL_divergence: 9.5125
150/200 [=====================>........] - ETA: 0s - loss: 1571834149.5467 - KL_divergence: 9.5049
156/200 [======================>.......] - ETA: 0s - loss: 1572042451.6923 - KL_divergence: 9.5144
162/200 [=======================>......] - ETA: 0s - loss: 1571100666.4691 - KL_divergence: 9.5209
169/200 [========================>.....] - ETA: 0s - loss: 1572498905.3728 - KL_divergence: 9.5218
176/200 [=========================>....] - ETA: 0s - loss: 1571933426.1818 - KL_divergence: 9.5225
182/200 [==========================>...] - ETA: 0s - loss: 1570585272.9670 - KL_divergence: 9.5274
187/200 [===========================>..] - ETA: 0s - loss: 1570747218.8235 - KL_divergence: 9.5304
193/200 [===========================>..] - ETA: 0s - loss: 1570411204.3109 - KL_divergence: 9.5377
199/200 [============================>.] - ETA: 0s - loss: 1570951224.6030 - KL_divergence: 9.5351
200/200 [==============================] - 2s 10ms/step - loss: 1571439358.7200 - KL_divergence: 9.5352 - val_loss: 1573419609.6000 - val_KL_divergence: 9.8405
Epoch 18/100

  1/200 [..............................] - ETA: 1s - loss: 1572157056.0000 - KL_divergence: 9.8552
  7/200 [>.............................] - ETA: 1s - loss: 1550653238.8571 - KL_divergence: 9.4576
 13/200 [>.............................] - ETA: 1s - loss: 1555994929.2308 - KL_divergence: 9.5924
 19/200 [=>............................] - ETA: 1s - loss: 1558963132.6316 - KL_divergence: 9.5576
 25/200 [==>...........................] - ETA: 1s - loss: 1567809914.8800 - KL_divergence: 9.6012
 31/200 [===>..........................] - ETA: 1s - loss: 1560961292.3871 - KL_divergence: 9.5319
 37/200 [====>.........................] - ETA: 1s - loss: 1557775979.2432 - KL_divergence: 9.5068
 43/200 [=====>........................] - ETA: 1s - loss: 1557388046.8837 - KL_divergence: 9.5213
 49/200 [======>.......................] - ETA: 1s - loss: 1556362119.8367 - KL_divergence: 9.5283
 55/200 [=======>......................] - ETA: 1s - loss: 1555858639.1273 - KL_divergence: 9.5536
 61/200 [========>.....................] - ETA: 1s - loss: 1558746588.3279 - KL_divergence: 9.5468
 67/200 [=========>....................] - ETA: 1s - loss: 1558727376.2388 - KL_divergence: 9.5386
 73/200 [=========>....................] - ETA: 1s - loss: 1557574242.1918 - KL_divergence: 9.5339
 79/200 [==========>...................] - ETA: 1s - loss: 1560826551.0886 - KL_divergence: 9.5559
 85/200 [===========>..................] - ETA: 1s - loss: 1563400082.0706 - KL_divergence: 9.5681
 91/200 [============>.................] - ETA: 0s - loss: 1563992670.2418 - KL_divergence: 9.5607
 97/200 [=============>................] - ETA: 0s - loss: 1563172559.1753 - KL_divergence: 9.5672
103/200 [==============>...............] - ETA: 0s - loss: 1563954731.4951 - KL_divergence: 9.5665
109/200 [===============>..............] - ETA: 0s - loss: 1563653791.7064 - KL_divergence: 9.5731
115/200 [================>.............] - ETA: 0s - loss: 1562997847.9304 - KL_divergence: 9.5670
122/200 [=================>............] - ETA: 0s - loss: 1562551631.7377 - KL_divergence: 9.5572
129/200 [==================>...........] - ETA: 0s - loss: 1564673613.3953 - KL_divergence: 9.5587
135/200 [===================>..........] - ETA: 0s - loss: 1563608156.9185 - KL_divergence: 9.5579
141/200 [====================>.........] - ETA: 0s - loss: 1563824579.1773 - KL_divergence: 9.5547
148/200 [=====================>........] - ETA: 0s - loss: 1562107233.7297 - KL_divergence: 9.5622
155/200 [======================>.......] - ETA: 0s - loss: 1563976765.1097 - KL_divergence: 9.5645
161/200 [=======================>......] - ETA: 0s - loss: 1563055509.4658 - KL_divergence: 9.5635
167/200 [========================>.....] - ETA: 0s - loss: 1564626635.1138 - KL_divergence: 9.5791
173/200 [========================>.....] - ETA: 0s - loss: 1563783532.7630 - KL_divergence: 9.5869
179/200 [=========================>....] - ETA: 0s - loss: 1564705084.0670 - KL_divergence: 9.5851
185/200 [==========================>...] - ETA: 0s - loss: 1565082687.6541 - KL_divergence: 9.5877
191/200 [===========================>..] - ETA: 0s - loss: 1566006740.4398 - KL_divergence: 9.5903
197/200 [============================>.] - ETA: 0s - loss: 1564699033.3401 - KL_divergence: 9.5987
200/200 [==============================] - 2s 10ms/step - loss: 1565162584.9600 - KL_divergence: 9.6034 - val_loss: 1552276561.9200 - val_KL_divergence: 9.8344
Epoch 19/100

  1/200 [..............................] - ETA: 1s - loss: 1539826304.0000 - KL_divergence: 9.9124
  7/200 [>.............................] - ETA: 1s - loss: 1578260864.0000 - KL_divergence: 9.7268
 14/200 [=>............................] - ETA: 1s - loss: 1565749549.7143 - KL_divergence: 9.7864
 21/200 [==>...........................] - ETA: 1s - loss: 1565743920.7619 - KL_divergence: 9.8264
 27/200 [===>..........................] - ETA: 1s - loss: 1572050076.4444 - KL_divergence: 9.8293
 34/200 [====>.........................] - ETA: 1s - loss: 1559335717.6471 - KL_divergence: 9.7619
 40/200 [=====>........................] - ETA: 1s - loss: 1557985923.2000 - KL_divergence: 9.7438
 46/200 [=====>........................] - ETA: 1s - loss: 1556569939.4783 - KL_divergence: 9.7391
 52/200 [======>.......................] - ETA: 1s - loss: 1553631630.7692 - KL_divergence: 9.7297
 58/200 [=======>......................] - ETA: 1s - loss: 1559314100.9655 - KL_divergence: 9.6939
 64/200 [========>.....................] - ETA: 1s - loss: 1563485644.0000 - KL_divergence: 9.6812
 70/200 [=========>....................] - ETA: 1s - loss: 1564737119.0857 - KL_divergence: 9.6880
 76/200 [==========>...................] - ETA: 1s - loss: 1565247865.2632 - KL_divergence: 9.6938
 82/200 [===========>..................] - ETA: 1s - loss: 1564521879.4146 - KL_divergence: 9.6897
 88/200 [============>.................] - ETA: 0s - loss: 1563923090.9091 - KL_divergence: 9.6871
 94/200 [=============>................] - ETA: 0s - loss: 1561594248.1702 - KL_divergence: 9.7043
100/200 [==============>...............] - ETA: 0s - loss: 1562369287.6800 - KL_divergence: 9.6754
106/200 [==============>...............] - ETA: 0s - loss: 1560997888.0000 - KL_divergence: 9.6869
112/200 [===============>..............] - ETA: 0s - loss: 1558114634.2857 - KL_divergence: 9.6925
118/200 [================>.............] - ETA: 0s - loss: 1558128132.3390 - KL_divergence: 9.6981
124/200 [=================>............] - ETA: 0s - loss: 1558199226.8387 - KL_divergence: 9.7010
130/200 [==================>...........] - ETA: 0s - loss: 1556403510.1538 - KL_divergence: 9.7154
136/200 [===================>..........] - ETA: 0s - loss: 1555455241.4118 - KL_divergence: 9.7138
142/200 [====================>.........] - ETA: 0s - loss: 1554636938.8169 - KL_divergence: 9.6922
148/200 [=====================>........] - ETA: 0s - loss: 1554130885.1892 - KL_divergence: 9.6790
154/200 [======================>.......] - ETA: 0s - loss: 1552270453.1948 - KL_divergence: 9.6956
160/200 [=======================>......] - ETA: 0s - loss: 1549895148.8000 - KL_divergence: 9.6997
166/200 [=======================>......] - ETA: 0s - loss: 1550357605.0120 - KL_divergence: 9.7032
172/200 [========================>.....] - ETA: 0s - loss: 1550141371.5349 - KL_divergence: 9.7052
178/200 [=========================>....] - ETA: 0s - loss: 1549805695.2809 - KL_divergence: 9.7079
184/200 [==========================>...] - ETA: 0s - loss: 1549207010.0870 - KL_divergence: 9.7081
190/200 [===========================>..] - ETA: 0s - loss: 1549233237.5579 - KL_divergence: 9.7030
196/200 [============================>.] - ETA: 0s - loss: 1547850923.1020 - KL_divergence: 9.6974
200/200 [==============================] - 2s 10ms/step - loss: 1548268768.6400 - KL_divergence: 9.7003 - val_loss: 1538143688.9600 - val_KL_divergence: 9.8861
Epoch 20/100

  1/200 [..............................] - ETA: 1s - loss: 1449662848.0000 - KL_divergence: 10.0814
  7/200 [>.............................] - ETA: 1s - loss: 1548633197.7143 - KL_divergence: 9.6369 
 14/200 [=>............................] - ETA: 1s - loss: 1580894756.5714 - KL_divergence: 9.5528
 20/200 [==>...........................] - ETA: 1s - loss: 1573622560.0000 - KL_divergence: 9.5939
 26/200 [==>...........................] - ETA: 1s - loss: 1567717430.1538 - KL_divergence: 9.6068
 32/200 [===>..........................] - ETA: 1s - loss: 1567807120.0000 - KL_divergence: 9.6033
 38/200 [====>.........................] - ETA: 1s - loss: 1561733517.4737 - KL_divergence: 9.5847
 44/200 [=====>........................] - ETA: 1s - loss: 1563752125.0909 - KL_divergence: 9.5825
 50/200 [======>.......................] - ETA: 1s - loss: 1557138432.0000 - KL_divergence: 9.5878
 56/200 [=======>......................] - ETA: 1s - loss: 1558918566.8571 - KL_divergence: 9.6486
 62/200 [========>.....................] - ETA: 1s - loss: 1554890564.1290 - KL_divergence: 9.6762
 68/200 [=========>....................] - ETA: 1s - loss: 1554736188.2353 - KL_divergence: 9.7201
 74/200 [==========>...................] - ETA: 1s - loss: 1553857985.7297 - KL_divergence: 9.7093
 80/200 [===========>..................] - ETA: 1s - loss: 1553825584.0000 - KL_divergence: 9.7045
 86/200 [===========>..................] - ETA: 1s - loss: 1549735537.1163 - KL_divergence: 9.7194
 92/200 [============>.................] - ETA: 1s - loss: 1551724107.1304 - KL_divergence: 9.6986
 98/200 [=============>................] - ETA: 0s - loss: 1552327621.2245 - KL_divergence: 9.6871
104/200 [==============>...............] - ETA: 0s - loss: 1551661745.2308 - KL_divergence: 9.6787
110/200 [===============>..............] - ETA: 0s - loss: 1553204462.5455 - KL_divergence: 9.6684
116/200 [================>.............] - ETA: 0s - loss: 1552184240.5517 - KL_divergence: 9.6576
122/200 [=================>............] - ETA: 0s - loss: 1552922860.0656 - KL_divergence: 9.6556
128/200 [==================>...........] - ETA: 0s - loss: 1552343653.0000 - KL_divergence: 9.6463
134/200 [===================>..........] - ETA: 0s - loss: 1553256202.5075 - KL_divergence: 9.6529
140/200 [====================>.........] - ETA: 0s - loss: 1552005900.8000 - KL_divergence: 9.6717
146/200 [====================>.........] - ETA: 0s - loss: 1551915434.0822 - KL_divergence: 9.6720
152/200 [=====================>........] - ETA: 0s - loss: 1549265930.1053 - KL_divergence: 9.6645
159/200 [======================>.......] - ETA: 0s - loss: 1547637252.0252 - KL_divergence: 9.6611
165/200 [=======================>......] - ETA: 0s - loss: 1548375120.6788 - KL_divergence: 9.6663
171/200 [========================>.....] - ETA: 0s - loss: 1546657097.3567 - KL_divergence: 9.6587
177/200 [=========================>....] - ETA: 0s - loss: 1547127947.5706 - KL_divergence: 9.6608
183/200 [==========================>...] - ETA: 0s - loss: 1547318695.8689 - KL_divergence: 9.6547
189/200 [===========================>..] - ETA: 0s - loss: 1547230332.6138 - KL_divergence: 9.6529
195/200 [============================>.] - ETA: 0s - loss: 1547070168.6154 - KL_divergence: 9.6448
200/200 [==============================] - 2s 10ms/step - loss: 1547290074.2400 - KL_divergence: 9.6509 - val_loss: 1526129187.8400 - val_KL_divergence: 9.9918
Epoch 21/100

  1/200 [..............................] - ETA: 1s - loss: 1493277056.0000 - KL_divergence: 9.4415
  7/200 [>.............................] - ETA: 1s - loss: 1547024621.7143 - KL_divergence: 9.7218
 13/200 [>.............................] - ETA: 1s - loss: 1557781080.6154 - KL_divergence: 9.7260
 19/200 [=>............................] - ETA: 1s - loss: 1569426162.5263 - KL_divergence: 9.6839
 26/200 [==>...........................] - ETA: 1s - loss: 1568369600.0000 - KL_divergence: 9.6828
 32/200 [===>..........................] - ETA: 1s - loss: 1568249732.0000 - KL_divergence: 9.6000
 38/200 [====>.........................] - ETA: 1s - loss: 1560977633.6842 - KL_divergence: 9.5698
 44/200 [=====>........................] - ETA: 1s - loss: 1549877605.8182 - KL_divergence: 9.5719
 50/200 [======>.......................] - ETA: 1s - loss: 1549170841.6000 - KL_divergence: 9.6007
 56/200 [=======>......................] - ETA: 1s - loss: 1548211867.4286 - KL_divergence: 9.6312
 62/200 [========>.....................] - ETA: 1s - loss: 1547609156.1290 - KL_divergence: 9.6371
 68/200 [=========>....................] - ETA: 1s - loss: 1544247811.7647 - KL_divergence: 9.6148
 75/200 [==========>...................] - ETA: 1s - loss: 1544733240.3200 - KL_divergence: 9.6224
 81/200 [===========>..................] - ETA: 1s - loss: 1544488163.5556 - KL_divergence: 9.6017
 87/200 [============>.................] - ETA: 0s - loss: 1540994646.8046 - KL_divergence: 9.6056
 93/200 [============>.................] - ETA: 0s - loss: 1541945644.0430 - KL_divergence: 9.6028
100/200 [==============>...............] - ETA: 0s - loss: 1539318792.9600 - KL_divergence: 9.6088
106/200 [==============>...............] - ETA: 0s - loss: 1538194084.2264 - KL_divergence: 9.6421
112/200 [===============>..............] - ETA: 0s - loss: 1538155442.2857 - KL_divergence: 9.6553
118/200 [================>.............] - ETA: 0s - loss: 1536141170.9831 - KL_divergence: 9.6502
124/200 [=================>............] - ETA: 0s - loss: 1535834414.4516 - KL_divergence: 9.6489
130/200 [==================>...........] - ETA: 0s - loss: 1535215701.6615 - KL_divergence: 9.6442
136/200 [===================>..........] - ETA: 0s - loss: 1536240386.8235 - KL_divergence: 9.6486
142/200 [====================>.........] - ETA: 0s - loss: 1534445865.4648 - KL_divergence: 9.6647
148/200 [=====================>........] - ETA: 0s - loss: 1533706675.8919 - KL_divergence: 9.6644
155/200 [======================>.......] - ETA: 0s - loss: 1534456993.0323 - KL_divergence: 9.6726
162/200 [=======================>......] - ETA: 0s - loss: 1534239588.3457 - KL_divergence: 9.6775
168/200 [========================>.....] - ETA: 0s - loss: 1534681940.5714 - KL_divergence: 9.6839
175/200 [=========================>....] - ETA: 0s - loss: 1535168648.0457 - KL_divergence: 9.6796
181/200 [==========================>...] - ETA: 0s - loss: 1535693802.0773 - KL_divergence: 9.6868
187/200 [===========================>..] - ETA: 0s - loss: 1535670020.7914 - KL_divergence: 9.6887
193/200 [===========================>..] - ETA: 0s - loss: 1534624633.3679 - KL_divergence: 9.6901
199/200 [============================>.] - ETA: 0s - loss: 1534192187.8191 - KL_divergence: 9.6985
200/200 [==============================] - 2s 10ms/step - loss: 1534620455.6800 - KL_divergence: 9.6957 - val_loss: 1538727582.7200 - val_KL_divergence: 9.7214
Epoch 22/100

  1/200 [..............................] - ETA: 1s - loss: 1576689152.0000 - KL_divergence: 9.5035
  7/200 [>.............................] - ETA: 1s - loss: 1545306002.2857 - KL_divergence: 9.6019
 13/200 [>.............................] - ETA: 1s - loss: 1537899126.1538 - KL_divergence: 9.6293
 19/200 [=>............................] - ETA: 1s - loss: 1541812055.5789 - KL_divergence: 9.6144
 25/200 [==>...........................] - ETA: 1s - loss: 1530418467.8400 - KL_divergence: 9.6411
 31/200 [===>..........................] - ETA: 1s - loss: 1526315371.3548 - KL_divergence: 9.6752
 37/200 [====>.........................] - ETA: 1s - loss: 1532009240.2162 - KL_divergence: 9.7816
 43/200 [=====>........................] - ETA: 1s - loss: 1531811664.3721 - KL_divergence: 9.7846
 49/200 [======>.......................] - ETA: 1s - loss: 1524417980.0816 - KL_divergence: 9.8273
 55/200 [=======>......................] - ETA: 1s - loss: 1521853274.7636 - KL_divergence: 9.8024
 61/200 [========>.....................] - ETA: 1s - loss: 1521818540.0656 - KL_divergence: 9.7932
 67/200 [=========>....................] - ETA: 1s - loss: 1521982303.5224 - KL_divergence: 9.7956
 73/200 [=========>....................] - ETA: 1s - loss: 1523100195.0685 - KL_divergence: 9.7659
 79/200 [==========>...................] - ETA: 1s - loss: 1524236665.5190 - KL_divergence: 9.7605
 85/200 [===========>..................] - ETA: 1s - loss: 1523261083.1059 - KL_divergence: 9.7743
 91/200 [============>.................] - ETA: 0s - loss: 1522128862.2418 - KL_divergence: 9.7678
 97/200 [=============>................] - ETA: 0s - loss: 1521892249.0722 - KL_divergence: 9.7560
104/200 [==============>...............] - ETA: 0s - loss: 1523052793.8462 - KL_divergence: 9.7401
110/200 [===============>..............] - ETA: 0s - loss: 1524649936.2909 - KL_divergence: 9.7275
116/200 [================>.............] - ETA: 0s - loss: 1522938560.0000 - KL_divergence: 9.7264
122/200 [=================>............] - ETA: 0s - loss: 1522553738.4918 - KL_divergence: 9.7286
128/200 [==================>...........] - ETA: 0s - loss: 1525578454.0000 - KL_divergence: 9.7295
134/200 [===================>..........] - ETA: 0s - loss: 1524834051.8209 - KL_divergence: 9.7577
140/200 [====================>.........] - ETA: 0s - loss: 1525268704.0000 - KL_divergence: 9.7533
146/200 [====================>.........] - ETA: 0s - loss: 1525929388.7123 - KL_divergence: 9.7565
153/200 [=====================>........] - ETA: 0s - loss: 1525458201.0980 - KL_divergence: 9.7434
160/200 [=======================>......] - ETA: 0s - loss: 1527787291.2000 - KL_divergence: 9.7498
166/200 [=======================>......] - ETA: 0s - loss: 1528717850.2169 - KL_divergence: 9.7533
172/200 [========================>.....] - ETA: 0s - loss: 1527638748.2791 - KL_divergence: 9.7459
178/200 [=========================>....] - ETA: 0s - loss: 1526296017.9775 - KL_divergence: 9.7385
184/200 [==========================>...] - ETA: 0s - loss: 1526931698.7826 - KL_divergence: 9.7350
190/200 [===========================>..] - ETA: 0s - loss: 1526691117.8105 - KL_divergence: 9.7333
196/200 [============================>.] - ETA: 0s - loss: 1526920248.8163 - KL_divergence: 9.7356
200/200 [==============================] - 2s 10ms/step - loss: 1526901459.2000 - KL_divergence: 9.7391 - val_loss: 1545539927.0400 - val_KL_divergence: 9.6368
Epoch 23/100

  1/200 [..............................] - ETA: 1s - loss: 1499140608.0000 - KL_divergence: 9.1197
  7/200 [>.............................] - ETA: 1s - loss: 1530554660.5714 - KL_divergence: 9.4155
 13/200 [>.............................] - ETA: 1s - loss: 1539172745.8462 - KL_divergence: 9.5860
 19/200 [=>............................] - ETA: 1s - loss: 1525970735.1579 - KL_divergence: 9.6427
 25/200 [==>...........................] - ETA: 1s - loss: 1530822154.2400 - KL_divergence: 9.7047
 31/200 [===>..........................] - ETA: 1s - loss: 1526947823.4839 - KL_divergence: 9.6394
 37/200 [====>.........................] - ETA: 1s - loss: 1510009091.4595 - KL_divergence: 9.6211
 43/200 [=====>........................] - ETA: 1s - loss: 1505405949.0233 - KL_divergence: 9.6586
 49/200 [======>.......................] - ETA: 1s - loss: 1507750036.8980 - KL_divergence: 9.6488
 55/200 [=======>......................] - ETA: 1s - loss: 1511102636.2182 - KL_divergence: 9.6568
 61/200 [========>.....................] - ETA: 1s - loss: 1508780273.3115 - KL_divergence: 9.6889
 67/200 [=========>....................] - ETA: 1s - loss: 1504118377.0746 - KL_divergence: 9.6814
 73/200 [=========>....................] - ETA: 1s - loss: 1503313450.0822 - KL_divergence: 9.6867
 80/200 [===========>..................] - ETA: 1s - loss: 1506352796.8000 - KL_divergence: 9.7085
 86/200 [===========>..................] - ETA: 1s - loss: 1509150132.0930 - KL_divergence: 9.7305
 93/200 [============>.................] - ETA: 0s - loss: 1514086413.7634 - KL_divergence: 9.7584
 99/200 [=============>................] - ETA: 0s - loss: 1513619631.8384 - KL_divergence: 9.7611
105/200 [==============>...............] - ETA: 0s - loss: 1513606115.9619 - KL_divergence: 9.7618
111/200 [===============>..............] - ETA: 0s - loss: 1510835989.9099 - KL_divergence: 9.7470
117/200 [================>.............] - ETA: 0s - loss: 1511801040.9573 - KL_divergence: 9.7481
123/200 [=================>............] - ETA: 0s - loss: 1511224235.7073 - KL_divergence: 9.7516
129/200 [==================>...........] - ETA: 0s - loss: 1510152813.1473 - KL_divergence: 9.7497
135/200 [===================>..........] - ETA: 0s - loss: 1511260999.1111 - KL_divergence: 9.7489
141/200 [====================>.........] - ETA: 0s - loss: 1512822678.6950 - KL_divergence: 9.7564
147/200 [=====================>........] - ETA: 0s - loss: 1510876618.8844 - KL_divergence: 9.7535
153/200 [=====================>........] - ETA: 0s - loss: 1513018086.9020 - KL_divergence: 9.7621
159/200 [======================>.......] - ETA: 0s - loss: 1512768199.6478 - KL_divergence: 9.7548
165/200 [=======================>......] - ETA: 0s - loss: 1514361312.9697 - KL_divergence: 9.7486
171/200 [========================>.....] - ETA: 0s - loss: 1514160992.5614 - KL_divergence: 9.7529
177/200 [=========================>....] - ETA: 0s - loss: 1514701019.8418 - KL_divergence: 9.7442
183/200 [==========================>...] - ETA: 0s - loss: 1515312673.5738 - KL_divergence: 9.7499
189/200 [===========================>..] - ETA: 0s - loss: 1515633139.8095 - KL_divergence: 9.7504
195/200 [============================>.] - ETA: 0s - loss: 1514478440.3692 - KL_divergence: 9.7424
200/200 [==============================] - 2s 10ms/step - loss: 1513650979.2000 - KL_divergence: 9.7491 - val_loss: 1513127253.7600 - val_KL_divergence: 9.8130
Epoch 24/100

  1/200 [..............................] - ETA: 1s - loss: 1461386880.0000 - KL_divergence: 9.4938
  7/200 [>.............................] - ETA: 1s - loss: 1483877705.1429 - KL_divergence: 9.7699
 13/200 [>.............................] - ETA: 1s - loss: 1478886833.2308 - KL_divergence: 9.7197
 19/200 [=>............................] - ETA: 1s - loss: 1512260911.1579 - KL_divergence: 9.7282
 25/200 [==>...........................] - ETA: 1s - loss: 1524401361.9200 - KL_divergence: 9.7490
 31/200 [===>..........................] - ETA: 1s - loss: 1516503386.8387 - KL_divergence: 9.6991
 37/200 [====>.........................] - ETA: 1s - loss: 1513530070.4865 - KL_divergence: 9.7087
 43/200 [=====>........................] - ETA: 1s - loss: 1508858540.6512 - KL_divergence: 9.7335
 49/200 [======>.......................] - ETA: 1s - loss: 1505215681.3061 - KL_divergence: 9.7233
 55/200 [=======>......................] - ETA: 1s - loss: 1505002640.2909 - KL_divergence: 9.7149
 61/200 [========>.....................] - ETA: 1s - loss: 1506424452.1967 - KL_divergence: 9.7158
 67/200 [=========>....................] - ETA: 1s - loss: 1504517509.7313 - KL_divergence: 9.7520
 73/200 [=========>....................] - ETA: 1s - loss: 1505170112.8767 - KL_divergence: 9.7487
 79/200 [==========>...................] - ETA: 1s - loss: 1504048481.2152 - KL_divergence: 9.7913
 85/200 [===========>..................] - ETA: 1s - loss: 1503407591.9059 - KL_divergence: 9.7975
 91/200 [============>.................] - ETA: 0s - loss: 1503864327.0330 - KL_divergence: 9.8007
 97/200 [=============>................] - ETA: 0s - loss: 1503653816.7423 - KL_divergence: 9.8054
103/200 [==============>...............] - ETA: 0s - loss: 1501330085.2816 - KL_divergence: 9.8261
109/200 [===============>..............] - ETA: 0s - loss: 1501493158.7523 - KL_divergence: 9.8373
115/200 [================>.............] - ETA: 0s - loss: 1504618010.7130 - KL_divergence: 9.8437
121/200 [=================>............] - ETA: 0s - loss: 1505392497.1901 - KL_divergence: 9.8457
127/200 [==================>...........] - ETA: 0s - loss: 1503777294.1102 - KL_divergence: 9.8669
133/200 [==================>...........] - ETA: 0s - loss: 1504429405.3534 - KL_divergence: 9.8688
139/200 [===================>..........] - ETA: 0s - loss: 1505136285.4676 - KL_divergence: 9.8674
145/200 [====================>.........] - ETA: 0s - loss: 1508325660.2483 - KL_divergence: 9.8705
151/200 [=====================>........] - ETA: 0s - loss: 1506533275.1258 - KL_divergence: 9.8761
157/200 [======================>.......] - ETA: 0s - loss: 1506142573.2484 - KL_divergence: 9.8823
163/200 [=======================>......] - ETA: 0s - loss: 1505972376.3436 - KL_divergence: 9.8816
170/200 [========================>.....] - ETA: 0s - loss: 1505398080.0000 - KL_divergence: 9.8917
177/200 [=========================>....] - ETA: 0s - loss: 1504610737.8983 - KL_divergence: 9.9060
183/200 [==========================>...] - ETA: 0s - loss: 1504906102.9071 - KL_divergence: 9.9052
190/200 [===========================>..] - ETA: 0s - loss: 1504879069.6421 - KL_divergence: 9.9123
197/200 [============================>.] - ETA: 0s - loss: 1504472175.7563 - KL_divergence: 9.9053
200/200 [==============================] - 2s 10ms/step - loss: 1504831605.1200 - KL_divergence: 9.9163 - val_loss: 1514091928.3200 - val_KL_divergence: 10.1508
Epoch 25/100

  1/200 [..............................] - ETA: 1s - loss: 1581487616.0000 - KL_divergence: 9.8546
  7/200 [>.............................] - ETA: 1s - loss: 1499970706.2857 - KL_divergence: 10.3603
 13/200 [>.............................] - ETA: 1s - loss: 1498621627.0769 - KL_divergence: 10.1429
 19/200 [=>............................] - ETA: 1s - loss: 1485380345.2632 - KL_divergence: 10.0022
 25/200 [==>...........................] - ETA: 1s - loss: 1498035404.8000 - KL_divergence: 10.0208
 31/200 [===>..........................] - ETA: 1s - loss: 1499414160.5161 - KL_divergence: 10.0260
 38/200 [====>.........................] - ETA: 1s - loss: 1497942464.0000 - KL_divergence: 10.0653
 45/200 [=====>........................] - ETA: 1s - loss: 1495291878.4000 - KL_divergence: 10.0854
 52/200 [======>.......................] - ETA: 1s - loss: 1499248088.6154 - KL_divergence: 10.0865
 58/200 [=======>......................] - ETA: 1s - loss: 1495719563.0345 - KL_divergence: 10.0892
 64/200 [========>.....................] - ETA: 1s - loss: 1491076906.0000 - KL_divergence: 10.0921
 70/200 [=========>....................] - ETA: 1s - loss: 1490333498.5143 - KL_divergence: 10.1026
 76/200 [==========>...................] - ETA: 1s - loss: 1489719951.1579 - KL_divergence: 10.0834
 82/200 [===========>..................] - ETA: 1s - loss: 1490807372.4878 - KL_divergence: 10.0852
 88/200 [============>.................] - ETA: 0s - loss: 1492076126.5455 - KL_divergence: 10.0982
 94/200 [=============>................] - ETA: 0s - loss: 1493259955.7447 - KL_divergence: 10.0978
100/200 [==============>...............] - ETA: 0s - loss: 1492022823.6800 - KL_divergence: 10.1146
106/200 [==============>...............] - ETA: 0s - loss: 1495745313.8113 - KL_divergence: 10.1209
113/200 [===============>..............] - ETA: 0s - loss: 1496552626.9735 - KL_divergence: 10.1347
120/200 [=================>............] - ETA: 0s - loss: 1496846461.8667 - KL_divergence: 10.1202
126/200 [=================>............] - ETA: 0s - loss: 1498694873.3968 - KL_divergence: 10.1057
132/200 [==================>...........] - ETA: 0s - loss: 1497751215.5152 - KL_divergence: 10.0841
139/200 [===================>..........] - ETA: 0s - loss: 1498785948.5468 - KL_divergence: 10.0863
146/200 [====================>.........] - ETA: 0s - loss: 1496519402.0822 - KL_divergence: 10.0892
153/200 [=====================>........] - ETA: 0s - loss: 1496110160.3137 - KL_divergence: 10.0898
160/200 [=======================>......] - ETA: 0s - loss: 1496376798.4000 - KL_divergence: 10.0796
167/200 [========================>.....] - ETA: 0s - loss: 1497350577.8204 - KL_divergence: 10.0877
173/200 [========================>.....] - ETA: 0s - loss: 1497257014.0116 - KL_divergence: 10.0773
179/200 [=========================>....] - ETA: 0s - loss: 1497702316.3352 - KL_divergence: 10.0845
186/200 [==========================>...] - ETA: 0s - loss: 1498417959.2258 - KL_divergence: 10.0979
192/200 [===========================>..] - ETA: 0s - loss: 1498123954.6667 - KL_divergence: 10.0903
198/200 [============================>.] - ETA: 0s - loss: 1498771630.5455 - KL_divergence: 10.0946
200/200 [==============================] - 2s 9ms/step - loss: 1498372490.2400 - KL_divergence: 10.0896 - val_loss: 1488047104.0000 - val_KL_divergence: 10.3801
Epoch 26/100

  1/200 [..............................] - ETA: 1s - loss: 1420920064.0000 - KL_divergence: 10.4034
  8/200 [>.............................] - ETA: 1s - loss: 1472111072.0000 - KL_divergence: 10.1830
 15/200 [=>............................] - ETA: 1s - loss: 1483285333.3333 - KL_divergence: 10.0155
 22/200 [==>...........................] - ETA: 1s - loss: 1488101387.6364 - KL_divergence: 10.1268
 29/200 [===>..........................] - ETA: 1s - loss: 1489946915.3103 - KL_divergence: 10.1403
 35/200 [====>.........................] - ETA: 1s - loss: 1490166641.3714 - KL_divergence: 10.1427
 41/200 [=====>........................] - ETA: 1s - loss: 1490110129.9512 - KL_divergence: 10.1580
 47/200 [======>.......................] - ETA: 1s - loss: 1485589049.1915 - KL_divergence: 10.1295
 53/200 [======>.......................] - ETA: 1s - loss: 1482148965.4340 - KL_divergence: 10.1504
 59/200 [=======>......................] - ETA: 1s - loss: 1481904670.3729 - KL_divergence: 10.1757
 65/200 [========>.....................] - ETA: 1s - loss: 1480436481.9692 - KL_divergence: 10.1627
 71/200 [=========>....................] - ETA: 1s - loss: 1478643867.0423 - KL_divergence: 10.1887
 77/200 [==========>...................] - ETA: 1s - loss: 1478828454.2338 - KL_divergence: 10.1686
 83/200 [===========>..................] - ETA: 1s - loss: 1475627953.3494 - KL_divergence: 10.1469
 89/200 [============>.................] - ETA: 0s - loss: 1478419299.2360 - KL_divergence: 10.1596
 95/200 [=============>................] - ETA: 0s - loss: 1480232734.9895 - KL_divergence: 10.1740
101/200 [==============>...............] - ETA: 0s - loss: 1484551833.3465 - KL_divergence: 10.2145
107/200 [===============>..............] - ETA: 0s - loss: 1489300701.3084 - KL_divergence: 10.2262
113/200 [===============>..............] - ETA: 0s - loss: 1489476658.9735 - KL_divergence: 10.2351
119/200 [================>.............] - ETA: 0s - loss: 1488105169.7479 - KL_divergence: 10.2369
125/200 [=================>............] - ETA: 0s - loss: 1487913853.9520 - KL_divergence: 10.2192
132/200 [==================>...........] - ETA: 0s - loss: 1490357632.9697 - KL_divergence: 10.2060
138/200 [===================>..........] - ETA: 0s - loss: 1488605163.5942 - KL_divergence: 10.1989
144/200 [====================>.........] - ETA: 0s - loss: 1488802536.8889 - KL_divergence: 10.2148
150/200 [=====================>........] - ETA: 0s - loss: 1489642565.9733 - KL_divergence: 10.2459
156/200 [======================>.......] - ETA: 0s - loss: 1490481331.6923 - KL_divergence: 10.2520
162/200 [=======================>......] - ETA: 0s - loss: 1489391291.2593 - KL_divergence: 10.2503
168/200 [========================>.....] - ETA: 0s - loss: 1489620953.1429 - KL_divergence: 10.2488
174/200 [=========================>....] - ETA: 0s - loss: 1488860235.0345 - KL_divergence: 10.2374
180/200 [==========================>...] - ETA: 0s - loss: 1488681631.2889 - KL_divergence: 10.2335
186/200 [==========================>...] - ETA: 0s - loss: 1488197940.9892 - KL_divergence: 10.2269
192/200 [===========================>..] - ETA: 0s - loss: 1488346180.0000 - KL_divergence: 10.2287
198/200 [============================>.] - ETA: 0s - loss: 1488771788.9293 - KL_divergence: 10.2293
200/200 [==============================] - 2s 10ms/step - loss: 1489085165.4400 - KL_divergence: 10.2255 - val_loss: 1483134216.9600 - val_KL_divergence: 10.3342
Epoch 27/100

  1/200 [..............................] - ETA: 1s - loss: 1531185536.0000 - KL_divergence: 10.6333
  7/200 [>.............................] - ETA: 1s - loss: 1530673481.1429 - KL_divergence: 10.0920
 13/200 [>.............................] - ETA: 1s - loss: 1516319143.3846 - KL_divergence: 10.3087
 20/200 [==>...........................] - ETA: 1s - loss: 1501038233.6000 - KL_divergence: 10.1153
 27/200 [===>..........................] - ETA: 1s - loss: 1493796541.6296 - KL_divergence: 10.1221
 33/200 [===>..........................] - ETA: 1s - loss: 1489052353.9394 - KL_divergence: 10.2165
 39/200 [====>.........................] - ETA: 1s - loss: 1472370215.3846 - KL_divergence: 10.2286
 45/200 [=====>........................] - ETA: 1s - loss: 1471416888.8889 - KL_divergence: 10.2243
 51/200 [======>.......................] - ETA: 1s - loss: 1476839584.6275 - KL_divergence: 10.2734
 57/200 [=======>......................] - ETA: 1s - loss: 1479415740.6316 - KL_divergence: 10.2501
 63/200 [========>.....................] - ETA: 1s - loss: 1477563450.9206 - KL_divergence: 10.2711
 69/200 [=========>....................] - ETA: 1s - loss: 1475205481.7391 - KL_divergence: 10.2030
 75/200 [==========>...................] - ETA: 1s - loss: 1479919037.4400 - KL_divergence: 10.2347
 81/200 [===========>..................] - ETA: 1s - loss: 1481856243.3580 - KL_divergence: 10.2328
 87/200 [============>.................] - ETA: 0s - loss: 1479832970.2989 - KL_divergence: 10.2474
 93/200 [============>.................] - ETA: 0s - loss: 1479389395.9570 - KL_divergence: 10.2402
 99/200 [=============>................] - ETA: 0s - loss: 1481958802.1010 - KL_divergence: 10.2678
105/200 [==============>...............] - ETA: 0s - loss: 1483773346.1333 - KL_divergence: 10.2632
111/200 [===============>..............] - ETA: 0s - loss: 1482642807.9279 - KL_divergence: 10.2467
117/200 [================>.............] - ETA: 0s - loss: 1481862910.9060 - KL_divergence: 10.2516
123/200 [=================>............] - ETA: 0s - loss: 1483083395.1220 - KL_divergence: 10.2739
129/200 [==================>...........] - ETA: 0s - loss: 1483060108.8992 - KL_divergence: 10.2894
135/200 [===================>..........] - ETA: 0s - loss: 1481827254.9926 - KL_divergence: 10.2963
141/200 [====================>.........] - ETA: 0s - loss: 1482704943.2057 - KL_divergence: 10.3075
147/200 [=====================>........] - ETA: 0s - loss: 1483198060.8435 - KL_divergence: 10.3247
153/200 [=====================>........] - ETA: 0s - loss: 1482076846.8497 - KL_divergence: 10.3266
159/200 [======================>.......] - ETA: 0s - loss: 1482572166.4403 - KL_divergence: 10.3215
165/200 [=======================>......] - ETA: 0s - loss: 1482066102.3030 - KL_divergence: 10.3237
171/200 [========================>.....] - ETA: 0s - loss: 1482480181.1462 - KL_divergence: 10.3164
177/200 [=========================>....] - ETA: 0s - loss: 1482191612.3842 - KL_divergence: 10.3171
183/200 [==========================>...] - ETA: 0s - loss: 1481462376.9180 - KL_divergence: 10.3323
189/200 [===========================>..] - ETA: 0s - loss: 1482274899.3016 - KL_divergence: 10.3425
195/200 [============================>.] - ETA: 0s - loss: 1482244249.6000 - KL_divergence: 10.3510
200/200 [==============================] - 2s 10ms/step - loss: 1479917315.8400 - KL_divergence: 10.3502 - val_loss: 1487609030.4000 - val_KL_divergence: 10.6966
Epoch 28/100

  1/200 [..............................] - ETA: 1s - loss: 1516017408.0000 - KL_divergence: 10.9894
  7/200 [>.............................] - ETA: 1s - loss: 1468220781.7143 - KL_divergence: 11.0491
 13/200 [>.............................] - ETA: 1s - loss: 1453683593.8462 - KL_divergence: 10.8640
 19/200 [=>............................] - ETA: 1s - loss: 1448059109.0526 - KL_divergence: 10.7520
 25/200 [==>...........................] - ETA: 1s - loss: 1459548984.3200 - KL_divergence: 10.6306
 31/200 [===>..........................] - ETA: 1s - loss: 1459513500.9032 - KL_divergence: 10.6134
 37/200 [====>.........................] - ETA: 1s - loss: 1457144147.0270 - KL_divergence: 10.5747
 43/200 [=====>........................] - ETA: 1s - loss: 1459757684.0930 - KL_divergence: 10.5795
 49/200 [======>.......................] - ETA: 1s - loss: 1458029748.2449 - KL_divergence: 10.5382
 55/200 [=======>......................] - ETA: 1s - loss: 1458517117.6727 - KL_divergence: 10.4914
 61/200 [========>.....................] - ETA: 1s - loss: 1459873525.5082 - KL_divergence: 10.4874
 67/200 [=========>....................] - ETA: 1s - loss: 1461248049.6716 - KL_divergence: 10.4942
 73/200 [=========>....................] - ETA: 1s - loss: 1462554429.3699 - KL_divergence: 10.4742
 79/200 [==========>...................] - ETA: 1s - loss: 1464170518.6835 - KL_divergence: 10.4607
 85/200 [===========>..................] - ETA: 1s - loss: 1466710023.5294 - KL_divergence: 10.4701
 91/200 [============>.................] - ETA: 1s - loss: 1463695953.5824 - KL_divergence: 10.4621
 97/200 [=============>................] - ETA: 0s - loss: 1463257271.4227 - KL_divergence: 10.4585
103/200 [==============>...............] - ETA: 0s - loss: 1462499617.5534 - KL_divergence: 10.4457
109/200 [===============>..............] - ETA: 0s - loss: 1463075204.6972 - KL_divergence: 10.4470
115/200 [================>.............] - ETA: 0s - loss: 1464984948.8696 - KL_divergence: 10.4567
121/200 [=================>............] - ETA: 0s - loss: 1463715650.6446 - KL_divergence: 10.4539
127/200 [==================>...........] - ETA: 0s - loss: 1465149097.3228 - KL_divergence: 10.4726
133/200 [==================>...........] - ETA: 0s - loss: 1464741424.1203 - KL_divergence: 10.4655
140/200 [====================>.........] - ETA: 0s - loss: 1465736234.9714 - KL_divergence: 10.4791
146/200 [====================>.........] - ETA: 0s - loss: 1465990242.1918 - KL_divergence: 10.4875
152/200 [=====================>........] - ETA: 0s - loss: 1466627213.4737 - KL_divergence: 10.5004
158/200 [======================>.......] - ETA: 0s - loss: 1467126092.1519 - KL_divergence: 10.5044
164/200 [=======================>......] - ETA: 0s - loss: 1466727722.1463 - KL_divergence: 10.4985
170/200 [========================>.....] - ETA: 0s - loss: 1465895561.7882 - KL_divergence: 10.5014
176/200 [=========================>....] - ETA: 0s - loss: 1468334415.2727 - KL_divergence: 10.5061
182/200 [==========================>...] - ETA: 0s - loss: 1468725226.9011 - KL_divergence: 10.5067
188/200 [===========================>..] - ETA: 0s - loss: 1468208077.6170 - KL_divergence: 10.5001
194/200 [============================>.] - ETA: 0s - loss: 1468605360.8247 - KL_divergence: 10.4989
200/200 [==============================] - 2s 10ms/step - loss: 1467821397.1200 - KL_divergence: 10.4918 - val_loss: 1465801926.4000 - val_KL_divergence: 10.4104
Epoch 29/100

  1/200 [..............................] - ETA: 1s - loss: 1394830208.0000 - KL_divergence: 11.2429
  7/200 [>.............................] - ETA: 1s - loss: 1437346121.1429 - KL_divergence: 10.3828
 13/200 [>.............................] - ETA: 1s - loss: 1460968467.6923 - KL_divergence: 10.7285
 19/200 [=>............................] - ETA: 1s - loss: 1465705155.3684 - KL_divergence: 10.8698
 25/200 [==>...........................] - ETA: 1s - loss: 1469544785.9200 - KL_divergence: 10.8981
 31/200 [===>..........................] - ETA: 1s - loss: 1451663983.4839 - KL_divergence: 10.8180
 37/200 [====>.........................] - ETA: 1s - loss: 1450716184.2162 - KL_divergence: 10.7991
 42/200 [=====>........................] - ETA: 1s - loss: 1450597412.5714 - KL_divergence: 10.7585
 48/200 [======>.......................] - ETA: 1s - loss: 1457900397.3333 - KL_divergence: 10.7218
 54/200 [=======>......................] - ETA: 1s - loss: 1455542260.1481 - KL_divergence: 10.7209
 60/200 [========>.....................] - ETA: 1s - loss: 1455032428.8000 - KL_divergence: 10.6857
 66/200 [========>.....................] - ETA: 1s - loss: 1460156433.4545 - KL_divergence: 10.6279
 72/200 [=========>....................] - ETA: 1s - loss: 1464809386.6667 - KL_divergence: 10.5830
 78/200 [==========>...................] - ETA: 1s - loss: 1468009193.0256 - KL_divergence: 10.5622
 85/200 [===========>..................] - ETA: 1s - loss: 1469244111.8118 - KL_divergence: 10.5618
 91/200 [============>.................] - ETA: 1s - loss: 1469046450.6374 - KL_divergence: 10.5602
 97/200 [=============>................] - ETA: 0s - loss: 1467333790.3505 - KL_divergence: 10.5365
103/200 [==============>...............] - ETA: 0s - loss: 1465526862.2913 - KL_divergence: 10.5384
109/200 [===============>..............] - ETA: 0s - loss: 1464651092.5505 - KL_divergence: 10.5510
115/200 [================>.............] - ETA: 0s - loss: 1465943139.0609 - KL_divergence: 10.5586
122/200 [=================>............] - ETA: 0s - loss: 1466856229.7705 - KL_divergence: 10.5617
128/200 [==================>...........] - ETA: 0s - loss: 1467365282.0000 - KL_divergence: 10.5597
135/200 [===================>..........] - ETA: 0s - loss: 1467453928.2963 - KL_divergence: 10.5546
141/200 [====================>.........] - ETA: 0s - loss: 1465243760.5674 - KL_divergence: 10.5433
147/200 [=====================>........] - ETA: 0s - loss: 1465707432.0544 - KL_divergence: 10.5478
153/200 [=====================>........] - ETA: 0s - loss: 1466125822.3268 - KL_divergence: 10.5592
158/200 [======================>.......] - ETA: 0s - loss: 1465008712.9114 - KL_divergence: 10.5508
164/200 [=======================>......] - ETA: 0s - loss: 1465352287.2195 - KL_divergence: 10.5406
170/200 [========================>.....] - ETA: 0s - loss: 1465429377.5059 - KL_divergence: 10.5452
176/200 [=========================>....] - ETA: 0s - loss: 1465071986.9091 - KL_divergence: 10.5518
182/200 [==========================>...] - ETA: 0s - loss: 1465429015.9121 - KL_divergence: 10.5490
188/200 [===========================>..] - ETA: 0s - loss: 1465728789.7872 - KL_divergence: 10.5569
194/200 [============================>.] - ETA: 0s - loss: 1465635004.0412 - KL_divergence: 10.5533
200/200 [==============================] - 2s 10ms/step - loss: 1465325502.0800 - KL_divergence: 10.5430 - val_loss: 1459590826.2400 - val_KL_divergence: 10.4003
Epoch 30/100

  1/200 [..............................] - ETA: 1s - loss: 1480979072.0000 - KL_divergence: 10.8690
  7/200 [>.............................] - ETA: 1s - loss: 1471085403.4286 - KL_divergence: 10.6559
 13/200 [>.............................] - ETA: 1s - loss: 1464655488.0000 - KL_divergence: 10.5881
 19/200 [=>............................] - ETA: 1s - loss: 1470007578.9474 - KL_divergence: 10.5466
 25/200 [==>...........................] - ETA: 1s - loss: 1478294871.0400 - KL_divergence: 10.5980
 31/200 [===>..........................] - ETA: 1s - loss: 1466553649.5484 - KL_divergence: 10.5293
 37/200 [====>.........................] - ETA: 1s - loss: 1466176366.7027 - KL_divergence: 10.5661
 43/200 [=====>........................] - ETA: 1s - loss: 1460215281.1163 - KL_divergence: 10.5487
 49/200 [======>.......................] - ETA: 1s - loss: 1458688504.1633 - KL_divergence: 10.5278
 55/200 [=======>......................] - ETA: 1s - loss: 1460729842.0364 - KL_divergence: 10.5086
 61/200 [========>.....................] - ETA: 1s - loss: 1465104077.6393 - KL_divergence: 10.5114
 67/200 [=========>....................] - ETA: 1s - loss: 1464198386.6269 - KL_divergence: 10.5065
 73/200 [=========>....................] - ETA: 1s - loss: 1466210179.5068 - KL_divergence: 10.5000
 79/200 [==========>...................] - ETA: 1s - loss: 1462785492.2532 - KL_divergence: 10.5122
 85/200 [===========>..................] - ETA: 1s - loss: 1467719936.0000 - KL_divergence: 10.5033
 91/200 [============>.................] - ETA: 0s - loss: 1466966633.4945 - KL_divergence: 10.5076
 97/200 [=============>................] - ETA: 0s - loss: 1471250963.7938 - KL_divergence: 10.5046
103/200 [==============>...............] - ETA: 0s - loss: 1469326159.5340 - KL_divergence: 10.5115
109/200 [===============>..............] - ETA: 0s - loss: 1467490960.4404 - KL_divergence: 10.5244
115/200 [================>.............] - ETA: 0s - loss: 1467880234.2957 - KL_divergence: 10.5393
121/200 [=================>............] - ETA: 0s - loss: 1470155019.6364 - KL_divergence: 10.5330
127/200 [==================>...........] - ETA: 0s - loss: 1470281406.4882 - KL_divergence: 10.5450
133/200 [==================>...........] - ETA: 0s - loss: 1469990802.2857 - KL_divergence: 10.5370
139/200 [===================>..........] - ETA: 0s - loss: 1469271884.4317 - KL_divergence: 10.5227
145/200 [====================>.........] - ETA: 0s - loss: 1469458451.4207 - KL_divergence: 10.5189
151/200 [=====================>........] - ETA: 0s - loss: 1468850240.4238 - KL_divergence: 10.5167
157/200 [======================>.......] - ETA: 0s - loss: 1468030876.5350 - KL_divergence: 10.5057
163/200 [=======================>......] - ETA: 0s - loss: 1468022434.5521 - KL_divergence: 10.5154
169/200 [========================>.....] - ETA: 0s - loss: 1469580931.0296 - KL_divergence: 10.5219
175/200 [=========================>....] - ETA: 0s - loss: 1472383896.1371 - KL_divergence: 10.5263
181/200 [==========================>...] - ETA: 0s - loss: 1472402671.7348 - KL_divergence: 10.5273
187/200 [===========================>..] - ETA: 0s - loss: 1472314362.5241 - KL_divergence: 10.5274
193/200 [===========================>..] - ETA: 0s - loss: 1471874552.7047 - KL_divergence: 10.5336
199/200 [============================>.] - ETA: 0s - loss: 1472000249.5678 - KL_divergence: 10.5454
200/200 [==============================] - 2s 10ms/step - loss: 1472416291.2000 - KL_divergence: 10.5477 - val_loss: 1452879257.6000 - val_KL_divergence: 10.4374
Epoch 31/100

  1/200 [..............................] - ETA: 1s - loss: 1480568448.0000 - KL_divergence: 10.2650
  7/200 [>.............................] - ETA: 1s - loss: 1433566555.4286 - KL_divergence: 10.1975
 13/200 [>.............................] - ETA: 1s - loss: 1445836563.6923 - KL_divergence: 10.3178
 19/200 [=>............................] - ETA: 1s - loss: 1435373466.9474 - KL_divergence: 10.5551
 25/200 [==>...........................] - ETA: 1s - loss: 1442811315.2000 - KL_divergence: 10.5720
 31/200 [===>..........................] - ETA: 1s - loss: 1453335754.3226 - KL_divergence: 10.5494
 37/200 [====>.........................] - ETA: 1s - loss: 1463203843.4595 - KL_divergence: 10.4999
 43/200 [=====>........................] - ETA: 1s - loss: 1464477740.6512 - KL_divergence: 10.4783
 49/200 [======>.......................] - ETA: 1s - loss: 1466510296.8163 - KL_divergence: 10.5192
 55/200 [=======>......................] - ETA: 1s - loss: 1464621356.2182 - KL_divergence: 10.4825
 61/200 [========>.....................] - ETA: 1s - loss: 1467630447.2131 - KL_divergence: 10.4973
 67/200 [=========>....................] - ETA: 1s - loss: 1462573953.9104 - KL_divergence: 10.4868
 72/200 [=========>....................] - ETA: 1s - loss: 1462040232.8889 - KL_divergence: 10.5054
 78/200 [==========>...................] - ETA: 1s - loss: 1460827656.2051 - KL_divergence: 10.5175
 84/200 [===========>..................] - ETA: 1s - loss: 1459384565.3333 - KL_divergence: 10.5145
 90/200 [============>.................] - ETA: 0s - loss: 1457073335.4667 - KL_divergence: 10.5336
 96/200 [=============>................] - ETA: 0s - loss: 1454280201.3333 - KL_divergence: 10.5457
102/200 [==============>...............] - ETA: 0s - loss: 1452658960.3137 - KL_divergence: 10.5382
108/200 [===============>..............] - ETA: 0s - loss: 1451110126.2222 - KL_divergence: 10.5408
114/200 [================>.............] - ETA: 0s - loss: 1449289634.8070 - KL_divergence: 10.5245
120/200 [=================>............] - ETA: 0s - loss: 1449863154.1333 - KL_divergence: 10.5339
126/200 [=================>............] - ETA: 0s - loss: 1447803013.0794 - KL_divergence: 10.5331
132/200 [==================>...........] - ETA: 0s - loss: 1446840487.7576 - KL_divergence: 10.5267
138/200 [===================>..........] - ETA: 0s - loss: 1447729682.5507 - KL_divergence: 10.5267
144/200 [====================>.........] - ETA: 0s - loss: 1449219347.5556 - KL_divergence: 10.5222
150/200 [=====================>........] - ETA: 0s - loss: 1448512847.3600 - KL_divergence: 10.5266
156/200 [======================>.......] - ETA: 0s - loss: 1448553388.3077 - KL_divergence: 10.5129
162/200 [=======================>......] - ETA: 0s - loss: 1448727811.9506 - KL_divergence: 10.5070
168/200 [========================>.....] - ETA: 0s - loss: 1450102316.1905 - KL_divergence: 10.5114
174/200 [=========================>....] - ETA: 0s - loss: 1448330740.2299 - KL_divergence: 10.5158
180/200 [==========================>...] - ETA: 0s - loss: 1450574380.8000 - KL_divergence: 10.5171
186/200 [==========================>...] - ETA: 0s - loss: 1451261649.2043 - KL_divergence: 10.5211
192/200 [===========================>..] - ETA: 0s - loss: 1449873763.3333 - KL_divergence: 10.5282
198/200 [============================>.] - ETA: 0s - loss: 1451309229.2525 - KL_divergence: 10.5354
200/200 [==============================] - 2s 10ms/step - loss: 1451170773.7600 - KL_divergence: 10.5337 - val_loss: 1457131168.0000 - val_KL_divergence: 10.5477
Epoch 32/100

  1/200 [..............................] - ETA: 1s - loss: 1469198336.0000 - KL_divergence: 10.1446
  7/200 [>.............................] - ETA: 1s - loss: 1437852836.5714 - KL_divergence: 10.6469
 13/200 [>.............................] - ETA: 1s - loss: 1431129668.9231 - KL_divergence: 10.5264
 18/200 [=>............................] - ETA: 1s - loss: 1439177080.8889 - KL_divergence: 10.5875
 24/200 [==>...........................] - ETA: 1s - loss: 1440086789.3333 - KL_divergence: 10.6656
 30/200 [===>..........................] - ETA: 1s - loss: 1448434069.3333 - KL_divergence: 10.6836
 36/200 [====>.........................] - ETA: 1s - loss: 1449035541.3333 - KL_divergence: 10.6825
 42/200 [=====>........................] - ETA: 1s - loss: 1449909342.4762 - KL_divergence: 10.7326
 48/200 [======>.......................] - ETA: 1s - loss: 1454937237.3333 - KL_divergence: 10.7415
 54/200 [=======>......................] - ETA: 1s - loss: 1455911706.0741 - KL_divergence: 10.7510
 60/200 [========>.....................] - ETA: 1s - loss: 1455712842.6667 - KL_divergence: 10.7257
 66/200 [========>.....................] - ETA: 1s - loss: 1457293197.5758 - KL_divergence: 10.6877
 72/200 [=========>....................] - ETA: 1s - loss: 1455450513.7778 - KL_divergence: 10.6870
 78/200 [==========>...................] - ETA: 1s - loss: 1454418194.0513 - KL_divergence: 10.6726
 84/200 [===========>..................] - ETA: 1s - loss: 1455435567.2381 - KL_divergence: 10.6776
 90/200 [============>.................] - ETA: 0s - loss: 1458118957.5111 - KL_divergence: 10.6670
 96/200 [=============>................] - ETA: 0s - loss: 1453919950.6667 - KL_divergence: 10.6536
102/200 [==============>...............] - ETA: 0s - loss: 1456588089.7255 - KL_divergence: 10.6551
108/200 [===============>..............] - ETA: 0s - loss: 1457658590.8148 - KL_divergence: 10.6469
115/200 [================>.............] - ETA: 0s - loss: 1459855996.6609 - KL_divergence: 10.6607
121/200 [=================>............] - ETA: 0s - loss: 1459676583.1405 - KL_divergence: 10.6676
127/200 [==================>...........] - ETA: 0s - loss: 1459982677.6693 - KL_divergence: 10.6721
133/200 [==================>...........] - ETA: 0s - loss: 1460081633.2030 - KL_divergence: 10.6719
139/200 [===================>..........] - ETA: 0s - loss: 1458937078.7914 - KL_divergence: 10.6763
145/200 [====================>.........] - ETA: 0s - loss: 1457680304.5517 - KL_divergence: 10.6780
151/200 [=====================>........] - ETA: 0s - loss: 1457229838.4106 - KL_divergence: 10.6925
157/200 [======================>.......] - ETA: 0s - loss: 1456384815.2866 - KL_divergence: 10.6930
163/200 [=======================>......] - ETA: 0s - loss: 1455232054.1840 - KL_divergence: 10.6975
169/200 [========================>.....] - ETA: 0s - loss: 1457349432.0473 - KL_divergence: 10.6814
175/200 [=========================>....] - ETA: 0s - loss: 1455314666.7886 - KL_divergence: 10.6891
181/200 [==========================>...] - ETA: 0s - loss: 1457118708.6851 - KL_divergence: 10.6954
187/200 [===========================>..] - ETA: 0s - loss: 1456800631.7861 - KL_divergence: 10.7009
193/200 [===========================>..] - ETA: 0s - loss: 1455332237.2642 - KL_divergence: 10.7061
199/200 [============================>.] - ETA: 0s - loss: 1455152306.1709 - KL_divergence: 10.7186
200/200 [==============================] - 2s 10ms/step - loss: 1455269684.4800 - KL_divergence: 10.7221 - val_loss: 1455081369.6000 - val_KL_divergence: 11.3052
Epoch 33/100

  1/200 [..............................] - ETA: 1s - loss: 1606486784.0000 - KL_divergence: 11.8691
  7/200 [>.............................] - ETA: 1s - loss: 1453606454.8571 - KL_divergence: 10.8807
 13/200 [>.............................] - ETA: 1s - loss: 1474793432.6154 - KL_divergence: 10.9540
 19/200 [=>............................] - ETA: 1s - loss: 1450611226.9474 - KL_divergence: 10.8006
 24/200 [==>...........................] - ETA: 1s - loss: 1449089589.3333 - KL_divergence: 10.8006
 30/200 [===>..........................] - ETA: 1s - loss: 1451133687.4667 - KL_divergence: 10.8606
 36/200 [====>.........................] - ETA: 1s - loss: 1454536942.2222 - KL_divergence: 10.9709
 42/200 [=====>........................] - ETA: 1s - loss: 1448147574.8571 - KL_divergence: 10.9687
 48/200 [======>.......................] - ETA: 1s - loss: 1451514656.0000 - KL_divergence: 10.9355
 54/200 [=======>......................] - ETA: 1s - loss: 1451172020.1481 - KL_divergence: 10.9273
 59/200 [=======>......................] - ETA: 1s - loss: 1447485722.0339 - KL_divergence: 10.9425
 65/200 [========>.....................] - ETA: 1s - loss: 1447633516.3077 - KL_divergence: 10.9974
 71/200 [=========>....................] - ETA: 1s - loss: 1444119564.6197 - KL_divergence: 10.9940
 77/200 [==========>...................] - ETA: 1s - loss: 1441215202.0779 - KL_divergence: 10.9713
 83/200 [===========>..................] - ETA: 1s - loss: 1440456852.0482 - KL_divergence: 10.9326
 89/200 [============>.................] - ETA: 1s - loss: 1441532149.9326 - KL_divergence: 10.9087
 95/200 [=============>................] - ETA: 0s - loss: 1441088914.8632 - KL_divergence: 10.8912
101/200 [==============>...............] - ETA: 0s - loss: 1440952600.0792 - KL_divergence: 10.8929
107/200 [===============>..............] - ETA: 0s - loss: 1444475086.9533 - KL_divergence: 10.8842
113/200 [===============>..............] - ETA: 0s - loss: 1442290171.4690 - KL_divergence: 10.8792
119/200 [================>.............] - ETA: 0s - loss: 1441510535.5294 - KL_divergence: 10.8760
125/200 [=================>............] - ETA: 0s - loss: 1443646099.4560 - KL_divergence: 10.8684
131/200 [==================>...........] - ETA: 0s - loss: 1444567092.7634 - KL_divergence: 10.8637
137/200 [===================>..........] - ETA: 0s - loss: 1444591925.2555 - KL_divergence: 10.8636
143/200 [====================>.........] - ETA: 0s - loss: 1445893088.6713 - KL_divergence: 10.8514
149/200 [=====================>........] - ETA: 0s - loss: 1445574514.2550 - KL_divergence: 10.8630
155/200 [======================>.......] - ETA: 0s - loss: 1445405321.9097 - KL_divergence: 10.8494
161/200 [=======================>......] - ETA: 0s - loss: 1445865227.1304 - KL_divergence: 10.8485
167/200 [========================>.....] - ETA: 0s - loss: 1444972479.6168 - KL_divergence: 10.8381
173/200 [========================>.....] - ETA: 0s - loss: 1443639718.4740 - KL_divergence: 10.8387
179/200 [=========================>....] - ETA: 0s - loss: 1444046192.2682 - KL_divergence: 10.8359
185/200 [==========================>...] - ETA: 0s - loss: 1442548436.4108 - KL_divergence: 10.8323
191/200 [===========================>..] - ETA: 0s - loss: 1442582638.5759 - KL_divergence: 10.8278
197/200 [============================>.] - ETA: 0s - loss: 1441741363.9797 - KL_divergence: 10.8222
200/200 [==============================] - 2s 10ms/step - loss: 1441886493.4400 - KL_divergence: 10.8161 - val_loss: 1455471527.6800 - val_KL_divergence: 10.7778
Epoch 34/100

  1/200 [..............................] - ETA: 2s - loss: 1454954624.0000 - KL_divergence: 10.4339
  7/200 [>.............................] - ETA: 1s - loss: 1398686573.7143 - KL_divergence: 10.2443
 13/200 [>.............................] - ETA: 1s - loss: 1422810476.3077 - KL_divergence: 10.4825
 19/200 [=>............................] - ETA: 1s - loss: 1436346105.2632 - KL_divergence: 10.5956
 25/200 [==>...........................] - ETA: 1s - loss: 1431595929.6000 - KL_divergence: 10.5429
 31/200 [===>..........................] - ETA: 1s - loss: 1432306531.0968 - KL_divergence: 10.5370
 37/200 [====>.........................] - ETA: 1s - loss: 1436305148.5405 - KL_divergence: 10.5855
 43/200 [=====>........................] - ETA: 1s - loss: 1431927001.3023 - KL_divergence: 10.6075
 49/200 [======>.......................] - ETA: 1s - loss: 1432018309.2245 - KL_divergence: 10.6205
 55/200 [=======>......................] - ETA: 1s - loss: 1431535245.9636 - KL_divergence: 10.6129
 61/200 [========>.....................] - ETA: 1s - loss: 1432548196.7213 - KL_divergence: 10.5963
 67/200 [=========>....................] - ETA: 1s - loss: 1433490789.2537 - KL_divergence: 10.6325
 73/200 [=========>....................] - ETA: 1s - loss: 1437012262.5753 - KL_divergence: 10.6296
 80/200 [===========>..................] - ETA: 1s - loss: 1437842340.8000 - KL_divergence: 10.6412
 87/200 [============>.................] - ETA: 1s - loss: 1438510349.2414 - KL_divergence: 10.6582
 94/200 [=============>................] - ETA: 0s - loss: 1438361071.6596 - KL_divergence: 10.6541
100/200 [==============>...............] - ETA: 0s - loss: 1438225304.3200 - KL_divergence: 10.6577
106/200 [==============>...............] - ETA: 0s - loss: 1438082715.7736 - KL_divergence: 10.6529
112/200 [===============>..............] - ETA: 0s - loss: 1438585628.5714 - KL_divergence: 10.6600
118/200 [================>.............] - ETA: 0s - loss: 1435576777.7627 - KL_divergence: 10.6647
124/200 [=================>............] - ETA: 0s - loss: 1433714850.0645 - KL_divergence: 10.6483
130/200 [==================>...........] - ETA: 0s - loss: 1435681502.5231 - KL_divergence: 10.6444
136/200 [===================>..........] - ETA: 0s - loss: 1436718517.6471 - KL_divergence: 10.6565
142/200 [====================>.........] - ETA: 0s - loss: 1437601092.5070 - KL_divergence: 10.6580
148/200 [=====================>........] - ETA: 0s - loss: 1438030827.2432 - KL_divergence: 10.6453
154/200 [======================>.......] - ETA: 0s - loss: 1437635219.9481 - KL_divergence: 10.6362
160/200 [=======================>......] - ETA: 0s - loss: 1437853845.6000 - KL_divergence: 10.6256
166/200 [=======================>......] - ETA: 0s - loss: 1436839555.0843 - KL_divergence: 10.6435
173/200 [========================>.....] - ETA: 0s - loss: 1436777213.0405 - KL_divergence: 10.6470
179/200 [=========================>....] - ETA: 0s - loss: 1436013909.8101 - KL_divergence: 10.6402
185/200 [==========================>...] - ETA: 0s - loss: 1434965634.7676 - KL_divergence: 10.6263
191/200 [===========================>..] - ETA: 0s - loss: 1433965805.9058 - KL_divergence: 10.6318
197/200 [============================>.] - ETA: 0s - loss: 1434095826.5178 - KL_divergence: 10.6260
200/200 [==============================] - 2s 10ms/step - loss: 1434538120.3200 - KL_divergence: 10.6325 - val_loss: 1442568293.1200 - val_KL_divergence: 10.6673
Epoch 35/100

  1/200 [..............................] - ETA: 1s - loss: 1472634368.0000 - KL_divergence: 11.3029
  7/200 [>.............................] - ETA: 1s - loss: 1446764306.2857 - KL_divergence: 11.0624
 13/200 [>.............................] - ETA: 1s - loss: 1433431364.9231 - KL_divergence: 11.0478
 19/200 [=>............................] - ETA: 1s - loss: 1433039514.9474 - KL_divergence: 10.9286
 25/200 [==>...........................] - ETA: 1s - loss: 1438595445.7600 - KL_divergence: 10.9173
 31/200 [===>..........................] - ETA: 1s - loss: 1440558447.4839 - KL_divergence: 10.9113
 37/200 [====>.........................] - ETA: 1s - loss: 1450885133.8378 - KL_divergence: 10.8880
 43/200 [=====>........................] - ETA: 1s - loss: 1446258878.5116 - KL_divergence: 10.8594
 49/200 [======>.......................] - ETA: 1s - loss: 1449912296.4898 - KL_divergence: 10.8365
 55/200 [=======>......................] - ETA: 1s - loss: 1449174905.0182 - KL_divergence: 10.8045
 61/200 [========>.....................] - ETA: 1s - loss: 1455002013.3770 - KL_divergence: 10.8097
 67/200 [=========>....................] - ETA: 1s - loss: 1451309644.4179 - KL_divergence: 10.8026
 73/200 [=========>....................] - ETA: 1s - loss: 1447705822.6849 - KL_divergence: 10.8053
 79/200 [==========>...................] - ETA: 1s - loss: 1445550146.4304 - KL_divergence: 10.7753
 85/200 [===========>..................] - ETA: 1s - loss: 1451142862.3059 - KL_divergence: 10.7785
 91/200 [============>.................] - ETA: 0s - loss: 1450932975.1209 - KL_divergence: 10.7587
 97/200 [=============>................] - ETA: 0s - loss: 1450588326.2680 - KL_divergence: 10.7600
104/200 [==============>...............] - ETA: 0s - loss: 1451129057.2308 - KL_divergence: 10.7613
111/200 [===============>..............] - ETA: 0s - loss: 1450552759.3514 - KL_divergence: 10.7652
118/200 [================>.............] - ETA: 0s - loss: 1450470829.5593 - KL_divergence: 10.7443
125/200 [=================>............] - ETA: 0s - loss: 1449402798.0800 - KL_divergence: 10.7408
131/200 [==================>...........] - ETA: 0s - loss: 1449486909.5573 - KL_divergence: 10.7468
138/200 [===================>..........] - ETA: 0s - loss: 1446626185.2754 - KL_divergence: 10.7440
144/200 [====================>.........] - ETA: 0s - loss: 1445202152.8889 - KL_divergence: 10.7518
150/200 [=====================>........] - ETA: 0s - loss: 1444175510.1867 - KL_divergence: 10.7512
156/200 [======================>.......] - ETA: 0s - loss: 1442850821.7436 - KL_divergence: 10.7530
162/200 [=======================>......] - ETA: 0s - loss: 1444658199.7037 - KL_divergence: 10.7490
168/200 [========================>.....] - ETA: 0s - loss: 1444303118.4762 - KL_divergence: 10.7372
174/200 [=========================>....] - ETA: 0s - loss: 1444489485.2414 - KL_divergence: 10.7344
180/200 [==========================>...] - ETA: 0s - loss: 1445009798.4000 - KL_divergence: 10.7403
187/200 [===========================>..] - ETA: 0s - loss: 1443309155.2513 - KL_divergence: 10.7383
194/200 [============================>.] - ETA: 0s - loss: 1443255344.1649 - KL_divergence: 10.7407
200/200 [==============================] - 2s 10ms/step - loss: 1442288397.4400 - KL_divergence: 10.7367 - val_loss: 1446115452.1600 - val_KL_divergence: 10.6752
Epoch 36/100

  1/200 [..............................] - ETA: 1s - loss: 1400335360.0000 - KL_divergence: 11.1137
  7/200 [>.............................] - ETA: 1s - loss: 1446162505.1429 - KL_divergence: 10.7222
 13/200 [>.............................] - ETA: 1s - loss: 1451901459.6923 - KL_divergence: 10.5633
 19/200 [=>............................] - ETA: 1s - loss: 1446384889.2632 - KL_divergence: 10.4702
 25/200 [==>...........................] - ETA: 1s - loss: 1442093946.8800 - KL_divergence: 10.3909
 31/200 [===>..........................] - ETA: 1s - loss: 1438371224.7742 - KL_divergence: 10.3635
 37/200 [====>.........................] - ETA: 1s - loss: 1430415640.2162 - KL_divergence: 10.3340
 43/200 [=====>........................] - ETA: 1s - loss: 1430770048.0000 - KL_divergence: 10.3002
 49/200 [======>.......................] - ETA: 1s - loss: 1435857167.6735 - KL_divergence: 10.3237
 55/200 [=======>......................] - ETA: 1s - loss: 1436274362.1818 - KL_divergence: 10.3391
 61/200 [========>.....................] - ETA: 1s - loss: 1429349472.5246 - KL_divergence: 10.3627
 67/200 [=========>....................] - ETA: 1s - loss: 1426549798.2090 - KL_divergence: 10.4076
 73/200 [=========>....................] - ETA: 1s - loss: 1428652149.4795 - KL_divergence: 10.4216
 79/200 [==========>...................] - ETA: 1s - loss: 1427258515.4430 - KL_divergence: 10.4578
 85/200 [===========>..................] - ETA: 1s - loss: 1429421885.7412 - KL_divergence: 10.5048
 91/200 [============>.................] - ETA: 0s - loss: 1431137623.2088 - KL_divergence: 10.5210
 97/200 [=============>................] - ETA: 0s - loss: 1430633131.5464 - KL_divergence: 10.5262
103/200 [==============>...............] - ETA: 0s - loss: 1428884827.9612 - KL_divergence: 10.5218
109/200 [===============>..............] - ETA: 0s - loss: 1425807066.4220 - KL_divergence: 10.5170
115/200 [================>.............] - ETA: 0s - loss: 1425919210.8522 - KL_divergence: 10.5261
121/200 [=================>............] - ETA: 0s - loss: 1427759225.6529 - KL_divergence: 10.5500
127/200 [==================>...........] - ETA: 0s - loss: 1427828992.0000 - KL_divergence: 10.5390
133/200 [==================>...........] - ETA: 0s - loss: 1426427838.5564 - KL_divergence: 10.5427
139/200 [===================>..........] - ETA: 0s - loss: 1425539206.4460 - KL_divergence: 10.5639
145/200 [====================>.........] - ETA: 0s - loss: 1424301628.0276 - KL_divergence: 10.5602
151/200 [=====================>........] - ETA: 0s - loss: 1422562194.6490 - KL_divergence: 10.5424
157/200 [======================>.......] - ETA: 0s - loss: 1421721644.8408 - KL_divergence: 10.5373
163/200 [=======================>......] - ETA: 0s - loss: 1422313235.6319 - KL_divergence: 10.5275
169/200 [========================>.....] - ETA: 0s - loss: 1422190816.1893 - KL_divergence: 10.5265
175/200 [=========================>....] - ETA: 0s - loss: 1424204050.2857 - KL_divergence: 10.5416
181/200 [==========================>...] - ETA: 0s - loss: 1425047288.9282 - KL_divergence: 10.5376
187/200 [===========================>..] - ETA: 0s - loss: 1425644463.2299 - KL_divergence: 10.5343
193/200 [===========================>..] - ETA: 0s - loss: 1425028261.1399 - KL_divergence: 10.5471
199/200 [============================>.] - ETA: 0s - loss: 1424540280.2814 - KL_divergence: 10.5617
200/200 [==============================] - 2s 10ms/step - loss: 1425318857.6000 - KL_divergence: 10.5631 - val_loss: 1438157870.0800 - val_KL_divergence: 11.0314
Epoch 37/100

  1/200 [..............................] - ETA: 1s - loss: 1579151232.0000 - KL_divergence: 11.9192
  7/200 [>.............................] - ETA: 1s - loss: 1440648338.2857 - KL_divergence: 11.0184
 13/200 [>.............................] - ETA: 1s - loss: 1447758848.0000 - KL_divergence: 10.7665
 19/200 [=>............................] - ETA: 1s - loss: 1452217256.4211 - KL_divergence: 10.7749
 25/200 [==>...........................] - ETA: 1s - loss: 1451464222.7200 - KL_divergence: 10.7993
 31/200 [===>..........................] - ETA: 1s - loss: 1443088631.7419 - KL_divergence: 10.7779
 37/200 [====>.........................] - ETA: 1s - loss: 1437992932.3243 - KL_divergence: 10.7490
 43/200 [=====>........................] - ETA: 1s - loss: 1432140160.0000 - KL_divergence: 10.6895
 49/200 [======>.......................] - ETA: 1s - loss: 1429373693.3878 - KL_divergence: 10.7130
 55/200 [=======>......................] - ETA: 1s - loss: 1434357110.6909 - KL_divergence: 10.7579
 61/200 [========>.....................] - ETA: 1s - loss: 1436462491.2787 - KL_divergence: 10.7253
 67/200 [=========>....................] - ETA: 1s - loss: 1437585566.5672 - KL_divergence: 10.7354
 73/200 [=========>....................] - ETA: 1s - loss: 1435752982.7945 - KL_divergence: 10.7351
 79/200 [==========>...................] - ETA: 1s - loss: 1434717576.1013 - KL_divergence: 10.7242
 85/200 [===========>..................] - ETA: 1s - loss: 1435948929.5059 - KL_divergence: 10.7320
 91/200 [============>.................] - ETA: 0s - loss: 1430986922.1978 - KL_divergence: 10.7009
 97/200 [=============>................] - ETA: 0s - loss: 1430735262.3505 - KL_divergence: 10.6798
103/200 [==============>...............] - ETA: 0s - loss: 1431608502.6796 - KL_divergence: 10.6787
109/200 [===============>..............] - ETA: 0s - loss: 1430825480.2202 - KL_divergence: 10.6805
115/200 [================>.............] - ETA: 0s - loss: 1427881546.5739 - KL_divergence: 10.6719
121/200 [=================>............] - ETA: 0s - loss: 1428922641.9835 - KL_divergence: 10.6492
127/200 [==================>...........] - ETA: 0s - loss: 1427329740.5984 - KL_divergence: 10.6289
133/200 [==================>...........] - ETA: 0s - loss: 1424824181.4135 - KL_divergence: 10.6173
139/200 [===================>..........] - ETA: 0s - loss: 1424937339.3957 - KL_divergence: 10.6142
145/200 [====================>.........] - ETA: 0s - loss: 1422864677.0759 - KL_divergence: 10.5967
151/200 [=====================>........] - ETA: 0s - loss: 1423699617.0596 - KL_divergence: 10.5904
157/200 [======================>.......] - ETA: 0s - loss: 1423887325.7580 - KL_divergence: 10.5779
163/200 [=======================>......] - ETA: 0s - loss: 1423853739.9755 - KL_divergence: 10.5779
169/200 [========================>.....] - ETA: 0s - loss: 1424097387.5503 - KL_divergence: 10.5649
175/200 [=========================>....] - ETA: 0s - loss: 1424485869.7143 - KL_divergence: 10.5605
181/200 [==========================>...] - ETA: 0s - loss: 1423286110.7624 - KL_divergence: 10.5594
187/200 [===========================>..] - ETA: 0s - loss: 1423267753.7540 - KL_divergence: 10.5537
193/200 [===========================>..] - ETA: 0s - loss: 1421967456.1658 - KL_divergence: 10.5524
199/200 [============================>.] - ETA: 0s - loss: 1421406911.6784 - KL_divergence: 10.5577
200/200 [==============================] - 2s 10ms/step - loss: 1421686598.4000 - KL_divergence: 10.5536 - val_loss: 1421366115.8400 - val_KL_divergence: 10.6299
Epoch 38/100

  1/200 [..............................] - ETA: 1s - loss: 1394388992.0000 - KL_divergence: 10.2762
  7/200 [>.............................] - ETA: 1s - loss: 1416810020.5714 - KL_divergence: 10.5422
 13/200 [>.............................] - ETA: 1s - loss: 1423101627.0769 - KL_divergence: 10.4556
 19/200 [=>............................] - ETA: 1s - loss: 1415980806.7368 - KL_divergence: 10.5369
 25/200 [==>...........................] - ETA: 1s - loss: 1414788951.0400 - KL_divergence: 10.4935
 31/200 [===>..........................] - ETA: 1s - loss: 1416431351.7419 - KL_divergence: 10.4762
 37/200 [====>.........................] - ETA: 1s - loss: 1411146108.5405 - KL_divergence: 10.5089
 43/200 [=====>........................] - ETA: 1s - loss: 1408783532.6512 - KL_divergence: 10.5123
 49/200 [======>.......................] - ETA: 1s - loss: 1414611380.2449 - KL_divergence: 10.5310
 55/200 [=======>......................] - ETA: 1s - loss: 1416064637.6727 - KL_divergence: 10.5473
 61/200 [========>.....................] - ETA: 1s - loss: 1417568761.7049 - KL_divergence: 10.5908
 67/200 [=========>....................] - ETA: 1s - loss: 1412010767.2836 - KL_divergence: 10.6099
 73/200 [=========>....................] - ETA: 1s - loss: 1414733054.2466 - KL_divergence: 10.6120
 79/200 [==========>...................] - ETA: 1s - loss: 1415763174.0759 - KL_divergence: 10.6666
 85/200 [===========>..................] - ETA: 1s - loss: 1419473002.9176 - KL_divergence: 10.6829
 91/200 [============>.................] - ETA: 0s - loss: 1417627542.5055 - KL_divergence: 10.7118
 97/200 [=============>................] - ETA: 0s - loss: 1419488468.4536 - KL_divergence: 10.7423
103/200 [==============>...............] - ETA: 0s - loss: 1418914725.2816 - KL_divergence: 10.7466
109/200 [===============>..............] - ETA: 0s - loss: 1417937025.1743 - KL_divergence: 10.7421
115/200 [================>.............] - ETA: 0s - loss: 1422093772.8000 - KL_divergence: 10.7599
121/200 [=================>............] - ETA: 0s - loss: 1421441769.7851 - KL_divergence: 10.7614
127/200 [==================>...........] - ETA: 0s - loss: 1421403922.1417 - KL_divergence: 10.7616
134/200 [===================>..........] - ETA: 0s - loss: 1421617911.4030 - KL_divergence: 10.7736
140/200 [====================>.........] - ETA: 0s - loss: 1423370708.1143 - KL_divergence: 10.7616
146/200 [====================>.........] - ETA: 0s - loss: 1423480655.7808 - KL_divergence: 10.7535
152/200 [=====================>........] - ETA: 0s - loss: 1421629893.8947 - KL_divergence: 10.7583
158/200 [======================>.......] - ETA: 0s - loss: 1422893068.1519 - KL_divergence: 10.7717
164/200 [=======================>......] - ETA: 0s - loss: 1423252537.7561 - KL_divergence: 10.7715
170/200 [========================>.....] - ETA: 0s - loss: 1423115577.2235 - KL_divergence: 10.7741
176/200 [=========================>....] - ETA: 0s - loss: 1422349589.0909 - KL_divergence: 10.7741
182/200 [==========================>...] - ETA: 0s - loss: 1420745391.1209 - KL_divergence: 10.7728
188/200 [===========================>..] - ETA: 0s - loss: 1420951535.6596 - KL_divergence: 10.7816
194/200 [============================>.] - ETA: 0s - loss: 1419837553.4845 - KL_divergence: 10.7743
200/200 [==============================] - 2s 10ms/step - loss: 1421036203.5200 - KL_divergence: 10.7795 - val_loss: 1432526958.0800 - val_KL_divergence: 10.7775
Epoch 39/100

  1/200 [..............................] - ETA: 1s - loss: 1480536448.0000 - KL_divergence: 10.9797
  7/200 [>.............................] - ETA: 1s - loss: 1428892598.8571 - KL_divergence: 10.7261
 13/200 [>.............................] - ETA: 1s - loss: 1422074968.6154 - KL_divergence: 10.9057
 19/200 [=>............................] - ETA: 1s - loss: 1433653914.9474 - KL_divergence: 10.9127
 25/200 [==>...........................] - ETA: 1s - loss: 1432496102.4000 - KL_divergence: 10.8228
 31/200 [===>..........................] - ETA: 1s - loss: 1434694812.9032 - KL_divergence: 10.7925
 37/200 [====>.........................] - ETA: 1s - loss: 1425313670.9189 - KL_divergence: 10.7812
 43/200 [=====>........................] - ETA: 1s - loss: 1434419316.0930 - KL_divergence: 10.7632
 49/200 [======>.......................] - ETA: 1s - loss: 1434574202.7755 - KL_divergence: 10.7436
 55/200 [=======>......................] - ETA: 1s - loss: 1434473204.3636 - KL_divergence: 10.7112
 61/200 [========>.....................] - ETA: 1s - loss: 1428533982.4262 - KL_divergence: 10.6703
 67/200 [=========>....................] - ETA: 1s - loss: 1424949912.8358 - KL_divergence: 10.6344
 73/200 [=========>....................] - ETA: 1s - loss: 1423771221.9178 - KL_divergence: 10.6388
 79/200 [==========>...................] - ETA: 1s - loss: 1421595539.4430 - KL_divergence: 10.6369
 85/200 [===========>..................] - ETA: 1s - loss: 1416087353.2235 - KL_divergence: 10.6573
 91/200 [============>.................] - ETA: 0s - loss: 1415076226.8132 - KL_divergence: 10.6663
 97/200 [=============>................] - ETA: 0s - loss: 1414589300.1237 - KL_divergence: 10.6619
104/200 [==============>...............] - ETA: 0s - loss: 1417332083.6923 - KL_divergence: 10.6858
110/200 [===============>..............] - ETA: 0s - loss: 1416425724.5091 - KL_divergence: 10.6796
116/200 [================>.............] - ETA: 0s - loss: 1417189497.3793 - KL_divergence: 10.6775
122/200 [=================>............] - ETA: 0s - loss: 1417301919.4754 - KL_divergence: 10.6829
128/200 [==================>...........] - ETA: 0s - loss: 1416207312.0000 - KL_divergence: 10.6892
134/200 [===================>..........] - ETA: 0s - loss: 1419486493.6119 - KL_divergence: 10.6854
140/200 [====================>.........] - ETA: 0s - loss: 1417363189.0286 - KL_divergence: 10.6751
146/200 [====================>.........] - ETA: 0s - loss: 1418241530.7397 - KL_divergence: 10.6775
152/200 [=====================>........] - ETA: 0s - loss: 1419433184.8421 - KL_divergence: 10.6715
158/200 [======================>.......] - ETA: 0s - loss: 1416411560.5063 - KL_divergence: 10.6654
164/200 [=======================>......] - ETA: 0s - loss: 1416684942.0488 - KL_divergence: 10.6704
170/200 [========================>.....] - ETA: 0s - loss: 1415762328.0941 - KL_divergence: 10.6787
176/200 [=========================>....] - ETA: 0s - loss: 1415005325.8182 - KL_divergence: 10.6720
182/200 [==========================>...] - ETA: 0s - loss: 1414644874.5495 - KL_divergence: 10.6710
188/200 [===========================>..] - ETA: 0s - loss: 1414949522.3830 - KL_divergence: 10.6808
194/200 [============================>.] - ETA: 0s - loss: 1414284178.4742 - KL_divergence: 10.6696
200/200 [==============================] - 2s 10ms/step - loss: 1414621003.5200 - KL_divergence: 10.6602 - val_loss: 1435247571.2000 - val_KL_divergence: 10.6684
Epoch 40/100

  1/200 [..............................] - ETA: 1s - loss: 1516885248.0000 - KL_divergence: 10.9837
  7/200 [>.............................] - ETA: 1s - loss: 1399352484.5714 - KL_divergence: 10.8240
 13/200 [>.............................] - ETA: 1s - loss: 1379149341.5385 - KL_divergence: 10.6274
 19/200 [=>............................] - ETA: 1s - loss: 1387868220.6316 - KL_divergence: 10.6875
 25/200 [==>...........................] - ETA: 1s - loss: 1382565775.3600 - KL_divergence: 10.6509
 31/200 [===>..........................] - ETA: 1s - loss: 1389604327.2258 - KL_divergence: 10.6841
 37/200 [====>.........................] - ETA: 1s - loss: 1392300142.7027 - KL_divergence: 10.7208
 43/200 [=====>........................] - ETA: 1s - loss: 1403973069.3953 - KL_divergence: 10.7481
 49/200 [======>.......................] - ETA: 1s - loss: 1402654074.7755 - KL_divergence: 10.7422
 55/200 [=======>......................] - ETA: 1s - loss: 1407156980.3636 - KL_divergence: 10.7724
 61/200 [========>.....................] - ETA: 1s - loss: 1406234659.6721 - KL_divergence: 10.7672
 67/200 [=========>....................] - ETA: 1s - loss: 1404340210.6269 - KL_divergence: 10.7449
 73/200 [=========>....................] - ETA: 1s - loss: 1404792388.3836 - KL_divergence: 10.7169
 79/200 [==========>...................] - ETA: 1s - loss: 1409068571.5443 - KL_divergence: 10.7109
 85/200 [===========>..................] - ETA: 1s - loss: 1407710010.7294 - KL_divergence: 10.7176
 91/200 [============>.................] - ETA: 0s - loss: 1403905002.9011 - KL_divergence: 10.7220
 97/200 [=============>................] - ETA: 0s - loss: 1403632294.2680 - KL_divergence: 10.7253
103/200 [==============>...............] - ETA: 0s - loss: 1403274584.2330 - KL_divergence: 10.7220
109/200 [===============>..............] - ETA: 0s - loss: 1404018071.4862 - KL_divergence: 10.7440
115/200 [================>.............] - ETA: 0s - loss: 1402016380.6609 - KL_divergence: 10.7428
121/200 [=================>............] - ETA: 0s - loss: 1400934161.9835 - KL_divergence: 10.7491
127/200 [==================>...........] - ETA: 0s - loss: 1403198926.6142 - KL_divergence: 10.7575
133/200 [==================>...........] - ETA: 0s - loss: 1404393102.4361 - KL_divergence: 10.7536
139/200 [===================>..........] - ETA: 0s - loss: 1404560135.3669 - KL_divergence: 10.7602
145/200 [====================>.........] - ETA: 0s - loss: 1403432176.1103 - KL_divergence: 10.7436
151/200 [=====================>........] - ETA: 0s - loss: 1403621687.0993 - KL_divergence: 10.7470
157/200 [======================>.......] - ETA: 0s - loss: 1403676683.4140 - KL_divergence: 10.7579
163/200 [=======================>......] - ETA: 0s - loss: 1405876456.4417 - KL_divergence: 10.7568
169/200 [========================>.....] - ETA: 0s - loss: 1405221010.9349 - KL_divergence: 10.7476
175/200 [=========================>....] - ETA: 0s - loss: 1403877599.0857 - KL_divergence: 10.7420
181/200 [==========================>...] - ETA: 0s - loss: 1403710469.6575 - KL_divergence: 10.7371
187/200 [===========================>..] - ETA: 0s - loss: 1404178888.5561 - KL_divergence: 10.7272
193/200 [===========================>..] - ETA: 0s - loss: 1404493759.6684 - KL_divergence: 10.7265
199/200 [============================>.] - ETA: 0s - loss: 1404972989.7487 - KL_divergence: 10.7293
200/200 [==============================] - 2s 10ms/step - loss: 1405320214.4000 - KL_divergence: 10.7298 - val_loss: 1418247171.8400 - val_KL_divergence: 10.7441
Epoch 41/100

  1/200 [..............................] - ETA: 1s - loss: 1445477120.0000 - KL_divergence: 11.0313
  7/200 [>.............................] - ETA: 1s - loss: 1420208292.5714 - KL_divergence: 11.0255
 13/200 [>.............................] - ETA: 1s - loss: 1402001289.8462 - KL_divergence: 10.8805
 19/200 [=>............................] - ETA: 1s - loss: 1397774881.6842 - KL_divergence: 10.9474
 26/200 [==>...........................] - ETA: 1s - loss: 1400318798.7692 - KL_divergence: 10.8706
 32/200 [===>..........................] - ETA: 1s - loss: 1404907220.0000 - KL_divergence: 10.8539
 38/200 [====>.........................] - ETA: 1s - loss: 1398685628.6316 - KL_divergence: 10.8773
 44/200 [=====>........................] - ETA: 1s - loss: 1402124279.2727 - KL_divergence: 10.8789
 50/200 [======>.......................] - ETA: 1s - loss: 1396530933.7600 - KL_divergence: 10.8558
 56/200 [=======>......................] - ETA: 1s - loss: 1398680091.4286 - KL_divergence: 10.8540
 62/200 [========>.....................] - ETA: 1s - loss: 1402219381.6774 - KL_divergence: 10.8549
 68/200 [=========>....................] - ETA: 1s - loss: 1398411090.8235 - KL_divergence: 10.8789
 74/200 [==========>...................] - ETA: 1s - loss: 1400283819.2432 - KL_divergence: 10.8834
 80/200 [===========>..................] - ETA: 1s - loss: 1403060038.4000 - KL_divergence: 10.9226
 86/200 [===========>..................] - ETA: 1s - loss: 1407218954.4186 - KL_divergence: 10.9540
 92/200 [============>.................] - ETA: 0s - loss: 1403664749.9130 - KL_divergence: 10.9493
 98/200 [=============>................] - ETA: 0s - loss: 1403640991.3469 - KL_divergence: 10.9400
104/200 [==============>...............] - ETA: 0s - loss: 1406426300.3077 - KL_divergence: 10.9397
110/200 [===============>..............] - ETA: 0s - loss: 1407892009.8909 - KL_divergence: 10.9537
116/200 [================>.............] - ETA: 0s - loss: 1407945223.7241 - KL_divergence: 10.9412
122/200 [=================>............] - ETA: 0s - loss: 1407919028.4590 - KL_divergence: 10.9488
128/200 [==================>...........] - ETA: 0s - loss: 1408658939.0000 - KL_divergence: 10.9618
134/200 [===================>..........] - ETA: 0s - loss: 1407623435.4627 - KL_divergence: 10.9630
140/200 [====================>.........] - ETA: 0s - loss: 1409046381.7143 - KL_divergence: 10.9651
146/200 [====================>.........] - ETA: 0s - loss: 1409452521.2055 - KL_divergence: 10.9806
152/200 [=====================>........] - ETA: 0s - loss: 1409095134.3158 - KL_divergence: 10.9784
158/200 [======================>.......] - ETA: 0s - loss: 1410245983.5949 - KL_divergence: 10.9802
164/200 [=======================>......] - ETA: 0s - loss: 1407894512.3902 - KL_divergence: 10.9958
170/200 [========================>.....] - ETA: 0s - loss: 1407338399.6235 - KL_divergence: 10.9806
176/200 [=========================>....] - ETA: 0s - loss: 1407862386.1818 - KL_divergence: 10.9808
182/200 [==========================>...] - ETA: 0s - loss: 1406710028.6593 - KL_divergence: 10.9790
188/200 [===========================>..] - ETA: 0s - loss: 1405630662.8085 - KL_divergence: 10.9715
194/200 [============================>.] - ETA: 0s - loss: 1406155485.6907 - KL_divergence: 10.9700
200/200 [==============================] - 2s 10ms/step - loss: 1406544778.2400 - KL_divergence: 10.9691 - val_loss: 1409839115.5200 - val_KL_divergence: 10.9150
Epoch 42/100

  1/200 [..............................] - ETA: 1s - loss: 1367835008.0000 - KL_divergence: 11.0753
  7/200 [>.............................] - ETA: 1s - loss: 1403551945.1429 - KL_divergence: 11.1948
 13/200 [>.............................] - ETA: 1s - loss: 1405445681.2308 - KL_divergence: 11.0807
 19/200 [=>............................] - ETA: 1s - loss: 1429029760.0000 - KL_divergence: 11.1511
 25/200 [==>...........................] - ETA: 1s - loss: 1430840125.4400 - KL_divergence: 11.0663
 31/200 [===>..........................] - ETA: 1s - loss: 1428262738.5806 - KL_divergence: 11.0838
 37/200 [====>.........................] - ETA: 1s - loss: 1421609966.7027 - KL_divergence: 11.0741
 44/200 [=====>........................] - ETA: 1s - loss: 1414833213.0909 - KL_divergence: 11.0505
 50/200 [======>.......................] - ETA: 1s - loss: 1410028165.1200 - KL_divergence: 11.0568
 56/200 [=======>......................] - ETA: 1s - loss: 1407813796.5714 - KL_divergence: 11.0510
 62/200 [========>.....................] - ETA: 1s - loss: 1407039128.7742 - KL_divergence: 11.0149
 68/200 [=========>....................] - ETA: 1s - loss: 1404186302.1176 - KL_divergence: 10.9985
 74/200 [==========>...................] - ETA: 1s - loss: 1405579357.4054 - KL_divergence: 11.0025
 81/200 [===========>..................] - ETA: 1s - loss: 1400708323.5556 - KL_divergence: 11.0214
 87/200 [============>.................] - ETA: 0s - loss: 1401677039.8161 - KL_divergence: 11.0425
 93/200 [============>.................] - ETA: 0s - loss: 1398165527.3978 - KL_divergence: 11.0579
 99/200 [=============>................] - ETA: 0s - loss: 1397827851.6364 - KL_divergence: 11.0533
105/200 [==============>...............] - ETA: 0s - loss: 1396860303.8476 - KL_divergence: 11.0640
112/200 [===============>..............] - ETA: 0s - loss: 1398423970.2857 - KL_divergence: 11.0636
118/200 [================>.............] - ETA: 0s - loss: 1399250607.7288 - KL_divergence: 11.0815
124/200 [=================>............] - ETA: 0s - loss: 1401393453.4194 - KL_divergence: 11.0925
130/200 [==================>...........] - ETA: 0s - loss: 1401657603.9385 - KL_divergence: 11.1006
136/200 [===================>..........] - ETA: 0s - loss: 1403004493.1765 - KL_divergence: 11.0975
142/200 [====================>.........] - ETA: 0s - loss: 1403049635.1549 - KL_divergence: 11.0898
148/200 [=====================>........] - ETA: 0s - loss: 1401012754.1622 - KL_divergence: 11.0827
154/200 [======================>.......] - ETA: 0s - loss: 1399170784.4156 - KL_divergence: 11.0770
160/200 [=======================>......] - ETA: 0s - loss: 1400694166.4000 - KL_divergence: 11.0857
166/200 [=======================>......] - ETA: 0s - loss: 1400388456.8675 - KL_divergence: 11.0858
172/200 [========================>.....] - ETA: 0s - loss: 1401547365.9535 - KL_divergence: 11.0829
178/200 [=========================>....] - ETA: 0s - loss: 1401483633.6180 - KL_divergence: 11.0910
184/200 [==========================>...] - ETA: 0s - loss: 1402375110.9565 - KL_divergence: 11.0997
190/200 [===========================>..] - ETA: 0s - loss: 1402682739.2000 - KL_divergence: 11.1148
196/200 [============================>.] - ETA: 0s - loss: 1402235196.7347 - KL_divergence: 11.1086
200/200 [==============================] - 2s 10ms/step - loss: 1402634668.1600 - KL_divergence: 11.1106 - val_loss: 1400843070.7200 - val_KL_divergence: 11.0462
Epoch 43/100

  1/200 [..............................] - ETA: 1s - loss: 1314969600.0000 - KL_divergence: 10.6631
  7/200 [>.............................] - ETA: 1s - loss: 1398357979.4286 - KL_divergence: 11.3487
 13/200 [>.............................] - ETA: 1s - loss: 1394050471.3846 - KL_divergence: 11.2676
 20/200 [==>...........................] - ETA: 1s - loss: 1384064345.6000 - KL_divergence: 11.3059
 27/200 [===>..........................] - ETA: 1s - loss: 1397203356.4444 - KL_divergence: 11.3464
 33/200 [===>..........................] - ETA: 1s - loss: 1396837123.8788 - KL_divergence: 11.3381
 39/200 [====>.........................] - ETA: 1s - loss: 1395162010.2564 - KL_divergence: 11.3228
 46/200 [=====>........................] - ETA: 1s - loss: 1397760253.2174 - KL_divergence: 11.2730
 52/200 [======>.......................] - ETA: 1s - loss: 1399701649.2308 - KL_divergence: 11.2361
 58/200 [=======>......................] - ETA: 1s - loss: 1407005398.0690 - KL_divergence: 11.2068
 64/200 [========>.....................] - ETA: 1s - loss: 1409561982.0000 - KL_divergence: 11.1806
 70/200 [=========>....................] - ETA: 1s - loss: 1405820878.6286 - KL_divergence: 11.1681
 76/200 [==========>...................] - ETA: 1s - loss: 1406120653.4737 - KL_divergence: 11.1471
 82/200 [===========>..................] - ETA: 1s - loss: 1407495459.9024 - KL_divergence: 11.1556
 88/200 [============>.................] - ETA: 0s - loss: 1407386174.5455 - KL_divergence: 11.1506
 94/200 [=============>................] - ETA: 0s - loss: 1409038040.5106 - KL_divergence: 11.1567
100/200 [==============>...............] - ETA: 0s - loss: 1409584322.5600 - KL_divergence: 11.1525
106/200 [==============>...............] - ETA: 0s - loss: 1407264489.0566 - KL_divergence: 11.1524
112/200 [===============>..............] - ETA: 0s - loss: 1407421940.5714 - KL_divergence: 11.1812
118/200 [================>.............] - ETA: 0s - loss: 1406707533.0169 - KL_divergence: 11.1814
124/200 [=================>............] - ETA: 0s - loss: 1407554116.1290 - KL_divergence: 11.1837
130/200 [==================>...........] - ETA: 0s - loss: 1406676491.8154 - KL_divergence: 11.1797
136/200 [===================>..........] - ETA: 0s - loss: 1407058244.7059 - KL_divergence: 11.1710
142/200 [====================>.........] - ETA: 0s - loss: 1403449133.9718 - KL_divergence: 11.1703
148/200 [=====================>........] - ETA: 0s - loss: 1402788039.7838 - KL_divergence: 11.1824
154/200 [======================>.......] - ETA: 0s - loss: 1401283134.3377 - KL_divergence: 11.1700
160/200 [=======================>......] - ETA: 0s - loss: 1402031437.6000 - KL_divergence: 11.1576
167/200 [========================>.....] - ETA: 0s - loss: 1400643833.1018 - KL_divergence: 11.1663
173/200 [========================>.....] - ETA: 0s - loss: 1400756660.5318 - KL_divergence: 11.1603
179/200 [=========================>....] - ETA: 0s - loss: 1399846495.8212 - KL_divergence: 11.1412
185/200 [==========================>...] - ETA: 0s - loss: 1400686058.5514 - KL_divergence: 11.1437
191/200 [===========================>..] - ETA: 0s - loss: 1399957906.7644 - KL_divergence: 11.1421
197/200 [============================>.] - ETA: 0s - loss: 1398654987.6954 - KL_divergence: 11.1397
200/200 [==============================] - 2s 10ms/step - loss: 1399874314.2400 - KL_divergence: 11.1293 - val_loss: 1420641352.9600 - val_KL_divergence: 11.1260
Epoch 44/100

  1/200 [..............................] - ETA: 1s - loss: 1480995328.0000 - KL_divergence: 11.6544
  8/200 [>.............................] - ETA: 1s - loss: 1400864032.0000 - KL_divergence: 11.1722
 14/200 [=>............................] - ETA: 1s - loss: 1383502820.5714 - KL_divergence: 11.1282
 20/200 [==>...........................] - ETA: 1s - loss: 1377125446.4000 - KL_divergence: 10.9923
 26/200 [==>...........................] - ETA: 1s - loss: 1384484755.6923 - KL_divergence: 11.0095
 32/200 [===>..........................] - ETA: 1s - loss: 1387545268.0000 - KL_divergence: 11.0332
 38/200 [====>.........................] - ETA: 1s - loss: 1391637786.9474 - KL_divergence: 11.1064
 44/200 [=====>........................] - ETA: 1s - loss: 1392276421.8182 - KL_divergence: 11.1351
 50/200 [======>.......................] - ETA: 1s - loss: 1394130606.0800 - KL_divergence: 11.1455
 56/200 [=======>......................] - ETA: 1s - loss: 1392025243.4286 - KL_divergence: 11.1558
 62/200 [========>.....................] - ETA: 1s - loss: 1386509774.4516 - KL_divergence: 11.1735
 68/200 [=========>....................] - ETA: 1s - loss: 1389128886.5882 - KL_divergence: 11.1747
 74/200 [==========>...................] - ETA: 1s - loss: 1388639541.6216 - KL_divergence: 11.1970
 80/200 [===========>..................] - ETA: 1s - loss: 1390189049.6000 - KL_divergence: 11.1976
 86/200 [===========>..................] - ETA: 1s - loss: 1387582961.1163 - KL_divergence: 11.1994
 92/200 [============>.................] - ETA: 0s - loss: 1386214436.1739 - KL_divergence: 11.2044
 98/200 [=============>................] - ETA: 0s - loss: 1389939489.9592 - KL_divergence: 11.2479
104/200 [==============>...............] - ETA: 0s - loss: 1387743257.8462 - KL_divergence: 11.2437
110/200 [===============>..............] - ETA: 0s - loss: 1391305024.0000 - KL_divergence: 11.2314
116/200 [================>.............] - ETA: 0s - loss: 1392104219.5862 - KL_divergence: 11.2357
122/200 [=================>............] - ETA: 0s - loss: 1392212847.2131 - KL_divergence: 11.2299
128/200 [==================>...........] - ETA: 0s - loss: 1393318692.0000 - KL_divergence: 11.2065
134/200 [===================>..........] - ETA: 0s - loss: 1392362066.1493 - KL_divergence: 11.1914
139/200 [===================>..........] - ETA: 0s - loss: 1391435565.1223 - KL_divergence: 11.2004
145/200 [====================>.........] - ETA: 0s - loss: 1394246263.1724 - KL_divergence: 11.2108
150/200 [=====================>........] - ETA: 0s - loss: 1395226791.2533 - KL_divergence: 11.2138
156/200 [======================>.......] - ETA: 0s - loss: 1393387631.5897 - KL_divergence: 11.2016
162/200 [=======================>......] - ETA: 0s - loss: 1393426111.2099 - KL_divergence: 11.1941
168/200 [========================>.....] - ETA: 0s - loss: 1393248908.9524 - KL_divergence: 11.2046
174/200 [=========================>....] - ETA: 0s - loss: 1392581783.5402 - KL_divergence: 11.2036
180/200 [==========================>...] - ETA: 0s - loss: 1392254038.0444 - KL_divergence: 11.2166
186/200 [==========================>...] - ETA: 0s - loss: 1391327736.4301 - KL_divergence: 11.2251
192/200 [===========================>..] - ETA: 0s - loss: 1391123886.6667 - KL_divergence: 11.2272
198/200 [============================>.] - ETA: 0s - loss: 1390517717.9798 - KL_divergence: 11.2252
200/200 [==============================] - 2s 10ms/step - loss: 1390006284.1600 - KL_divergence: 11.2230 - val_loss: 1398538100.4800 - val_KL_divergence: 11.2556
Epoch 45/100

  1/200 [..............................] - ETA: 1s - loss: 1287040896.0000 - KL_divergence: 10.9995
  7/200 [>.............................] - ETA: 1s - loss: 1340709504.0000 - KL_divergence: 11.2685
 13/200 [>.............................] - ETA: 1s - loss: 1370340273.2308 - KL_divergence: 11.4044
 19/200 [=>............................] - ETA: 1s - loss: 1376466256.8421 - KL_divergence: 11.2647
 25/200 [==>...........................] - ETA: 1s - loss: 1382979491.8400 - KL_divergence: 11.1305
 31/200 [===>..........................] - ETA: 1s - loss: 1379963045.1613 - KL_divergence: 11.1363
 37/200 [====>.........................] - ETA: 1s - loss: 1388428755.0270 - KL_divergence: 11.0956
 43/200 [=====>........................] - ETA: 1s - loss: 1384006274.9767 - KL_divergence: 11.1244
 49/200 [======>.......................] - ETA: 1s - loss: 1379571239.1837 - KL_divergence: 11.1322
 55/200 [=======>......................] - ETA: 1s - loss: 1384644170.4727 - KL_divergence: 11.1235
 61/200 [========>.....................] - ETA: 1s - loss: 1385774608.7869 - KL_divergence: 11.1332
 67/200 [=========>....................] - ETA: 1s - loss: 1388293710.3284 - KL_divergence: 11.1367
 73/200 [=========>....................] - ETA: 1s - loss: 1387077624.9863 - KL_divergence: 11.1156
 79/200 [==========>...................] - ETA: 1s - loss: 1387178583.4937 - KL_divergence: 11.1094
 85/200 [===========>..................] - ETA: 1s - loss: 1386329613.5529 - KL_divergence: 11.1092
 91/200 [============>.................] - ETA: 0s - loss: 1387567450.0220 - KL_divergence: 11.1102
 97/200 [=============>................] - ETA: 0s - loss: 1385284453.6082 - KL_divergence: 11.0971
103/200 [==============>...............] - ETA: 0s - loss: 1388267681.5534 - KL_divergence: 11.0748
109/200 [===============>..............] - ETA: 0s - loss: 1387298002.2018 - KL_divergence: 11.0957
115/200 [================>.............] - ETA: 0s - loss: 1386970645.1478 - KL_divergence: 11.0909
121/200 [=================>............] - ETA: 0s - loss: 1387943491.7025 - KL_divergence: 11.0904
127/200 [==================>...........] - ETA: 0s - loss: 1388937682.6457 - KL_divergence: 11.0807
133/200 [==================>...........] - ETA: 0s - loss: 1388487120.8421 - KL_divergence: 11.0629
139/200 [===================>..........] - ETA: 0s - loss: 1388206824.0576 - KL_divergence: 11.0636
145/200 [====================>.........] - ETA: 0s - loss: 1388181122.6483 - KL_divergence: 11.0595
151/200 [=====================>........] - ETA: 0s - loss: 1388939933.6689 - KL_divergence: 11.0725
157/200 [======================>.......] - ETA: 0s - loss: 1389357291.6178 - KL_divergence: 11.0764
163/200 [=======================>......] - ETA: 0s - loss: 1390443305.6196 - KL_divergence: 11.0894
169/200 [========================>.....] - ETA: 0s - loss: 1391237758.4852 - KL_divergence: 11.0887
175/200 [=========================>....] - ETA: 0s - loss: 1391723353.9657 - KL_divergence: 11.0836
181/200 [==========================>...] - ETA: 0s - loss: 1392744769.0608 - KL_divergence: 11.0694
187/200 [===========================>..] - ETA: 0s - loss: 1393051688.3850 - KL_divergence: 11.0718
193/200 [===========================>..] - ETA: 0s - loss: 1392424789.5544 - KL_divergence: 11.0685
199/200 [============================>.] - ETA: 0s - loss: 1390324331.4171 - KL_divergence: 11.0605
200/200 [==============================] - 2s 10ms/step - loss: 1390850553.6000 - KL_divergence: 11.0600 - val_loss: 1402924660.4800 - val_KL_divergence: 10.8991
Epoch 46/100

  1/200 [..............................] - ETA: 1s - loss: 1401053568.0000 - KL_divergence: 10.7813
  8/200 [>.............................] - ETA: 1s - loss: 1374665824.0000 - KL_divergence: 11.2156
 14/200 [=>............................] - ETA: 1s - loss: 1375738925.7143 - KL_divergence: 11.0247
 20/200 [==>...........................] - ETA: 1s - loss: 1375278272.0000 - KL_divergence: 11.0658
 26/200 [==>...........................] - ETA: 1s - loss: 1381022523.0769 - KL_divergence: 11.0821
 32/200 [===>..........................] - ETA: 1s - loss: 1381207208.0000 - KL_divergence: 11.0986
 38/200 [====>.........................] - ETA: 1s - loss: 1379722667.7895 - KL_divergence: 11.1066
 44/200 [=====>........................] - ETA: 1s - loss: 1379806240.0000 - KL_divergence: 11.1117
 50/200 [======>.......................] - ETA: 1s - loss: 1371933189.1200 - KL_divergence: 11.1250
 56/200 [=======>......................] - ETA: 1s - loss: 1372488073.1429 - KL_divergence: 11.1020
 62/200 [========>.....................] - ETA: 1s - loss: 1369982895.4839 - KL_divergence: 11.0993
 68/200 [=========>....................] - ETA: 1s - loss: 1371227941.6471 - KL_divergence: 11.1063
 74/200 [==========>...................] - ETA: 1s - loss: 1374333270.4865 - KL_divergence: 11.0997
 81/200 [===========>..................] - ETA: 1s - loss: 1376222225.3827 - KL_divergence: 11.1052
 87/200 [============>.................] - ETA: 0s - loss: 1385162307.6782 - KL_divergence: 11.1121
 93/200 [============>.................] - ETA: 0s - loss: 1384543574.7097 - KL_divergence: 11.1056
 99/200 [=============>................] - ETA: 0s - loss: 1383356419.8788 - KL_divergence: 11.0893
105/200 [==============>...............] - ETA: 0s - loss: 1385979646.7810 - KL_divergence: 11.0793
112/200 [===============>..............] - ETA: 0s - loss: 1386719360.0000 - KL_divergence: 11.0774
118/200 [================>.............] - ETA: 0s - loss: 1387201906.9831 - KL_divergence: 11.0630
124/200 [=================>............] - ETA: 0s - loss: 1385364124.9032 - KL_divergence: 11.0646
130/200 [==================>...........] - ETA: 0s - loss: 1383951808.9846 - KL_divergence: 11.0620
136/200 [===================>..........] - ETA: 0s - loss: 1384247728.0000 - KL_divergence: 11.0817
142/200 [====================>.........] - ETA: 0s - loss: 1385759041.8028 - KL_divergence: 11.0887
148/200 [=====================>........] - ETA: 0s - loss: 1385873463.3514 - KL_divergence: 11.1091
154/200 [======================>.......] - ETA: 0s - loss: 1384384276.7792 - KL_divergence: 11.0981
160/200 [=======================>......] - ETA: 0s - loss: 1383447868.0000 - KL_divergence: 11.0997
166/200 [=======================>......] - ETA: 0s - loss: 1382273754.9880 - KL_divergence: 11.1039
172/200 [========================>.....] - ETA: 0s - loss: 1381110744.5581 - KL_divergence: 11.1043
178/200 [=========================>....] - ETA: 0s - loss: 1381731711.2809 - KL_divergence: 11.1132
184/200 [==========================>...] - ETA: 0s - loss: 1381285001.7391 - KL_divergence: 11.1140
190/200 [===========================>..] - ETA: 0s - loss: 1382562710.9053 - KL_divergence: 11.1098
196/200 [============================>.] - ETA: 0s - loss: 1382852202.4490 - KL_divergence: 11.1065
200/200 [==============================] - 2s 10ms/step - loss: 1382393367.6800 - KL_divergence: 11.1125 - val_loss: 1396527868.1600 - val_KL_divergence: 10.8694
Epoch 47/100

  1/200 [..............................] - ETA: 1s - loss: 1416566912.0000 - KL_divergence: 11.8256
  7/200 [>.............................] - ETA: 1s - loss: 1389499940.5714 - KL_divergence: 10.9884
 13/200 [>.............................] - ETA: 1s - loss: 1388118557.5385 - KL_divergence: 11.0823
 19/200 [=>............................] - ETA: 1s - loss: 1389485318.7368 - KL_divergence: 11.0348
 25/200 [==>...........................] - ETA: 1s - loss: 1397406981.1200 - KL_divergence: 11.1078
 31/200 [===>..........................] - ETA: 1s - loss: 1392920885.6774 - KL_divergence: 11.0737
 37/200 [====>.........................] - ETA: 1s - loss: 1393968124.5405 - KL_divergence: 11.0754
 43/200 [=====>........................] - ETA: 1s - loss: 1392173758.5116 - KL_divergence: 10.9914
 49/200 [======>.......................] - ETA: 1s - loss: 1392979662.3673 - KL_divergence: 10.9635
 55/200 [=======>......................] - ETA: 1s - loss: 1391264474.7636 - KL_divergence: 10.9356
 61/200 [========>.....................] - ETA: 1s - loss: 1390147678.4262 - KL_divergence: 10.9405
 67/200 [=========>....................] - ETA: 1s - loss: 1387245973.0149 - KL_divergence: 10.9302
 73/200 [=========>....................] - ETA: 1s - loss: 1392470489.4247 - KL_divergence: 10.9375
 79/200 [==========>...................] - ETA: 1s - loss: 1390549977.1139 - KL_divergence: 10.9541
 85/200 [===========>..................] - ETA: 1s - loss: 1389723223.3412 - KL_divergence: 10.9316
 91/200 [============>.................] - ETA: 0s - loss: 1391394690.8132 - KL_divergence: 10.9510
 98/200 [=============>................] - ETA: 0s - loss: 1390892674.6122 - KL_divergence: 10.9254
104/200 [==============>...............] - ETA: 0s - loss: 1391487474.4615 - KL_divergence: 10.9267
110/200 [===============>..............] - ETA: 0s - loss: 1390309961.3091 - KL_divergence: 10.9237
116/200 [================>.............] - ETA: 0s - loss: 1387784454.6207 - KL_divergence: 10.9232
122/200 [=================>............] - ETA: 0s - loss: 1387175473.3115 - KL_divergence: 10.9234
128/200 [==================>...........] - ETA: 0s - loss: 1387865431.0000 - KL_divergence: 10.9378
134/200 [===================>..........] - ETA: 0s - loss: 1388187724.4179 - KL_divergence: 10.9420
140/200 [====================>.........] - ETA: 0s - loss: 1390150829.7143 - KL_divergence: 10.9460
146/200 [====================>.........] - ETA: 0s - loss: 1389758708.6027 - KL_divergence: 10.9512
152/200 [=====================>........] - ETA: 0s - loss: 1391800608.0000 - KL_divergence: 10.9711
158/200 [======================>.......] - ETA: 0s - loss: 1391441234.6329 - KL_divergence: 10.9675
164/200 [=======================>......] - ETA: 0s - loss: 1392089934.8293 - KL_divergence: 10.9760
170/200 [========================>.....] - ETA: 0s - loss: 1390590488.8471 - KL_divergence: 10.9717
176/200 [=========================>....] - ETA: 0s - loss: 1390629009.4545 - KL_divergence: 10.9732
182/200 [==========================>...] - ETA: 0s - loss: 1390507271.7363 - KL_divergence: 10.9725
188/200 [===========================>..] - ETA: 0s - loss: 1391444205.6170 - KL_divergence: 10.9761
194/200 [============================>.] - ETA: 0s - loss: 1390995380.1237 - KL_divergence: 10.9647
200/200 [==============================] - 2s 10ms/step - loss: 1389132919.6800 - KL_divergence: 10.9699 - val_loss: 1387793049.6000 - val_KL_divergence: 10.9844
Epoch 48/100

  1/200 [..............................] - ETA: 1s - loss: 1357865216.0000 - KL_divergence: 11.9648
  8/200 [>.............................] - ETA: 1s - loss: 1312028576.0000 - KL_divergence: 10.9253
 14/200 [=>............................] - ETA: 1s - loss: 1325813321.1429 - KL_divergence: 10.8317
 20/200 [==>...........................] - ETA: 1s - loss: 1345143500.8000 - KL_divergence: 10.8464
 26/200 [==>...........................] - ETA: 1s - loss: 1353210663.3846 - KL_divergence: 10.8715
 32/200 [===>..........................] - ETA: 1s - loss: 1366923688.0000 - KL_divergence: 10.9793
 38/200 [====>.........................] - ETA: 1s - loss: 1367642516.2105 - KL_divergence: 10.9681
 44/200 [=====>........................] - ETA: 1s - loss: 1366137521.4545 - KL_divergence: 10.9234
 50/200 [======>.......................] - ETA: 1s - loss: 1365800194.5600 - KL_divergence: 10.9312
 56/200 [=======>......................] - ETA: 1s - loss: 1369394516.5714 - KL_divergence: 10.9169
 62/200 [========>.....................] - ETA: 1s - loss: 1371485016.7742 - KL_divergence: 10.9249
 68/200 [=========>....................] - ETA: 1s - loss: 1373419920.9412 - KL_divergence: 10.9054
 74/200 [==========>...................] - ETA: 1s - loss: 1373503794.1622 - KL_divergence: 10.9134
 80/200 [===========>..................] - ETA: 1s - loss: 1377253556.8000 - KL_divergence: 10.8998
 86/200 [===========>..................] - ETA: 1s - loss: 1377554375.4419 - KL_divergence: 10.9101
 92/200 [============>.................] - ETA: 0s - loss: 1376694390.2609 - KL_divergence: 10.9057
 98/200 [=============>................] - ETA: 0s - loss: 1378614157.0612 - KL_divergence: 10.9076
104/200 [==============>...............] - ETA: 0s - loss: 1379789079.3846 - KL_divergence: 10.9020
110/200 [===============>..............] - ETA: 0s - loss: 1381652694.1091 - KL_divergence: 10.9011
116/200 [================>.............] - ETA: 0s - loss: 1382102489.3793 - KL_divergence: 10.9090
122/200 [=================>............] - ETA: 0s - loss: 1382286962.3607 - KL_divergence: 10.9209
128/200 [==================>...........] - ETA: 0s - loss: 1383268001.0000 - KL_divergence: 10.9203
134/200 [===================>..........] - ETA: 0s - loss: 1383526218.5075 - KL_divergence: 10.9459
140/200 [====================>.........] - ETA: 0s - loss: 1382684528.4571 - KL_divergence: 10.9446
146/200 [====================>.........] - ETA: 0s - loss: 1382514907.1781 - KL_divergence: 10.9505
152/200 [=====================>........] - ETA: 0s - loss: 1382716495.1579 - KL_divergence: 10.9535
158/200 [======================>.......] - ETA: 0s - loss: 1382624670.7848 - KL_divergence: 10.9554
164/200 [=======================>......] - ETA: 0s - loss: 1380616337.9512 - KL_divergence: 10.9662
170/200 [========================>.....] - ETA: 0s - loss: 1379194028.4235 - KL_divergence: 10.9757
176/200 [=========================>....] - ETA: 0s - loss: 1379599132.3636 - KL_divergence: 10.9874
182/200 [==========================>...] - ETA: 0s - loss: 1379633742.7692 - KL_divergence: 11.0032
188/200 [===========================>..] - ETA: 0s - loss: 1378776988.5957 - KL_divergence: 11.0083
194/200 [============================>.] - ETA: 0s - loss: 1379012514.3093 - KL_divergence: 11.0107
200/200 [==============================] - 2s 10ms/step - loss: 1379679349.7600 - KL_divergence: 11.0101 - val_loss: 1393484254.7200 - val_KL_divergence: 11.3182
Epoch 49/100

  1/200 [..............................] - ETA: 1s - loss: 1372539904.0000 - KL_divergence: 11.0939
  7/200 [>.............................] - ETA: 1s - loss: 1408479451.4286 - KL_divergence: 11.0955
 13/200 [>.............................] - ETA: 1s - loss: 1389309164.3077 - KL_divergence: 11.1341
 19/200 [=>............................] - ETA: 1s - loss: 1390659065.2632 - KL_divergence: 11.1422
 25/200 [==>...........................] - ETA: 1s - loss: 1391758279.6800 - KL_divergence: 11.0872
 31/200 [===>..........................] - ETA: 1s - loss: 1388694779.8710 - KL_divergence: 11.0818
 37/200 [====>.........................] - ETA: 1s - loss: 1385501813.6216 - KL_divergence: 10.9932
 43/200 [=====>........................] - ETA: 1s - loss: 1385451725.3953 - KL_divergence: 10.9894
 49/200 [======>.......................] - ETA: 1s - loss: 1378563035.4286 - KL_divergence: 11.0181
 55/200 [=======>......................] - ETA: 1s - loss: 1372239383.2727 - KL_divergence: 11.0093
 61/200 [========>.....................] - ETA: 1s - loss: 1375864064.0000 - KL_divergence: 11.0609
 67/200 [=========>....................] - ETA: 1s - loss: 1379710592.0000 - KL_divergence: 11.0669
 73/200 [=========>....................] - ETA: 1s - loss: 1376514872.1096 - KL_divergence: 11.0395
 79/200 [==========>...................] - ETA: 1s - loss: 1375591415.8987 - KL_divergence: 11.0356
 85/200 [===========>..................] - ETA: 1s - loss: 1378650038.2118 - KL_divergence: 11.0554
 91/200 [============>.................] - ETA: 0s - loss: 1377388845.0110 - KL_divergence: 11.0591
 97/200 [=============>................] - ETA: 0s - loss: 1376393027.2990 - KL_divergence: 11.0548
103/200 [==============>...............] - ETA: 0s - loss: 1376499264.6214 - KL_divergence: 11.0684
109/200 [===============>..............] - ETA: 0s - loss: 1374970403.2294 - KL_divergence: 11.0822
115/200 [================>.............] - ETA: 0s - loss: 1373478359.9304 - KL_divergence: 11.1056
121/200 [=================>............] - ETA: 0s - loss: 1373862851.7025 - KL_divergence: 11.1250
127/200 [==================>...........] - ETA: 0s - loss: 1372999372.5984 - KL_divergence: 11.1288
133/200 [==================>...........] - ETA: 0s - loss: 1372209516.7519 - KL_divergence: 11.1383
139/200 [===================>..........] - ETA: 0s - loss: 1373920686.9640 - KL_divergence: 11.1336
145/200 [====================>.........] - ETA: 0s - loss: 1373291387.5862 - KL_divergence: 11.1205
151/200 [=====================>........] - ETA: 0s - loss: 1372828204.0795 - KL_divergence: 11.1269
158/200 [======================>.......] - ETA: 0s - loss: 1374191782.0759 - KL_divergence: 11.1494
164/200 [=======================>......] - ETA: 0s - loss: 1372639617.5610 - KL_divergence: 11.1528
170/200 [========================>.....] - ETA: 0s - loss: 1372229752.4706 - KL_divergence: 11.1509
176/200 [=========================>....] - ETA: 0s - loss: 1372195285.8182 - KL_divergence: 11.1406
182/200 [==========================>...] - ETA: 0s - loss: 1372172656.5275 - KL_divergence: 11.1491
188/200 [===========================>..] - ETA: 0s - loss: 1372526807.8298 - KL_divergence: 11.1630
194/200 [============================>.] - ETA: 0s - loss: 1371981576.5773 - KL_divergence: 11.1809
200/200 [==============================] - 2s 10ms/step - loss: 1373412906.8800 - KL_divergence: 11.1789 - val_loss: 1399143571.2000 - val_KL_divergence: 11.1594
Epoch 50/100

  1/200 [..............................] - ETA: 1s - loss: 1419201536.0000 - KL_divergence: 11.5718
  7/200 [>.............................] - ETA: 1s - loss: 1375335680.0000 - KL_divergence: 11.7359
 13/200 [>.............................] - ETA: 1s - loss: 1372933828.9231 - KL_divergence: 11.5707
 19/200 [=>............................] - ETA: 1s - loss: 1377551312.8421 - KL_divergence: 11.5902
 25/200 [==>...........................] - ETA: 1s - loss: 1385179018.2400 - KL_divergence: 11.4861
 31/200 [===>..........................] - ETA: 1s - loss: 1383301504.0000 - KL_divergence: 11.4457
 37/200 [====>.........................] - ETA: 1s - loss: 1384737750.4865 - KL_divergence: 11.4136
 43/200 [=====>........................] - ETA: 1s - loss: 1377462706.6047 - KL_divergence: 11.3298
 49/200 [======>.......................] - ETA: 1s - loss: 1377600579.9184 - KL_divergence: 11.3600
 55/200 [=======>......................] - ETA: 1s - loss: 1373375590.4000 - KL_divergence: 11.3236
 61/200 [========>.....................] - ETA: 1s - loss: 1371622414.6885 - KL_divergence: 11.3167
 68/200 [=========>....................] - ETA: 1s - loss: 1373360425.4118 - KL_divergence: 11.3027
 75/200 [==========>...................] - ETA: 1s - loss: 1372600478.7200 - KL_divergence: 11.2955
 81/200 [===========>..................] - ETA: 1s - loss: 1371948643.5556 - KL_divergence: 11.3059
 87/200 [============>.................] - ETA: 1s - loss: 1375302967.9080 - KL_divergence: 11.3215
 93/200 [============>.................] - ETA: 0s - loss: 1375303235.4409 - KL_divergence: 11.3249
 99/200 [=============>................] - ETA: 0s - loss: 1375416603.1515 - KL_divergence: 11.3174
105/200 [==============>...............] - ETA: 0s - loss: 1373674684.9524 - KL_divergence: 11.3227
111/200 [===============>..............] - ETA: 0s - loss: 1373438543.5676 - KL_divergence: 11.3338
118/200 [================>.............] - ETA: 0s - loss: 1372654316.4746 - KL_divergence: 11.3399
124/200 [=================>............] - ETA: 0s - loss: 1372174662.1935 - KL_divergence: 11.3214
130/200 [==================>...........] - ETA: 0s - loss: 1371141750.1538 - KL_divergence: 11.3210
136/200 [===================>..........] - ETA: 0s - loss: 1373567064.4706 - KL_divergence: 11.3346
142/200 [====================>.........] - ETA: 0s - loss: 1374322553.6901 - KL_divergence: 11.3347
148/200 [=====================>........] - ETA: 0s - loss: 1374853483.2432 - KL_divergence: 11.3373
154/200 [======================>.......] - ETA: 0s - loss: 1376286769.0390 - KL_divergence: 11.3498
160/200 [=======================>......] - ETA: 0s - loss: 1376369482.4000 - KL_divergence: 11.3425
167/200 [========================>.....] - ETA: 0s - loss: 1376167968.1916 - KL_divergence: 11.3686
173/200 [========================>.....] - ETA: 0s - loss: 1376129067.6532 - KL_divergence: 11.3835
180/200 [==========================>...] - ETA: 0s - loss: 1377419682.1333 - KL_divergence: 11.3962
186/200 [==========================>...] - ETA: 0s - loss: 1377865067.3548 - KL_divergence: 11.3958
192/200 [===========================>..] - ETA: 0s - loss: 1377311706.6667 - KL_divergence: 11.3991
199/200 [============================>.] - ETA: 0s - loss: 1377096594.6533 - KL_divergence: 11.3977
200/200 [==============================] - 2s 10ms/step - loss: 1377172645.1200 - KL_divergence: 11.3951 - val_loss: 1418376065.2800 - val_KL_divergence: 11.5412
Epoch 51/100

  1/200 [..............................] - ETA: 1s - loss: 1508928256.0000 - KL_divergence: 13.6198
  7/200 [>.............................] - ETA: 1s - loss: 1410867474.2857 - KL_divergence: 12.0819
 13/200 [>.............................] - ETA: 1s - loss: 1419227332.9231 - KL_divergence: 11.8528
 19/200 [=>............................] - ETA: 1s - loss: 1401221591.5789 - KL_divergence: 11.8728
 25/200 [==>...........................] - ETA: 1s - loss: 1403131678.7200 - KL_divergence: 11.8829
 30/200 [===>..........................] - ETA: 1s - loss: 1397615283.2000 - KL_divergence: 11.8893
 36/200 [====>.........................] - ETA: 1s - loss: 1392376263.1111 - KL_divergence: 11.7107
 42/200 [=====>........................] - ETA: 1s - loss: 1394053184.0000 - KL_divergence: 11.6812
 48/200 [======>.......................] - ETA: 1s - loss: 1395567269.3333 - KL_divergence: 11.6575
 54/200 [=======>......................] - ETA: 1s - loss: 1388071357.6296 - KL_divergence: 11.5687
 60/200 [========>.....................] - ETA: 1s - loss: 1389674598.4000 - KL_divergence: 11.5815
 66/200 [========>.....................] - ETA: 1s - loss: 1387819933.0909 - KL_divergence: 11.5941
 72/200 [=========>....................] - ETA: 1s - loss: 1386676922.6667 - KL_divergence: 11.5491
 78/200 [==========>...................] - ETA: 1s - loss: 1385390319.5897 - KL_divergence: 11.5551
 84/200 [===========>..................] - ETA: 1s - loss: 1388237828.5714 - KL_divergence: 11.5177
 90/200 [============>.................] - ETA: 1s - loss: 1387161254.4000 - KL_divergence: 11.5302
 96/200 [=============>................] - ETA: 0s - loss: 1384700020.0000 - KL_divergence: 11.5105
102/200 [==============>...............] - ETA: 0s - loss: 1380439504.3137 - KL_divergence: 11.5077
108/200 [===============>..............] - ETA: 0s - loss: 1383521833.4815 - KL_divergence: 11.5114
114/200 [================>.............] - ETA: 0s - loss: 1380235329.1228 - KL_divergence: 11.4954
120/200 [=================>............] - ETA: 0s - loss: 1379230906.6667 - KL_divergence: 11.4953
126/200 [=================>............] - ETA: 0s - loss: 1378461020.4444 - KL_divergence: 11.5045
132/200 [==================>...........] - ETA: 0s - loss: 1378557559.2727 - KL_divergence: 11.4994
138/200 [===================>..........] - ETA: 0s - loss: 1378310266.4348 - KL_divergence: 11.4936
144/200 [====================>.........] - ETA: 0s - loss: 1379231381.3333 - KL_divergence: 11.5112
150/200 [=====================>........] - ETA: 0s - loss: 1378764998.8267 - KL_divergence: 11.5003
156/200 [======================>.......] - ETA: 0s - loss: 1378917256.2051 - KL_divergence: 11.5115
162/200 [=======================>......] - ETA: 0s - loss: 1379798589.6296 - KL_divergence: 11.5083
168/200 [========================>.....] - ETA: 0s - loss: 1378451498.6667 - KL_divergence: 11.5118
174/200 [=========================>....] - ETA: 0s - loss: 1378907878.9885 - KL_divergence: 11.5160
180/200 [==========================>...] - ETA: 0s - loss: 1379907062.7556 - KL_divergence: 11.4903
186/200 [==========================>...] - ETA: 0s - loss: 1378777350.1935 - KL_divergence: 11.4831
192/200 [===========================>..] - ETA: 0s - loss: 1378533906.6667 - KL_divergence: 11.4744
198/200 [============================>.] - ETA: 0s - loss: 1378078370.2626 - KL_divergence: 11.4847
200/200 [==============================] - 2s 10ms/step - loss: 1379031319.6800 - KL_divergence: 11.4858 - val_loss: 1400303175.6800 - val_KL_divergence: 11.4981
Epoch 52/100

  1/200 [..............................] - ETA: 1s - loss: 1477659008.0000 - KL_divergence: 11.8938
  7/200 [>.............................] - ETA: 1s - loss: 1358454912.0000 - KL_divergence: 11.5735
 13/200 [>.............................] - ETA: 1s - loss: 1367795731.6923 - KL_divergence: 11.7302
 19/200 [=>............................] - ETA: 1s - loss: 1360698280.4211 - KL_divergence: 11.5077
 25/200 [==>...........................] - ETA: 1s - loss: 1361884134.4000 - KL_divergence: 11.4230
 31/200 [===>..........................] - ETA: 1s - loss: 1367010432.0000 - KL_divergence: 11.3143
 37/200 [====>.........................] - ETA: 1s - loss: 1374289006.7027 - KL_divergence: 11.2470
 43/200 [=====>........................] - ETA: 1s - loss: 1378848753.1163 - KL_divergence: 11.3390
 48/200 [======>.......................] - ETA: 1s - loss: 1378001394.6667 - KL_divergence: 11.3554
 54/200 [=======>......................] - ETA: 1s - loss: 1380124484.7407 - KL_divergence: 11.3857
 60/200 [========>.....................] - ETA: 1s - loss: 1376913307.7333 - KL_divergence: 11.3795
 66/200 [========>.....................] - ETA: 1s - loss: 1375071464.7273 - KL_divergence: 11.3884
 72/200 [=========>....................] - ETA: 1s - loss: 1376441105.7778 - KL_divergence: 11.4060
 78/200 [==========>...................] - ETA: 1s - loss: 1376171311.5897 - KL_divergence: 11.4081
 84/200 [===========>..................] - ETA: 1s - loss: 1377343070.4762 - KL_divergence: 11.4275
 90/200 [============>.................] - ETA: 1s - loss: 1376295917.5111 - KL_divergence: 11.4293
 97/200 [=============>................] - ETA: 0s - loss: 1372199813.2784 - KL_divergence: 11.4524
103/200 [==============>...............] - ETA: 0s - loss: 1374046854.2136 - KL_divergence: 11.4691
109/200 [===============>..............] - ETA: 0s - loss: 1373498311.6330 - KL_divergence: 11.4949
115/200 [================>.............] - ETA: 0s - loss: 1371204902.9565 - KL_divergence: 11.4680
121/200 [=================>............] - ETA: 0s - loss: 1371560652.1653 - KL_divergence: 11.4445
127/200 [==================>...........] - ETA: 0s - loss: 1371945944.6929 - KL_divergence: 11.4402
133/200 [==================>...........] - ETA: 0s - loss: 1371407810.4060 - KL_divergence: 11.4570
139/200 [===================>..........] - ETA: 0s - loss: 1372046859.9712 - KL_divergence: 11.4575
145/200 [====================>.........] - ETA: 0s - loss: 1372712545.1034 - KL_divergence: 11.4454
151/200 [=====================>........] - ETA: 0s - loss: 1374808684.5033 - KL_divergence: 11.4306
157/200 [======================>.......] - ETA: 0s - loss: 1373177692.9427 - KL_divergence: 11.4359
163/200 [=======================>......] - ETA: 0s - loss: 1372851346.8466 - KL_divergence: 11.4356
169/200 [========================>.....] - ETA: 0s - loss: 1372995136.3787 - KL_divergence: 11.4225
175/200 [=========================>....] - ETA: 0s - loss: 1372941356.6171 - KL_divergence: 11.4154
181/200 [==========================>...] - ETA: 0s - loss: 1372798546.7403 - KL_divergence: 11.4102
187/200 [===========================>..] - ETA: 0s - loss: 1372293310.9733 - KL_divergence: 11.4050
193/200 [===========================>..] - ETA: 0s - loss: 1372547215.2539 - KL_divergence: 11.4024
199/200 [============================>.] - ETA: 0s - loss: 1371227457.6080 - KL_divergence: 11.4100
200/200 [==============================] - 2s 10ms/step - loss: 1371297687.6800 - KL_divergence: 11.4087 - val_loss: 1389460593.9200 - val_KL_divergence: 11.7431
Epoch 53/100

  1/200 [..............................] - ETA: 1s - loss: 1445410048.0000 - KL_divergence: 11.3365
  7/200 [>.............................] - ETA: 1s - loss: 1349615945.1429 - KL_divergence: 11.5176
 13/200 [>.............................] - ETA: 1s - loss: 1356594668.3077 - KL_divergence: 11.4881
 19/200 [=>............................] - ETA: 1s - loss: 1363638581.8947 - KL_divergence: 11.4443
 24/200 [==>...........................] - ETA: 1s - loss: 1363181962.6667 - KL_divergence: 11.4649
 30/200 [===>..........................] - ETA: 1s - loss: 1363278016.0000 - KL_divergence: 11.3978
 36/200 [====>.........................] - ETA: 1s - loss: 1364177770.6667 - KL_divergence: 11.3781
 42/200 [=====>........................] - ETA: 1s - loss: 1357838902.8571 - KL_divergence: 11.3646
 48/200 [======>.......................] - ETA: 1s - loss: 1357137242.6667 - KL_divergence: 11.4037
 54/200 [=======>......................] - ETA: 1s - loss: 1360318295.7037 - KL_divergence: 11.3945
 61/200 [========>.....................] - ETA: 1s - loss: 1367242588.3279 - KL_divergence: 11.3956
 67/200 [=========>....................] - ETA: 1s - loss: 1363139398.6866 - KL_divergence: 11.4218
 73/200 [=========>....................] - ETA: 1s - loss: 1363408138.5205 - KL_divergence: 11.4241
 79/200 [==========>...................] - ETA: 1s - loss: 1362659358.7848 - KL_divergence: 11.4063
 85/200 [===========>..................] - ETA: 1s - loss: 1362197383.5294 - KL_divergence: 11.4060
 91/200 [============>.................] - ETA: 0s - loss: 1364757985.0549 - KL_divergence: 11.4142
 97/200 [=============>................] - ETA: 0s - loss: 1364359711.6701 - KL_divergence: 11.3894
103/200 [==============>...............] - ETA: 0s - loss: 1362965075.2621 - KL_divergence: 11.3671
109/200 [===============>..............] - ETA: 0s - loss: 1363690127.2661 - KL_divergence: 11.3701
115/200 [================>.............] - ETA: 0s - loss: 1360843978.5739 - KL_divergence: 11.3838
121/200 [=================>............] - ETA: 0s - loss: 1360478720.0000 - KL_divergence: 11.3832
127/200 [==================>...........] - ETA: 0s - loss: 1359888477.7323 - KL_divergence: 11.3785
133/200 [==================>...........] - ETA: 0s - loss: 1360441488.3609 - KL_divergence: 11.3765
139/200 [===================>..........] - ETA: 0s - loss: 1361414354.8777 - KL_divergence: 11.3677
145/200 [====================>.........] - ETA: 0s - loss: 1362086223.4483 - KL_divergence: 11.3653
151/200 [=====================>........] - ETA: 0s - loss: 1361740354.9669 - KL_divergence: 11.3722
157/200 [======================>.......] - ETA: 0s - loss: 1362120828.7389 - KL_divergence: 11.4022
164/200 [=======================>......] - ETA: 0s - loss: 1361941486.8293 - KL_divergence: 11.3953
170/200 [========================>.....] - ETA: 0s - loss: 1361187554.6353 - KL_divergence: 11.3960
176/200 [=========================>....] - ETA: 0s - loss: 1361447946.9091 - KL_divergence: 11.4058
182/200 [==========================>...] - ETA: 0s - loss: 1360020430.7692 - KL_divergence: 11.4240
188/200 [===========================>..] - ETA: 0s - loss: 1360023229.9574 - KL_divergence: 11.4089
194/200 [============================>.] - ETA: 0s - loss: 1361214482.4742 - KL_divergence: 11.4207
200/200 [==============================] - 2s 10ms/step - loss: 1360815949.4400 - KL_divergence: 11.4213 - val_loss: 1380846073.6000 - val_KL_divergence: 11.4049
Epoch 54/100

  1/200 [..............................] - ETA: 1s - loss: 1442847488.0000 - KL_divergence: 11.2194
  7/200 [>.............................] - ETA: 1s - loss: 1400004187.4286 - KL_divergence: 11.5225
 13/200 [>.............................] - ETA: 1s - loss: 1392476514.4615 - KL_divergence: 11.3792
 19/200 [=>............................] - ETA: 1s - loss: 1392479582.3158 - KL_divergence: 11.4249
 25/200 [==>...........................] - ETA: 1s - loss: 1407870499.8400 - KL_divergence: 11.4511
 31/200 [===>..........................] - ETA: 1s - loss: 1398359494.1935 - KL_divergence: 11.4274
 37/200 [====>.........................] - ETA: 1s - loss: 1387274630.9189 - KL_divergence: 11.4034
 43/200 [=====>........................] - ETA: 1s - loss: 1376054161.8605 - KL_divergence: 11.3248
 49/200 [======>.......................] - ETA: 1s - loss: 1376321985.3061 - KL_divergence: 11.3380
 55/200 [=======>......................] - ETA: 1s - loss: 1372516521.8909 - KL_divergence: 11.3505
 61/200 [========>.....................] - ETA: 1s - loss: 1367502709.5082 - KL_divergence: 11.3721
 67/200 [=========>....................] - ETA: 1s - loss: 1365681570.3881 - KL_divergence: 11.3612
 74/200 [==========>...................] - ETA: 1s - loss: 1361051058.1622 - KL_divergence: 11.3734
 80/200 [===========>..................] - ETA: 1s - loss: 1358367670.4000 - KL_divergence: 11.3509
 86/200 [===========>..................] - ETA: 1s - loss: 1360262484.8372 - KL_divergence: 11.3302
 92/200 [============>.................] - ETA: 0s - loss: 1359954016.0000 - KL_divergence: 11.3045
 98/200 [=============>................] - ETA: 0s - loss: 1360949894.5306 - KL_divergence: 11.3161
104/200 [==============>...............] - ETA: 0s - loss: 1365139266.4615 - KL_divergence: 11.3133
110/200 [===============>..............] - ETA: 0s - loss: 1363860217.0182 - KL_divergence: 11.2907
116/200 [================>.............] - ETA: 0s - loss: 1362197107.8621 - KL_divergence: 11.2831
122/200 [=================>............] - ETA: 0s - loss: 1361914872.6557 - KL_divergence: 11.2874
128/200 [==================>...........] - ETA: 0s - loss: 1362263556.0000 - KL_divergence: 11.3007
134/200 [===================>..........] - ETA: 0s - loss: 1362998770.6269 - KL_divergence: 11.2967
140/200 [====================>.........] - ETA: 0s - loss: 1363113421.7143 - KL_divergence: 11.2916
146/200 [====================>.........] - ETA: 0s - loss: 1363702748.0548 - KL_divergence: 11.2920
152/200 [=====================>........] - ETA: 0s - loss: 1362157157.0526 - KL_divergence: 11.2791
158/200 [======================>.......] - ETA: 0s - loss: 1362874477.3671 - KL_divergence: 11.2871
164/200 [=======================>......] - ETA: 0s - loss: 1362723612.0976 - KL_divergence: 11.2909
170/200 [========================>.....] - ETA: 0s - loss: 1364107376.1882 - KL_divergence: 11.3022
176/200 [=========================>....] - ETA: 0s - loss: 1364326472.7273 - KL_divergence: 11.3038
182/200 [==========================>...] - ETA: 0s - loss: 1363777052.8352 - KL_divergence: 11.3042
188/200 [===========================>..] - ETA: 0s - loss: 1363726441.5319 - KL_divergence: 11.3056
194/200 [============================>.] - ETA: 0s - loss: 1363815628.5361 - KL_divergence: 11.3170
200/200 [==============================] - 2s 10ms/step - loss: 1364885895.0400 - KL_divergence: 11.3275 - val_loss: 1382494442.2400 - val_KL_divergence: 11.3845
Epoch 55/100

  1/200 [..............................] - ETA: 1s - loss: 1302611456.0000 - KL_divergence: 10.9063
  7/200 [>.............................] - ETA: 1s - loss: 1350874788.5714 - KL_divergence: 11.4144
 13/200 [>.............................] - ETA: 1s - loss: 1328629966.7692 - KL_divergence: 11.5308
 19/200 [=>............................] - ETA: 1s - loss: 1323485197.4737 - KL_divergence: 11.5980
 25/200 [==>...........................] - ETA: 1s - loss: 1332506393.6000 - KL_divergence: 11.5092
 32/200 [===>..........................] - ETA: 1s - loss: 1335198428.0000 - KL_divergence: 11.4721
 38/200 [====>.........................] - ETA: 1s - loss: 1339103632.8421 - KL_divergence: 11.5154
 44/200 [=====>........................] - ETA: 1s - loss: 1342638469.8182 - KL_divergence: 11.5840
 50/200 [======>.......................] - ETA: 1s - loss: 1338110269.4400 - KL_divergence: 11.5625
 56/200 [=======>......................] - ETA: 1s - loss: 1341868770.2857 - KL_divergence: 11.5600
 62/200 [========>.....................] - ETA: 1s - loss: 1341414156.3871 - KL_divergence: 11.6092
 68/200 [=========>....................] - ETA: 1s - loss: 1342007491.7647 - KL_divergence: 11.5999
 74/200 [==========>...................] - ETA: 1s - loss: 1342645720.2162 - KL_divergence: 11.6142
 80/200 [===========>..................] - ETA: 1s - loss: 1341597320.0000 - KL_divergence: 11.5709
 86/200 [===========>..................] - ETA: 1s - loss: 1345818065.8605 - KL_divergence: 11.5901
 92/200 [============>.................] - ETA: 0s - loss: 1347455590.9565 - KL_divergence: 11.5796
 98/200 [=============>................] - ETA: 0s - loss: 1346995893.5510 - KL_divergence: 11.5851
104/200 [==============>...............] - ETA: 0s - loss: 1346849392.0000 - KL_divergence: 11.5804
110/200 [===============>..............] - ETA: 0s - loss: 1346672809.8909 - KL_divergence: 11.5851
116/200 [================>.............] - ETA: 0s - loss: 1347572963.3103 - KL_divergence: 11.5808
122/200 [=================>............] - ETA: 0s - loss: 1347251439.2131 - KL_divergence: 11.5627
128/200 [==================>...........] - ETA: 0s - loss: 1346933482.0000 - KL_divergence: 11.5510
134/200 [===================>..........] - ETA: 0s - loss: 1347043267.8209 - KL_divergence: 11.5614
140/200 [====================>.........] - ETA: 0s - loss: 1348541932.8000 - KL_divergence: 11.5443
147/200 [=====================>........] - ETA: 0s - loss: 1348878422.2041 - KL_divergence: 11.5355
153/200 [=====================>........] - ETA: 0s - loss: 1349503230.3268 - KL_divergence: 11.5306
160/200 [=======================>......] - ETA: 0s - loss: 1350267647.2000 - KL_divergence: 11.5184
166/200 [=======================>......] - ETA: 0s - loss: 1352073987.8554 - KL_divergence: 11.5172
173/200 [========================>.....] - ETA: 0s - loss: 1352822934.9364 - KL_divergence: 11.5085
180/200 [==========================>...] - ETA: 0s - loss: 1351551972.2667 - KL_divergence: 11.5074
187/200 [===========================>..] - ETA: 0s - loss: 1351353235.8503 - KL_divergence: 11.5016
193/200 [===========================>..] - ETA: 0s - loss: 1350143604.7254 - KL_divergence: 11.4978
199/200 [============================>.] - ETA: 0s - loss: 1351345826.0905 - KL_divergence: 11.4872
200/200 [==============================] - 2s 10ms/step - loss: 1351153800.3200 - KL_divergence: 11.4850 - val_loss: 1365187631.3600 - val_KL_divergence: 11.2663
Epoch 56/100

  1/200 [..............................] - ETA: 1s - loss: 1221174656.0000 - KL_divergence: 10.4200
  7/200 [>.............................] - ETA: 1s - loss: 1314987501.7143 - KL_divergence: 11.2036
 13/200 [>.............................] - ETA: 1s - loss: 1330958267.0769 - KL_divergence: 11.3659
 19/200 [=>............................] - ETA: 1s - loss: 1337554789.0526 - KL_divergence: 11.2808
 25/200 [==>...........................] - ETA: 1s - loss: 1347331312.6400 - KL_divergence: 11.3308
 31/200 [===>..........................] - ETA: 1s - loss: 1352926051.0968 - KL_divergence: 11.3597
 37/200 [====>.........................] - ETA: 1s - loss: 1356255802.8108 - KL_divergence: 11.4246
 43/200 [=====>........................] - ETA: 1s - loss: 1352663909.2093 - KL_divergence: 11.4657
 49/200 [======>.......................] - ETA: 1s - loss: 1348697963.1020 - KL_divergence: 11.4703
 55/200 [=======>......................] - ETA: 1s - loss: 1348349181.6727 - KL_divergence: 11.4226
 61/200 [========>.....................] - ETA: 1s - loss: 1348681799.3443 - KL_divergence: 11.4533
 67/200 [=========>....................] - ETA: 1s - loss: 1350663561.5522 - KL_divergence: 11.4498
 73/200 [=========>....................] - ETA: 1s - loss: 1353939645.3699 - KL_divergence: 11.4747
 79/200 [==========>...................] - ETA: 1s - loss: 1356281431.4937 - KL_divergence: 11.4854
 86/200 [===========>..................] - ETA: 1s - loss: 1352648937.6744 - KL_divergence: 11.4639
 92/200 [============>.................] - ETA: 0s - loss: 1353358099.4783 - KL_divergence: 11.4627
 98/200 [=============>................] - ETA: 0s - loss: 1354744274.2857 - KL_divergence: 11.4799
104/200 [==============>...............] - ETA: 0s - loss: 1355596803.6923 - KL_divergence: 11.4792
110/200 [===============>..............] - ETA: 0s - loss: 1356710273.1636 - KL_divergence: 11.4660
116/200 [================>.............] - ETA: 0s - loss: 1357271347.8621 - KL_divergence: 11.4680
122/200 [=================>............] - ETA: 0s - loss: 1357701771.5410 - KL_divergence: 11.4689
128/200 [==================>...........] - ETA: 0s - loss: 1357458470.0000 - KL_divergence: 11.4660
134/200 [===================>..........] - ETA: 0s - loss: 1358589715.1045 - KL_divergence: 11.4567
140/200 [====================>.........] - ETA: 0s - loss: 1359020234.9714 - KL_divergence: 11.4457
146/200 [====================>.........] - ETA: 0s - loss: 1359385292.2740 - KL_divergence: 11.4253
152/200 [=====================>........] - ETA: 0s - loss: 1357553267.3684 - KL_divergence: 11.4007
158/200 [======================>.......] - ETA: 0s - loss: 1359288342.6835 - KL_divergence: 11.4079
164/200 [=======================>......] - ETA: 0s - loss: 1358470474.9268 - KL_divergence: 11.4049
170/200 [========================>.....] - ETA: 0s - loss: 1359237571.0118 - KL_divergence: 11.4176
176/200 [=========================>....] - ETA: 0s - loss: 1359233575.2727 - KL_divergence: 11.4251
182/200 [==========================>...] - ETA: 0s - loss: 1358771718.3297 - KL_divergence: 11.4465
189/200 [===========================>..] - ETA: 0s - loss: 1357507747.2169 - KL_divergence: 11.4407
195/200 [============================>.] - ETA: 0s - loss: 1357480109.2923 - KL_divergence: 11.4404
200/200 [==============================] - 2s 10ms/step - loss: 1358811130.2400 - KL_divergence: 11.4509 - val_loss: 1392182542.0800 - val_KL_divergence: 11.7857
Epoch 57/100

  1/200 [..............................] - ETA: 1s - loss: 1339857408.0000 - KL_divergence: 12.8277
  7/200 [>.............................] - ETA: 1s - loss: 1387061046.8571 - KL_divergence: 11.8605
 13/200 [>.............................] - ETA: 1s - loss: 1351918759.3846 - KL_divergence: 11.8595
 19/200 [=>............................] - ETA: 1s - loss: 1357647905.6842 - KL_divergence: 11.8055
 25/200 [==>...........................] - ETA: 1s - loss: 1363998423.0400 - KL_divergence: 11.6979
 31/200 [===>..........................] - ETA: 1s - loss: 1367022889.2903 - KL_divergence: 11.6376
 37/200 [====>.........................] - ETA: 1s - loss: 1368067161.9459 - KL_divergence: 11.5850
 43/200 [=====>........................] - ETA: 1s - loss: 1371675847.4419 - KL_divergence: 11.4990
 49/200 [======>.......................] - ETA: 1s - loss: 1367336641.3061 - KL_divergence: 11.4701
 55/200 [=======>......................] - ETA: 1s - loss: 1362595176.7273 - KL_divergence: 11.4578
 61/200 [========>.....................] - ETA: 1s - loss: 1367008965.2459 - KL_divergence: 11.4736
 67/200 [=========>....................] - ETA: 1s - loss: 1365910419.1045 - KL_divergence: 11.4620
 74/200 [==========>...................] - ETA: 1s - loss: 1369541571.4595 - KL_divergence: 11.4948
 81/200 [===========>..................] - ETA: 1s - loss: 1368926716.8395 - KL_divergence: 11.5318
 88/200 [============>.................] - ETA: 0s - loss: 1369309697.4545 - KL_divergence: 11.5745
 95/200 [=============>................] - ETA: 0s - loss: 1368816153.6000 - KL_divergence: 11.5767
101/200 [==============>...............] - ETA: 0s - loss: 1369823948.0396 - KL_divergence: 11.5891
107/200 [===============>..............] - ETA: 0s - loss: 1368739234.6916 - KL_divergence: 11.5794
113/200 [===============>..............] - ETA: 0s - loss: 1370892800.0000 - KL_divergence: 11.5829
119/200 [================>.............] - ETA: 0s - loss: 1372296880.4034 - KL_divergence: 11.5806
125/200 [=================>............] - ETA: 0s - loss: 1372359161.8560 - KL_divergence: 11.5738
131/200 [==================>...........] - ETA: 0s - loss: 1370461186.9313 - KL_divergence: 11.5717
138/200 [===================>..........] - ETA: 0s - loss: 1367781076.4058 - KL_divergence: 11.5623
144/200 [====================>.........] - ETA: 0s - loss: 1367249596.4444 - KL_divergence: 11.5801
150/200 [=====================>........] - ETA: 0s - loss: 1367233007.7867 - KL_divergence: 11.5875
156/200 [======================>.......] - ETA: 0s - loss: 1367894445.1282 - KL_divergence: 11.5942
162/200 [=======================>......] - ETA: 0s - loss: 1367820739.1605 - KL_divergence: 11.5905
168/200 [========================>.....] - ETA: 0s - loss: 1366958873.1429 - KL_divergence: 11.5951
174/200 [=========================>....] - ETA: 0s - loss: 1366973974.0690 - KL_divergence: 11.6024
180/200 [==========================>...] - ETA: 0s - loss: 1367996706.8444 - KL_divergence: 11.6061
186/200 [==========================>...] - ETA: 0s - loss: 1365661056.6882 - KL_divergence: 11.5965
192/200 [===========================>..] - ETA: 0s - loss: 1364999412.6667 - KL_divergence: 11.6134
198/200 [============================>.] - ETA: 0s - loss: 1366416244.3636 - KL_divergence: 11.6106
200/200 [==============================] - 2s 10ms/step - loss: 1366332001.2800 - KL_divergence: 11.6154 - val_loss: 1391678607.3600 - val_KL_divergence: 11.7101
Epoch 58/100

  1/200 [..............................] - ETA: 1s - loss: 1331175680.0000 - KL_divergence: 11.9793
  7/200 [>.............................] - ETA: 1s - loss: 1349779876.5714 - KL_divergence: 12.2892
 13/200 [>.............................] - ETA: 1s - loss: 1345986215.3846 - KL_divergence: 12.1881
 19/200 [=>............................] - ETA: 1s - loss: 1360550521.2632 - KL_divergence: 12.2489
 25/200 [==>...........................] - ETA: 1s - loss: 1357468241.9200 - KL_divergence: 12.2523
 31/200 [===>..........................] - ETA: 1s - loss: 1361046755.0968 - KL_divergence: 12.2302
 37/200 [====>.........................] - ETA: 1s - loss: 1357083018.3784 - KL_divergence: 12.2159
 43/200 [=====>........................] - ETA: 1s - loss: 1352351726.1395 - KL_divergence: 12.1999
 49/200 [======>.......................] - ETA: 1s - loss: 1360085577.1429 - KL_divergence: 12.1464
 55/200 [=======>......................] - ETA: 1s - loss: 1351280367.7091 - KL_divergence: 12.0997
 61/200 [========>.....................] - ETA: 1s - loss: 1352575427.1475 - KL_divergence: 12.0725
 67/200 [=========>....................] - ETA: 1s - loss: 1355627976.5970 - KL_divergence: 12.0605
 73/200 [=========>....................] - ETA: 1s - loss: 1356060107.3973 - KL_divergence: 12.0113
 79/200 [==========>...................] - ETA: 1s - loss: 1356525321.7215 - KL_divergence: 11.9742
 85/200 [===========>..................] - ETA: 1s - loss: 1359005134.3059 - KL_divergence: 11.9674
 91/200 [============>.................] - ETA: 0s - loss: 1358421802.1978 - KL_divergence: 11.9589
 97/200 [=============>................] - ETA: 0s - loss: 1359941056.6598 - KL_divergence: 11.9452
103/200 [==============>...............] - ETA: 0s - loss: 1359409127.1456 - KL_divergence: 11.9354
109/200 [===============>..............] - ETA: 0s - loss: 1358973337.8349 - KL_divergence: 11.9466
115/200 [================>.............] - ETA: 0s - loss: 1359746954.0174 - KL_divergence: 11.9223
121/200 [=================>............] - ETA: 0s - loss: 1359194387.0413 - KL_divergence: 11.8941
127/200 [==================>...........] - ETA: 0s - loss: 1358230290.1417 - KL_divergence: 11.8780
133/200 [==================>...........] - ETA: 0s - loss: 1355901712.3609 - KL_divergence: 11.8729
139/200 [===================>..........] - ETA: 0s - loss: 1357509321.6691 - KL_divergence: 11.8598
145/200 [====================>.........] - ETA: 0s - loss: 1357067218.0966 - KL_divergence: 11.8738
151/200 [=====================>........] - ETA: 0s - loss: 1359049446.5695 - KL_divergence: 11.8798
157/200 [======================>.......] - ETA: 0s - loss: 1357774403.6688 - KL_divergence: 11.8841
163/200 [=======================>......] - ETA: 0s - loss: 1355562059.3865 - KL_divergence: 11.8735
169/200 [========================>.....] - ETA: 0s - loss: 1356149885.7278 - KL_divergence: 11.8758
175/200 [=========================>....] - ETA: 0s - loss: 1356866845.2571 - KL_divergence: 11.8727
181/200 [==========================>...] - ETA: 0s - loss: 1357139935.4696 - KL_divergence: 11.8625
187/200 [===========================>..] - ETA: 0s - loss: 1355664280.6417 - KL_divergence: 11.8471
193/200 [===========================>..] - ETA: 0s - loss: 1355424218.8601 - KL_divergence: 11.8331
199/200 [============================>.] - ETA: 0s - loss: 1356484916.1005 - KL_divergence: 11.8307
200/200 [==============================] - 2s 10ms/step - loss: 1355839760.0000 - KL_divergence: 11.8298 - val_loss: 1374278312.9600 - val_KL_divergence: 11.5726
Epoch 59/100

  1/200 [..............................] - ETA: 1s - loss: 1396082176.0000 - KL_divergence: 10.4712
  7/200 [>.............................] - ETA: 1s - loss: 1365830217.1429 - KL_divergence: 11.2557
 14/200 [=>............................] - ETA: 1s - loss: 1353924717.7143 - KL_divergence: 11.6644
 21/200 [==>...........................] - ETA: 1s - loss: 1354813964.1905 - KL_divergence: 11.5423
 28/200 [===>..........................] - ETA: 1s - loss: 1349402176.0000 - KL_divergence: 11.5391
 34/200 [====>.........................] - ETA: 1s - loss: 1350681344.0000 - KL_divergence: 11.4741
 40/200 [=====>........................] - ETA: 1s - loss: 1351109769.6000 - KL_divergence: 11.5046
 46/200 [=====>........................] - ETA: 1s - loss: 1344930493.2174 - KL_divergence: 11.4558
 52/200 [======>.......................] - ETA: 1s - loss: 1340332770.4615 - KL_divergence: 11.4836
 58/200 [=======>......................] - ETA: 1s - loss: 1348242707.8621 - KL_divergence: 11.4827
 64/200 [========>.....................] - ETA: 1s - loss: 1348955082.0000 - KL_divergence: 11.4450
 70/200 [=========>....................] - ETA: 1s - loss: 1349824469.9429 - KL_divergence: 11.4486
 76/200 [==========>...................] - ETA: 1s - loss: 1348219006.3158 - KL_divergence: 11.4393
 82/200 [===========>..................] - ETA: 1s - loss: 1348860111.6098 - KL_divergence: 11.4236
 88/200 [============>.................] - ETA: 0s - loss: 1349869588.3636 - KL_divergence: 11.4135
 94/200 [=============>................] - ETA: 0s - loss: 1348628516.7660 - KL_divergence: 11.4273
100/200 [==============>...............] - ETA: 0s - loss: 1350015351.0400 - KL_divergence: 11.4501
106/200 [==============>...............] - ETA: 0s - loss: 1350302464.0000 - KL_divergence: 11.4961
112/200 [===============>..............] - ETA: 0s - loss: 1351814770.2857 - KL_divergence: 11.5299
118/200 [================>.............] - ETA: 0s - loss: 1347677777.3559 - KL_divergence: 11.5168
124/200 [=================>............] - ETA: 0s - loss: 1345703652.1290 - KL_divergence: 11.5126
130/200 [==================>...........] - ETA: 0s - loss: 1348102224.7385 - KL_divergence: 11.5410
136/200 [===================>..........] - ETA: 0s - loss: 1348455491.7647 - KL_divergence: 11.5454
142/200 [====================>.........] - ETA: 0s - loss: 1349277834.8169 - KL_divergence: 11.5578
148/200 [=====================>........] - ETA: 0s - loss: 1348817652.7568 - KL_divergence: 11.5664
154/200 [======================>.......] - ETA: 0s - loss: 1348933779.9481 - KL_divergence: 11.5708
160/200 [=======================>......] - ETA: 0s - loss: 1349231863.2000 - KL_divergence: 11.5736
166/200 [=======================>......] - ETA: 0s - loss: 1350121533.6867 - KL_divergence: 11.5695
172/200 [========================>.....] - ETA: 0s - loss: 1350135883.9070 - KL_divergence: 11.5626
178/200 [=========================>....] - ETA: 0s - loss: 1347821629.8427 - KL_divergence: 11.5545
184/200 [==========================>...] - ETA: 0s - loss: 1348323911.6522 - KL_divergence: 11.5633
190/200 [===========================>..] - ETA: 0s - loss: 1348912074.7789 - KL_divergence: 11.5738
196/200 [============================>.] - ETA: 0s - loss: 1348736751.6735 - KL_divergence: 11.5711
200/200 [==============================] - 2s 10ms/step - loss: 1348164133.7600 - KL_divergence: 11.5667 - val_loss: 1384574777.6000 - val_KL_divergence: 11.8842
Epoch 60/100

  1/200 [..............................] - ETA: 1s - loss: 1435680128.0000 - KL_divergence: 12.9530
  7/200 [>.............................] - ETA: 1s - loss: 1404747465.1429 - KL_divergence: 11.6806
 13/200 [>.............................] - ETA: 1s - loss: 1397714569.8462 - KL_divergence: 11.6806
 19/200 [=>............................] - ETA: 1s - loss: 1355375110.7368 - KL_divergence: 11.6139
 25/200 [==>...........................] - ETA: 1s - loss: 1354041943.0400 - KL_divergence: 11.7090
 31/200 [===>..........................] - ETA: 1s - loss: 1354089641.2903 - KL_divergence: 11.7676
 37/200 [====>.........................] - ETA: 1s - loss: 1363960430.7027 - KL_divergence: 11.7805
 43/200 [=====>........................] - ETA: 1s - loss: 1362560029.7674 - KL_divergence: 11.7428
 49/200 [======>.......................] - ETA: 1s - loss: 1367141564.0816 - KL_divergence: 11.7420
 55/200 [=======>......................] - ETA: 1s - loss: 1362302654.8364 - KL_divergence: 11.7320
 61/200 [========>.....................] - ETA: 1s - loss: 1358915080.3934 - KL_divergence: 11.7347
 67/200 [=========>....................] - ETA: 1s - loss: 1357402515.1045 - KL_divergence: 11.7521
 73/200 [=========>....................] - ETA: 1s - loss: 1360542981.2603 - KL_divergence: 11.7469
 79/200 [==========>...................] - ETA: 1s - loss: 1360850281.3165 - KL_divergence: 11.7310
 85/200 [===========>..................] - ETA: 1s - loss: 1358974161.3176 - KL_divergence: 11.7345
 91/200 [============>.................] - ETA: 0s - loss: 1358418986.1978 - KL_divergence: 11.7421
 97/200 [=============>................] - ETA: 0s - loss: 1357286070.1031 - KL_divergence: 11.7650
103/200 [==============>...............] - ETA: 0s - loss: 1354785501.2039 - KL_divergence: 11.7788
109/200 [===============>..............] - ETA: 0s - loss: 1354728462.0917 - KL_divergence: 11.7828
115/200 [================>.............] - ETA: 0s - loss: 1353873886.6087 - KL_divergence: 11.7794
121/200 [=================>............] - ETA: 0s - loss: 1354807527.6694 - KL_divergence: 11.8014
127/200 [==================>...........] - ETA: 0s - loss: 1353681612.5984 - KL_divergence: 11.8084
133/200 [==================>...........] - ETA: 0s - loss: 1351984155.9098 - KL_divergence: 11.8140
139/200 [===================>..........] - ETA: 0s - loss: 1352043559.5971 - KL_divergence: 11.7949
145/200 [====================>.........] - ETA: 0s - loss: 1349887212.5793 - KL_divergence: 11.8019
151/200 [=====================>........] - ETA: 0s - loss: 1349571309.3510 - KL_divergence: 11.8138
157/200 [======================>.......] - ETA: 0s - loss: 1350277455.0828 - KL_divergence: 11.8156
163/200 [=======================>......] - ETA: 0s - loss: 1350618227.4356 - KL_divergence: 11.8211
169/200 [========================>.....] - ETA: 0s - loss: 1349684262.6272 - KL_divergence: 11.8322
175/200 [=========================>....] - ETA: 0s - loss: 1350948177.1886 - KL_divergence: 11.8575
181/200 [==========================>...] - ETA: 0s - loss: 1350308042.9613 - KL_divergence: 11.8544
187/200 [===========================>..] - ETA: 0s - loss: 1350926535.1872 - KL_divergence: 11.8543
193/200 [===========================>..] - ETA: 0s - loss: 1350099184.7461 - KL_divergence: 11.8527
199/200 [============================>.] - ETA: 0s - loss: 1351756178.6533 - KL_divergence: 11.8518
200/200 [==============================] - 2s 10ms/step - loss: 1351998645.7600 - KL_divergence: 11.8503 - val_loss: 1361468601.6000 - val_KL_divergence: 11.6071
Epoch 61/100

  1/200 [..............................] - ETA: 1s - loss: 1391091328.0000 - KL_divergence: 12.3498
  8/200 [>.............................] - ETA: 1s - loss: 1334735120.0000 - KL_divergence: 11.9550
 14/200 [=>............................] - ETA: 1s - loss: 1350586697.1429 - KL_divergence: 11.9750
 21/200 [==>...........................] - ETA: 1s - loss: 1352369859.0476 - KL_divergence: 11.9242
 27/200 [===>..........................] - ETA: 1s - loss: 1352888751.4074 - KL_divergence: 11.9460
 33/200 [===>..........................] - ETA: 1s - loss: 1350154197.3333 - KL_divergence: 11.9247
 39/200 [====>.........................] - ETA: 1s - loss: 1348977857.6410 - KL_divergence: 11.8558
 45/200 [=====>........................] - ETA: 1s - loss: 1347279965.8667 - KL_divergence: 11.7942
 51/200 [======>.......................] - ETA: 1s - loss: 1348948274.1961 - KL_divergence: 11.8053
 58/200 [=======>......................] - ETA: 1s - loss: 1352173380.4138 - KL_divergence: 11.8015
 64/200 [========>.....................] - ETA: 1s - loss: 1353804048.0000 - KL_divergence: 11.8056
 70/200 [=========>....................] - ETA: 1s - loss: 1351961537.8286 - KL_divergence: 11.7931
 76/200 [==========>...................] - ETA: 1s - loss: 1350677020.6316 - KL_divergence: 11.7971
 82/200 [===========>..................] - ETA: 1s - loss: 1352096110.8293 - KL_divergence: 11.7720
 88/200 [============>.................] - ETA: 0s - loss: 1349926382.5455 - KL_divergence: 11.7610
 94/200 [=============>................] - ETA: 0s - loss: 1349799820.2553 - KL_divergence: 11.7730
100/200 [==============>...............] - ETA: 0s - loss: 1350203819.5200 - KL_divergence: 11.7870
106/200 [==============>...............] - ETA: 0s - loss: 1349981700.8302 - KL_divergence: 11.7907
112/200 [===============>..............] - ETA: 0s - loss: 1346888389.7143 - KL_divergence: 11.7691
118/200 [================>.............] - ETA: 0s - loss: 1347535746.1695 - KL_divergence: 11.7708
124/200 [=================>............] - ETA: 0s - loss: 1345643971.0968 - KL_divergence: 11.7783
130/200 [==================>...........] - ETA: 0s - loss: 1345744526.7692 - KL_divergence: 11.7804
136/200 [===================>..........] - ETA: 0s - loss: 1347270264.4706 - KL_divergence: 11.7799
142/200 [====================>.........] - ETA: 0s - loss: 1345726581.1831 - KL_divergence: 11.7736
149/200 [=====================>........] - ETA: 0s - loss: 1346637327.4631 - KL_divergence: 11.7854
155/200 [======================>.......] - ETA: 0s - loss: 1347021076.6452 - KL_divergence: 11.7706
161/200 [=======================>......] - ETA: 0s - loss: 1345659853.9130 - KL_divergence: 11.7648
168/200 [========================>.....] - ETA: 0s - loss: 1345887383.6190 - KL_divergence: 11.7699
174/200 [=========================>....] - ETA: 0s - loss: 1346616197.1494 - KL_divergence: 11.7585
180/200 [==========================>...] - ETA: 0s - loss: 1345114433.4222 - KL_divergence: 11.7568
186/200 [==========================>...] - ETA: 0s - loss: 1344519131.5269 - KL_divergence: 11.7591
192/200 [===========================>..] - ETA: 0s - loss: 1345368263.3333 - KL_divergence: 11.7617
199/200 [============================>.] - ETA: 0s - loss: 1346400533.8693 - KL_divergence: 11.7770
200/200 [==============================] - 2s 10ms/step - loss: 1347042826.2400 - KL_divergence: 11.7761 - val_loss: 1374158754.5600 - val_KL_divergence: 11.8865
Epoch 62/100

  1/200 [..............................] - ETA: 1s - loss: 1385918976.0000 - KL_divergence: 13.4387
  7/200 [>.............................] - ETA: 1s - loss: 1343598774.8571 - KL_divergence: 12.1768
 14/200 [=>............................] - ETA: 1s - loss: 1335372406.8571 - KL_divergence: 12.0646
 20/200 [==>...........................] - ETA: 1s - loss: 1324753081.6000 - KL_divergence: 11.9821
 26/200 [==>...........................] - ETA: 1s - loss: 1334777038.7692 - KL_divergence: 11.9417
 32/200 [===>..........................] - ETA: 1s - loss: 1335845268.0000 - KL_divergence: 11.8898
 38/200 [====>.........................] - ETA: 1s - loss: 1337579674.9474 - KL_divergence: 11.8496
 44/200 [=====>........................] - ETA: 1s - loss: 1340149280.0000 - KL_divergence: 11.8080
 50/200 [======>.......................] - ETA: 1s - loss: 1341908741.1200 - KL_divergence: 11.7840
 56/200 [=======>......................] - ETA: 1s - loss: 1342433974.8571 - KL_divergence: 11.7101
 62/200 [========>.....................] - ETA: 1s - loss: 1344861307.8710 - KL_divergence: 11.6889
 68/200 [=========>....................] - ETA: 1s - loss: 1344545556.7059 - KL_divergence: 11.7122
 74/200 [==========>...................] - ETA: 1s - loss: 1343703382.4865 - KL_divergence: 11.7458
 80/200 [===========>..................] - ETA: 1s - loss: 1347866718.4000 - KL_divergence: 11.7415
 86/200 [===========>..................] - ETA: 1s - loss: 1348189707.9070 - KL_divergence: 11.7322
 91/200 [============>.................] - ETA: 0s - loss: 1348990382.4176 - KL_divergence: 11.7482
 97/200 [=============>................] - ETA: 0s - loss: 1350399931.3814 - KL_divergence: 11.7645
103/200 [==============>...............] - ETA: 0s - loss: 1352308758.3689 - KL_divergence: 11.7763
109/200 [===============>..............] - ETA: 0s - loss: 1350870838.0183 - KL_divergence: 11.7783
116/200 [================>.............] - ETA: 0s - loss: 1350175849.9310 - KL_divergence: 11.7622
122/200 [=================>............] - ETA: 0s - loss: 1351161972.4590 - KL_divergence: 11.7615
128/200 [==================>...........] - ETA: 0s - loss: 1352157743.0000 - KL_divergence: 11.7564
134/200 [===================>..........] - ETA: 0s - loss: 1350823274.9851 - KL_divergence: 11.7427
140/200 [====================>.........] - ETA: 0s - loss: 1349862839.7714 - KL_divergence: 11.7511
146/200 [====================>.........] - ETA: 0s - loss: 1348752518.1370 - KL_divergence: 11.7500
152/200 [=====================>........] - ETA: 0s - loss: 1348488864.8421 - KL_divergence: 11.7551
159/200 [======================>.......] - ETA: 0s - loss: 1347578468.6289 - KL_divergence: 11.7526
165/200 [=======================>......] - ETA: 0s - loss: 1345816052.3636 - KL_divergence: 11.7557
171/200 [========================>.....] - ETA: 0s - loss: 1344963244.1637 - KL_divergence: 11.7612
177/200 [=========================>....] - ETA: 0s - loss: 1344237146.3955 - KL_divergence: 11.7674
183/200 [==========================>...] - ETA: 0s - loss: 1343282487.2568 - KL_divergence: 11.7562
189/200 [===========================>..] - ETA: 0s - loss: 1342149072.5926 - KL_divergence: 11.7722
196/200 [============================>.] - ETA: 0s - loss: 1343489549.7143 - KL_divergence: 11.7902
200/200 [==============================] - 2s 10ms/step - loss: 1343827169.2800 - KL_divergence: 11.7951 - val_loss: 1369163736.3200 - val_KL_divergence: 12.0156
Epoch 63/100

  1/200 [..............................] - ETA: 1s - loss: 1299422720.0000 - KL_divergence: 11.3114
  7/200 [>.............................] - ETA: 1s - loss: 1333537243.4286 - KL_divergence: 11.7216
 13/200 [>.............................] - ETA: 1s - loss: 1333093031.3846 - KL_divergence: 11.9396
 19/200 [=>............................] - ETA: 1s - loss: 1342106165.8947 - KL_divergence: 11.9705
 25/200 [==>...........................] - ETA: 1s - loss: 1337626839.0400 - KL_divergence: 11.9447
 31/200 [===>..........................] - ETA: 1s - loss: 1337395447.7419 - KL_divergence: 11.9072
 37/200 [====>.........................] - ETA: 1s - loss: 1334747831.3514 - KL_divergence: 11.8463
 43/200 [=====>........................] - ETA: 1s - loss: 1332035396.4651 - KL_divergence: 11.8263
 49/200 [======>.......................] - ETA: 1s - loss: 1336530403.2653 - KL_divergence: 11.7871
 55/200 [=======>......................] - ETA: 1s - loss: 1339581558.6909 - KL_divergence: 11.7611
 61/200 [========>.....................] - ETA: 1s - loss: 1341719136.5246 - KL_divergence: 11.7505
 67/200 [=========>....................] - ETA: 1s - loss: 1340827783.6418 - KL_divergence: 11.7608
 73/200 [=========>....................] - ETA: 1s - loss: 1345705671.8904 - KL_divergence: 11.7446
 79/200 [==========>...................] - ETA: 1s - loss: 1347434460.3544 - KL_divergence: 11.7557
 85/200 [===========>..................] - ETA: 1s - loss: 1346654968.4706 - KL_divergence: 11.7682
 91/200 [============>.................] - ETA: 0s - loss: 1345603124.0440 - KL_divergence: 11.7814
 97/200 [=============>................] - ETA: 0s - loss: 1346610389.7732 - KL_divergence: 11.7960
103/200 [==============>...............] - ETA: 0s - loss: 1346119328.3107 - KL_divergence: 11.8040
109/200 [===============>..............] - ETA: 0s - loss: 1344705568.8807 - KL_divergence: 11.8038
115/200 [================>.............] - ETA: 0s - loss: 1343369588.8696 - KL_divergence: 11.8172
121/200 [=================>............] - ETA: 0s - loss: 1345119178.0496 - KL_divergence: 11.8031
127/200 [==================>...........] - ETA: 0s - loss: 1345206354.6457 - KL_divergence: 11.8041
133/200 [==================>...........] - ETA: 0s - loss: 1345750061.2331 - KL_divergence: 11.8214
139/200 [===================>..........] - ETA: 0s - loss: 1346116175.1942 - KL_divergence: 11.8382
145/200 [====================>.........] - ETA: 0s - loss: 1345754455.3931 - KL_divergence: 11.8319
151/200 [=====================>........] - ETA: 0s - loss: 1347114439.2053 - KL_divergence: 11.8627
157/200 [======================>.......] - ETA: 0s - loss: 1347389613.6561 - KL_divergence: 11.8623
163/200 [=======================>......] - ETA: 0s - loss: 1347647415.7546 - KL_divergence: 11.8537
169/200 [========================>.....] - ETA: 0s - loss: 1346926870.7219 - KL_divergence: 11.8560
175/200 [=========================>....] - ETA: 0s - loss: 1346512131.6571 - KL_divergence: 11.8495
181/200 [==========================>...] - ETA: 0s - loss: 1345454887.6022 - KL_divergence: 11.8458
187/200 [===========================>..] - ETA: 0s - loss: 1345495500.6631 - KL_divergence: 11.8472
193/200 [===========================>..] - ETA: 0s - loss: 1345875524.9741 - KL_divergence: 11.8612
199/200 [============================>.] - ETA: 0s - loss: 1346039455.5176 - KL_divergence: 11.8675
200/200 [==============================] - 2s 10ms/step - loss: 1346363093.7600 - KL_divergence: 11.8655 - val_loss: 1364441608.9600 - val_KL_divergence: 11.9621
Epoch 64/100

  1/200 [..............................] - ETA: 1s - loss: 1344902144.0000 - KL_divergence: 11.5892
  7/200 [>.............................] - ETA: 1s - loss: 1356839350.8571 - KL_divergence: 11.9623
 13/200 [>.............................] - ETA: 1s - loss: 1340684652.3077 - KL_divergence: 11.7633
 19/200 [=>............................] - ETA: 1s - loss: 1340245456.8421 - KL_divergence: 11.8295
 25/200 [==>...........................] - ETA: 1s - loss: 1341241390.0800 - KL_divergence: 11.8865
 31/200 [===>..........................] - ETA: 1s - loss: 1340570632.2581 - KL_divergence: 11.9177
 37/200 [====>.........................] - ETA: 1s - loss: 1335812632.2162 - KL_divergence: 11.8918
 43/200 [=====>........................] - ETA: 1s - loss: 1336690470.6977 - KL_divergence: 11.8858
 49/200 [======>.......................] - ETA: 1s - loss: 1337149317.2245 - KL_divergence: 11.9257
 55/200 [=======>......................] - ETA: 1s - loss: 1341542632.7273 - KL_divergence: 11.9706
 61/200 [========>.....................] - ETA: 1s - loss: 1342313811.9344 - KL_divergence: 12.0235
 67/200 [=========>....................] - ETA: 1s - loss: 1343805963.4627 - KL_divergence: 12.0260
 73/200 [=========>....................] - ETA: 1s - loss: 1343151126.7945 - KL_divergence: 12.0445
 79/200 [==========>...................] - ETA: 1s - loss: 1344780704.4051 - KL_divergence: 12.0322
 85/200 [===========>..................] - ETA: 1s - loss: 1344282054.7765 - KL_divergence: 12.0154
 91/200 [============>.................] - ETA: 0s - loss: 1345398331.0769 - KL_divergence: 12.0350
 97/200 [=============>................] - ETA: 0s - loss: 1345216808.9072 - KL_divergence: 12.0391
103/200 [==============>...............] - ETA: 0s - loss: 1346707264.6214 - KL_divergence: 12.0190
109/200 [===============>..............] - ETA: 0s - loss: 1346237652.5505 - KL_divergence: 12.0338
115/200 [================>.............] - ETA: 0s - loss: 1345345090.7826 - KL_divergence: 12.0503
121/200 [=================>............] - ETA: 0s - loss: 1345412978.2479 - KL_divergence: 12.0480
127/200 [==================>...........] - ETA: 0s - loss: 1346823396.7874 - KL_divergence: 12.0668
133/200 [==================>...........] - ETA: 0s - loss: 1345616759.3383 - KL_divergence: 12.0527
139/200 [===================>..........] - ETA: 0s - loss: 1346486871.4820 - KL_divergence: 12.0490
144/200 [====================>.........] - ETA: 0s - loss: 1346412598.2222 - KL_divergence: 12.0572
150/200 [=====================>........] - ETA: 0s - loss: 1346188308.4800 - KL_divergence: 12.0581
156/200 [======================>.......] - ETA: 0s - loss: 1345212705.6410 - KL_divergence: 12.0450
162/200 [=======================>......] - ETA: 0s - loss: 1345979644.8395 - KL_divergence: 12.0479
169/200 [========================>.....] - ETA: 0s - loss: 1346258713.7515 - KL_divergence: 12.0340
175/200 [=========================>....] - ETA: 0s - loss: 1346045348.5714 - KL_divergence: 12.0320
182/200 [==========================>...] - ETA: 0s - loss: 1345437098.1978 - KL_divergence: 12.0336
188/200 [===========================>..] - ETA: 0s - loss: 1345268499.7447 - KL_divergence: 12.0285
194/200 [============================>.] - ETA: 0s - loss: 1344111313.8144 - KL_divergence: 12.0134
200/200 [==============================] - 2s 10ms/step - loss: 1343680506.8800 - KL_divergence: 12.0165 - val_loss: 1358109916.1600 - val_KL_divergence: 11.6810
Epoch 65/100

  1/200 [..............................] - ETA: 1s - loss: 1267758848.0000 - KL_divergence: 11.7739
  7/200 [>.............................] - ETA: 1s - loss: 1301786422.8571 - KL_divergence: 12.0862
 13/200 [>.............................] - ETA: 1s - loss: 1316210244.9231 - KL_divergence: 11.8151
 19/200 [=>............................] - ETA: 1s - loss: 1325691398.7368 - KL_divergence: 11.9805
 25/200 [==>...........................] - ETA: 1s - loss: 1333875461.1200 - KL_divergence: 11.9953
 31/200 [===>..........................] - ETA: 1s - loss: 1325008582.1935 - KL_divergence: 11.9321
 38/200 [====>.........................] - ETA: 1s - loss: 1320371782.7368 - KL_divergence: 11.9919
 44/200 [=====>........................] - ETA: 1s - loss: 1324592253.0909 - KL_divergence: 11.9435
 50/200 [======>.......................] - ETA: 1s - loss: 1330574479.3600 - KL_divergence: 11.9272
 57/200 [=======>......................] - ETA: 1s - loss: 1326102905.2632 - KL_divergence: 11.8998
 63/200 [========>.....................] - ETA: 1s - loss: 1332014401.0159 - KL_divergence: 11.9777
 69/200 [=========>....................] - ETA: 1s - loss: 1330094981.5652 - KL_divergence: 11.9809
 75/200 [==========>...................] - ETA: 1s - loss: 1328285644.8000 - KL_divergence: 11.9730
 81/200 [===========>..................] - ETA: 1s - loss: 1327884357.5309 - KL_divergence: 11.9699
 87/200 [============>.................] - ETA: 0s - loss: 1328483379.4943 - KL_divergence: 11.9957
 93/200 [============>.................] - ETA: 0s - loss: 1330180204.7312 - KL_divergence: 12.0074
 99/200 [=============>................] - ETA: 0s - loss: 1331552258.5859 - KL_divergence: 12.0174
105/200 [==============>...............] - ETA: 0s - loss: 1332431711.0857 - KL_divergence: 12.0028
111/200 [===============>..............] - ETA: 0s - loss: 1333687729.5856 - KL_divergence: 11.9873
117/200 [================>.............] - ETA: 0s - loss: 1333348099.2821 - KL_divergence: 11.9864
123/200 [=================>............] - ETA: 0s - loss: 1334401131.1870 - KL_divergence: 11.9904
129/200 [==================>...........] - ETA: 0s - loss: 1334565115.0388 - KL_divergence: 11.9949
135/200 [===================>..........] - ETA: 0s - loss: 1335421198.2222 - KL_divergence: 12.0243
141/200 [====================>.........] - ETA: 0s - loss: 1333594936.2837 - KL_divergence: 12.0087
147/200 [=====================>........] - ETA: 0s - loss: 1333377360.1088 - KL_divergence: 11.9955
153/200 [=====================>........] - ETA: 0s - loss: 1334825584.9412 - KL_divergence: 11.9866
159/200 [======================>.......] - ETA: 0s - loss: 1334873265.1069 - KL_divergence: 11.9748
165/200 [=======================>......] - ETA: 0s - loss: 1333045524.1697 - KL_divergence: 11.9422
171/200 [========================>.....] - ETA: 0s - loss: 1333728039.6725 - KL_divergence: 11.9461
177/200 [=========================>....] - ETA: 0s - loss: 1334310661.7853 - KL_divergence: 11.9461
183/200 [==========================>...] - ETA: 0s - loss: 1334369405.2022 - KL_divergence: 11.9431
189/200 [===========================>..] - ETA: 0s - loss: 1333387916.8677 - KL_divergence: 11.9342
195/200 [============================>.] - ETA: 0s - loss: 1335497967.5897 - KL_divergence: 11.9388
200/200 [==============================] - 2s 10ms/step - loss: 1334965485.4400 - KL_divergence: 11.9287 - val_loss: 1360857219.8400 - val_KL_divergence: 12.0973
Epoch 66/100

  1/200 [..............................] - ETA: 1s - loss: 1357562368.0000 - KL_divergence: 12.1917
  7/200 [>.............................] - ETA: 1s - loss: 1357861138.2857 - KL_divergence: 12.0806
 13/200 [>.............................] - ETA: 1s - loss: 1366428691.6923 - KL_divergence: 12.0959
 19/200 [=>............................] - ETA: 1s - loss: 1366093143.5789 - KL_divergence: 12.1672
 25/200 [==>...........................] - ETA: 1s - loss: 1364448552.9600 - KL_divergence: 12.0666
 31/200 [===>..........................] - ETA: 1s - loss: 1360311762.5806 - KL_divergence: 11.9697
 37/200 [====>.........................] - ETA: 1s - loss: 1355212125.4054 - KL_divergence: 11.9549
 43/200 [=====>........................] - ETA: 1s - loss: 1354726995.3488 - KL_divergence: 11.9105
 49/200 [======>.......................] - ETA: 1s - loss: 1350806509.7143 - KL_divergence: 11.8128
 55/200 [=======>......................] - ETA: 1s - loss: 1350046903.8545 - KL_divergence: 11.7950
 61/200 [========>.....................] - ETA: 1s - loss: 1348241684.9836 - KL_divergence: 11.7759
 67/200 [=========>....................] - ETA: 1s - loss: 1348391729.6716 - KL_divergence: 11.8179
 73/200 [=========>....................] - ETA: 1s - loss: 1347085808.2192 - KL_divergence: 11.8182
 79/200 [==========>...................] - ETA: 1s - loss: 1345251640.7089 - KL_divergence: 11.8035
 85/200 [===========>..................] - ETA: 1s - loss: 1342246643.9529 - KL_divergence: 11.8089
 91/200 [============>.................] - ETA: 0s - loss: 1340201763.1648 - KL_divergence: 11.7936
 97/200 [=============>................] - ETA: 0s - loss: 1340388754.4742 - KL_divergence: 11.7911
103/200 [==============>...............] - ETA: 0s - loss: 1342958169.4757 - KL_divergence: 11.8131
109/200 [===============>..............] - ETA: 0s - loss: 1342350913.7615 - KL_divergence: 11.8165
115/200 [================>.............] - ETA: 0s - loss: 1342239142.9565 - KL_divergence: 11.8354
121/200 [=================>............] - ETA: 0s - loss: 1341478889.7851 - KL_divergence: 11.8272
127/200 [==================>...........] - ETA: 0s - loss: 1342315593.5748 - KL_divergence: 11.8238
133/200 [==================>...........] - ETA: 0s - loss: 1341855892.2105 - KL_divergence: 11.8032
140/200 [====================>.........] - ETA: 0s - loss: 1341354645.9429 - KL_divergence: 11.8094
146/200 [====================>.........] - ETA: 0s - loss: 1341070099.2877 - KL_divergence: 11.8035
152/200 [=====================>........] - ETA: 0s - loss: 1339910672.8421 - KL_divergence: 11.8083
158/200 [======================>.......] - ETA: 0s - loss: 1340312819.8481 - KL_divergence: 11.7902
164/200 [=======================>......] - ETA: 0s - loss: 1341219128.9756 - KL_divergence: 11.7828
170/200 [========================>.....] - ETA: 0s - loss: 1340271488.7529 - KL_divergence: 11.7896
176/200 [=========================>....] - ETA: 0s - loss: 1339920340.3636 - KL_divergence: 11.8028
182/200 [==========================>...] - ETA: 0s - loss: 1339047194.7253 - KL_divergence: 11.8073
188/200 [===========================>..] - ETA: 0s - loss: 1339086671.6596 - KL_divergence: 11.8042
194/200 [============================>.] - ETA: 0s - loss: 1339132006.9278 - KL_divergence: 11.7985
200/200 [==============================] - 2s 10ms/step - loss: 1337895310.0800 - KL_divergence: 11.8028 - val_loss: 1367891338.2400 - val_KL_divergence: 12.1907
Epoch 67/100

  1/200 [..............................] - ETA: 1s - loss: 1287389312.0000 - KL_divergence: 12.7881
  7/200 [>.............................] - ETA: 1s - loss: 1343799972.5714 - KL_divergence: 11.8490
 13/200 [>.............................] - ETA: 1s - loss: 1347923111.3846 - KL_divergence: 11.9537
 19/200 [=>............................] - ETA: 1s - loss: 1349887616.0000 - KL_divergence: 11.8978
 25/200 [==>...........................] - ETA: 1s - loss: 1335719306.2400 - KL_divergence: 11.9300
 31/200 [===>..........................] - ETA: 1s - loss: 1331859270.1935 - KL_divergence: 11.8502
 37/200 [====>.........................] - ETA: 1s - loss: 1332507551.1351 - KL_divergence: 11.8380
 43/200 [=====>........................] - ETA: 1s - loss: 1337166556.2791 - KL_divergence: 11.8632
 49/200 [======>.......................] - ETA: 1s - loss: 1331893906.2857 - KL_divergence: 11.8053
 55/200 [=======>......................] - ETA: 1s - loss: 1328178627.4909 - KL_divergence: 11.8228
 61/200 [========>.....................] - ETA: 1s - loss: 1329319642.2295 - KL_divergence: 11.8270
 67/200 [=========>....................] - ETA: 1s - loss: 1326258747.2239 - KL_divergence: 11.8167
 73/200 [=========>....................] - ETA: 1s - loss: 1328667833.8630 - KL_divergence: 11.8414
 79/200 [==========>...................] - ETA: 1s - loss: 1326608980.2532 - KL_divergence: 11.8319
 85/200 [===========>..................] - ETA: 1s - loss: 1324675297.8824 - KL_divergence: 11.8440
 91/200 [============>.................] - ETA: 0s - loss: 1325115621.2747 - KL_divergence: 11.8554
 97/200 [=============>................] - ETA: 0s - loss: 1323205015.7526 - KL_divergence: 11.8528
103/200 [==============>...............] - ETA: 0s - loss: 1323151023.2233 - KL_divergence: 11.8914
109/200 [===============>..............] - ETA: 0s - loss: 1322405734.1651 - KL_divergence: 11.9290
115/200 [================>.............] - ETA: 0s - loss: 1322478131.2000 - KL_divergence: 11.9441
121/200 [=================>............] - ETA: 0s - loss: 1326630892.9587 - KL_divergence: 11.9487
127/200 [==================>...........] - ETA: 0s - loss: 1327999489.0079 - KL_divergence: 11.9579
133/200 [==================>...........] - ETA: 0s - loss: 1329815533.7143 - KL_divergence: 11.9593
139/200 [===================>..........] - ETA: 0s - loss: 1328840062.1583 - KL_divergence: 11.9508
145/200 [====================>.........] - ETA: 0s - loss: 1329802146.4276 - KL_divergence: 11.9714
151/200 [=====================>........] - ETA: 0s - loss: 1329711181.1391 - KL_divergence: 11.9889
157/200 [======================>.......] - ETA: 0s - loss: 1329403937.4268 - KL_divergence: 12.0027
163/200 [=======================>......] - ETA: 0s - loss: 1329574059.9755 - KL_divergence: 12.0006
169/200 [========================>.....] - ETA: 0s - loss: 1329660078.2012 - KL_divergence: 12.0062
175/200 [=========================>....] - ETA: 0s - loss: 1329949019.4286 - KL_divergence: 12.0153
181/200 [==========================>...] - ETA: 0s - loss: 1329811646.2320 - KL_divergence: 12.0255
187/200 [===========================>..] - ETA: 0s - loss: 1328760695.7861 - KL_divergence: 12.0380
193/200 [===========================>..] - ETA: 0s - loss: 1329261777.5751 - KL_divergence: 12.0315
199/200 [============================>.] - ETA: 0s - loss: 1328700848.2412 - KL_divergence: 12.0227
200/200 [==============================] - 2s 10ms/step - loss: 1328525180.1600 - KL_divergence: 12.0206 - val_loss: 1347040861.4400 - val_KL_divergence: 12.0428
Epoch 68/100

  1/200 [..............................] - ETA: 1s - loss: 1321579264.0000 - KL_divergence: 12.1046
  7/200 [>.............................] - ETA: 1s - loss: 1376926665.1429 - KL_divergence: 12.0148
 13/200 [>.............................] - ETA: 1s - loss: 1355057860.9231 - KL_divergence: 12.0067
 19/200 [=>............................] - ETA: 1s - loss: 1350807349.8947 - KL_divergence: 12.0500
 25/200 [==>...........................] - ETA: 1s - loss: 1346809717.7600 - KL_divergence: 12.0900
 31/200 [===>..........................] - ETA: 1s - loss: 1336404839.2258 - KL_divergence: 12.0450
 37/200 [====>.........................] - ETA: 1s - loss: 1329178637.8378 - KL_divergence: 12.0912
 42/200 [=====>........................] - ETA: 1s - loss: 1323054220.1905 - KL_divergence: 12.0863
 48/200 [======>.......................] - ETA: 1s - loss: 1323257704.0000 - KL_divergence: 12.0915
 54/200 [=======>......................] - ETA: 1s - loss: 1330454328.8889 - KL_divergence: 12.0915
 60/200 [========>.....................] - ETA: 1s - loss: 1333554749.8667 - KL_divergence: 12.0759
 66/200 [========>.....................] - ETA: 1s - loss: 1335535445.3333 - KL_divergence: 12.0490
 72/200 [=========>....................] - ETA: 1s - loss: 1333381335.1111 - KL_divergence: 12.0382
 78/200 [==========>...................] - ETA: 1s - loss: 1336243756.3077 - KL_divergence: 12.0228
 84/200 [===========>..................] - ETA: 1s - loss: 1335387311.2381 - KL_divergence: 12.0041
 90/200 [============>.................] - ETA: 1s - loss: 1334643975.1111 - KL_divergence: 12.0077
 96/200 [=============>................] - ETA: 0s - loss: 1339116162.6667 - KL_divergence: 12.0356
102/200 [==============>...............] - ETA: 0s - loss: 1337822110.1176 - KL_divergence: 12.0371
108/200 [===============>..............] - ETA: 0s - loss: 1337203506.9630 - KL_divergence: 12.0650
114/200 [================>.............] - ETA: 0s - loss: 1337077042.5263 - KL_divergence: 12.0696
120/200 [=================>............] - ETA: 0s - loss: 1334209396.2667 - KL_divergence: 12.0856
126/200 [=================>............] - ETA: 0s - loss: 1336743368.1270 - KL_divergence: 12.0614
132/200 [==================>...........] - ETA: 0s - loss: 1335937056.9697 - KL_divergence: 12.0604
138/200 [===================>..........] - ETA: 0s - loss: 1336238445.4493 - KL_divergence: 12.0563
144/200 [====================>.........] - ETA: 0s - loss: 1337253031.1111 - KL_divergence: 12.0458
150/200 [=====================>........] - ETA: 0s - loss: 1336519773.8667 - KL_divergence: 12.0306
156/200 [======================>.......] - ETA: 0s - loss: 1337134025.0256 - KL_divergence: 12.0327
162/200 [=======================>......] - ETA: 0s - loss: 1338177968.9877 - KL_divergence: 12.0276
168/200 [========================>.....] - ETA: 0s - loss: 1336246595.8095 - KL_divergence: 12.0106
174/200 [=========================>....] - ETA: 0s - loss: 1337417532.3218 - KL_divergence: 12.0027
180/200 [==========================>...] - ETA: 0s - loss: 1337682747.0222 - KL_divergence: 11.9862
186/200 [==========================>...] - ETA: 0s - loss: 1338766391.0538 - KL_divergence: 11.9896
192/200 [===========================>..] - ETA: 0s - loss: 1337271672.0000 - KL_divergence: 11.9793
198/200 [============================>.] - ETA: 0s - loss: 1337340280.2424 - KL_divergence: 11.9889
200/200 [==============================] - 2s 10ms/step - loss: 1337191810.5600 - KL_divergence: 11.9870 - val_loss: 1367199507.2000 - val_KL_divergence: 12.0061
Epoch 69/100

  1/200 [..............................] - ETA: 1s - loss: 1311524608.0000 - KL_divergence: 11.0367
  8/200 [>.............................] - ETA: 1s - loss: 1334618640.0000 - KL_divergence: 11.3219
 15/200 [=>............................] - ETA: 1s - loss: 1342366830.9333 - KL_divergence: 11.6824
 21/200 [==>...........................] - ETA: 1s - loss: 1341660141.7143 - KL_divergence: 11.8798
 27/200 [===>..........................] - ETA: 1s - loss: 1332352630.5185 - KL_divergence: 11.8706
 33/200 [===>..........................] - ETA: 1s - loss: 1336303918.5455 - KL_divergence: 11.8584
 39/200 [====>.........................] - ETA: 1s - loss: 1338714945.6410 - KL_divergence: 11.8711
 45/200 [=====>........................] - ETA: 1s - loss: 1346077394.4889 - KL_divergence: 11.8453
 51/200 [======>.......................] - ETA: 1s - loss: 1345131043.1373 - KL_divergence: 11.8697
 57/200 [=======>......................] - ETA: 1s - loss: 1347347938.8070 - KL_divergence: 11.9100
 63/200 [========>.....................] - ETA: 1s - loss: 1348786706.2857 - KL_divergence: 11.9259
 69/200 [=========>....................] - ETA: 1s - loss: 1346920466.5507 - KL_divergence: 11.9255
 76/200 [==========>...................] - ETA: 1s - loss: 1345898074.9474 - KL_divergence: 11.9629
 83/200 [===========>..................] - ETA: 1s - loss: 1347567756.3373 - KL_divergence: 11.9927
 90/200 [============>.................] - ETA: 0s - loss: 1344926375.8222 - KL_divergence: 11.9652
 96/200 [=============>................] - ETA: 0s - loss: 1343299118.6667 - KL_divergence: 11.9742
102/200 [==============>...............] - ETA: 0s - loss: 1345554384.3137 - KL_divergence: 11.9504
108/200 [===============>..............] - ETA: 0s - loss: 1347722040.8889 - KL_divergence: 11.9430
114/200 [================>.............] - ETA: 0s - loss: 1345271499.2281 - KL_divergence: 11.9428
121/200 [=================>............] - ETA: 0s - loss: 1342840753.7190 - KL_divergence: 11.9671
127/200 [==================>...........] - ETA: 0s - loss: 1344252993.5118 - KL_divergence: 11.9948
133/200 [==================>...........] - ETA: 0s - loss: 1344737531.1880 - KL_divergence: 12.0084
139/200 [===================>..........] - ETA: 0s - loss: 1344013442.7626 - KL_divergence: 11.9875
145/200 [====================>.........] - ETA: 0s - loss: 1345296866.8690 - KL_divergence: 11.9809
151/200 [=====================>........] - ETA: 0s - loss: 1344365547.6556 - KL_divergence: 12.0034
157/200 [======================>.......] - ETA: 0s - loss: 1344539381.4013 - KL_divergence: 12.0095
163/200 [=======================>......] - ETA: 0s - loss: 1344656921.1288 - KL_divergence: 12.0068
169/200 [========================>.....] - ETA: 0s - loss: 1343644764.4024 - KL_divergence: 12.0129
175/200 [=========================>....] - ETA: 0s - loss: 1345321105.5543 - KL_divergence: 12.0193
181/200 [==========================>...] - ETA: 0s - loss: 1346173658.5193 - KL_divergence: 12.0184
188/200 [===========================>..] - ETA: 0s - loss: 1346800794.5532 - KL_divergence: 12.0366
194/200 [============================>.] - ETA: 0s - loss: 1347464609.6495 - KL_divergence: 12.0287
200/200 [==============================] - 2s 10ms/step - loss: 1345892866.5600 - KL_divergence: 12.0263 - val_loss: 1369349053.4400 - val_KL_divergence: 11.9801
Epoch 70/100

  1/200 [..............................] - ETA: 1s - loss: 1389623424.0000 - KL_divergence: 12.8415
  7/200 [>.............................] - ETA: 1s - loss: 1335196068.5714 - KL_divergence: 12.1113
 13/200 [>.............................] - ETA: 1s - loss: 1337660081.2308 - KL_divergence: 12.0351
 19/200 [=>............................] - ETA: 1s - loss: 1350952346.9474 - KL_divergence: 12.0588
 25/200 [==>...........................] - ETA: 1s - loss: 1349894702.0800 - KL_divergence: 12.0615
 31/200 [===>..........................] - ETA: 1s - loss: 1342833730.0645 - KL_divergence: 12.0284
 37/200 [====>.........................] - ETA: 1s - loss: 1340794191.5676 - KL_divergence: 12.0355
 43/200 [=====>........................] - ETA: 1s - loss: 1340364776.1860 - KL_divergence: 12.0681
 49/200 [======>.......................] - ETA: 1s - loss: 1338131139.9184 - KL_divergence: 12.0354
 55/200 [=======>......................] - ETA: 1s - loss: 1343247529.8909 - KL_divergence: 12.0497
 61/200 [========>.....................] - ETA: 1s - loss: 1343227211.5410 - KL_divergence: 12.0596
 67/200 [=========>....................] - ETA: 1s - loss: 1335812336.7164 - KL_divergence: 12.0799
 73/200 [=========>....................] - ETA: 1s - loss: 1333967745.7534 - KL_divergence: 12.0668
 79/200 [==========>...................] - ETA: 1s - loss: 1332015069.9747 - KL_divergence: 12.0468
 85/200 [===========>..................] - ETA: 1s - loss: 1331329947.1059 - KL_divergence: 12.0164
 91/200 [============>.................] - ETA: 0s - loss: 1329192808.0879 - KL_divergence: 11.9989
 97/200 [=============>................] - ETA: 0s - loss: 1327431778.9691 - KL_divergence: 11.9910
103/200 [==============>...............] - ETA: 0s - loss: 1326238977.2427 - KL_divergence: 11.9997
109/200 [===============>..............] - ETA: 0s - loss: 1326616401.0275 - KL_divergence: 12.0116
115/200 [================>.............] - ETA: 0s - loss: 1326501506.2261 - KL_divergence: 12.0098
121/200 [=================>............] - ETA: 0s - loss: 1326219179.3719 - KL_divergence: 12.0233
127/200 [==================>...........] - ETA: 0s - loss: 1326979135.4961 - KL_divergence: 12.0256
133/200 [==================>...........] - ETA: 0s - loss: 1326954704.8421 - KL_divergence: 12.0184
139/200 [===================>..........] - ETA: 0s - loss: 1325886091.0504 - KL_divergence: 12.0293
145/200 [====================>.........] - ETA: 0s - loss: 1327717234.7586 - KL_divergence: 12.0344
151/200 [=====================>........] - ETA: 0s - loss: 1329397070.8344 - KL_divergence: 12.0396
157/200 [======================>.......] - ETA: 0s - loss: 1330140209.7325 - KL_divergence: 12.0272
163/200 [=======================>......] - ETA: 0s - loss: 1330574760.8344 - KL_divergence: 12.0295
169/200 [========================>.....] - ETA: 0s - loss: 1330915183.3373 - KL_divergence: 12.0379
175/200 [=========================>....] - ETA: 0s - loss: 1330104731.7943 - KL_divergence: 12.0317
181/200 [==========================>...] - ETA: 0s - loss: 1330101802.4309 - KL_divergence: 12.0363
187/200 [===========================>..] - ETA: 0s - loss: 1331977700.6203 - KL_divergence: 12.0434
193/200 [===========================>..] - ETA: 0s - loss: 1333005357.0984 - KL_divergence: 12.0573
199/200 [============================>.] - ETA: 0s - loss: 1333641886.8744 - KL_divergence: 12.0515
200/200 [==============================] - 2s 10ms/step - loss: 1333543848.3200 - KL_divergence: 12.0479 - val_loss: 1351690983.6800 - val_KL_divergence: 12.1701
Epoch 71/100

  1/200 [..............................] - ETA: 1s - loss: 1338258688.0000 - KL_divergence: 12.5869
  7/200 [>.............................] - ETA: 1s - loss: 1334446610.2857 - KL_divergence: 12.1404
 13/200 [>.............................] - ETA: 1s - loss: 1349975148.3077 - KL_divergence: 12.2891
 19/200 [=>............................] - ETA: 1s - loss: 1343323749.0526 - KL_divergence: 12.2803
 25/200 [==>...........................] - ETA: 1s - loss: 1357846481.9200 - KL_divergence: 12.1905
 31/200 [===>..........................] - ETA: 1s - loss: 1353457317.1613 - KL_divergence: 12.2293
 37/200 [====>.........................] - ETA: 1s - loss: 1357083845.1892 - KL_divergence: 12.1123
 43/200 [=====>........................] - ETA: 1s - loss: 1355655444.8372 - KL_divergence: 12.0550
 49/200 [======>.......................] - ETA: 1s - loss: 1354559597.7143 - KL_divergence: 12.0510
 55/200 [=======>......................] - ETA: 1s - loss: 1354257817.6000 - KL_divergence: 12.0650
 61/200 [========>.....................] - ETA: 1s - loss: 1358469671.8689 - KL_divergence: 12.0569
 67/200 [=========>....................] - ETA: 1s - loss: 1358137792.9552 - KL_divergence: 12.0811
 73/200 [=========>....................] - ETA: 1s - loss: 1355938049.7534 - KL_divergence: 12.0871
 79/200 [==========>...................] - ETA: 1s - loss: 1353107741.1646 - KL_divergence: 12.0959
 85/200 [===========>..................] - ETA: 1s - loss: 1354777163.2941 - KL_divergence: 12.1092
 91/200 [============>.................] - ETA: 0s - loss: 1351517092.5714 - KL_divergence: 12.0985
 97/200 [=============>................] - ETA: 0s - loss: 1349914210.9691 - KL_divergence: 12.0860
103/200 [==============>...............] - ETA: 0s - loss: 1348506877.5146 - KL_divergence: 12.0804
110/200 [===============>..............] - ETA: 0s - loss: 1346156673.1636 - KL_divergence: 12.1090
116/200 [================>.............] - ETA: 0s - loss: 1344551493.5172 - KL_divergence: 12.0943
122/200 [=================>............] - ETA: 0s - loss: 1343798223.7377 - KL_divergence: 12.1211
128/200 [==================>...........] - ETA: 0s - loss: 1344038645.0000 - KL_divergence: 12.1015
135/200 [===================>..........] - ETA: 0s - loss: 1342445986.1333 - KL_divergence: 12.0673
141/200 [====================>.........] - ETA: 0s - loss: 1341622789.4468 - KL_divergence: 12.0539
147/200 [=====================>........] - ETA: 0s - loss: 1341558596.7891 - KL_divergence: 12.0493
153/200 [=====================>........] - ETA: 0s - loss: 1341990234.3529 - KL_divergence: 12.0311
159/200 [======================>.......] - ETA: 0s - loss: 1340999357.9874 - KL_divergence: 12.0347
165/200 [=======================>......] - ETA: 0s - loss: 1339724954.3758 - KL_divergence: 12.0494
171/200 [========================>.....] - ETA: 0s - loss: 1339291142.7368 - KL_divergence: 12.0436
177/200 [=========================>....] - ETA: 0s - loss: 1339514886.5085 - KL_divergence: 12.0379
183/200 [==========================>...] - ETA: 0s - loss: 1338928409.8798 - KL_divergence: 12.0365
189/200 [===========================>..] - ETA: 0s - loss: 1338814466.7090 - KL_divergence: 12.0345
195/200 [============================>.] - ETA: 0s - loss: 1339591813.9077 - KL_divergence: 12.0466
200/200 [==============================] - 2s 10ms/step - loss: 1339247974.4000 - KL_divergence: 12.0506 - val_loss: 1360203023.3600 - val_KL_divergence: 12.1068
Epoch 72/100

  1/200 [..............................] - ETA: 1s - loss: 1439825536.0000 - KL_divergence: 11.4990
  7/200 [>.............................] - ETA: 1s - loss: 1328246144.0000 - KL_divergence: 12.1467
 12/200 [>.............................] - ETA: 1s - loss: 1334398186.6667 - KL_divergence: 12.0899
 18/200 [=>............................] - ETA: 1s - loss: 1337516302.2222 - KL_divergence: 11.9263
 25/200 [==>...........................] - ETA: 1s - loss: 1311099540.4800 - KL_divergence: 11.8745
 31/200 [===>..........................] - ETA: 1s - loss: 1313052308.6452 - KL_divergence: 11.8947
 37/200 [====>.........................] - ETA: 1s - loss: 1318400013.8378 - KL_divergence: 11.8807
 44/200 [=====>........................] - ETA: 1s - loss: 1321299086.5455 - KL_divergence: 11.9236
 50/200 [======>.......................] - ETA: 1s - loss: 1326366574.0800 - KL_divergence: 12.0217
 56/200 [=======>......................] - ETA: 1s - loss: 1323101849.1429 - KL_divergence: 12.0207
 62/200 [========>.....................] - ETA: 1s - loss: 1325312658.5806 - KL_divergence: 12.0573
 68/200 [=========>....................] - ETA: 1s - loss: 1324275661.1765 - KL_divergence: 12.0454
 74/200 [==========>...................] - ETA: 1s - loss: 1327799098.8108 - KL_divergence: 12.0669
 80/200 [===========>..................] - ETA: 1s - loss: 1325886848.0000 - KL_divergence: 12.0858
 86/200 [===========>..................] - ETA: 1s - loss: 1324724710.6977 - KL_divergence: 12.1134
 92/200 [============>.................] - ETA: 0s - loss: 1325273235.4783 - KL_divergence: 12.1527
 99/200 [=============>................] - ETA: 0s - loss: 1325080547.5556 - KL_divergence: 12.1435
105/200 [==============>...............] - ETA: 0s - loss: 1323099945.4476 - KL_divergence: 12.1533
111/200 [===============>..............] - ETA: 0s - loss: 1322689913.0811 - KL_divergence: 12.1679
117/200 [================>.............] - ETA: 0s - loss: 1323375998.9060 - KL_divergence: 12.1630
123/200 [=================>............] - ETA: 0s - loss: 1323097283.6423 - KL_divergence: 12.1568
129/200 [==================>...........] - ETA: 0s - loss: 1324333436.0310 - KL_divergence: 12.1608
135/200 [===================>..........] - ETA: 0s - loss: 1322637674.1926 - KL_divergence: 12.1518
141/200 [====================>.........] - ETA: 0s - loss: 1323999997.2766 - KL_divergence: 12.1540
147/200 [=====================>........] - ETA: 0s - loss: 1323838911.5646 - KL_divergence: 12.1460
153/200 [=====================>........] - ETA: 0s - loss: 1321996249.5163 - KL_divergence: 12.1401
159/200 [======================>.......] - ETA: 0s - loss: 1322563575.9497 - KL_divergence: 12.1426
165/200 [=======================>......] - ETA: 0s - loss: 1321690047.6121 - KL_divergence: 12.1475
171/200 [========================>.....] - ETA: 0s - loss: 1323062423.9532 - KL_divergence: 12.1549
177/200 [=========================>....] - ETA: 0s - loss: 1322910848.0000 - KL_divergence: 12.1805
183/200 [==========================>...] - ETA: 0s - loss: 1321685566.2514 - KL_divergence: 12.1749
189/200 [===========================>..] - ETA: 0s - loss: 1322233310.1376 - KL_divergence: 12.1739
195/200 [============================>.] - ETA: 0s - loss: 1323638069.1692 - KL_divergence: 12.1712
200/200 [==============================] - 2s 10ms/step - loss: 1323194947.8400 - KL_divergence: 12.1658 - val_loss: 1350194158.0800 - val_KL_divergence: 12.1465
Epoch 73/100

  1/200 [..............................] - ETA: 1s - loss: 1224564736.0000 - KL_divergence: 13.0698
  7/200 [>.............................] - ETA: 1s - loss: 1311967872.0000 - KL_divergence: 12.5120
 13/200 [>.............................] - ETA: 1s - loss: 1331307598.7692 - KL_divergence: 12.4680
 19/200 [=>............................] - ETA: 1s - loss: 1324185323.7895 - KL_divergence: 12.3607
 25/200 [==>...........................] - ETA: 1s - loss: 1327500472.3200 - KL_divergence: 12.3218
 31/200 [===>..........................] - ETA: 1s - loss: 1324021892.1290 - KL_divergence: 12.1905
 37/200 [====>.........................] - ETA: 1s - loss: 1323975022.7027 - KL_divergence: 12.1252
 43/200 [=====>........................] - ETA: 1s - loss: 1329360395.9070 - KL_divergence: 12.1449
 49/200 [======>.......................] - ETA: 1s - loss: 1325225516.4082 - KL_divergence: 12.1550
 55/200 [=======>......................] - ETA: 1s - loss: 1325952432.8727 - KL_divergence: 12.1298
 61/200 [========>.....................] - ETA: 1s - loss: 1322628515.6721 - KL_divergence: 12.1527
 68/200 [=========>....................] - ETA: 1s - loss: 1325552619.2941 - KL_divergence: 12.2217
 74/200 [==========>...................] - ETA: 1s - loss: 1325070242.5946 - KL_divergence: 12.2133
 80/200 [===========>..................] - ETA: 1s - loss: 1327433484.8000 - KL_divergence: 12.2474
 86/200 [===========>..................] - ETA: 1s - loss: 1326871732.0930 - KL_divergence: 12.2520
 92/200 [============>.................] - ETA: 0s - loss: 1328208827.8261 - KL_divergence: 12.2229
 99/200 [=============>................] - ETA: 0s - loss: 1328802578.1010 - KL_divergence: 12.2030
105/200 [==============>...............] - ETA: 0s - loss: 1329128619.8857 - KL_divergence: 12.2094
111/200 [===============>..............] - ETA: 0s - loss: 1331157821.1171 - KL_divergence: 12.2103
117/200 [================>.............] - ETA: 0s - loss: 1331104703.4530 - KL_divergence: 12.2106
123/200 [=================>............] - ETA: 0s - loss: 1332657161.3659 - KL_divergence: 12.2039
129/200 [==================>...........] - ETA: 0s - loss: 1334372580.2171 - KL_divergence: 12.2015
135/200 [===================>..........] - ETA: 0s - loss: 1332966604.8000 - KL_divergence: 12.1811
141/200 [====================>.........] - ETA: 0s - loss: 1333193890.4965 - KL_divergence: 12.1658
147/200 [=====================>........] - ETA: 0s - loss: 1331674939.2109 - KL_divergence: 12.1649
153/200 [=====================>........] - ETA: 0s - loss: 1331717688.8889 - KL_divergence: 12.1715
159/200 [======================>.......] - ETA: 0s - loss: 1332599549.5849 - KL_divergence: 12.1771
165/200 [=======================>......] - ETA: 0s - loss: 1330926034.2303 - KL_divergence: 12.1687
171/200 [========================>.....] - ETA: 0s - loss: 1330361583.5322 - KL_divergence: 12.1494
177/200 [=========================>....] - ETA: 0s - loss: 1330181954.5311 - KL_divergence: 12.1533
183/200 [==========================>...] - ETA: 0s - loss: 1328893549.8142 - KL_divergence: 12.1478
189/200 [===========================>..] - ETA: 0s - loss: 1328743526.9418 - KL_divergence: 12.1445
195/200 [============================>.] - ETA: 0s - loss: 1327631816.2051 - KL_divergence: 12.1340
200/200 [==============================] - 2s 10ms/step - loss: 1328872472.3200 - KL_divergence: 12.1325 - val_loss: 1345322426.8800 - val_KL_divergence: 12.0951
Epoch 74/100

  1/200 [..............................] - ETA: 1s - loss: 1348650240.0000 - KL_divergence: 12.0838
  7/200 [>.............................] - ETA: 1s - loss: 1267407762.2857 - KL_divergence: 12.0497
 14/200 [=>............................] - ETA: 1s - loss: 1300210313.1429 - KL_divergence: 12.1419
 21/200 [==>...........................] - ETA: 1s - loss: 1308922404.5714 - KL_divergence: 12.2362
 28/200 [===>..........................] - ETA: 1s - loss: 1310550084.5714 - KL_divergence: 12.3222
 34/200 [====>.........................] - ETA: 1s - loss: 1311274285.1765 - KL_divergence: 12.3189
 40/200 [=====>........................] - ETA: 1s - loss: 1317068793.6000 - KL_divergence: 12.2816
 46/200 [=====>........................] - ETA: 1s - loss: 1311584236.5217 - KL_divergence: 12.2419
 52/200 [======>.......................] - ETA: 1s - loss: 1314250993.2308 - KL_divergence: 12.2381
 58/200 [=======>......................] - ETA: 1s - loss: 1319981680.5517 - KL_divergence: 12.2172
 64/200 [========>.....................] - ETA: 1s - loss: 1317277690.0000 - KL_divergence: 12.2296
 70/200 [=========>....................] - ETA: 1s - loss: 1318404163.6571 - KL_divergence: 12.1985
 76/200 [==========>...................] - ETA: 1s - loss: 1315239461.0526 - KL_divergence: 12.2153
 82/200 [===========>..................] - ETA: 1s - loss: 1316762383.6098 - KL_divergence: 12.1914
 88/200 [============>.................] - ETA: 0s - loss: 1317050624.0000 - KL_divergence: 12.1431
 94/200 [=============>................] - ETA: 0s - loss: 1318102635.5745 - KL_divergence: 12.1661
100/200 [==============>...............] - ETA: 0s - loss: 1319263037.4400 - KL_divergence: 12.1679
106/200 [==============>...............] - ETA: 0s - loss: 1319861010.1132 - KL_divergence: 12.1621
112/200 [===============>..............] - ETA: 0s - loss: 1322248034.2857 - KL_divergence: 12.1607
118/200 [================>.............] - ETA: 0s - loss: 1322323176.1356 - KL_divergence: 12.1459
124/200 [=================>............] - ETA: 0s - loss: 1321966094.4516 - KL_divergence: 12.1550
130/200 [==================>...........] - ETA: 0s - loss: 1321802854.4000 - KL_divergence: 12.1469
136/200 [===================>..........] - ETA: 0s - loss: 1320912062.1176 - KL_divergence: 12.1368
143/200 [====================>.........] - ETA: 0s - loss: 1323778748.8671 - KL_divergence: 12.1197
150/200 [=====================>........] - ETA: 0s - loss: 1324200236.3733 - KL_divergence: 12.1106
156/200 [======================>.......] - ETA: 0s - loss: 1323678312.2051 - KL_divergence: 12.1090
162/200 [=======================>......] - ETA: 0s - loss: 1321937897.8765 - KL_divergence: 12.1003
168/200 [========================>.....] - ETA: 0s - loss: 1322457728.0000 - KL_divergence: 12.1014
174/200 [=========================>....] - ETA: 0s - loss: 1321845297.2874 - KL_divergence: 12.1066
180/200 [==========================>...] - ETA: 0s - loss: 1320893187.5556 - KL_divergence: 12.1021
186/200 [==========================>...] - ETA: 0s - loss: 1321859208.9462 - KL_divergence: 12.0967
192/200 [===========================>..] - ETA: 0s - loss: 1323013765.3333 - KL_divergence: 12.1029
199/200 [============================>.] - ETA: 0s - loss: 1323258166.6734 - KL_divergence: 12.1269
200/200 [==============================] - 2s 10ms/step - loss: 1323500699.5200 - KL_divergence: 12.1248 - val_loss: 1352819326.7200 - val_KL_divergence: 12.1672
Epoch 75/100

  1/200 [..............................] - ETA: 1s - loss: 1412003584.0000 - KL_divergence: 11.9191
  7/200 [>.............................] - ETA: 1s - loss: 1339636059.4286 - KL_divergence: 12.5616
 14/200 [=>............................] - ETA: 1s - loss: 1308239588.5714 - KL_divergence: 12.1845
 21/200 [==>...........................] - ETA: 1s - loss: 1329067337.1429 - KL_divergence: 12.1769
 28/200 [===>..........................] - ETA: 1s - loss: 1323001531.4286 - KL_divergence: 12.1392
 35/200 [====>.........................] - ETA: 1s - loss: 1323109317.4857 - KL_divergence: 12.0490
 41/200 [=====>........................] - ETA: 1s - loss: 1323066733.2683 - KL_divergence: 12.0353
 47/200 [======>.......................] - ETA: 1s - loss: 1323374273.3617 - KL_divergence: 12.0556
 53/200 [======>.......................] - ETA: 1s - loss: 1328328088.1509 - KL_divergence: 12.0705
 59/200 [=======>......................] - ETA: 1s - loss: 1326825801.7627 - KL_divergence: 12.0605
 65/200 [========>.....................] - ETA: 1s - loss: 1328196722.2154 - KL_divergence: 12.0533
 71/200 [=========>....................] - ETA: 1s - loss: 1330499232.4507 - KL_divergence: 12.0133
 77/200 [==========>...................] - ETA: 1s - loss: 1332379529.9740 - KL_divergence: 12.0442
 83/200 [===========>..................] - ETA: 1s - loss: 1330021773.8795 - KL_divergence: 12.0541
 89/200 [============>.................] - ETA: 0s - loss: 1329110804.1348 - KL_divergence: 12.0403
 95/200 [=============>................] - ETA: 0s - loss: 1326576185.9368 - KL_divergence: 12.0036
101/200 [==============>...............] - ETA: 0s - loss: 1327596177.7426 - KL_divergence: 11.9930
107/200 [===============>..............] - ETA: 0s - loss: 1328119647.7009 - KL_divergence: 11.9859
113/200 [===============>..............] - ETA: 0s - loss: 1328926501.3805 - KL_divergence: 11.9924
119/200 [================>.............] - ETA: 0s - loss: 1330556855.9328 - KL_divergence: 11.9948
125/200 [=================>............] - ETA: 0s - loss: 1331407149.0560 - KL_divergence: 12.0034
131/200 [==================>...........] - ETA: 0s - loss: 1332291372.9466 - KL_divergence: 12.0183
137/200 [===================>..........] - ETA: 0s - loss: 1332364297.3431 - KL_divergence: 12.0397
144/200 [====================>.........] - ETA: 0s - loss: 1331925273.7778 - KL_divergence: 12.0413
150/200 [=====================>........] - ETA: 0s - loss: 1331969820.1600 - KL_divergence: 12.0507
155/200 [======================>.......] - ETA: 0s - loss: 1331135440.1032 - KL_divergence: 12.0589
161/200 [=======================>......] - ETA: 0s - loss: 1331815889.8882 - KL_divergence: 12.0727
168/200 [========================>.....] - ETA: 0s - loss: 1329953080.3810 - KL_divergence: 12.0779
174/200 [=========================>....] - ETA: 0s - loss: 1328546301.7931 - KL_divergence: 12.0820
180/200 [==========================>...] - ETA: 0s - loss: 1329091296.0000 - KL_divergence: 12.0750
186/200 [==========================>...] - ETA: 0s - loss: 1330031047.5699 - KL_divergence: 12.0805
192/200 [===========================>..] - ETA: 0s - loss: 1329065904.0000 - KL_divergence: 12.0844
198/200 [============================>.] - ETA: 0s - loss: 1328320795.7980 - KL_divergence: 12.0927
200/200 [==============================] - 2s 10ms/step - loss: 1328017893.1200 - KL_divergence: 12.0962 - val_loss: 1349743722.2400 - val_KL_divergence: 11.8525
Epoch 76/100

  1/200 [..............................] - ETA: 1s - loss: 1391749504.0000 - KL_divergence: 11.9698
  7/200 [>.............................] - ETA: 1s - loss: 1319913947.4286 - KL_divergence: 12.0351
 13/200 [>.............................] - ETA: 1s - loss: 1323333976.6154 - KL_divergence: 12.0449
 19/200 [=>............................] - ETA: 1s - loss: 1309522600.4211 - KL_divergence: 12.2268
 25/200 [==>...........................] - ETA: 1s - loss: 1301516195.8400 - KL_divergence: 12.2202
 32/200 [===>..........................] - ETA: 1s - loss: 1304994732.0000 - KL_divergence: 12.2737
 39/200 [====>.........................] - ETA: 1s - loss: 1311828821.3333 - KL_divergence: 12.1627
 46/200 [=====>........................] - ETA: 1s - loss: 1315717590.2609 - KL_divergence: 12.1867
 53/200 [======>.......................] - ETA: 1s - loss: 1320226586.5660 - KL_divergence: 12.1981
 60/200 [========>.....................] - ETA: 1s - loss: 1317945286.4000 - KL_divergence: 12.1776
 67/200 [=========>....................] - ETA: 1s - loss: 1319196629.9701 - KL_divergence: 12.1268
 73/200 [=========>....................] - ETA: 1s - loss: 1317914029.5890 - KL_divergence: 12.1158
 79/200 [==========>...................] - ETA: 1s - loss: 1316732300.9620 - KL_divergence: 12.1246
 85/200 [===========>..................] - ETA: 0s - loss: 1318880364.4235 - KL_divergence: 12.1861
 91/200 [============>.................] - ETA: 0s - loss: 1320142819.8681 - KL_divergence: 12.1448
 97/200 [=============>................] - ETA: 0s - loss: 1319561755.7113 - KL_divergence: 12.1413
103/200 [==============>...............] - ETA: 0s - loss: 1321863750.8350 - KL_divergence: 12.1347
109/200 [===============>..............] - ETA: 0s - loss: 1325511014.1651 - KL_divergence: 12.1391
115/200 [================>.............] - ETA: 0s - loss: 1324199513.0435 - KL_divergence: 12.1227
121/200 [=================>............] - ETA: 0s - loss: 1323966450.2479 - KL_divergence: 12.1093
127/200 [==================>...........] - ETA: 0s - loss: 1324445791.7480 - KL_divergence: 12.1340
133/200 [==================>...........] - ETA: 0s - loss: 1323667870.7970 - KL_divergence: 12.1224
139/200 [===================>..........] - ETA: 0s - loss: 1322706115.2230 - KL_divergence: 12.1063
145/200 [====================>.........] - ETA: 0s - loss: 1323233762.8690 - KL_divergence: 12.0949
151/200 [=====================>........] - ETA: 0s - loss: 1323326379.2318 - KL_divergence: 12.0860
157/200 [======================>.......] - ETA: 0s - loss: 1323339897.4777 - KL_divergence: 12.0906
163/200 [=======================>......] - ETA: 0s - loss: 1323575516.6626 - KL_divergence: 12.0894
169/200 [========================>.....] - ETA: 0s - loss: 1322990064.0947 - KL_divergence: 12.0849
175/200 [=========================>....] - ETA: 0s - loss: 1324103987.9314 - KL_divergence: 12.0889
181/200 [==========================>...] - ETA: 0s - loss: 1325633108.1547 - KL_divergence: 12.1059
187/200 [===========================>..] - ETA: 0s - loss: 1325763618.2246 - KL_divergence: 12.1159
193/200 [===========================>..] - ETA: 0s - loss: 1324992382.6736 - KL_divergence: 12.1141
199/200 [============================>.] - ETA: 0s - loss: 1325000577.2864 - KL_divergence: 12.1292
200/200 [==============================] - 2s 10ms/step - loss: 1325236021.1200 - KL_divergence: 12.1339 - val_loss: 1347255233.2800 - val_KL_divergence: 11.9784
Epoch 77/100

  1/200 [..............................] - ETA: 1s - loss: 1378731264.0000 - KL_divergence: 12.5530
  7/200 [>.............................] - ETA: 1s - loss: 1301389147.4286 - KL_divergence: 11.8831
 14/200 [=>............................] - ETA: 1s - loss: 1327545124.5714 - KL_divergence: 11.8302
 20/200 [==>...........................] - ETA: 1s - loss: 1326558700.8000 - KL_divergence: 11.9146
 26/200 [==>...........................] - ETA: 1s - loss: 1321590331.0769 - KL_divergence: 11.9257
 32/200 [===>..........................] - ETA: 1s - loss: 1321306820.0000 - KL_divergence: 11.9469
 38/200 [====>.........................] - ETA: 1s - loss: 1321238322.5263 - KL_divergence: 11.8947
 44/200 [=====>........................] - ETA: 1s - loss: 1322237678.5455 - KL_divergence: 11.8914
 50/200 [======>.......................] - ETA: 1s - loss: 1318318105.6000 - KL_divergence: 11.9287
 56/200 [=======>......................] - ETA: 1s - loss: 1319959264.0000 - KL_divergence: 11.9664
 62/200 [========>.....................] - ETA: 1s - loss: 1314581444.1290 - KL_divergence: 12.0126
 69/200 [=========>....................] - ETA: 1s - loss: 1314100255.5362 - KL_divergence: 12.0568
 76/200 [==========>...................] - ETA: 1s - loss: 1311401298.5263 - KL_divergence: 12.0884
 82/200 [===========>..................] - ETA: 1s - loss: 1313465106.7317 - KL_divergence: 12.0997
 88/200 [============>.................] - ETA: 0s - loss: 1317658251.6364 - KL_divergence: 12.0932
 94/200 [=============>................] - ETA: 0s - loss: 1319389431.8298 - KL_divergence: 12.0935
100/200 [==============>...............] - ETA: 0s - loss: 1318707681.2800 - KL_divergence: 12.1393
106/200 [==============>...............] - ETA: 0s - loss: 1319648429.8868 - KL_divergence: 12.1474
112/200 [===============>..............] - ETA: 0s - loss: 1321129128.0000 - KL_divergence: 12.1495
118/200 [================>.............] - ETA: 0s - loss: 1319290095.7288 - KL_divergence: 12.1406
124/200 [=================>............] - ETA: 0s - loss: 1319680156.9032 - KL_divergence: 12.1590
130/200 [==================>...........] - ETA: 0s - loss: 1319174318.2769 - KL_divergence: 12.1660
136/200 [===================>..........] - ETA: 0s - loss: 1318637056.0000 - KL_divergence: 12.1692
142/200 [====================>.........] - ETA: 0s - loss: 1318814518.0845 - KL_divergence: 12.1780
148/200 [=====================>........] - ETA: 0s - loss: 1317682633.5135 - KL_divergence: 12.1897
154/200 [======================>.......] - ETA: 0s - loss: 1318713366.4416 - KL_divergence: 12.2265
160/200 [=======================>......] - ETA: 0s - loss: 1320690101.6000 - KL_divergence: 12.2508
166/200 [=======================>......] - ETA: 0s - loss: 1320399898.9880 - KL_divergence: 12.2678
172/200 [========================>.....] - ETA: 0s - loss: 1320432727.8140 - KL_divergence: 12.2751
178/200 [=========================>....] - ETA: 0s - loss: 1320039938.8764 - KL_divergence: 12.2764
184/200 [==========================>...] - ETA: 0s - loss: 1319653704.3478 - KL_divergence: 12.2796
191/200 [===========================>..] - ETA: 0s - loss: 1319806252.9005 - KL_divergence: 12.2890
197/200 [============================>.] - ETA: 0s - loss: 1320757431.8782 - KL_divergence: 12.2940
200/200 [==============================] - 2s 10ms/step - loss: 1320345327.3600 - KL_divergence: 12.3026 - val_loss: 1360818977.2800 - val_KL_divergence: 12.1928
Epoch 78/100

  1/200 [..............................] - ETA: 1s - loss: 1330122240.0000 - KL_divergence: 11.3334
  7/200 [>.............................] - ETA: 1s - loss: 1348814171.4286 - KL_divergence: 12.3702
 13/200 [>.............................] - ETA: 1s - loss: 1337054375.3846 - KL_divergence: 12.3239
 19/200 [=>............................] - ETA: 1s - loss: 1341881835.7895 - KL_divergence: 12.4334
 25/200 [==>...........................] - ETA: 1s - loss: 1332367877.1200 - KL_divergence: 12.4432
 31/200 [===>..........................] - ETA: 1s - loss: 1330753061.1613 - KL_divergence: 12.3990
 37/200 [====>.........................] - ETA: 1s - loss: 1332168710.9189 - KL_divergence: 12.4985
 43/200 [=====>........................] - ETA: 1s - loss: 1327669828.4651 - KL_divergence: 12.5413
 49/200 [======>.......................] - ETA: 1s - loss: 1328701228.4082 - KL_divergence: 12.5115
 55/200 [=======>......................] - ETA: 1s - loss: 1326132058.7636 - KL_divergence: 12.5139
 61/200 [========>.....................] - ETA: 1s - loss: 1329933419.0164 - KL_divergence: 12.5002
 67/200 [=========>....................] - ETA: 1s - loss: 1329305777.6716 - KL_divergence: 12.4511
 73/200 [=========>....................] - ETA: 1s - loss: 1327241799.8904 - KL_divergence: 12.4737
 79/200 [==========>...................] - ETA: 1s - loss: 1328253992.5063 - KL_divergence: 12.4769
 85/200 [===========>..................] - ETA: 1s - loss: 1326322665.4118 - KL_divergence: 12.4711
 91/200 [============>.................] - ETA: 0s - loss: 1324809275.0769 - KL_divergence: 12.4596
 97/200 [=============>................] - ETA: 0s - loss: 1323185130.8866 - KL_divergence: 12.4894
103/200 [==============>...............] - ETA: 0s - loss: 1323875702.0583 - KL_divergence: 12.4881
109/200 [===============>..............] - ETA: 0s - loss: 1324846700.0367 - KL_divergence: 12.4834
115/200 [================>.............] - ETA: 0s - loss: 1324718646.5391 - KL_divergence: 12.4575
121/200 [=================>............] - ETA: 0s - loss: 1325901054.9421 - KL_divergence: 12.4341
127/200 [==================>...........] - ETA: 0s - loss: 1325031963.2126 - KL_divergence: 12.4291
134/200 [===================>..........] - ETA: 0s - loss: 1323630048.4776 - KL_divergence: 12.4073
140/200 [====================>.........] - ETA: 0s - loss: 1323850704.4571 - KL_divergence: 12.3993
146/200 [====================>.........] - ETA: 0s - loss: 1323404255.5616 - KL_divergence: 12.3836
152/200 [=====================>........] - ETA: 0s - loss: 1323583050.9474 - KL_divergence: 12.3826
158/200 [======================>.......] - ETA: 0s - loss: 1325296685.3671 - KL_divergence: 12.3863
164/200 [=======================>......] - ETA: 0s - loss: 1325924924.8780 - KL_divergence: 12.3815
170/200 [========================>.....] - ETA: 0s - loss: 1327226760.2824 - KL_divergence: 12.3594
176/200 [=========================>....] - ETA: 0s - loss: 1327816821.0909 - KL_divergence: 12.3607
182/200 [==========================>...] - ETA: 0s - loss: 1328717591.9121 - KL_divergence: 12.3591
188/200 [===========================>..] - ETA: 0s - loss: 1328791542.4681 - KL_divergence: 12.3694
195/200 [============================>.] - ETA: 0s - loss: 1328862371.4462 - KL_divergence: 12.3749
200/200 [==============================] - 2s 10ms/step - loss: 1329081096.9600 - KL_divergence: 12.3833 - val_loss: 1341542851.8400 - val_KL_divergence: 12.4575
Epoch 79/100

  1/200 [..............................] - ETA: 1s - loss: 1361769728.0000 - KL_divergence: 13.8048
  7/200 [>.............................] - ETA: 1s - loss: 1330655872.0000 - KL_divergence: 12.5793
 13/200 [>.............................] - ETA: 1s - loss: 1333428647.3846 - KL_divergence: 12.4428
 19/200 [=>............................] - ETA: 1s - loss: 1323264720.8421 - KL_divergence: 12.5049
 25/200 [==>...........................] - ETA: 1s - loss: 1317102899.2000 - KL_divergence: 12.4777
 31/200 [===>..........................] - ETA: 1s - loss: 1314273829.1613 - KL_divergence: 12.4695
 37/200 [====>.........................] - ETA: 1s - loss: 1311511500.1081 - KL_divergence: 12.4724
 43/200 [=====>........................] - ETA: 1s - loss: 1308434649.3023 - KL_divergence: 12.5217
 49/200 [======>.......................] - ETA: 1s - loss: 1309571892.2449 - KL_divergence: 12.5366
 55/200 [=======>......................] - ETA: 1s - loss: 1310358593.1636 - KL_divergence: 12.5033
 61/200 [========>.....................] - ETA: 1s - loss: 1308212444.3279 - KL_divergence: 12.5298
 67/200 [=========>....................] - ETA: 1s - loss: 1308475401.5522 - KL_divergence: 12.5343
 73/200 [=========>....................] - ETA: 1s - loss: 1306412288.0000 - KL_divergence: 12.5152
 79/200 [==========>...................] - ETA: 1s - loss: 1307532855.0886 - KL_divergence: 12.5045
 85/200 [===========>..................] - ETA: 1s - loss: 1309188892.6118 - KL_divergence: 12.5036
 91/200 [============>.................] - ETA: 0s - loss: 1310308679.7363 - KL_divergence: 12.5100
 97/200 [=============>................] - ETA: 0s - loss: 1311454320.1649 - KL_divergence: 12.4838
103/200 [==============>...............] - ETA: 0s - loss: 1308894445.3592 - KL_divergence: 12.4615
109/200 [===============>..............] - ETA: 0s - loss: 1307364029.0642 - KL_divergence: 12.4513
115/200 [================>.............] - ETA: 0s - loss: 1308563303.5130 - KL_divergence: 12.4618
121/200 [=================>............] - ETA: 0s - loss: 1310199768.8595 - KL_divergence: 12.4564
127/200 [==================>...........] - ETA: 0s - loss: 1310628646.2992 - KL_divergence: 12.4240
133/200 [==================>...........] - ETA: 0s - loss: 1312503811.8496 - KL_divergence: 12.4255
139/200 [===================>..........] - ETA: 0s - loss: 1313853118.6187 - KL_divergence: 12.4085
145/200 [====================>.........] - ETA: 0s - loss: 1312847837.5724 - KL_divergence: 12.4063
151/200 [=====================>........] - ETA: 0s - loss: 1311784822.6755 - KL_divergence: 12.3886
157/200 [======================>.......] - ETA: 0s - loss: 1312793347.2611 - KL_divergence: 12.3845
163/200 [=======================>......] - ETA: 0s - loss: 1312562223.9018 - KL_divergence: 12.3732
169/200 [========================>.....] - ETA: 0s - loss: 1312993531.4556 - KL_divergence: 12.3751
175/200 [=========================>....] - ETA: 0s - loss: 1313762152.5943 - KL_divergence: 12.3753
181/200 [==========================>...] - ETA: 0s - loss: 1313253625.6354 - KL_divergence: 12.3784
187/200 [===========================>..] - ETA: 0s - loss: 1312461401.6684 - KL_divergence: 12.3740
193/200 [===========================>..] - ETA: 0s - loss: 1313200985.5337 - KL_divergence: 12.3632
199/200 [============================>.] - ETA: 0s - loss: 1314025698.4121 - KL_divergence: 12.3548
200/200 [==============================] - 2s 10ms/step - loss: 1313745335.0400 - KL_divergence: 12.3520 - val_loss: 1336170382.0800 - val_KL_divergence: 12.3289
Epoch 80/100

  1/200 [..............................] - ETA: 1s - loss: 1268739968.0000 - KL_divergence: 13.5306
  7/200 [>.............................] - ETA: 1s - loss: 1319829558.8571 - KL_divergence: 12.5522
 13/200 [>.............................] - ETA: 1s - loss: 1327432211.6923 - KL_divergence: 12.2983
 19/200 [=>............................] - ETA: 1s - loss: 1314533032.4211 - KL_divergence: 12.2728
 25/200 [==>...........................] - ETA: 1s - loss: 1310319795.2000 - KL_divergence: 12.2923
 31/200 [===>..........................] - ETA: 1s - loss: 1308008006.1935 - KL_divergence: 12.3166
 37/200 [====>.........................] - ETA: 1s - loss: 1303554625.7297 - KL_divergence: 12.3583
 43/200 [=====>........................] - ETA: 1s - loss: 1303225832.1860 - KL_divergence: 12.3666
 49/200 [======>.......................] - ETA: 1s - loss: 1303777259.1020 - KL_divergence: 12.3817
 55/200 [=======>......................] - ETA: 1s - loss: 1304545084.5091 - KL_divergence: 12.3643
 62/200 [========>.....................] - ETA: 1s - loss: 1303788176.5161 - KL_divergence: 12.3747
 68/200 [=========>....................] - ETA: 1s - loss: 1305068007.5294 - KL_divergence: 12.3688
 74/200 [==========>...................] - ETA: 1s - loss: 1306873771.2432 - KL_divergence: 12.3827
 80/200 [===========>..................] - ETA: 1s - loss: 1309169302.4000 - KL_divergence: 12.3959
 86/200 [===========>..................] - ETA: 1s - loss: 1307574093.3953 - KL_divergence: 12.3674
 92/200 [============>.................] - ETA: 0s - loss: 1308988626.0870 - KL_divergence: 12.3670
 98/200 [=============>................] - ETA: 0s - loss: 1312060094.6939 - KL_divergence: 12.3707
104/200 [==============>...............] - ETA: 0s - loss: 1310225073.2308 - KL_divergence: 12.3914
110/200 [===============>..............] - ETA: 0s - loss: 1310127314.6182 - KL_divergence: 12.3837
116/200 [================>.............] - ETA: 0s - loss: 1310875922.7586 - KL_divergence: 12.3721
122/200 [=================>............] - ETA: 0s - loss: 1310631894.0328 - KL_divergence: 12.3689
128/200 [==================>...........] - ETA: 0s - loss: 1309909506.0000 - KL_divergence: 12.3672
134/200 [===================>..........] - ETA: 0s - loss: 1309649841.6716 - KL_divergence: 12.3427
140/200 [====================>.........] - ETA: 0s - loss: 1311240146.2857 - KL_divergence: 12.3335
146/200 [====================>.........] - ETA: 0s - loss: 1312043181.5890 - KL_divergence: 12.3440
152/200 [=====================>........] - ETA: 0s - loss: 1313002320.8421 - KL_divergence: 12.3348
158/200 [======================>.......] - ETA: 0s - loss: 1312804886.6835 - KL_divergence: 12.3270
164/200 [=======================>......] - ETA: 0s - loss: 1314934311.8049 - KL_divergence: 12.3178
170/200 [========================>.....] - ETA: 0s - loss: 1313633105.3176 - KL_divergence: 12.3202
177/200 [=========================>....] - ETA: 0s - loss: 1313455105.4463 - KL_divergence: 12.3195
184/200 [==========================>...] - ETA: 0s - loss: 1313007907.4783 - KL_divergence: 12.3166
190/200 [===========================>..] - ETA: 0s - loss: 1313001353.4316 - KL_divergence: 12.3345
196/200 [============================>.] - ETA: 0s - loss: 1313290132.8980 - KL_divergence: 12.3349
200/200 [==============================] - 2s 10ms/step - loss: 1314462893.4400 - KL_divergence: 12.3498 - val_loss: 1344486298.8800 - val_KL_divergence: 12.4300
Epoch 81/100

  1/200 [..............................] - ETA: 1s - loss: 1341117696.0000 - KL_divergence: 13.3925
  7/200 [>.............................] - ETA: 1s - loss: 1277964342.8571 - KL_divergence: 12.4083
 13/200 [>.............................] - ETA: 1s - loss: 1304477124.9231 - KL_divergence: 12.3892
 19/200 [=>............................] - ETA: 1s - loss: 1321227189.8947 - KL_divergence: 12.4072
 25/200 [==>...........................] - ETA: 1s - loss: 1329969280.0000 - KL_divergence: 12.5001
 31/200 [===>..........................] - ETA: 1s - loss: 1336402403.0968 - KL_divergence: 12.4348
 37/200 [====>.........................] - ETA: 1s - loss: 1327261038.7027 - KL_divergence: 12.4542
 43/200 [=====>........................] - ETA: 1s - loss: 1328609744.3721 - KL_divergence: 12.4676
 49/200 [======>.......................] - ETA: 1s - loss: 1328597057.3061 - KL_divergence: 12.4721
 55/200 [=======>......................] - ETA: 1s - loss: 1325229158.4000 - KL_divergence: 12.4692
 61/200 [========>.....................] - ETA: 1s - loss: 1327356189.3770 - KL_divergence: 12.4982
 67/200 [=========>....................] - ETA: 1s - loss: 1327495825.1940 - KL_divergence: 12.4854
 73/200 [=========>....................] - ETA: 1s - loss: 1327375765.0411 - KL_divergence: 12.5059
 79/200 [==========>...................] - ETA: 1s - loss: 1327803234.8354 - KL_divergence: 12.5087
 86/200 [===========>..................] - ETA: 0s - loss: 1326491342.8837 - KL_divergence: 12.4992
 92/200 [============>.................] - ETA: 0s - loss: 1327200297.7391 - KL_divergence: 12.5184
 98/200 [=============>................] - ETA: 0s - loss: 1331171525.2245 - KL_divergence: 12.5581
103/200 [==============>...............] - ETA: 0s - loss: 1331379577.7864 - KL_divergence: 12.5567
109/200 [===============>..............] - ETA: 0s - loss: 1328684575.7064 - KL_divergence: 12.5400
115/200 [================>.............] - ETA: 0s - loss: 1328940070.9565 - KL_divergence: 12.5376
121/200 [=================>............] - ETA: 0s - loss: 1329475036.0331 - KL_divergence: 12.5306
127/200 [==================>...........] - ETA: 0s - loss: 1329288574.9921 - KL_divergence: 12.5379
133/200 [==================>...........] - ETA: 0s - loss: 1328719513.9850 - KL_divergence: 12.5236
139/200 [===================>..........] - ETA: 0s - loss: 1327624731.6259 - KL_divergence: 12.5385
145/200 [====================>.........] - ETA: 0s - loss: 1327783326.8966 - KL_divergence: 12.5319
151/200 [=====================>........] - ETA: 0s - loss: 1326791808.0000 - KL_divergence: 12.5381
157/200 [======================>.......] - ETA: 0s - loss: 1327129562.4968 - KL_divergence: 12.5310
163/200 [=======================>......] - ETA: 0s - loss: 1326572135.6564 - KL_divergence: 12.5263
169/200 [========================>.....] - ETA: 0s - loss: 1326419434.7929 - KL_divergence: 12.5135
175/200 [=========================>....] - ETA: 0s - loss: 1327118068.2971 - KL_divergence: 12.5058
181/200 [==========================>...] - ETA: 0s - loss: 1326639401.0166 - KL_divergence: 12.4993
187/200 [===========================>..] - ETA: 0s - loss: 1326803091.8503 - KL_divergence: 12.4901
194/200 [============================>.] - ETA: 0s - loss: 1325662134.1031 - KL_divergence: 12.4991
200/200 [==============================] - 2s 10ms/step - loss: 1324451006.0800 - KL_divergence: 12.5064 - val_loss: 1332367329.2800 - val_KL_divergence: 12.3403
Epoch 82/100

  1/200 [..............................] - ETA: 1s - loss: 1460339328.0000 - KL_divergence: 12.6530
  7/200 [>.............................] - ETA: 1s - loss: 1358954112.0000 - KL_divergence: 12.5093
 12/200 [>.............................] - ETA: 1s - loss: 1320928917.3333 - KL_divergence: 12.5287
 18/200 [=>............................] - ETA: 1s - loss: 1316724629.3333 - KL_divergence: 12.4353
 24/200 [==>...........................] - ETA: 1s - loss: 1306236560.0000 - KL_divergence: 12.4615
 30/200 [===>..........................] - ETA: 1s - loss: 1307770781.8667 - KL_divergence: 12.3615
 36/200 [====>.........................] - ETA: 1s - loss: 1312254826.6667 - KL_divergence: 12.4435
 42/200 [=====>........................] - ETA: 1s - loss: 1306111984.7619 - KL_divergence: 12.4030
 48/200 [======>.......................] - ETA: 1s - loss: 1306883544.0000 - KL_divergence: 12.4048
 54/200 [=======>......................] - ETA: 1s - loss: 1299475048.2963 - KL_divergence: 12.4550
 60/200 [========>.....................] - ETA: 1s - loss: 1299540902.4000 - KL_divergence: 12.4631
 67/200 [=========>....................] - ETA: 1s - loss: 1299632817.6716 - KL_divergence: 12.4215
 74/200 [==========>...................] - ETA: 1s - loss: 1297419852.1081 - KL_divergence: 12.4066
 80/200 [===========>..................] - ETA: 1s - loss: 1297632796.8000 - KL_divergence: 12.3860
 86/200 [===========>..................] - ETA: 1s - loss: 1298108232.9302 - KL_divergence: 12.3988
 92/200 [============>.................] - ETA: 0s - loss: 1300092118.2609 - KL_divergence: 12.3785
 98/200 [=============>................] - ETA: 0s - loss: 1301316681.1429 - KL_divergence: 12.3911
104/200 [==============>...............] - ETA: 0s - loss: 1300812971.0769 - KL_divergence: 12.3867
110/200 [===============>..............] - ETA: 0s - loss: 1301969802.4727 - KL_divergence: 12.3974
116/200 [================>.............] - ETA: 0s - loss: 1303049891.3103 - KL_divergence: 12.4136
122/200 [=================>............] - ETA: 0s - loss: 1302503091.4098 - KL_divergence: 12.4250
128/200 [==================>...........] - ETA: 0s - loss: 1303177116.0000 - KL_divergence: 12.4280
134/200 [===================>..........] - ETA: 0s - loss: 1304796524.8955 - KL_divergence: 12.4361
140/200 [====================>.........] - ETA: 0s - loss: 1303685691.4286 - KL_divergence: 12.4355
146/200 [====================>.........] - ETA: 0s - loss: 1304332121.4247 - KL_divergence: 12.4417
152/200 [=====================>........] - ETA: 0s - loss: 1303735626.9474 - KL_divergence: 12.4395
158/200 [======================>.......] - ETA: 0s - loss: 1304484491.3418 - KL_divergence: 12.4434
164/200 [=======================>......] - ETA: 0s - loss: 1303156016.3902 - KL_divergence: 12.4372
170/200 [========================>.....] - ETA: 0s - loss: 1302954539.6706 - KL_divergence: 12.4473
177/200 [=========================>....] - ETA: 0s - loss: 1303894156.2938 - KL_divergence: 12.4450
183/200 [==========================>...] - ETA: 0s - loss: 1304436172.2404 - KL_divergence: 12.4468
189/200 [===========================>..] - ETA: 0s - loss: 1305219474.2857 - KL_divergence: 12.4539
195/200 [============================>.] - ETA: 0s - loss: 1305316257.4769 - KL_divergence: 12.4522
200/200 [==============================] - 2s 10ms/step - loss: 1304704301.4400 - KL_divergence: 12.4609 - val_loss: 1342680441.6000 - val_KL_divergence: 12.3503
Epoch 83/100

  1/200 [..............................] - ETA: 1s - loss: 1309818752.0000 - KL_divergence: 13.2674
  7/200 [>.............................] - ETA: 1s - loss: 1310729984.0000 - KL_divergence: 12.6600
 13/200 [>.............................] - ETA: 1s - loss: 1329138313.8462 - KL_divergence: 12.6206
 19/200 [=>............................] - ETA: 1s - loss: 1330823161.2632 - KL_divergence: 12.4248
 25/200 [==>...........................] - ETA: 1s - loss: 1331869864.9600 - KL_divergence: 12.3399
 31/200 [===>..........................] - ETA: 1s - loss: 1326297476.1290 - KL_divergence: 12.2605
 37/200 [====>.........................] - ETA: 1s - loss: 1326516864.0000 - KL_divergence: 12.2122
 44/200 [=====>........................] - ETA: 1s - loss: 1328512994.9091 - KL_divergence: 12.2055
 51/200 [======>.......................] - ETA: 1s - loss: 1320822472.7843 - KL_divergence: 12.2412
 57/200 [=======>......................] - ETA: 1s - loss: 1321127576.7018 - KL_divergence: 12.2654
 63/200 [========>.....................] - ETA: 1s - loss: 1319858503.1111 - KL_divergence: 12.2873
 69/200 [=========>....................] - ETA: 1s - loss: 1316835882.6667 - KL_divergence: 12.2666
 75/200 [==========>...................] - ETA: 1s - loss: 1317091500.3733 - KL_divergence: 12.2559
 81/200 [===========>..................] - ETA: 1s - loss: 1319678034.1728 - KL_divergence: 12.2440
 87/200 [============>.................] - ETA: 0s - loss: 1317769132.1379 - KL_divergence: 12.2442
 93/200 [============>.................] - ETA: 0s - loss: 1317943107.4409 - KL_divergence: 12.2394
 99/200 [=============>................] - ETA: 0s - loss: 1319297740.2828 - KL_divergence: 12.2142
105/200 [==============>...............] - ETA: 0s - loss: 1321155838.7810 - KL_divergence: 12.2027
111/200 [===============>..............] - ETA: 0s - loss: 1320939065.6577 - KL_divergence: 12.2086
117/200 [================>.............] - ETA: 0s - loss: 1321237039.0427 - KL_divergence: 12.2187
123/200 [=================>............] - ETA: 0s - loss: 1322484612.1626 - KL_divergence: 12.2130
129/200 [==================>...........] - ETA: 0s - loss: 1320406903.0698 - KL_divergence: 12.1987
135/200 [===================>..........] - ETA: 0s - loss: 1320942627.0815 - KL_divergence: 12.2034
141/200 [====================>.........] - ETA: 0s - loss: 1320791526.5816 - KL_divergence: 12.1999
147/200 [=====================>........] - ETA: 0s - loss: 1319576710.0952 - KL_divergence: 12.2003
153/200 [=====================>........] - ETA: 0s - loss: 1317647999.1634 - KL_divergence: 12.2027
159/200 [======================>.......] - ETA: 0s - loss: 1318599565.6855 - KL_divergence: 12.2018
166/200 [=======================>......] - ETA: 0s - loss: 1319135322.2169 - KL_divergence: 12.2089
172/200 [========================>.....] - ETA: 0s - loss: 1319050533.2093 - KL_divergence: 12.2186
179/200 [=========================>....] - ETA: 0s - loss: 1319017663.6425 - KL_divergence: 12.2186
185/200 [==========================>...] - ETA: 0s - loss: 1319375842.9405 - KL_divergence: 12.2281
191/200 [===========================>..] - ETA: 0s - loss: 1319827599.4136 - KL_divergence: 12.2445
197/200 [============================>.] - ETA: 0s - loss: 1319293154.1117 - KL_divergence: 12.2455
200/200 [==============================] - 2s 10ms/step - loss: 1318680802.5600 - KL_divergence: 12.2431 - val_loss: 1344024295.6800 - val_KL_divergence: 12.7433
Epoch 84/100

  1/200 [..............................] - ETA: 1s - loss: 1335195392.0000 - KL_divergence: 12.3571
  7/200 [>.............................] - ETA: 1s - loss: 1304104484.5714 - KL_divergence: 12.1439
 13/200 [>.............................] - ETA: 1s - loss: 1315294779.0769 - KL_divergence: 12.2616
 20/200 [==>...........................] - ETA: 1s - loss: 1316548307.2000 - KL_divergence: 12.2647
 26/200 [==>...........................] - ETA: 1s - loss: 1317140844.3077 - KL_divergence: 12.3040
 32/200 [===>..........................] - ETA: 1s - loss: 1314408296.0000 - KL_divergence: 12.3767
 38/200 [====>.........................] - ETA: 1s - loss: 1317806349.4737 - KL_divergence: 12.3955
 44/200 [=====>........................] - ETA: 1s - loss: 1318743784.7273 - KL_divergence: 12.4312
 50/200 [======>.......................] - ETA: 1s - loss: 1311300490.2400 - KL_divergence: 12.4116
 56/200 [=======>......................] - ETA: 1s - loss: 1313440093.7143 - KL_divergence: 12.4656
 62/200 [========>.....................] - ETA: 1s - loss: 1315370995.6129 - KL_divergence: 12.4437
 68/200 [=========>....................] - ETA: 1s - loss: 1315286915.7647 - KL_divergence: 12.4402
 74/200 [==========>...................] - ETA: 1s - loss: 1315436544.0000 - KL_divergence: 12.4535
 80/200 [===========>..................] - ETA: 1s - loss: 1313014918.4000 - KL_divergence: 12.4428
 86/200 [===========>..................] - ETA: 1s - loss: 1316400096.7442 - KL_divergence: 12.4089
 92/200 [============>.................] - ETA: 0s - loss: 1312844374.2609 - KL_divergence: 12.4086
 98/200 [=============>................] - ETA: 0s - loss: 1316600336.9796 - KL_divergence: 12.4175
104/200 [==============>...............] - ETA: 0s - loss: 1317381632.0000 - KL_divergence: 12.4258
110/200 [===============>..............] - ETA: 0s - loss: 1315533420.2182 - KL_divergence: 12.4374
116/200 [================>.............] - ETA: 0s - loss: 1314648912.5517 - KL_divergence: 12.4500
122/200 [=================>............] - ETA: 0s - loss: 1311695538.3607 - KL_divergence: 12.4402
128/200 [==================>...........] - ETA: 0s - loss: 1310215927.0000 - KL_divergence: 12.4222
134/200 [===================>..........] - ETA: 0s - loss: 1309640262.6866 - KL_divergence: 12.4299
140/200 [====================>.........] - ETA: 0s - loss: 1307643103.0857 - KL_divergence: 12.4439
146/200 [====================>.........] - ETA: 0s - loss: 1307874447.7808 - KL_divergence: 12.4533
152/200 [=====================>........] - ETA: 0s - loss: 1308209729.6842 - KL_divergence: 12.4706
158/200 [======================>.......] - ETA: 0s - loss: 1308503519.5949 - KL_divergence: 12.4755
164/200 [=======================>......] - ETA: 0s - loss: 1307180141.2683 - KL_divergence: 12.4802
170/200 [========================>.....] - ETA: 0s - loss: 1306997997.9294 - KL_divergence: 12.4677
176/200 [=========================>....] - ETA: 0s - loss: 1307058944.0000 - KL_divergence: 12.4753
182/200 [==========================>...] - ETA: 0s - loss: 1307284342.8571 - KL_divergence: 12.4820
188/200 [===========================>..] - ETA: 0s - loss: 1307510440.1702 - KL_divergence: 12.4812
194/200 [============================>.] - ETA: 0s - loss: 1307326014.0206 - KL_divergence: 12.4892
200/200 [==============================] - 2s 10ms/step - loss: 1307436684.1600 - KL_divergence: 12.5147 - val_loss: 1331643891.2000 - val_KL_divergence: 12.4091
Epoch 85/100

  1/200 [..............................] - ETA: 1s - loss: 1273314560.0000 - KL_divergence: 11.1325
  7/200 [>.............................] - ETA: 1s - loss: 1272945060.5714 - KL_divergence: 12.4022
 13/200 [>.............................] - ETA: 1s - loss: 1276694144.0000 - KL_divergence: 12.7257
 19/200 [=>............................] - ETA: 1s - loss: 1295608104.4211 - KL_divergence: 12.6094
 25/200 [==>...........................] - ETA: 1s - loss: 1299194224.6400 - KL_divergence: 12.6361
 31/200 [===>..........................] - ETA: 1s - loss: 1294685588.6452 - KL_divergence: 12.5931
 37/200 [====>.........................] - ETA: 1s - loss: 1290498691.4595 - KL_divergence: 12.5777
 43/200 [=====>........................] - ETA: 1s - loss: 1292083920.3721 - KL_divergence: 12.6109
 49/200 [======>.......................] - ETA: 1s - loss: 1298986062.3673 - KL_divergence: 12.7038
 55/200 [=======>......................] - ETA: 1s - loss: 1296914469.2364 - KL_divergence: 12.6850
 61/200 [========>.....................] - ETA: 1s - loss: 1299849364.9836 - KL_divergence: 12.7514
 67/200 [=========>....................] - ETA: 1s - loss: 1299591704.8358 - KL_divergence: 12.7310
 73/200 [=========>....................] - ETA: 1s - loss: 1298604763.1781 - KL_divergence: 12.7339
 79/200 [==========>...................] - ETA: 1s - loss: 1299082823.2911 - KL_divergence: 12.7202
 85/200 [===========>..................] - ETA: 1s - loss: 1297135114.5412 - KL_divergence: 12.7006
 91/200 [============>.................] - ETA: 0s - loss: 1296358461.8901 - KL_divergence: 12.7130
 97/200 [=============>................] - ETA: 0s - loss: 1299218944.0000 - KL_divergence: 12.6956
103/200 [==============>...............] - ETA: 0s - loss: 1298088112.4660 - KL_divergence: 12.7282
109/200 [===============>..............] - ETA: 0s - loss: 1299032530.2018 - KL_divergence: 12.7059
115/200 [================>.............] - ETA: 0s - loss: 1298882617.8783 - KL_divergence: 12.7283
121/200 [=================>............] - ETA: 0s - loss: 1299873142.4793 - KL_divergence: 12.7300
128/200 [==================>...........] - ETA: 0s - loss: 1297178100.0000 - KL_divergence: 12.7098
134/200 [===================>..........] - ETA: 0s - loss: 1297084891.7015 - KL_divergence: 12.7329
140/200 [====================>.........] - ETA: 0s - loss: 1297486204.3429 - KL_divergence: 12.7431
146/200 [====================>.........] - ETA: 0s - loss: 1299515037.8082 - KL_divergence: 12.7469
152/200 [=====================>........] - ETA: 0s - loss: 1301538119.5789 - KL_divergence: 12.7471
158/200 [======================>.......] - ETA: 0s - loss: 1302820974.1772 - KL_divergence: 12.7458
164/200 [=======================>......] - ETA: 0s - loss: 1302602625.5610 - KL_divergence: 12.7474
170/200 [========================>.....] - ETA: 0s - loss: 1304100167.5294 - KL_divergence: 12.7478
176/200 [=========================>....] - ETA: 0s - loss: 1303209564.3636 - KL_divergence: 12.7432
182/200 [==========================>...] - ETA: 0s - loss: 1303001161.1429 - KL_divergence: 12.7406
188/200 [===========================>..] - ETA: 0s - loss: 1302243240.8511 - KL_divergence: 12.7300
194/200 [============================>.] - ETA: 0s - loss: 1302076906.8866 - KL_divergence: 12.7396
200/200 [==============================] - 2s 10ms/step - loss: 1302897539.8400 - KL_divergence: 12.7383 - val_loss: 1339542661.1200 - val_KL_divergence: 12.5476
Epoch 86/100

  1/200 [..............................] - ETA: 1s - loss: 1296699008.0000 - KL_divergence: 11.8405
  7/200 [>.............................] - ETA: 1s - loss: 1322598290.2857 - KL_divergence: 12.6871
 13/200 [>.............................] - ETA: 1s - loss: 1317038966.1538 - KL_divergence: 12.5117
 19/200 [=>............................] - ETA: 1s - loss: 1295688077.4737 - KL_divergence: 12.5013
 25/200 [==>...........................] - ETA: 1s - loss: 1303354777.6000 - KL_divergence: 12.4698
 31/200 [===>..........................] - ETA: 1s - loss: 1304554132.6452 - KL_divergence: 12.5638
 37/200 [====>.........................] - ETA: 1s - loss: 1302883999.1351 - KL_divergence: 12.5055
 43/200 [=====>........................] - ETA: 1s - loss: 1304585608.9302 - KL_divergence: 12.5778
 49/200 [======>.......................] - ETA: 1s - loss: 1308693140.8980 - KL_divergence: 12.6027
 55/200 [=======>......................] - ETA: 1s - loss: 1307193651.2000 - KL_divergence: 12.6437
 61/200 [========>.....................] - ETA: 1s - loss: 1307214103.0820 - KL_divergence: 12.6284
 67/200 [=========>....................] - ETA: 1s - loss: 1311447467.9403 - KL_divergence: 12.6576
 73/200 [=========>....................] - ETA: 1s - loss: 1307161170.4110 - KL_divergence: 12.6683
 79/200 [==========>...................] - ETA: 1s - loss: 1307681644.5570 - KL_divergence: 12.7078
 85/200 [===========>..................] - ETA: 1s - loss: 1307006891.6706 - KL_divergence: 12.7300
 91/200 [============>.................] - ETA: 0s - loss: 1308365949.1868 - KL_divergence: 12.7417
 97/200 [=============>................] - ETA: 0s - loss: 1307805863.5876 - KL_divergence: 12.7390
103/200 [==============>...............] - ETA: 0s - loss: 1305255872.6214 - KL_divergence: 12.7454
109/200 [===============>..............] - ETA: 0s - loss: 1305159580.1835 - KL_divergence: 12.7611
115/200 [================>.............] - ETA: 0s - loss: 1303752662.8174 - KL_divergence: 12.7458
121/200 [=================>............] - ETA: 0s - loss: 1305365941.9504 - KL_divergence: 12.7551
127/200 [==================>...........] - ETA: 0s - loss: 1307226288.3780 - KL_divergence: 12.7341
133/200 [==================>...........] - ETA: 0s - loss: 1308907696.1203 - KL_divergence: 12.7330
139/200 [===================>..........] - ETA: 0s - loss: 1308018749.6978 - KL_divergence: 12.7481
145/200 [====================>.........] - ETA: 0s - loss: 1309037879.6138 - KL_divergence: 12.7536
151/200 [=====================>........] - ETA: 0s - loss: 1311515979.4437 - KL_divergence: 12.7590
157/200 [======================>.......] - ETA: 0s - loss: 1311853345.4268 - KL_divergence: 12.7552
163/200 [=======================>......] - ETA: 0s - loss: 1310855225.3252 - KL_divergence: 12.7457
169/200 [========================>.....] - ETA: 0s - loss: 1311578745.1834 - KL_divergence: 12.7678
175/200 [=========================>....] - ETA: 0s - loss: 1310898820.3886 - KL_divergence: 12.7691
181/200 [==========================>...] - ETA: 0s - loss: 1308752997.8343 - KL_divergence: 12.7618
187/200 [===========================>..] - ETA: 0s - loss: 1310284953.3262 - KL_divergence: 12.7623
193/200 [===========================>..] - ETA: 0s - loss: 1311481915.6891 - KL_divergence: 12.7676
199/200 [============================>.] - ETA: 0s - loss: 1309605969.6884 - KL_divergence: 12.7537
200/200 [==============================] - 2s 10ms/step - loss: 1309188155.5200 - KL_divergence: 12.7544 - val_loss: 1322619316.4800 - val_KL_divergence: 12.4458
Epoch 87/100

  1/200 [..............................] - ETA: 1s - loss: 1355522816.0000 - KL_divergence: 12.3936
  7/200 [>.............................] - ETA: 1s - loss: 1326617618.2857 - KL_divergence: 12.5977
 14/200 [=>............................] - ETA: 1s - loss: 1332957494.8571 - KL_divergence: 12.5152
 20/200 [==>...........................] - ETA: 1s - loss: 1319453587.2000 - KL_divergence: 12.6164
 26/200 [==>...........................] - ETA: 1s - loss: 1311832507.0769 - KL_divergence: 12.6094
 32/200 [===>..........................] - ETA: 1s - loss: 1310002496.0000 - KL_divergence: 12.5640
 38/200 [====>.........................] - ETA: 1s - loss: 1304549918.3158 - KL_divergence: 12.5555
 44/200 [=====>........................] - ETA: 1s - loss: 1299932512.0000 - KL_divergence: 12.5629
 50/200 [======>.......................] - ETA: 1s - loss: 1302498746.8800 - KL_divergence: 12.5171
 56/200 [=======>......................] - ETA: 1s - loss: 1299540137.1429 - KL_divergence: 12.5753
 62/200 [========>.....................] - ETA: 1s - loss: 1301566073.8065 - KL_divergence: 12.5968
 68/200 [=========>....................] - ETA: 1s - loss: 1303753641.4118 - KL_divergence: 12.5951
 74/200 [==========>...................] - ETA: 1s - loss: 1305787033.9459 - KL_divergence: 12.6124
 81/200 [===========>..................] - ETA: 1s - loss: 1305383428.7407 - KL_divergence: 12.5985
 87/200 [============>.................] - ETA: 0s - loss: 1303739236.0460 - KL_divergence: 12.5679
 94/200 [=============>................] - ETA: 0s - loss: 1306166250.2128 - KL_divergence: 12.5924
101/200 [==============>...............] - ETA: 0s - loss: 1310625087.3663 - KL_divergence: 12.6110
108/200 [===============>..............] - ETA: 0s - loss: 1310789308.4444 - KL_divergence: 12.5977
114/200 [================>.............] - ETA: 0s - loss: 1309811900.6316 - KL_divergence: 12.5656
120/200 [=================>............] - ETA: 0s - loss: 1309664477.8667 - KL_divergence: 12.5971
126/200 [=================>............] - ETA: 0s - loss: 1309098333.4603 - KL_divergence: 12.5678
132/200 [==================>...........] - ETA: 0s - loss: 1309425069.5758 - KL_divergence: 12.5799
138/200 [===================>..........] - ETA: 0s - loss: 1310794441.2754 - KL_divergence: 12.5979
144/200 [====================>.........] - ETA: 0s - loss: 1309654929.7778 - KL_divergence: 12.5889
151/200 [=====================>........] - ETA: 0s - loss: 1307446588.1854 - KL_divergence: 12.5816
157/200 [======================>.......] - ETA: 0s - loss: 1307409841.7325 - KL_divergence: 12.5866
163/200 [=======================>......] - ETA: 0s - loss: 1305824382.4294 - KL_divergence: 12.5890
169/200 [========================>.....] - ETA: 0s - loss: 1305654733.2544 - KL_divergence: 12.5925
175/200 [=========================>....] - ETA: 0s - loss: 1305258923.8857 - KL_divergence: 12.6033
181/200 [==========================>...] - ETA: 0s - loss: 1304468902.1878 - KL_divergence: 12.6151
187/200 [===========================>..] - ETA: 0s - loss: 1305193118.1176 - KL_divergence: 12.6106
193/200 [===========================>..] - ETA: 0s - loss: 1304744266.2798 - KL_divergence: 12.5994
199/200 [============================>.] - ETA: 0s - loss: 1303652188.6231 - KL_divergence: 12.6050
200/200 [==============================] - 2s 10ms/step - loss: 1303509852.1600 - KL_divergence: 12.6028 - val_loss: 1334001536.0000 - val_KL_divergence: 12.3630
Epoch 88/100

  1/200 [..............................] - ETA: 1s - loss: 1270256640.0000 - KL_divergence: 12.6574
  8/200 [>.............................] - ETA: 1s - loss: 1347307408.0000 - KL_divergence: 12.6508
 15/200 [=>............................] - ETA: 1s - loss: 1347851153.0667 - KL_divergence: 12.7376
 22/200 [==>...........................] - ETA: 1s - loss: 1329633902.5455 - KL_divergence: 12.7845
 29/200 [===>..........................] - ETA: 1s - loss: 1324768154.4828 - KL_divergence: 12.6768
 36/200 [====>.........................] - ETA: 1s - loss: 1311370286.2222 - KL_divergence: 12.6946
 43/200 [=====>........................] - ETA: 1s - loss: 1313959810.9767 - KL_divergence: 12.7961
 49/200 [======>.......................] - ETA: 1s - loss: 1313329342.6939 - KL_divergence: 12.8240
 55/200 [=======>......................] - ETA: 1s - loss: 1310125763.4909 - KL_divergence: 12.8103
 61/200 [========>.....................] - ETA: 1s - loss: 1310935382.0328 - KL_divergence: 12.8070
 67/200 [=========>....................] - ETA: 1s - loss: 1311516184.8358 - KL_divergence: 12.8270
 73/200 [=========>....................] - ETA: 1s - loss: 1310353590.3562 - KL_divergence: 12.8017
 79/200 [==========>...................] - ETA: 1s - loss: 1310245541.2658 - KL_divergence: 12.7487
 85/200 [===========>..................] - ETA: 0s - loss: 1309472037.6471 - KL_divergence: 12.7468
 91/200 [============>.................] - ETA: 0s - loss: 1309821119.2967 - KL_divergence: 12.7609
 97/200 [=============>................] - ETA: 0s - loss: 1307264314.0619 - KL_divergence: 12.7674
103/200 [==============>...............] - ETA: 0s - loss: 1303216089.4757 - KL_divergence: 12.7606
109/200 [===============>..............] - ETA: 0s - loss: 1301496177.9083 - KL_divergence: 12.7576
116/200 [================>.............] - ETA: 0s - loss: 1301107070.8966 - KL_divergence: 12.7800
122/200 [=================>............] - ETA: 0s - loss: 1299965404.3279 - KL_divergence: 12.7692
128/200 [==================>...........] - ETA: 0s - loss: 1299588367.0000 - KL_divergence: 12.7845
134/200 [===================>..........] - ETA: 0s - loss: 1299759827.1045 - KL_divergence: 12.7922
141/200 [====================>.........] - ETA: 0s - loss: 1301313385.3050 - KL_divergence: 12.7942
147/200 [=====================>........] - ETA: 0s - loss: 1301242271.3469 - KL_divergence: 12.7948
153/200 [=====================>........] - ETA: 0s - loss: 1299623580.4444 - KL_divergence: 12.7789
159/200 [======================>.......] - ETA: 0s - loss: 1300013432.7547 - KL_divergence: 12.7700
166/200 [=======================>......] - ETA: 0s - loss: 1297495738.6024 - KL_divergence: 12.7844
172/200 [========================>.....] - ETA: 0s - loss: 1297339302.6977 - KL_divergence: 12.7861
178/200 [=========================>....] - ETA: 0s - loss: 1296485221.3933 - KL_divergence: 12.8035
184/200 [==========================>...] - ETA: 0s - loss: 1297612402.0870 - KL_divergence: 12.8029
190/200 [===========================>..] - ETA: 0s - loss: 1297801172.8842 - KL_divergence: 12.7991
196/200 [============================>.] - ETA: 0s - loss: 1296930686.0408 - KL_divergence: 12.7901
200/200 [==============================] - 2s 10ms/step - loss: 1296542449.2800 - KL_divergence: 12.7888 - val_loss: 1330907356.1600 - val_KL_divergence: 12.7313
Epoch 89/100

  1/200 [..............................] - ETA: 1s - loss: 1234017792.0000 - KL_divergence: 13.1713
  7/200 [>.............................] - ETA: 1s - loss: 1287491273.1429 - KL_divergence: 12.7549
 13/200 [>.............................] - ETA: 1s - loss: 1287776827.0769 - KL_divergence: 12.9705
 19/200 [=>............................] - ETA: 1s - loss: 1298942396.6316 - KL_divergence: 12.8682
 25/200 [==>...........................] - ETA: 1s - loss: 1290564003.8400 - KL_divergence: 12.7517
 31/200 [===>..........................] - ETA: 1s - loss: 1293817170.5806 - KL_divergence: 12.7714
 37/200 [====>.........................] - ETA: 1s - loss: 1290392185.0811 - KL_divergence: 12.6909
 43/200 [=====>........................] - ETA: 1s - loss: 1293459554.2326 - KL_divergence: 12.7345
 49/200 [======>.......................] - ETA: 1s - loss: 1294266459.4286 - KL_divergence: 12.8016
 55/200 [=======>......................] - ETA: 1s - loss: 1297193399.8545 - KL_divergence: 12.8250
 62/200 [========>.....................] - ETA: 1s - loss: 1300824462.4516 - KL_divergence: 12.8402
 68/200 [=========>....................] - ETA: 1s - loss: 1299966061.1765 - KL_divergence: 12.7606
 74/200 [==========>...................] - ETA: 1s - loss: 1304413846.4865 - KL_divergence: 12.7576
 81/200 [===========>..................] - ETA: 1s - loss: 1304790714.4691 - KL_divergence: 12.7395
 87/200 [============>.................] - ETA: 0s - loss: 1306456796.6897 - KL_divergence: 12.7306
 93/200 [============>.................] - ETA: 0s - loss: 1307669154.4086 - KL_divergence: 12.7364
100/200 [==============>...............] - ETA: 0s - loss: 1305980879.3600 - KL_divergence: 12.7180
106/200 [==============>...............] - ETA: 0s - loss: 1307806008.7547 - KL_divergence: 12.7176
112/200 [===============>..............] - ETA: 0s - loss: 1306389310.8571 - KL_divergence: 12.7280
119/200 [================>.............] - ETA: 0s - loss: 1303368797.5798 - KL_divergence: 12.7233
126/200 [=================>............] - ETA: 0s - loss: 1303833490.2857 - KL_divergence: 12.7047
132/200 [==================>...........] - ETA: 0s - loss: 1303377010.4242 - KL_divergence: 12.7009
138/200 [===================>..........] - ETA: 0s - loss: 1303380740.6377 - KL_divergence: 12.7113
144/200 [====================>.........] - ETA: 0s - loss: 1302836894.2222 - KL_divergence: 12.7085
150/200 [=====================>........] - ETA: 0s - loss: 1301044623.3600 - KL_divergence: 12.7134
156/200 [======================>.......] - ETA: 0s - loss: 1302706857.0256 - KL_divergence: 12.7188
162/200 [=======================>......] - ETA: 0s - loss: 1301759055.8025 - KL_divergence: 12.7189
168/200 [========================>.....] - ETA: 0s - loss: 1301408265.1429 - KL_divergence: 12.7212
174/200 [=========================>....] - ETA: 0s - loss: 1301852105.5632 - KL_divergence: 12.7292
180/200 [==========================>...] - ETA: 0s - loss: 1300946719.2889 - KL_divergence: 12.7115
186/200 [==========================>...] - ETA: 0s - loss: 1300736982.0215 - KL_divergence: 12.7136
192/200 [===========================>..] - ETA: 0s - loss: 1299872256.0000 - KL_divergence: 12.7167
198/200 [============================>.] - ETA: 0s - loss: 1299215967.0303 - KL_divergence: 12.7188
200/200 [==============================] - 2s 10ms/step - loss: 1299195479.6800 - KL_divergence: 12.7204 - val_loss: 1328189030.4000 - val_KL_divergence: 12.7831
Epoch 90/100

  1/200 [..............................] - ETA: 1s - loss: 1298929920.0000 - KL_divergence: 12.8918
  7/200 [>.............................] - ETA: 1s - loss: 1300705974.8571 - KL_divergence: 12.5531
 13/200 [>.............................] - ETA: 1s - loss: 1314907283.6923 - KL_divergence: 12.6032
 19/200 [=>............................] - ETA: 1s - loss: 1299490789.0526 - KL_divergence: 12.5022
 25/200 [==>...........................] - ETA: 1s - loss: 1307974824.9600 - KL_divergence: 12.6899
 31/200 [===>..........................] - ETA: 1s - loss: 1309092455.2258 - KL_divergence: 12.7112
 37/200 [====>.........................] - ETA: 1s - loss: 1314769248.8649 - KL_divergence: 12.6818
 44/200 [=====>........................] - ETA: 1s - loss: 1313253844.3636 - KL_divergence: 12.6562
 50/200 [======>.......................] - ETA: 1s - loss: 1315544980.4800 - KL_divergence: 12.6344
 56/200 [=======>......................] - ETA: 1s - loss: 1314554617.1429 - KL_divergence: 12.6126
 62/200 [========>.....................] - ETA: 1s - loss: 1314872057.8065 - KL_divergence: 12.5944
 68/200 [=========>....................] - ETA: 1s - loss: 1316341005.1765 - KL_divergence: 12.6164
 74/200 [==========>...................] - ETA: 1s - loss: 1318456273.2973 - KL_divergence: 12.6328
 80/200 [===========>..................] - ETA: 1s - loss: 1315741748.8000 - KL_divergence: 12.6434
 87/200 [============>.................] - ETA: 0s - loss: 1316280437.7011 - KL_divergence: 12.6553
 93/200 [============>.................] - ETA: 0s - loss: 1314215641.4624 - KL_divergence: 12.6752
 99/200 [=============>................] - ETA: 0s - loss: 1312528056.8889 - KL_divergence: 12.6670
105/200 [==============>...............] - ETA: 0s - loss: 1312930658.7429 - KL_divergence: 12.6967
111/200 [===============>..............] - ETA: 0s - loss: 1312099255.3514 - KL_divergence: 12.7048
118/200 [================>.............] - ETA: 0s - loss: 1312418080.5424 - KL_divergence: 12.7236
125/200 [=================>............] - ETA: 0s - loss: 1311484574.7200 - KL_divergence: 12.7455
131/200 [==================>...........] - ETA: 0s - loss: 1310388037.3740 - KL_divergence: 12.7213
137/200 [===================>..........] - ETA: 0s - loss: 1309643090.2190 - KL_divergence: 12.6974
143/200 [====================>.........] - ETA: 0s - loss: 1307972135.3846 - KL_divergence: 12.6995
149/200 [=====================>........] - ETA: 0s - loss: 1307865816.4832 - KL_divergence: 12.7174
155/200 [======================>.......] - ETA: 0s - loss: 1307334684.0774 - KL_divergence: 12.7040
161/200 [=======================>......] - ETA: 0s - loss: 1307345559.0559 - KL_divergence: 12.7070
167/200 [========================>.....] - ETA: 0s - loss: 1307328085.8443 - KL_divergence: 12.7201
173/200 [========================>.....] - ETA: 0s - loss: 1305709646.4277 - KL_divergence: 12.7047
179/200 [=========================>....] - ETA: 0s - loss: 1305674578.2346 - KL_divergence: 12.6812
185/200 [==========================>...] - ETA: 0s - loss: 1304357863.7838 - KL_divergence: 12.6715
191/200 [===========================>..] - ETA: 0s - loss: 1304871623.0366 - KL_divergence: 12.6840
197/200 [============================>.] - ETA: 0s - loss: 1303861006.9442 - KL_divergence: 12.6847
200/200 [==============================] - 2s 10ms/step - loss: 1304742598.4000 - KL_divergence: 12.6845 - val_loss: 1333221419.5200 - val_KL_divergence: 12.5878
Epoch 91/100

  1/200 [..............................] - ETA: 1s - loss: 1349211648.0000 - KL_divergence: 14.0291
  7/200 [>.............................] - ETA: 1s - loss: 1300309467.4286 - KL_divergence: 13.2130
 13/200 [>.............................] - ETA: 1s - loss: 1286899800.6154 - KL_divergence: 13.1380
 19/200 [=>............................] - ETA: 1s - loss: 1300191973.0526 - KL_divergence: 13.0025
 25/200 [==>...........................] - ETA: 1s - loss: 1291557043.2000 - KL_divergence: 12.9877
 31/200 [===>..........................] - ETA: 1s - loss: 1295822724.1290 - KL_divergence: 12.9671
 37/200 [====>.........................] - ETA: 1s - loss: 1297897752.2162 - KL_divergence: 12.9320
 43/200 [=====>........................] - ETA: 1s - loss: 1296997599.2558 - KL_divergence: 12.9134
 49/200 [======>.......................] - ETA: 1s - loss: 1294243351.5102 - KL_divergence: 12.8931
 55/200 [=======>......................] - ETA: 1s - loss: 1286862561.7455 - KL_divergence: 12.8917
 61/200 [========>.....................] - ETA: 1s - loss: 1290945122.6230 - KL_divergence: 12.9192
 67/200 [=========>....................] - ETA: 1s - loss: 1293689991.6418 - KL_divergence: 12.9185
 73/200 [=========>....................] - ETA: 1s - loss: 1292439569.5342 - KL_divergence: 12.8955
 78/200 [==========>...................] - ETA: 1s - loss: 1294392830.3590 - KL_divergence: 12.9073
 84/200 [===========>..................] - ETA: 1s - loss: 1294793712.7619 - KL_divergence: 12.9131
 90/200 [============>.................] - ETA: 1s - loss: 1290828801.4222 - KL_divergence: 12.9235
 96/200 [=============>................] - ETA: 0s - loss: 1292018200.0000 - KL_divergence: 12.9329
101/200 [==============>...............] - ETA: 0s - loss: 1294098364.8317 - KL_divergence: 12.9426
107/200 [===============>..............] - ETA: 0s - loss: 1297157230.0561 - KL_divergence: 12.9465
113/200 [===============>..............] - ETA: 0s - loss: 1296050033.2743 - KL_divergence: 12.9186
119/200 [================>.............] - ETA: 0s - loss: 1295078099.8992 - KL_divergence: 12.8810
125/200 [=================>............] - ETA: 0s - loss: 1295866293.2480 - KL_divergence: 12.8888
131/200 [==================>...........] - ETA: 0s - loss: 1297418393.4046 - KL_divergence: 12.9091
136/200 [===================>..........] - ETA: 0s - loss: 1298852479.0588 - KL_divergence: 12.9245
142/200 [====================>.........] - ETA: 0s - loss: 1299517938.4789 - KL_divergence: 12.9332
148/200 [=====================>........] - ETA: 0s - loss: 1300110933.6216 - KL_divergence: 12.9539
154/200 [======================>.......] - ETA: 0s - loss: 1297818792.7273 - KL_divergence: 12.9557
160/200 [=======================>......] - ETA: 0s - loss: 1298011641.6000 - KL_divergence: 12.9584
166/200 [=======================>......] - ETA: 0s - loss: 1298838399.2289 - KL_divergence: 12.9449
172/200 [========================>.....] - ETA: 0s - loss: 1298940175.6279 - KL_divergence: 12.9420
178/200 [=========================>....] - ETA: 0s - loss: 1298929728.7191 - KL_divergence: 12.9363
184/200 [==========================>...] - ETA: 0s - loss: 1299427541.5652 - KL_divergence: 12.9549
190/200 [===========================>..] - ETA: 0s - loss: 1300046960.5053 - KL_divergence: 12.9504
196/200 [============================>.] - ETA: 0s - loss: 1298031226.7755 - KL_divergence: 12.9426
200/200 [==============================] - 2s 10ms/step - loss: 1298297311.3600 - KL_divergence: 12.9288 - val_loss: 1333973340.1600 - val_KL_divergence: 13.1469
Epoch 92/100

  1/200 [..............................] - ETA: 1s - loss: 1366525184.0000 - KL_divergence: 12.3243
  7/200 [>.............................] - ETA: 1s - loss: 1299725677.7143 - KL_divergence: 12.7971
 13/200 [>.............................] - ETA: 1s - loss: 1291932435.6923 - KL_divergence: 12.8303
 19/200 [=>............................] - ETA: 1s - loss: 1304001226.1053 - KL_divergence: 12.7641
 25/200 [==>...........................] - ETA: 1s - loss: 1310967603.2000 - KL_divergence: 12.8057
 31/200 [===>..........................] - ETA: 1s - loss: 1301486075.8710 - KL_divergence: 12.8882
 37/200 [====>.........................] - ETA: 1s - loss: 1292087368.6486 - KL_divergence: 12.8602
 43/200 [=====>........................] - ETA: 1s - loss: 1291053609.6744 - KL_divergence: 12.8212
 50/200 [======>.......................] - ETA: 1s - loss: 1290957478.4000 - KL_divergence: 12.8430
 56/200 [=======>......................] - ETA: 1s - loss: 1287692829.7143 - KL_divergence: 12.7815
 62/200 [========>.....................] - ETA: 1s - loss: 1287852050.5806 - KL_divergence: 12.8452
 68/200 [=========>....................] - ETA: 1s - loss: 1288478351.0588 - KL_divergence: 12.8892
 74/200 [==========>...................] - ETA: 1s - loss: 1289587630.7027 - KL_divergence: 12.8706
 80/200 [===========>..................] - ETA: 1s - loss: 1287659625.6000 - KL_divergence: 12.8562
 86/200 [===========>..................] - ETA: 0s - loss: 1287998542.8837 - KL_divergence: 12.8446
 92/200 [============>.................] - ETA: 0s - loss: 1288792416.0000 - KL_divergence: 12.8205
 98/200 [=============>................] - ETA: 0s - loss: 1285826382.3673 - KL_divergence: 12.8003
104/200 [==============>...............] - ETA: 0s - loss: 1289226408.6154 - KL_divergence: 12.7997
110/200 [===============>..............] - ETA: 0s - loss: 1287511411.2000 - KL_divergence: 12.7866
116/200 [================>.............] - ETA: 0s - loss: 1289475721.9310 - KL_divergence: 12.7732
122/200 [=================>............] - ETA: 0s - loss: 1291725557.5082 - KL_divergence: 12.7895
128/200 [==================>...........] - ETA: 0s - loss: 1293904426.0000 - KL_divergence: 12.7919
134/200 [===================>..........] - ETA: 0s - loss: 1294499066.2687 - KL_divergence: 12.7949
140/200 [====================>.........] - ETA: 0s - loss: 1293336041.1429 - KL_divergence: 12.7959
146/200 [====================>.........] - ETA: 0s - loss: 1292681846.3562 - KL_divergence: 12.7920
152/200 [=====================>........] - ETA: 0s - loss: 1293590194.5263 - KL_divergence: 12.8264
158/200 [======================>.......] - ETA: 0s - loss: 1294826169.5190 - KL_divergence: 12.8206
164/200 [=======================>......] - ETA: 0s - loss: 1294901675.7073 - KL_divergence: 12.8355
171/200 [========================>.....] - ETA: 0s - loss: 1294308707.5556 - KL_divergence: 12.8408
177/200 [=========================>....] - ETA: 0s - loss: 1293142332.0226 - KL_divergence: 12.8409
183/200 [==========================>...] - ETA: 0s - loss: 1293112216.4809 - KL_divergence: 12.8343
188/200 [===========================>..] - ETA: 0s - loss: 1293120885.1064 - KL_divergence: 12.8369
194/200 [============================>.] - ETA: 0s - loss: 1294403134.6804 - KL_divergence: 12.8515
200/200 [==============================] - 2s 10ms/step - loss: 1293341112.9600 - KL_divergence: 12.8522 - val_loss: 1331078598.4000 - val_KL_divergence: 12.6223
Epoch 93/100

  1/200 [..............................] - ETA: 1s - loss: 1339220992.0000 - KL_divergence: 11.9547
  7/200 [>.............................] - ETA: 1s - loss: 1275846089.1429 - KL_divergence: 12.4626
 13/200 [>.............................] - ETA: 1s - loss: 1264386471.3846 - KL_divergence: 12.6277
 19/200 [=>............................] - ETA: 1s - loss: 1272060725.8947 - KL_divergence: 12.7893
 25/200 [==>...........................] - ETA: 1s - loss: 1267901209.6000 - KL_divergence: 12.7336
 31/200 [===>..........................] - ETA: 1s - loss: 1272102011.8710 - KL_divergence: 12.7010
 37/200 [====>.........................] - ETA: 1s - loss: 1289312079.5676 - KL_divergence: 12.7738
 43/200 [=====>........................] - ETA: 1s - loss: 1286571243.1628 - KL_divergence: 12.7743
 49/200 [======>.......................] - ETA: 1s - loss: 1290488865.9592 - KL_divergence: 12.7528
 55/200 [=======>......................] - ETA: 1s - loss: 1290329164.8000 - KL_divergence: 12.7809
 61/200 [========>.....................] - ETA: 1s - loss: 1290369200.2623 - KL_divergence: 12.8071
 67/200 [=========>....................] - ETA: 1s - loss: 1287695428.7761 - KL_divergence: 12.8539
 73/200 [=========>....................] - ETA: 1s - loss: 1288167497.6438 - KL_divergence: 12.8149
 79/200 [==========>...................] - ETA: 1s - loss: 1291004817.8228 - KL_divergence: 12.8535
 85/200 [===========>..................] - ETA: 1s - loss: 1289248100.8941 - KL_divergence: 12.8374
 91/200 [============>.................] - ETA: 0s - loss: 1286894743.9121 - KL_divergence: 12.8603
 97/200 [=============>................] - ETA: 0s - loss: 1288509395.1340 - KL_divergence: 12.8890
103/200 [==============>...............] - ETA: 0s - loss: 1290477664.9320 - KL_divergence: 12.9002
109/200 [===============>..............] - ETA: 0s - loss: 1290467325.6514 - KL_divergence: 12.8912
115/200 [================>.............] - ETA: 0s - loss: 1289582343.7913 - KL_divergence: 12.9067
122/200 [=================>............] - ETA: 0s - loss: 1292614594.0984 - KL_divergence: 12.9124
128/200 [==================>...........] - ETA: 0s - loss: 1292874700.0000 - KL_divergence: 12.9424
134/200 [===================>..........] - ETA: 0s - loss: 1295558121.0746 - KL_divergence: 12.9414
140/200 [====================>.........] - ETA: 0s - loss: 1295211262.1714 - KL_divergence: 12.9497
146/200 [====================>.........] - ETA: 0s - loss: 1295861913.4247 - KL_divergence: 12.9615
152/200 [=====================>........] - ETA: 0s - loss: 1296282064.8421 - KL_divergence: 12.9564
158/200 [======================>.......] - ETA: 0s - loss: 1296747720.9114 - KL_divergence: 12.9585
164/200 [=======================>......] - ETA: 0s - loss: 1295880646.2439 - KL_divergence: 12.9572
170/200 [========================>.....] - ETA: 0s - loss: 1295421345.8824 - KL_divergence: 12.9536
176/200 [=========================>....] - ETA: 0s - loss: 1296351261.8182 - KL_divergence: 12.9497
182/200 [==========================>...] - ETA: 0s - loss: 1296561441.7582 - KL_divergence: 12.9393
188/200 [===========================>..] - ETA: 0s - loss: 1296275392.0000 - KL_divergence: 12.9432
194/200 [============================>.] - ETA: 0s - loss: 1297231842.9691 - KL_divergence: 12.9574
200/200 [==============================] - 2s 10ms/step - loss: 1296727134.7200 - KL_divergence: 12.9747 - val_loss: 1324414732.8000 - val_KL_divergence: 12.8345
Epoch 94/100

  1/200 [..............................] - ETA: 1s - loss: 1293109632.0000 - KL_divergence: 12.5262
  7/200 [>.............................] - ETA: 1s - loss: 1324837632.0000 - KL_divergence: 12.8692
 13/200 [>.............................] - ETA: 1s - loss: 1308085336.6154 - KL_divergence: 12.9326
 19/200 [=>............................] - ETA: 1s - loss: 1296519403.7895 - KL_divergence: 12.8382
 25/200 [==>...........................] - ETA: 1s - loss: 1296746101.7600 - KL_divergence: 12.9409
 31/200 [===>..........................] - ETA: 1s - loss: 1294017969.5484 - KL_divergence: 12.8966
 37/200 [====>.........................] - ETA: 1s - loss: 1299284815.5676 - KL_divergence: 12.9466
 43/200 [=====>........................] - ETA: 1s - loss: 1296147521.4884 - KL_divergence: 12.9625
 49/200 [======>.......................] - ETA: 1s - loss: 1295313805.0612 - KL_divergence: 12.9002
 55/200 [=======>......................] - ETA: 1s - loss: 1292449666.3273 - KL_divergence: 12.8689
 61/200 [========>.....................] - ETA: 1s - loss: 1296839140.7213 - KL_divergence: 12.9189
 67/200 [=========>....................] - ETA: 1s - loss: 1301311285.4925 - KL_divergence: 12.9577
 73/200 [=========>....................] - ETA: 1s - loss: 1301550525.3699 - KL_divergence: 12.9792
 79/200 [==========>...................] - ETA: 1s - loss: 1302507380.6582 - KL_divergence: 12.9894
 85/200 [===========>..................] - ETA: 1s - loss: 1298314161.6941 - KL_divergence: 12.9833
 91/200 [============>.................] - ETA: 0s - loss: 1297630224.8791 - KL_divergence: 13.0093
 97/200 [=============>................] - ETA: 0s - loss: 1298114004.4536 - KL_divergence: 13.0256
103/200 [==============>...............] - ETA: 0s - loss: 1298004946.0194 - KL_divergence: 13.0198
109/200 [===============>..............] - ETA: 0s - loss: 1295330161.9083 - KL_divergence: 13.0062
115/200 [================>.............] - ETA: 0s - loss: 1294221732.7304 - KL_divergence: 12.9980
121/200 [=================>............] - ETA: 0s - loss: 1293624044.9587 - KL_divergence: 12.9897
128/200 [==================>...........] - ETA: 0s - loss: 1294337535.0000 - KL_divergence: 12.9714
134/200 [===================>..........] - ETA: 0s - loss: 1294048844.4179 - KL_divergence: 12.9673
140/200 [====================>.........] - ETA: 0s - loss: 1294346373.4857 - KL_divergence: 12.9637
146/200 [====================>.........] - ETA: 0s - loss: 1294524204.7123 - KL_divergence: 12.9775
152/200 [=====================>........] - ETA: 0s - loss: 1295357457.6842 - KL_divergence: 12.9891
158/200 [======================>.......] - ETA: 0s - loss: 1293231462.0759 - KL_divergence: 12.9786
164/200 [=======================>......] - ETA: 0s - loss: 1293626780.8780 - KL_divergence: 12.9771
170/200 [========================>.....] - ETA: 0s - loss: 1291419459.7647 - KL_divergence: 12.9646
176/200 [=========================>....] - ETA: 0s - loss: 1291794236.3636 - KL_divergence: 12.9713
182/200 [==========================>...] - ETA: 0s - loss: 1290668927.2967 - KL_divergence: 12.9711
188/200 [===========================>..] - ETA: 0s - loss: 1290461700.0851 - KL_divergence: 12.9660
194/200 [============================>.] - ETA: 0s - loss: 1288180701.0309 - KL_divergence: 12.9610
200/200 [==============================] - 2s 10ms/step - loss: 1287915342.7200 - KL_divergence: 12.9593 - val_loss: 1329385287.6800 - val_KL_divergence: 12.5340
Epoch 95/100

  1/200 [..............................] - ETA: 2s - loss: 1329076096.0000 - KL_divergence: 12.2288
  7/200 [>.............................] - ETA: 1s - loss: 1349658130.2857 - KL_divergence: 12.9735
 13/200 [>.............................] - ETA: 1s - loss: 1308879192.6154 - KL_divergence: 12.7605
 19/200 [=>............................] - ETA: 1s - loss: 1292562546.5263 - KL_divergence: 12.8042
 25/200 [==>...........................] - ETA: 1s - loss: 1293131960.3200 - KL_divergence: 12.8436
 31/200 [===>..........................] - ETA: 1s - loss: 1294709504.0000 - KL_divergence: 12.8181
 37/200 [====>.........................] - ETA: 1s - loss: 1297409418.3784 - KL_divergence: 12.8466
 43/200 [=====>........................] - ETA: 1s - loss: 1303915889.1163 - KL_divergence: 12.8233
 49/200 [======>.......................] - ETA: 1s - loss: 1304124327.1837 - KL_divergence: 12.8483
 55/200 [=======>......................] - ETA: 1s - loss: 1302106391.2727 - KL_divergence: 12.8283
 61/200 [========>.....................] - ETA: 1s - loss: 1299933068.5902 - KL_divergence: 12.8273
 67/200 [=========>....................] - ETA: 1s - loss: 1298070335.0448 - KL_divergence: 12.8214
 73/200 [=========>....................] - ETA: 1s - loss: 1297554498.6301 - KL_divergence: 12.8169
 79/200 [==========>...................] - ETA: 1s - loss: 1299797081.1139 - KL_divergence: 12.8213
 85/200 [===========>..................] - ETA: 1s - loss: 1300563437.9294 - KL_divergence: 12.8045
 91/200 [============>.................] - ETA: 0s - loss: 1300905906.6374 - KL_divergence: 12.8382
 97/200 [=============>................] - ETA: 0s - loss: 1302199978.2268 - KL_divergence: 12.8656
103/200 [==============>...............] - ETA: 0s - loss: 1300705096.0777 - KL_divergence: 12.8540
109/200 [===============>..............] - ETA: 0s - loss: 1303798206.2385 - KL_divergence: 12.8257
115/200 [================>.............] - ETA: 0s - loss: 1308467607.3739 - KL_divergence: 12.8455
121/200 [=================>............] - ETA: 0s - loss: 1308427193.1240 - KL_divergence: 12.8392
127/200 [==================>...........] - ETA: 0s - loss: 1308467587.0236 - KL_divergence: 12.8281
133/200 [==================>...........] - ETA: 0s - loss: 1308669839.3985 - KL_divergence: 12.8276
139/200 [===================>..........] - ETA: 0s - loss: 1308157085.4676 - KL_divergence: 12.8255
146/200 [====================>.........] - ETA: 0s - loss: 1306865504.4384 - KL_divergence: 12.8124
152/200 [=====================>........] - ETA: 0s - loss: 1306449086.3158 - KL_divergence: 12.7946
158/200 [======================>.......] - ETA: 0s - loss: 1304560243.8481 - KL_divergence: 12.7840
164/200 [=======================>......] - ETA: 0s - loss: 1303671373.2683 - KL_divergence: 12.7955
170/200 [========================>.....] - ETA: 0s - loss: 1302217782.9647 - KL_divergence: 12.7975
176/200 [=========================>....] - ETA: 0s - loss: 1302005334.5455 - KL_divergence: 12.7895
182/200 [==========================>...] - ETA: 0s - loss: 1302497604.9231 - KL_divergence: 12.7840
188/200 [===========================>..] - ETA: 0s - loss: 1301660640.0000 - KL_divergence: 12.7744
194/200 [============================>.] - ETA: 0s - loss: 1300762914.3093 - KL_divergence: 12.7749
200/200 [==============================] - 2s 10ms/step - loss: 1301414986.8800 - KL_divergence: 12.7755 - val_loss: 1330100175.3600 - val_KL_divergence: 12.8067
Epoch 96/100

  1/200 [..............................] - ETA: 1s - loss: 1282525696.0000 - KL_divergence: 13.7974
  8/200 [>.............................] - ETA: 1s - loss: 1328635920.0000 - KL_divergence: 12.8023
 15/200 [=>............................] - ETA: 1s - loss: 1322594312.5333 - KL_divergence: 12.9018
 21/200 [==>...........................] - ETA: 1s - loss: 1323758659.0476 - KL_divergence: 12.7745
 27/200 [===>..........................] - ETA: 1s - loss: 1324016417.1852 - KL_divergence: 12.8444
 33/200 [===>..........................] - ETA: 1s - loss: 1310776513.9394 - KL_divergence: 12.8109
 39/200 [====>.........................] - ETA: 1s - loss: 1303041404.7179 - KL_divergence: 12.7528
 45/200 [=====>........................] - ETA: 1s - loss: 1305854799.6444 - KL_divergence: 12.8499
 51/200 [======>.......................] - ETA: 1s - loss: 1309186409.4118 - KL_divergence: 12.8347
 57/200 [=======>......................] - ETA: 1s - loss: 1309611349.3333 - KL_divergence: 12.8116
 63/200 [========>.....................] - ETA: 1s - loss: 1313103516.4444 - KL_divergence: 12.8130
 69/200 [=========>....................] - ETA: 1s - loss: 1308576001.8551 - KL_divergence: 12.8317
 75/200 [==========>...................] - ETA: 1s - loss: 1308307247.7867 - KL_divergence: 12.8002
 81/200 [===========>..................] - ETA: 1s - loss: 1303212757.3333 - KL_divergence: 12.7873
 87/200 [============>.................] - ETA: 1s - loss: 1302939396.4138 - KL_divergence: 12.7831
 93/200 [============>.................] - ETA: 0s - loss: 1298210986.6667 - KL_divergence: 12.7773
 99/200 [=============>................] - ETA: 0s - loss: 1298250908.4444 - KL_divergence: 12.7515
105/200 [==============>...............] - ETA: 0s - loss: 1297647683.0476 - KL_divergence: 12.7195
111/200 [===============>..............] - ETA: 0s - loss: 1299558002.1622 - KL_divergence: 12.6927
117/200 [================>.............] - ETA: 0s - loss: 1299112325.4701 - KL_divergence: 12.6863
124/200 [=================>............] - ETA: 0s - loss: 1302440661.6774 - KL_divergence: 12.6789
130/200 [==================>...........] - ETA: 0s - loss: 1301797326.7692 - KL_divergence: 12.6745
136/200 [===================>..........] - ETA: 0s - loss: 1301381823.0588 - KL_divergence: 12.6725
142/200 [====================>.........] - ETA: 0s - loss: 1298531016.1127 - KL_divergence: 12.6546
148/200 [=====================>........] - ETA: 0s - loss: 1298838111.1351 - KL_divergence: 12.6564
154/200 [======================>.......] - ETA: 0s - loss: 1297033737.1429 - KL_divergence: 12.6698
161/200 [=======================>......] - ETA: 0s - loss: 1296356968.9441 - KL_divergence: 12.6785
167/200 [========================>.....] - ETA: 0s - loss: 1296836324.4072 - KL_divergence: 12.6898
173/200 [========================>.....] - ETA: 0s - loss: 1296409734.6590 - KL_divergence: 12.6912
179/200 [=========================>....] - ETA: 0s - loss: 1295933105.3408 - KL_divergence: 12.7052
185/200 [==========================>...] - ETA: 0s - loss: 1296611681.5568 - KL_divergence: 12.7241
191/200 [===========================>..] - ETA: 0s - loss: 1296450713.4660 - KL_divergence: 12.7347
197/200 [============================>.] - ETA: 0s - loss: 1295877197.3198 - KL_divergence: 12.7391
200/200 [==============================] - 2s 10ms/step - loss: 1295547850.2400 - KL_divergence: 12.7393 - val_loss: 1329532510.7200 - val_KL_divergence: 12.6013
Epoch 97/100

  1/200 [..............................] - ETA: 1s - loss: 1329709568.0000 - KL_divergence: 11.8364
  7/200 [>.............................] - ETA: 1s - loss: 1301440969.1429 - KL_divergence: 12.4762
 13/200 [>.............................] - ETA: 1s - loss: 1310474958.7692 - KL_divergence: 12.7839
 20/200 [==>...........................] - ETA: 1s - loss: 1299735110.4000 - KL_divergence: 12.8804
 26/200 [==>...........................] - ETA: 1s - loss: 1297614153.8462 - KL_divergence: 12.7790
 33/200 [===>..........................] - ETA: 1s - loss: 1296228964.8485 - KL_divergence: 12.8431
 40/200 [=====>........................] - ETA: 1s - loss: 1289001804.8000 - KL_divergence: 12.8660
 47/200 [======>.......................] - ETA: 1s - loss: 1289040689.0213 - KL_divergence: 12.8865
 53/200 [======>.......................] - ETA: 1s - loss: 1284375721.0566 - KL_divergence: 12.8648
 59/200 [=======>......................] - ETA: 1s - loss: 1285137245.2881 - KL_divergence: 12.8295
 65/200 [========>.....................] - ETA: 1s - loss: 1285542878.5231 - KL_divergence: 12.8045
 71/200 [=========>....................] - ETA: 1s - loss: 1282653818.5915 - KL_divergence: 12.7914
 77/200 [==========>...................] - ETA: 1s - loss: 1281282825.9740 - KL_divergence: 12.7975
 83/200 [===========>..................] - ETA: 1s - loss: 1278630813.3012 - KL_divergence: 12.7972
 89/200 [============>.................] - ETA: 0s - loss: 1277065338.2472 - KL_divergence: 12.8073
 95/200 [=============>................] - ETA: 0s - loss: 1277265358.1474 - KL_divergence: 12.7951
101/200 [==============>...............] - ETA: 0s - loss: 1274384364.9901 - KL_divergence: 12.8234
107/200 [===============>..............] - ETA: 0s - loss: 1274071678.8037 - KL_divergence: 12.8092
113/200 [===============>..............] - ETA: 0s - loss: 1274382493.4513 - KL_divergence: 12.8488
119/200 [================>.............] - ETA: 0s - loss: 1276827252.1681 - KL_divergence: 12.8628
125/200 [=================>............] - ETA: 0s - loss: 1277431643.1360 - KL_divergence: 12.8752
131/200 [==================>...........] - ETA: 0s - loss: 1278541806.4122 - KL_divergence: 12.8862
138/200 [===================>..........] - ETA: 0s - loss: 1278670885.1014 - KL_divergence: 12.8995
145/200 [====================>.........] - ETA: 0s - loss: 1279614185.0483 - KL_divergence: 12.9166
152/200 [=====================>........] - ETA: 0s - loss: 1278464661.0526 - KL_divergence: 12.9418
158/200 [======================>.......] - ETA: 0s - loss: 1280585548.1519 - KL_divergence: 12.9641
164/200 [=======================>......] - ETA: 0s - loss: 1280256665.7561 - KL_divergence: 12.9695
170/200 [========================>.....] - ETA: 0s - loss: 1280394165.4588 - KL_divergence: 12.9773
176/200 [=========================>....] - ETA: 0s - loss: 1280609526.5455 - KL_divergence: 12.9876
182/200 [==========================>...] - ETA: 0s - loss: 1281056196.2198 - KL_divergence: 12.9969
188/200 [===========================>..] - ETA: 0s - loss: 1282091517.2766 - KL_divergence: 13.0033
194/200 [============================>.] - ETA: 0s - loss: 1282588272.1649 - KL_divergence: 13.0179
200/200 [==============================] - 2s 10ms/step - loss: 1282145840.6400 - KL_divergence: 13.0244 - val_loss: 1320670583.0400 - val_KL_divergence: 13.0443
Epoch 98/100

  1/200 [..............................] - ETA: 1s - loss: 1252054400.0000 - KL_divergence: 13.5258
  7/200 [>.............................] - ETA: 1s - loss: 1257387830.8571 - KL_divergence: 13.1172
 13/200 [>.............................] - ETA: 1s - loss: 1270235273.8462 - KL_divergence: 13.1755
 19/200 [=>............................] - ETA: 1s - loss: 1294594351.1579 - KL_divergence: 13.3413
 25/200 [==>...........................] - ETA: 1s - loss: 1291023662.0800 - KL_divergence: 13.2747
 31/200 [===>..........................] - ETA: 1s - loss: 1286676570.8387 - KL_divergence: 13.2279
 37/200 [====>.........................] - ETA: 1s - loss: 1285113689.9459 - KL_divergence: 13.1906
 43/200 [=====>........................] - ETA: 1s - loss: 1285004481.4884 - KL_divergence: 13.1371
 50/200 [======>.......................] - ETA: 1s - loss: 1284857689.6000 - KL_divergence: 13.0674
 57/200 [=======>......................] - ETA: 1s - loss: 1288985954.8070 - KL_divergence: 13.0358
 63/200 [========>.....................] - ETA: 1s - loss: 1292310152.1270 - KL_divergence: 13.0437
 69/200 [=========>....................] - ETA: 1s - loss: 1293107871.5362 - KL_divergence: 13.0771
 75/200 [==========>...................] - ETA: 1s - loss: 1292143286.6133 - KL_divergence: 13.0774
 81/200 [===========>..................] - ETA: 1s - loss: 1292100525.8272 - KL_divergence: 13.0306
 88/200 [============>.................] - ETA: 0s - loss: 1292263800.7273 - KL_divergence: 13.0590
 95/200 [=============>................] - ETA: 0s - loss: 1292238404.7158 - KL_divergence: 13.0466
101/200 [==============>...............] - ETA: 0s - loss: 1290665133.6238 - KL_divergence: 13.0669
108/200 [===============>..............] - ETA: 0s - loss: 1290052804.7407 - KL_divergence: 13.0736
115/200 [================>.............] - ETA: 0s - loss: 1291571983.5826 - KL_divergence: 13.0717
122/200 [=================>............] - ETA: 0s - loss: 1294095659.0164 - KL_divergence: 13.0885
129/200 [==================>...........] - ETA: 0s - loss: 1294043218.3566 - KL_divergence: 13.0898
136/200 [===================>..........] - ETA: 0s - loss: 1294470396.2353 - KL_divergence: 13.0886
142/200 [====================>.........] - ETA: 0s - loss: 1293081960.5634 - KL_divergence: 13.0753
148/200 [=====================>........] - ETA: 0s - loss: 1295282020.3243 - KL_divergence: 13.0804
154/200 [======================>.......] - ETA: 0s - loss: 1293749927.8961 - KL_divergence: 13.0927
160/200 [=======================>......] - ETA: 0s - loss: 1292559641.6000 - KL_divergence: 13.1093
166/200 [=======================>......] - ETA: 0s - loss: 1291281175.9036 - KL_divergence: 13.1124
172/200 [========================>.....] - ETA: 0s - loss: 1292683742.5116 - KL_divergence: 13.1231
178/200 [=========================>....] - ETA: 0s - loss: 1293567932.4045 - KL_divergence: 13.1154
184/200 [==========================>...] - ETA: 0s - loss: 1293515736.3478 - KL_divergence: 13.0966
190/200 [===========================>..] - ETA: 0s - loss: 1293866737.8526 - KL_divergence: 13.0953
196/200 [============================>.] - ETA: 0s - loss: 1293625528.8163 - KL_divergence: 13.0847
200/200 [==============================] - 2s 10ms/step - loss: 1294285546.8800 - KL_divergence: 13.0816 - val_loss: 1326674963.2000 - val_KL_divergence: 12.9444
Epoch 99/100

  1/200 [..............................] - ETA: 1s - loss: 1449461376.0000 - KL_divergence: 13.2498
  7/200 [>.............................] - ETA: 1s - loss: 1311916672.0000 - KL_divergence: 12.6951
 13/200 [>.............................] - ETA: 1s - loss: 1286609122.4615 - KL_divergence: 12.7145
 19/200 [=>............................] - ETA: 1s - loss: 1287545485.4737 - KL_divergence: 12.8012
 25/200 [==>...........................] - ETA: 1s - loss: 1278987985.9200 - KL_divergence: 12.7673
 31/200 [===>..........................] - ETA: 1s - loss: 1282838841.8065 - KL_divergence: 12.8533
 37/200 [====>.........................] - ETA: 1s - loss: 1287508646.0541 - KL_divergence: 12.8985
 43/200 [=====>........................] - ETA: 1s - loss: 1282620859.5349 - KL_divergence: 12.8558
 49/200 [======>.......................] - ETA: 1s - loss: 1281965228.4082 - KL_divergence: 12.8564
 55/200 [=======>......................] - ETA: 1s - loss: 1281156910.5455 - KL_divergence: 12.8670
 61/200 [========>.....................] - ETA: 1s - loss: 1283425076.4590 - KL_divergence: 12.9008
 67/200 [=========>....................] - ETA: 1s - loss: 1282282725.2537 - KL_divergence: 12.9300
 73/200 [=========>....................] - ETA: 1s - loss: 1283237141.0411 - KL_divergence: 12.9557
 79/200 [==========>...................] - ETA: 1s - loss: 1282591055.3924 - KL_divergence: 12.9581
 85/200 [===========>..................] - ETA: 1s - loss: 1283167649.1294 - KL_divergence: 12.9656
 91/200 [============>.................] - ETA: 0s - loss: 1284037236.7473 - KL_divergence: 12.9238
 97/200 [=============>................] - ETA: 0s - loss: 1284604379.0515 - KL_divergence: 12.9337
103/200 [==============>...............] - ETA: 0s - loss: 1286061187.7282 - KL_divergence: 12.9530
109/200 [===============>..............] - ETA: 0s - loss: 1287057733.2844 - KL_divergence: 12.9446
115/200 [================>.............] - ETA: 0s - loss: 1289390314.8522 - KL_divergence: 12.9722
121/200 [=================>............] - ETA: 0s - loss: 1289070497.8512 - KL_divergence: 12.9709
127/200 [==================>...........] - ETA: 0s - loss: 1292548060.7244 - KL_divergence: 12.9927
133/200 [==================>...........] - ETA: 0s - loss: 1290351541.8947 - KL_divergence: 12.9954
139/200 [===================>..........] - ETA: 0s - loss: 1290682404.8345 - KL_divergence: 13.0064
145/200 [====================>.........] - ETA: 0s - loss: 1290080909.2414 - KL_divergence: 13.0042
151/200 [=====================>........] - ETA: 0s - loss: 1289528315.7616 - KL_divergence: 13.0080
157/200 [======================>.......] - ETA: 0s - loss: 1290124755.9745 - KL_divergence: 13.0276
163/200 [=======================>......] - ETA: 0s - loss: 1290442642.0613 - KL_divergence: 13.0273
169/200 [========================>.....] - ETA: 0s - loss: 1289713109.5858 - KL_divergence: 13.0196
175/200 [=========================>....] - ETA: 0s - loss: 1290494706.1029 - KL_divergence: 13.0078
181/200 [==========================>...] - ETA: 0s - loss: 1289592496.7956 - KL_divergence: 13.0041
187/200 [===========================>..] - ETA: 0s - loss: 1289812967.3583 - KL_divergence: 13.0051
193/200 [===========================>..] - ETA: 0s - loss: 1291237328.9119 - KL_divergence: 13.0031
199/200 [============================>.] - ETA: 0s - loss: 1291545069.3467 - KL_divergence: 13.0075
200/200 [==============================] - 2s 10ms/step - loss: 1291480191.3600 - KL_divergence: 13.0054 - val_loss: 1320779425.2800 - val_KL_divergence: 12.9904
Epoch 100/100

  1/200 [..............................] - ETA: 1s - loss: 1325367296.0000 - KL_divergence: 13.0150
  8/200 [>.............................] - ETA: 1s - loss: 1255866896.0000 - KL_divergence: 12.8554
 15/200 [=>............................] - ETA: 1s - loss: 1266778487.4667 - KL_divergence: 12.8450
 21/200 [==>...........................] - ETA: 1s - loss: 1267877680.7619 - KL_divergence: 12.8844
 27/200 [===>..........................] - ETA: 1s - loss: 1270812648.2963 - KL_divergence: 12.7919
 33/200 [===>..........................] - ETA: 1s - loss: 1277535053.5758 - KL_divergence: 12.8871
 39/200 [====>.........................] - ETA: 1s - loss: 1275641439.1795 - KL_divergence: 12.9288
 45/200 [=====>........................] - ETA: 1s - loss: 1277401984.0000 - KL_divergence: 12.9219
 52/200 [======>.......................] - ETA: 1s - loss: 1277334040.6154 - KL_divergence: 12.9112
 58/200 [=======>......................] - ETA: 1s - loss: 1282344776.8276 - KL_divergence: 12.9180
 64/200 [========>.....................] - ETA: 1s - loss: 1281437324.0000 - KL_divergence: 12.9078
 70/200 [=========>....................] - ETA: 1s - loss: 1285712106.0571 - KL_divergence: 12.9477
 76/200 [==========>...................] - ETA: 1s - loss: 1282706996.2105 - KL_divergence: 12.9447
 83/200 [===========>..................] - ETA: 1s - loss: 1285222531.0843 - KL_divergence: 12.9502
 89/200 [============>.................] - ETA: 0s - loss: 1285837550.7416 - KL_divergence: 12.9694
 95/200 [=============>................] - ETA: 0s - loss: 1287225986.6947 - KL_divergence: 12.9831
101/200 [==============>...............] - ETA: 0s - loss: 1287564260.1188 - KL_divergence: 12.9814
107/200 [===============>..............] - ETA: 0s - loss: 1287911653.6822 - KL_divergence: 12.9918
113/200 [===============>..............] - ETA: 0s - loss: 1285697967.5752 - KL_divergence: 12.9862
119/200 [================>.............] - ETA: 0s - loss: 1284763381.2437 - KL_divergence: 12.9726
125/200 [=================>............] - ETA: 0s - loss: 1283615476.7360 - KL_divergence: 12.9980
131/200 [==================>...........] - ETA: 0s - loss: 1282825564.8244 - KL_divergence: 12.9908
137/200 [===================>..........] - ETA: 0s - loss: 1282196960.2336 - KL_divergence: 12.9757
143/200 [====================>.........] - ETA: 0s - loss: 1281665927.1608 - KL_divergence: 12.9963
149/200 [=====================>........] - ETA: 0s - loss: 1278478002.6846 - KL_divergence: 13.0014
155/200 [======================>.......] - ETA: 0s - loss: 1279064208.5161 - KL_divergence: 13.0189
161/200 [=======================>......] - ETA: 0s - loss: 1278744107.7267 - KL_divergence: 13.0301
167/200 [========================>.....] - ETA: 0s - loss: 1279201964.4551 - KL_divergence: 13.0291
173/200 [========================>.....] - ETA: 0s - loss: 1278400971.4682 - KL_divergence: 13.0293
179/200 [=========================>....] - ETA: 0s - loss: 1278044341.6313 - KL_divergence: 13.0408
186/200 [==========================>...] - ETA: 0s - loss: 1278326978.0645 - KL_divergence: 13.0465
192/200 [===========================>..] - ETA: 0s - loss: 1278271336.0000 - KL_divergence: 13.0496
198/200 [============================>.] - ETA: 0s - loss: 1277263070.3838 - KL_divergence: 13.0506
200/200 [==============================] - 2s 10ms/step - loss: 1277396227.8400 - KL_divergence: 13.0594 - val_loss: 1318081451.5200 - val_KL_divergence: 12.9733
Saving the trained inference, generator and latent models...	
 1/50 [..............................] - ETA: 3s
14/50 [=======>......................] - ETA: 0s
23/50 [============>.................] - ETA: 0s
32/50 [==================>...........] - ETA: 0s
42/50 [========================>.....] - ETA: 0s
50/50 [==============================] - 0s 7ms/step
